<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Golang面经 | 菠萝萝のBLOG</title><meta name="keywords" content="面经"><meta name="author" content="菠萝"><meta name="copyright" content="菠萝"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#18171d"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Golang面经"><meta name="application-name" content="Golang面经"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#18171d"><meta property="og:type" content="article"><meta property="og:title" content="Golang面经"><meta property="og:url" content="https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/index.html"><meta property="og:site_name" content="菠萝萝のBLOG"><meta property="og:description" content="数组和切片 1.数组和切片有什么不同 slice 的底层数据是数组，slice 是对数组的封装，它描述一个数组的片段 数组是定长的，长度定义好之后，不能再更改。 数组就是一片连续的内存， slice 实际上是一个结构体，包含三个字段：长度、容量、底层数组。  &amp;#x2F;&amp;#x2F; runtime&amp;#x2F;slice.go"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=51754bf9-ed78-4d2b-fbe8-4e9699cf5ca3"><meta property="article:author" content="菠萝"><meta property="article:tag" content="博客, 菠萝, 菠萝的博客, 菠萝的BLOG"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=51754bf9-ed78-4d2b-fbe8-4e9699cf5ca3"><meta name="description" content="数组和切片 1.数组和切片有什么不同 slice 的底层数据是数组，slice 是对数组的封装，它描述一个数组的片段 数组是定长的，长度定义好之后，不能再更改。 数组就是一片连续的内存， slice 实际上是一个结构体，包含三个字段：长度、容量、底层数组。  &amp;#x2F;&amp;#x2F; runtime&amp;#x2F;slice.go"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/菠萝.png"><link rel="canonical" href="https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: undefined,
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: 菠萝","link":"链接: ","source":"来源: 菠萝萝のBLOG","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '菠萝萝のBLOG',
  title: 'Golang面经',
  postAI: '',
  pageFillDescription: '数组和切片, 1.数组和切片有什么不同, 2.切片的容量是怎么增长的, 3.切片作为函数参数, 4.指针在go中的作用？, 谈谈go中比较相等, 哈希表, 1.map的实现原理, 1.1 map的内存模型, 1.2 创建map, 1.3 哈希函数, 1.4 key 定位过程, 2.扩容过程, 3.key为什么是无序的, 4.float类型可以作为map的key吗？, 6.map是线程安全的吗？, 接口, 1.值接收者和指针接收者的区别, 两者分别在何时使用, 接口的实现 iface 和 eface 以及 itab, 谈一谈GO 的GPM模型, 聊一聊协程和线程的区别, 垃圾回收器, 聊一聊你对go的context的理解, 聊一聊反射, 聊一聊go中make和new, 聊一聊TCMalloc, go语言里面的空结构体用来做什么, redis, redis 如何实现好友功能, redis的持久化, redis 缓存, 什么是缓存雪崩击穿穿透, 数据库和缓存如何保证一致性, 如何保证 2个操作都能执行成功？, redis的线程模型, Redis 采用单线程为什么还那么快？, Redis 6.0之后为什么引入了多线程？, redis的持久化是如何实现的？, redis的集群模式模式, 主从的实现：, 哨兵模式, 切片模式, 集群脑裂导致数据丢失怎么办？, Redis过期删除与内存淘汰, Redis数据结构, 五种常见的Redis数据库是怎么实现的？, redis 的键值对数据库是怎么实现的, SDS  string的实现, 链表, 压缩链表, 哈希表, redis的rehash, 跳表, quicklist, listpack, Redis常见数据类型和应用场景, String, List, Hash, Set, ZSet, BitMap, HyperLogLog, GEO, Stream, Redis的过期策略与内存淘汰策略有什么区别, Redis的缓存策略, Redis实战, Redis如何实现延迟队列, Redis管道有什么作用？, 如何使用Redis实现分布式锁？, 计算机网络, 计算机网络的各层协议及作用？, TCP和UDP的区别, 什么事SYN洪泛攻击？如何防范？, TCP协议如何保证可靠性？, HTTP常见的状态码有哪些？, 状态码301和302的区别是什么？, GET请求和POST请求的区别？, 解释一下HTTP长连接和短链接？, HTTP请求报文和响应报文的格式?, 介绍一下HTTP缓存, HTTPx2F1.1如何优化, HTTPS RSA握手解析过程？, HTTPx2F1.0 HTTPx2F1.1 HTTPx2F2 HTTPx2F3, HTTPx2F1.1, HTTPx2F2, HTTPx2F3, , HTTP和HTTPS的区别, HTTP1.0和HTTP1.1的区别？, HTTP1.1和HTTP2.0的区别？, HTTPS解决了HTTP的哪些问题？, 谈一谈网址到页面显示期间发生了什么？, GET 与 POST 的区别, 谈谈HTTP和HTTPS有区别, 什么是Cookie和Session？, Cookie和Session是何如配合的呢？, Cookie和Session的区别？, 如何考虑吧分布式Session问题？, 什么是DDos攻击？, 什么是XSS攻击？, SQL注入是什么？如何避免？, 为什么又了HTTP协议还有RPC协议, 什么是TCP和TCP连接, 为什么三次握手四次挥手, 聊一聊TCP的重传机制, 你知道滑动窗口吗？, TCP如何做的 流量控制和拥塞控制？, IP, IP协议相关技术, DNS 域名解析, DHCP 协议, NAT  网络地址转换NAT, ICMP协议 互联网控制报文协议, 聊一聊你对跨域的看法。CORS, 简单请求, 非简单请求, 预检请求, 预检请求的回应, 浏览器的正确请求和回应, MySQL, 执行 select 语句发生了什么, 第一步：连接器, 第二步：查询缓存, 第三步：解析SQL–解析器, 第四步：执行SQL语句, MySQL的一行记录时如何存储的？, MySQL的数据存放在哪个文件？, , 表空间文件的结构是怎么样的呢？, 1、行（row）, 2、页（page）, 3、区（extent）, 4、段（segment）, InnoDB 行格式有哪些？, Compact行格式长什么样呢？, 行溢出后MySQL是怎么处理的？, 总结, 索引, 什么是索引？, 索引的分类, B+树？, InnoDB是如何存储数据的？, B+树是如何进行查询的呢？, MySQL为什么采用B+树作为索引？, 事务, 事务隔离级别是如何实现的？, 事务有哪些特性呢？, 事务隔离级别有哪些？, 总结, 锁, 全局锁, 表级锁, 行锁, MySQL是如何枷锁的, MySQL死锁了该怎么办？, 日志, undo log, redo log, binlog, buffer pool, 主从复制的实现, Update过程种三个日志, 为什么需要两段提交？2PC, 两段提交的过程是怎样的？, 异常重启会出现什么现象？ 2段提交, 两段提交有什么问题？, 减少磁盘IO次数的 组提交, MySQL磁盘Ix2FO 很高有什么优化的方法？, 一条Update语句流程, explain各个字段的意思, 聊一聊项目中用到的grpc, 分布式, CAP理论, 分布式锁的使用场景, 2段提交和3端提交以及 TTC, Raft算法和Paxos共识性算法的步骤, 一致性Hash算法, 操作系统, CPU缓存一致性, CPU如何选择线程？, 什么是软中断, 聊一聊虚拟内存, 操作系统的保护模式和实模式, 虚拟内存它的内存布局大概是什么样子的？, 聊一聊进程和线程, 说一说常见的调度算法, 进程间的通信有哪些方式呢？, 怎么避免死锁？, 网络系统, 什么是同步异步阻塞非阻塞, 什么是零拷贝, Ix2FO多路复用： selectx2Fpollx2Fepoll, Reactor和Proactor, 什么是一致性哈希, MQ系列, KafKa, KafKa的设计, KafKa性能高原因, KafKa文件高效存储设计原理, KafKa的优缺点, KafKa的应用场景, KafKa为什么要把消息分区, KafKa消息的消费模式, KafKa如何实现负载均衡和故障转移, KafKa中Zookeeoer的作用, asynq, RocketMq, 为什么使用NameServer而不是ZK, RocketMq如何防止消息丢失？, RocketMq如何保证消息有序？, RocketMq如何实现延迟消息, 消费消息是push还是pull, RocketMq如何对消息去重, 常见限流算法, 固定窗口（窗口计数法）, 滑动窗口, 漏桶算法, 令牌桶算法, go-zero相关的问题, DTM的TTC, 微服务面经, RPC和HTTP, RPC原理, 流行的RPC框架, 面经分享, 字节二面, 奇怪的问题, 在程序中一般溢出的处理？数据怎么存储的？, 系统设计类的问题？, 系统设计答题思路：, 短链路系统, 设计秒杀系统, 瞬间高并发：, 页面静态化, 秒杀按钮, 读多写少, 缓存问题, 库存问题, 分布式锁, mq异步, 如何限流？, Gee实现web框架数组和切片数组和切片有什么不同的底层数据是数组是对数组的封装它描述一个数组的片段数组是定长的长度定义好之后不能再更改数组就是一片连续的内存实际上是一个结构体包含三个字段长度容量底层数组元素指针长度容量切片的容量是怎么增长的一般都是在向追加了元素之后才会引起扩容追加元素调用的是函数使用可以向追加元素实际上是往底层数组添加元素但是底层数组的长度是固定的如果索引所指向的元素已经是底层数组的最后一个元素就没法再添加了这时会迁移到新的内存位置新底层数组的长度也会增加这样就可以放置新增的元素同时为了应对未来可能再次发生的操作新的底层数组的长度也就是新的容量是留了一定的的否则每次添加元素的时候都会发生迁移成本太高新预留的大小是有一定规律的在版本更新之前网上大多数的文章都是这样描述的扩容策略的当原容量小于的时候新容量变成原来的倍原容量超过新容量变成原来的倍在版本更新之后的扩容策略变为了当原容量小于的时候新容量为原来的倍原容量超过新容量最后要通过计算得到这个就是内存对齐的策略为了避免内存碎片最后会进行内存对齐计算进行内存对齐的计算切片作为函数参数前面我们说到其实是一个结构体包含了三个成员分别表示切片长度容量底层数据的地址当作为函数参数时就是一个普通的结构体其实很好理解若直接传在调用者看来实参并不会被函数中的操作改变若传的是的指针在调用者看来是会被改变原的值得注意的是不管传的是还是指针如果改变了底层数组的数据会反应到实参的底层数据为什么能改变底层数组的数据很好理解底层数据在结构体里是一个指针尽管结构体自身不会被改变也就是说底层数据地址不会被改变但是通过指向底层数据的指针可以改变切片的底层数据没有问题指针在中的作用引用传递在函数调用时通过指针可以实现引用传递这意味着当你将一个变量的地址作为参数传递给函数时函数可以直接操作该变量的原始值而非创建一个新的副本这提高了效率特别是在处理大数据结构如数组切片结构体等时避免了不必要的内存拷贝降低了开销动态内存分配使用内建的函数或函数对于和这类复合类型语言可以动态地在堆上分配内存并返回指向新分配内存的指针通过指针我们可以方便地创建和管理生命周期不受函数范围约束的变量修改函数外部变量函数默认是值传递的但通过传递变量的指针函数可以修改外部作用域内的变量值这对于需要改变原始数据的函数设计至关重要数据结构底层操作在开发诸如链表树图等高级数据结构时指针是构建这些结构的基础因为它们依赖于节点间的引用关系低级内存操作尽管语言的设计理念倾向于抽象掉大部分底层细节但在一些高级或系统级编程场景中指针仍然可以用于直接操作内存地址以满足特定的性能要求或与其他语言库进行交互接口实现在语言的接口类型中虽然接口变量本身不包含指针但是在实现接口时结构体指针经常被用来实现方法集这样可以避免方法接收者复制带来的额外开销并且更容易满足接口的语义总之语言中的指针极大地增强了程序设计的灵活性和效率它是实现高性能和低延迟代码的关键工具之一同时也要求开发者谨慎使用以避免潜在的悬挂指针内存泄漏和其他因不当使用指针引起的错误谈谈中比较相等哈希表的实现原理的结构主要用来存储数据的的内存模型的设计也被称为它的任务是设计一种数据结构用来维护一个集合的数据并且可以同时对集合进行增删查改的操作最主要的数据结构有两种哈希查找表搜索树哈希查找表用一个哈希函数将分配到不同的桶也就是数组的不同这样开销主要在哈希函数的计算以及数组的常数访问时间在很多场景下哈希查找表的性能很高哈希查找表一般会存在碰撞的问题就是说不同的被哈希到了同一个一般有两种应对方法链表法和开放地址法链表法将一个实现成一个链表落在同一个中的都会插入这个链表开放地址法则是碰撞发生后通过一定的规律在数组的后面挑选空位用来放置新的当的和都不是指针并且都小于字节的情况下会把标记为不含指针这样可以避免时扫描整个但是我们看其实有一个的字段是指针类型的破坏了不含指针的设想这时会把移动到字段来创建从语法层面上来说创建很简单指定长度为不能向其添加元素会直接通过汇编语言可以看到实际上底层调用的是函数主要做的工作就是初始化结构体的各种字段例如计算的大小设置哈希种子等等通过汇编语言可以看到实际上底层调用的是函数主要做的工作就是初始化结构体的各种字段例如计算的大小设置哈希种子等等省略各种条件检查找到一个使得的装载因子在正常范围内初始化如果等于那么就会在赋值的时候再分配如果长度比较大分配内存会花费长一点初始化引申和分别作为函数参数时有什么区别注意这个函数返回的结果它是一个指针而我们之前讲过的函数返回的是结构体回顾一下的结构体定义元素指针长度容量结构体内部包含底层的数据指针和的区别带来一个不同点当和作为函数参数时在函数参数内部对的操作会影响自身而对却不会之前讲的文章里有讲过主要原因一个是指针一个是结构体语言中的函数传参都是值传递在函数内部参数会被到本地指针完之后仍然指向同一个因此函数内部对的操作会影响实参而被后会成为一个新的对它进行的操作不会影响到实参哈希函数的一个关键点在于哈希函数的选择在程序启动时会检测是否支持如果支持则使用否则使用这是在函数中完成位于路径下函数有加密型和非加密型加密型的一般用于加密数据数字摘要等典型代表就是这种非加密型的一般就是查找在的应用场景中用的是查找选择函数主要考察的是两点性能碰撞概率定位过程经过哈希计算后得到哈希值共个位位机位机就不讨论了现在主流都是位机计算它到底要落在哪个桶时只会用到最后个位还记得前面提到过的吗如果那么桶的数量也就是数组的长度是扩容过程好的对于的扩容触发条件超过了负载因子的大小那么一般会发生扩容双倍扩容当的数量过多的时候会发生扩容等量扩容主要是申请到了新的空间把相关的标志位都进行了处理例如标志被置为表示当前搬迁进度为为什么是无序的在扩容后会发生的搬迁原来落在同一个中的搬迁后有些就要远走高飞了序号加上了而遍历的过程就是按顺序遍历同时按顺序遍历中的搬迁后的位置发生了重大的变化有些飞上高枝有些则原地不动这样遍历的结果就不可能按原来的顺序了当然如果我就一个的我也不会向进行插入删除的操作按理说每次遍历这样的都会返回一个固定顺序的序列吧的确是这样但是杜绝了这种做法因为这样会给新手程序员带来误解以为这是一定会发生的事情在某些情况下可能会酿成大错当然做得更绝当我们在遍历时并不是固定地从号开始遍历每次都是从一个随机值序号的开始遍历并且是从这个的一个随机序号的开始遍历这样即使你是一个写死的仅仅只是遍历它也不太可能会返回一个固定序列的对了多说一句迭代的结果是无序的这个特性是从开始加入的类型可以作为的吗最后说结论型可以作为但是由于精度的问题会导致一些诡异的问题慎用之由于的特性因此向中查找的为时什么也查不到如果向其中增加了次遍历会得到个最后说结论型可以作为但是由于精度的问题会导致一些诡异的问题慎用之如何比较个是否相等深度相等的条件都为非空长度相等指向同一个实体对象相应的指向的深度相等直接将使用是错误的这种写法只能比较是否为不能通过编译输出结果因此只能是遍历的每个元素比较元素是否都是深度相等是线程安全的吗不是线程安全的在查找赋值遍历删除的过程中都会检测写标志一旦发现写标志置位等于则直接赋值和删除函数在检测完写标志是复位之后先将写标志位置位才会进行之后的操作检测写标志设置写标志接口值接收者和指针接收者的区别方法能给用户自定义的类型添加新的行为它和函数的区别在于方法有一个接收者给一个函数添加一个接收者那么它就变成了方法接收者可以是值接收者也可以是指针接收者在调用方法的时候值类型既可以调用值接收者的方法也可以调用指针接收者的方法指针类型既可以调用指针接收者的方法也可以调用值接收者的方法也就是说不管方法的接收者是什么类型该类型的值和指针都可以调用不必严格符合接收者的类型前面说过不管接收者类型是值类型还是指针类型都可以通过值类型或指针类型调用这里面实际上通过语法糖起作用的先说结论实现了接收者是值类型的方法相当于自动实现了接收者是指针类型的方法而实现了接收者是指针类型的方法不会自动生成对应接收者是值类型的方法如果实现了接收者是值类型的方法会隐含地也实现了接收者是指针类型的方法两者分别在何时使用如果方法的接收者是值类型无论调用者是对象还是对象指针修改的都是对象的副本不影响调用者如果方法的接收者是指针类型则调用者修改的是指针指向的对象本身使用指针作为方法的接收者的理由方法能够修改接收者指向的值避免在每次调用方法时复制该值在值的类型为大型结构体时这样做会更加高效是使用值接收者还是指针接收者不是由该方法是否修改了调用者也就是接收者来决定而是应该基于该类型的本质如果类型具备原始的本质也就是说它的成员都是由语言里内置的原始类型如字符串整型值等那就定义值接收者类型的方法像内置的引用类型如这些类型比较特殊声明他们的时候实际上是创建了一个对于他们也是直接定义值接收者类型的方法这样调用函数时是直接了这些类型的而本身就是为复制设计的如果类型具备非原始的本质不能被安全地复制这种类型总是应该被共享那就定义指针接收者的方法比如源码里的文件结构体就不应该被复制应该只有一份实体接口的实现和以及接口的动态类型和动态值动态类型动态值类型转换类型断言本质都是把一个类型转换成另外一个类型不同之处在于类型断言是对接口变量进行的操作接口转换的原理当判定一种类型是否满足某个接口时使用类型的方法集和接口所需要的方法集进行匹配如果类型的方法集完全包含接口的方法集则可认为该类型实现了该接口具体类型转空接口时字段直接复制源类型的调用获得一块新内存把值复制进去再指向这块新内存具体类型转非空接口时入参是编译器在编译阶段预先生成好的新接口字段直接指向入参指向的调用获得一块新内存把值复制进去再指向这块新内存而对于接口转接口调用函数获取只用生成一次之后直接从表中获取谈一谈的模型好的协程保存了一个可以运行的的队列中的线程每个的话它会绑定才能去执行执行调度的任务再空闲的时候可能会去全局的的队列中获取可以处于的来运行同时如果全局的队列中没有了我们可以去其他绑定的的中去抢来运行聊一聊协程和线程的区别好的从几个方面内存消耗创建和销毁切换内存占用的话一个一般是分配的内存消耗一个线程的话一般是分配的内存创建和销毁的创建和销毁都比计较繁琐由于线程是操作系统级别的他的创建和销毁会于进行交互调度是由来进行管理的相当于他是用户级别的概念创建和销毁有来进行不需要于内核进行交互更快切换垃圾回收器目前的垃圾回收器采用的垃圾回收方式基本是大类追踪式标记清除标记整理增量式增量整理引用计数分代目前采用的式追踪式的垃圾回收方式标记类的回收三色标记法三种颜色的对象黑色对象灰色对象白色对象在的时候提出了混合屏障技术语言的垃圾回收过程可以概括为以下几个关键步骤尽管实际实现包含了许多复杂的优化和技术细节初始标记开始时首先进行根扫描标记所有活跃的根对象根对象包括全局变量栈上的局部变量的上下文以及其他一些内部数据结构引用的对象并发标记语言的使用并发标记算法来减少停顿时间在这个阶段程序继续执行同时垃圾回收器并发地追踪从根对象开始的所有可达对象并标记它们为存活标记终止为了保证一致性必须在某一时刻暂停所有的进行所谓的阶段完成剩余的标记工作解决可能存在的并发标记期间产生的数据竞争问题标记整理标记完成后进入清除阶段在传统的标记清除算法中未被标记的对象被视为垃圾并回收它们占用的内存在某些版本中为了减少内存碎片采用了标记压缩策略移动所有存活对象到连续的空间使得内存更加紧凑写屏障在并发标记阶段为了保持标记集合的一致性的引入了写屏障技术当程序在并发标记期间修改对象引用时写屏障会记录这种变化以便后续处理内存分配与清扫清理阶段之后会重新组织内存区域使其能够用于新的分配清理阶段也可能在并发模式下进行部分区域在不阻塞程序执行的情况下完成清扫增量清扫与并发清扫为了进一步减少时间的可能采用增量清扫策略分散清扫过程在整个程序执行过程中进行自适应调整聊一聊你对的的理解式在中加入的被叫做上下文包含的运行状态环境现场信息等可以存储一些变量可以用来之间通知退出和元数据传递的功能用来之间传递上下文信息包括取消信号超时信号截止时间等定义了接口的四个方法空可以取消的定时存储的不知道干嘛的时候后面可能需要传递参数暂时不知道要干嘛的时候可以使用用来标志取消的接口聊一聊反射在计算机科学中反射是指计算机程序在运行时可以访问检测和修改它本身状态或行为的一种能力用比喻来说反射就是程序在运行的时候能够观察并且修改自己的行为在计算机中反射是指在计算机程序运行过程中能够访问检测和修改程程序本身状态或行为的一种能力使用反射的常见场景有以下两种不能明确接口调用哪个函数需要根据传入的参数在运行时决定不能明确传入函数的参数类型需要在运行时处理任意对象聊一聊中和首先我们知道变量的初始化分为个过程变量的声明分配内存空间声明指类型变量的时候系统会默认给他们分配内存空间并且赋值该类型的零值和都是内置函数他们都是用来给变量分配内存空间的使用场景区别一般都是使用这三种的话可以分配任意类型的数据并赋值值返回值区别函数返回的是类型本身返回的是内存地址的指针聊一聊说一下微对象小对象大对象线程的内存管理中央内存管理堆内存管理语言里面的空结构体用来做什么不占据任何内存空间一般有三个用途实现集合和配合使用不具备任何意义但除用作之间通知实现一个不带字段仅包含方法的结构体如何实现好友功能总体思路我们采用里面的完成整个功能原因是有排序我们要按照关注时间的倒序排列去重我们不能多次关注同一用户功能一个用户我们存贮两个集合一个是保存用户关注的人另一个是保存关注用户的人用到的命令是添加成员命令格式移除某个成员命令格式统计集合内的成员数命令格式查询集合内的成员命令格式描述返回指定区间的成员其中成员位置按值递增从小到大来排序选项是用来让成员和它的值一并返回跟作用相反获取成员的排名命令格式描述返回有序集中成员的排名成员按值递增从小到大顺序排列排名以开始也就是说值最小的为返回值返回成员排名不存在返回取两个集合的交集命令格式描述计算给定的一个或多个有序集的交集其中给定的数量必须以参数指定并将该交集结果集储存到默认情况下结果集中某个成员的值是所有给定集下该成员值之和返回值保存到的结果集成员数在语言中我们可以使用库与进行交互来实现好友功能例如关注取关获取关注列表和共同关注等功能以下是一个简单的示例框架展示如何使用的集合结构来存储和查询用户的关注关系连接添加关注关系将粉丝添加到博主的关注者集合中将添加到的关注集合中反向添加也将添加到的关注对象集合中取消关注关系从的关注集合中移除从的关注对象集合中移除获取用户的关注列表获取用户的粉丝列表获取两个用户之间的共同关注示例调用获取共同关注数据库的设计好友功能的记录在开发社交应用时通常是要放入数据库进行存储的以便于管理和维护用户间的好友关系在设计数据库时可以采用不同的策略来存储好友关系数据一对一冗余存储为每个用户创建一个字段来存储其所有好友的列表这种方法直观简单但在处理大量好友关系时会导致数据冗余和更新困难一对多关联表创建一个中间关联表表或表包含两个字段分别对应用户如这样每对好友之间存在一条记录这种方式消除了数据冗余并且易于添加删除好友关系以及查询用户的社交网络例如在中中间关联表的设计可能如下所示其他可选字段比如添加时间好友备注等的持久化操作日志以追加写的方式快照机制记录所有键值对的快照混合模式和两种一起使用缓存什么是缓存雪崩击穿穿透数据库和缓存如何保证一致性先更新数据库再删除缓存的方案虽然保证了数据库与缓存的数据一致性但是每次更新数据的时候缓存的数据都会被删除这样会对缓存的命中率带来影响所以如果我们的业务对缓存命中率有很高的要求我们可以采用更新数据库更新缓存的方案因为更新缓存并不会出现缓存未命中的情况但是这个方案前面我们也分析过在两个更新请求并发执行的时候会出现数据不一致的问题因为更新数据库和更新缓存这两个操作是独立的而我们又没有对操作做任何并发控制那么当两个线程并发更新它们的话就会因为写入顺序的不同造成数据的不一致所以我们得增加一些手段来解决这个问题这里提供两种做法在更新缓存前先加个分布式锁保证同一时间只运行一个请求更新缓存就会不会产生并发问题了当然引入了锁后对于写入的性能就会带来影响在更新完缓存时给缓存加上较短的过期时间这样即时出现缓存不一致的情况缓存的数据也会很快过期对业务还是能接受的对了针对先删除缓存再更新数据库方案在读写并发请求而造成缓存不一致的解决办法是延迟双删延迟双删实现的伪代码如下删除缓存更新数据库睡眠再删除缓存加了个睡眠时间主要是为了确保请求在睡眠的时候请求能够在这这一段时间完成从数据库读取数据再把缺失的缓存写入缓存的操作然后请求睡眠完再删除缓存所以请求的睡眠时间就需要大于请求从数据库读取数据写入缓存的时间但是具体睡眠多久其实是个玄学很难评估出来所以这个方案也只是尽可能保证一致性而已极端情况下依然也会出现缓存不一致的现象因此还是比较建议用先更新数据库再删除缓存的方案如何保证个操作都能执行成功问题原因知道了该怎么解决呢有两种方法重试机制订阅再操作缓存的线程模型多路复用的主要工作线程是单线程多路复用版本之前的单线模式如下图首先在初始化的时候会做以下几件事首先调用创建一个对象和调用创建一个服务端然后调用绑定端口和调用监听该然后将调用将加入到同时注册连接事件处理函数初始化完成后呢就会进入到一个事件循环函数主要会做以下事情首先先调用处理发送队列函数看是发送队列里是否有任务如果有发送任务则通过函数将客户端发送缓存区里的数据发送出去如果这一轮数据没有发送完就会注册写事件处理函数等待发现可写后再处理接着调用函数等待事件的到来如果是连接事件到来则会调用连接事件处理函数该函数会做这些事情调用获取已连接的调用将已连接的加入到注册读事件处理函数如果是读事件到来则会调用读事件处理函数该函数会做这些事情调用获取客户端发送的数据解析命令处理命令将客户端对象添加到发送队列将执行结果写到发送缓存区等待发送如果是写事件到来则会调用写事件处理函数该函数会做这些事情通过函数将客户端发送缓存区里的数据发送出去如果这一轮数据没有发送完就会继续注册写事件处理函数等待发现可写后再处理采用单线程为什么还那么快的大部分操作都在内存中完成并且采用了高校的数据结构因此瓶颈可能是机器的内存或者网络带宽而并非既然不是性能瓶颈那么自然就采用单线程的解决方案了采用单线程模型可以避免多线程之间的竞争省去了多线程切换带来的时间和性能上的开销而且也不会导致死锁的问题采用了多路复用机制处理大量的客户端请求多路复用机制是指一个线程出路多个流就是我们经常听到的机制在只运行单线程的情况下该机制允许内核中同时存在多个监听和已连接的内核会一只监听这些上的连接请求或数据请求一旦有请求打倒就会交给线程处理这就实现了一个线程处理多个流的效果丰富的数据结构渐进式的缓存时间戳设计之后为什么引入了多线程虽然的主要工作网络和执行命令一直是单线程模型但是在版本之后也采用了多个线程来处理网络请求这是因为随着网络硬件的性能提升的性能瓶颈有时会出现在网络的处理上所以为了提高网络的并行度对于网络采用多线程来处理但是对于命令的执行仍然使用单线程来处理所以大家不要误解有多线程同时执行命令因此版本之后在启动的时候默认情况下会额外创建个线程这里的线程数不包括主线程的主线程主要负责执行命令三个后台线程分别异步处理关闭文件任务刷盘任务释放内存任务三个线程默认是所以会启动个多线程用来分担网络的压力的持久化是如何实现的日志和快照的集群模式模式想要设计一个高可用的服务一定要从的多服务借点来考虑主从复制哨兵模式切片模式主从的实现采用一主多从的模式且主从服务器之间采用的时读写分离的方式主从服务器间的第一次同步的过程可分为三个阶段第一阶段是建立链接协商同步第二阶段是主服务器同步数据给从服务器第三阶段是主服务器发送新写操作命令给从服务器主从复制共有三种模式全量复制基于长连接的命令传播增量复制主从服务器第一次同步的时候就是采用全量复制此时主服务器会两个耗时的地方分别是生成文件和传输文件为了避免过多的从服务器和主服务器进行全量复制可以把一部分从服务器升级为经理角色让它也有自己的从服务器通过这样可以分摊主服务器的压力第一次同步完成后主从服务器都会维护着一个长连接主服务器在接收到写操作命令后就会通过这个连接将写命令传播给从服务器来保证主从服务器的数据一致性如果遇到网络断开增量复制就可以上场了不过这个还跟这个大小有关系如果它配置的过小主从服务器网络恢复时可能发生从服务器想读的数据已经被覆盖了那么这时就会导致主服务器采用全量复制的方式所以为了避免这种情况的频繁发生要调大这个参数的值以降低主从服务器断开后全量同步的概率区别如下出现的阶段不一样是在增量复制阶段出现一个主节点只分配一个是在全量复制阶段和增量复制阶段都会出现主节点会给每个新连接的从节点分配一个这两个都有大小限制的当缓冲区满了之后发生的事情不一样当满了因为是环形结构会直接覆盖起始位置数据当满了会导致连接断开删除缓存从节点重新连接重新开始全量复制哨兵模式由于主从模式会出现再主从服务器出现宕机的时候需要手动进行恢复出现了哨兵模式哨兵模式可与监控主从服务器并提供主从结点故障转移的功能哨兵机制是基于发布订阅来实现的哨兵其实是一个运行在特殊模式下的进程所以它也是一个节点从哨兵这个名字也可以看得出来它相当于是观察者节点观察的对象是主从节点当然它不仅仅是观察那么简单在它观察到有异常的状况下会做出一些动作来修复异常状态哨兵节点主要负责三件事情监控选主通知切片模式当缓存数据量大到一台服务器无法缓存时就需要使用切片集群方案方案采用哈希槽来处理数据结点之间的映射关系再方案中一个切片集群有个哈希槽每个键值对会根据他的被映射到一个哈希槽中具体步骤更具键值对的按照算法计算一个的值在对的值取模得到范围内的模数每个模数代表一个相应编号的哈希槽接下来的问题就是这些哈希槽怎么被映射到具体的节点上的呢有两种方案平均分配在使用命令创建集群时会自动把所有哈希槽平均分布到集群节点上比如集群中有个节点则每个节点上槽的个数为个手动分配可以使用命令手动建立节点间的连接组成集群再使用命令指定每个节点上的哈希槽个数集群脑裂导致数据丢失怎么办脑裂由于网络问题集群节点之间失去联系主从数据不同步重新平衡选举产生两个主服务解决方案当主节点发现从节点下线或者通信超时的总数量小于阈值时那么禁止主节点进行写数据直接把错误返回给客户端在的配置文件中有两个参数我们可以设置主节点必须要有至少个从节点连接如果小于这个数主节点会禁止写数据主从数据复制和同步的延迟不能超过秒如果超过主节点会禁止写数据过期删除与内存淘汰使用的删除策略是惰性删除定期删除这两种策略配合使用惰性删除不主动删除过期键每次从数据库访问时都检测是否过期如果过期则删除该定期删除每隔一段时间随机从数据库中取出一定数量的进行检查并删除其中的过期数据结构类型的应用场景缓存对象常规计数分布式锁共享信息等类型的应用场景消息队列但是有两个问题生产者需要自行实现全局唯一不能以消费组形式消费数据等类型缓存对象购物车等类型聚合计算并集交集差集场景比如点赞共同关注抽奖活动等类型排序场景比如排行榜电话和姓名排序等版新增二值状态统计的场景比如签到判断用户登陆状态连续签到用户总数等版新增海量数据基数统计的场景比如百万级网页计数等版新增存储地理位置信息的场景比如滴滴叫车版新增消息队列相比于基于类型实现的消息队列有这两个特有的特性自动生成全局唯一消息支持以消费组形式消费数据五种常见的数据库是怎么实现的的键值对数据库是怎么实现的在开始讲数据结构之前先给介绍下是怎样实现键值对数据库的的键值对中的就是字符串对象而可以是字符串对象也可以是集合数据类型的对象比如对象对象对象和对象是使用了一个哈希表保存所有键值对哈希表的最大好处就是让我们可以用的时间复杂度来快速查找到键值对哈希表其实就是一个数组数组中的元素叫做哈希桶的哈希桶是怎么保存键值对数据的呢哈希桶存放的是指向键值对数据的指针这样通过指针就能找到键值对数据然后因为键值对的值可以保存字符串对象和集合数据类型的对象所以键值对的数据结构中并不是直接保存值本身而是保存了和指针分别指向了实际的键对象和值对象这样一来即使值是集合数据也可以通过指针找到结构表示数据库的结构结构体里存放了指向了结构的指针结构结构体里存放了个哈希表正常情况下都是用哈希表哈希表只有在的时候才用具体什么是我在本文的哈希表数据结构会讲结构表示哈希表的结构结构里存放了哈希表数组数组中的每个元素都是指向一个哈希表节点结构的指针结构表示哈希表节点的结构结构里存放了和指针指向的是对象而则可以指向对象也可以指向集合类型的对象比如对象对象对象和对象的实现是用语言实现的但是它没有直接使用语言的字符数组来实现字符串而是自己封装了一个名为简单动态字符串的数据结构来表示字符串也就是的数据类型的底层数据结构是结构中的每个成员变量分别介绍下记录了字符串长度这样获取字符串长度的时候只需要返回这个成员变量值就行时间复杂度只需要分配给字符数组的空间长度这样在修改字符串的时候可以通过计算出剩余的空间大小可以用来判断空间是否满足修改需求如果不满足的话就会自动将的空间扩展至执行修改所需的大小然后才执行实际的修改操作所以使用既不需要手动修改的空间大小也不会出现前面所说的缓冲区溢出的问题用来表示不同类型的一共设计了种类型分别是和后面在说明区别之处字符数组用来保存实际数据不仅可以保存字符串也可以保存二进制数据总的来说的结构在原本字符数组之上增加了三个元数据用来解决语言字符串的缺陷好处复杂度获取字符串长度二进制安全不会发生缓冲区溢出如果所需的长度小于那么最后的扩容是按照翻倍扩容来执行的即倍的如果所需的长度超过那么最后的扩容长度应该是节省内存结构中有个成员变量表示的是类型一共设计了种类型分别是和这种类型的主要区别就在于它们数据结构中的和成员变量的数据类型不同链表先来看看链表节点结构的样子前置节点后置节点节点的值有前置节点和后置节点可以看的出这个是一个双向链表不过在结构体基础上又封装了这个数据结构这样操作起来会更方便链表结构如下链表头节点链表尾节点节点值复制函数节点值释放函数节点值比较函数链表节点数量结构为链表提供了链表头指针链表尾节点链表节点数量以及可以自定义实现的函数链表的优势和劣势的链表实现优点如下链表节点的结构里带有和指针获取某个节点的前置节点或后置节点的时间复杂度只需而且这两个指针都可以指向所以链表是无环链表结构因为提供了表头指针和表尾节点所以获取链表的表头节点和表尾节点的时间复杂度只需结构因为提供了链表节点数量所以获取链表中的节点数量的时间复杂度只需链表节使用指针保存节点值并且可以通过结构的函数指针为节点设置该节点类型特定的函数因此链表节点可以保存各种不同类型的值链表的缺陷也是有的链表每个节点之间的内存都是不连续的意味着无法很好利用缓存能很好利用缓存的数据结构就是数组因为数组的内存是连续的这样就可以充分利用缓存来加速访问还有一点保存一个链表节点的值都需要一个链表节点结构头的分配内存开销较大压缩链表压缩列表的最大特点就是它被设计成一种内存紧凑型的数据结构占用一块连续的内存空间不仅可以利用缓存而且会针对不同长度的数据进行相应编码这种方法可以有效地节省内存开销但是压缩列表的缺陷也是有的不能保存过多的元素否则查询效率就会降低新增或修改某个元素时压缩列表占用的内存空间需要重新分配甚至可能引发连锁更新的问题因此对象对象对象对象包含的元素数量较少或者元素值不大的情况才会使用压缩列表作为底层数据结构压缩列表是为了节约内存而开发的它是由连续内存块组成的顺序型数据结构有点类似于数组压缩列表在表头有三个字段记录整个压缩列表占用对内存字节数记录压缩列表尾部节点距离起始地址由多少字节也就是列表尾的偏移量记录压缩列表包含的节点数量标记压缩列表的结束点固定值十进制在压缩列表中如果我们要查找定位第一个元素和最后一个元素可以通过表头三个字段的长度直接定位复杂度是而查找其他元素时就没有这么高效了只能逐个查找此时的复杂度就是了因此压缩列表不适合保存过多的元素另外压缩列表节点的构成如下压缩列表节点包含三部分内容记录了前一个节点的长度目的是为了实现从后向前遍历记录了当前节点实际数据的类型和长度类型主要有两种字符串和整数记录了当前节点的实际数据类型和长度都由决定当我们往压缩列表中插入数据时压缩列表就会根据数据类型是字符串还是整数以及数据的大小会使用不同空间大小的和这两个元素里保存的信息这种根据数据大小和类型进行不同的空间大小分配的设计思想正是为了节省内存而采用的分别说下和是如何根据数据的大小和类型来进行不同的空间大小分配压缩列表里的每个节点中的属性都记录了前一个节点的长度而且属性的空间大小跟前一个节点长度值有关比如如果前一个节点的长度小于字节那么属性需要用字节的空间来保存这个长度值如果前一个节点的长度大于等于字节那么属性需要用字节的空间来保存这个长度值连锁更新问题压缩列表新增某个元素或修改某个元素时如果空间不不够压缩列表占用的内存空间就需要重新分配而当新插入的元素较大时可能会导致后续元素的占用空间都发生变化从而引起连锁更新问题导致每个元素的空间都要重新分配造成访问压缩列表性能的下降哈希表哈希表是一种保存键值对的数据结构采用了链式哈希来解决哈希冲突在不扩容哈希表的前提下将具有相同哈希值的数据串起来形成链接起以便这些数据在表中仍然可以被查询到哈希表数组哈希表大小哈希表大小掩码用于计算索引值该哈希表已有的节点数量键值对中的键键值对中的值指向下一个哈希表节点形成链表哈希冲突链式哈希采用了链式哈希的方法来解决哈希冲突链式哈希是怎么实现的实现的方式就是每个哈希表节点都有一个指针用于指向下一个哈希表节点因此多个哈希表节点可以用指针构成一个单项链表被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来这样就解决了哈希冲突还是用前面的哈希冲突例子和经过哈希计算后都落在同一个哈希桶链式哈希的话就会通过指针指向形成一个单向链表不过链式哈希局限性也很明显随着链表长度的增加在查询这一位置上的数据的耗时就会增加毕竟链表的查询的时间复杂度是要想解决这一问题就需要进行也就是对哈希表的大小进行扩展接下来看看是如何实现的的的哈希表结构设计的这一小节我给大家介绍了使用结构体表示哈希表不过在实际使用哈希表时定义一个结构体这个结构体里定义了两个哈希表两个表交替使用用于操作之所以定义了个哈希表是因为进行的时候需要用上个哈希表了在正常服务请求阶段插入的数据都会写入到哈希表此时的哈希表并没有被分配空间随着数据逐步增多触发了操作这个过程分为三步给哈希表分配空间一般会比哈希表大一倍两倍的意思将哈希表的数据迁移到哈希表中迁移完成后哈希表的空间会被释放并把哈希表设置为哈希表然后在哈希表新创建一个空白的哈希表为下次做准备为了方便你理解我把这三个过程画在了下面这张图为了避免在数据迁移过程中因拷贝数据的耗时影响性能的情况所以采用了渐进式也就是将数据的迁移的工作不再是一次性迁移完成而是分多次迁移渐进式步骤如下给哈希表分配空间在进行期间每次哈希表元素进行新增删除查找或者更新操作时除了会执行对应的操作之外还会顺序将哈希表中索引位置上的所有迁移到哈希表上随着处理客户端发起的哈希表操作请求数量越多最终在某个时间点会把哈希表的所有迁移到哈希表从而完成操作的触发条件触发操作的条件主要有两个当负载因子大于等于并且没有在执行命令或者命令也就是没有执行快照或没有进行重写的时候就会进行操作当负载因子大于等于时此时说明哈希冲突非常严重了不管有没有有在执行快照或重写都会强制进行操作跳表只有对象的底层实现用到了跳表跳表的优势是能支持平均复杂度的节点查找结构体里有两个数据结构一个是跳表一个是哈希表这样的好处是既能进行高效的范围查询也能进行高效单点查询链表在查找元素的时候因为需要逐一查找所以查询效率非常低时间复杂度是于是就出现了跳表跳表是在链表基础上改进过来的实现了一种多层的有序链表这样的好处是能快读定位数据那跳表长什么样呢我这里举个例子下图展示了一个层级为的跳表对象的元素值元素权重值后向指针节点的数组保存每层上的前向指针和跨度对象要同时保存元素和元素的权重对应到跳表节点结构里就是类型的变量和类型的变量每个跳表节点都有一个后向指针指向前一个节点目的是为了方便从跳表的尾节点开始访问节点这样倒序查找时很方便跳表是一个带有层级关系的链表而且每一层级可以包含多个节点每一个节点通过指针连接起来实现这一特性就是靠跳表节点结构体中的结构体类型的数组数组中的每一个元素代表跳表的一层也就是由结构体表示比如就表示第一层就表示第二层结构体里定义了指向下一个跳表节点的指针和跨度跨度时用来记录两个节点之间的距离跳表结点的查询过程查找一个跳表节点的过程时跳表会从头节点的最高层开始逐一遍历每一层在遍历某一层的跳表节点时会用跳表节点中的类型的元素和元素的权重来进行判断共有两个判断条件如果当前节点的权重小于要查找的权重时跳表就会访问该层上的下一个节点如果当前节点的权重等于要查找的权重时并且当前节点的类型数据小于要查找的数据时跳表就会访问该层上的下一个节点如果上面两个条件都不满足或者下一个节点为空时跳表就会使用目前遍历到的节点的数组里的下一层指针然后沿着下一层指针继续查找这就相当于跳到了下一层接着查找如果要查找元素权重的节点查找的过程是这样的先从头节点的最高层开始指向了元素权重节点这个节点的权重比要查找节点的小所以要访问该层上的下一个节点但是该层的下一个节点是空节点指向的是空节点于是就会跳到元素权重节点的下一层去找也就是元素权重节点的的下一个指针指向了元素权重的节点然后将其和要查找的节点比较虽然元素权重的节点的权重和要查找的权重相同但是当前节点的类型数据大于要查找的数据所以会继续跳到元素权重节点的下一层去找也就是元素权重节点的的下一个指针指向了元素权重的节点该节点正是要查找的节点查询结束跳表层数的设置则采用一种巧妙的方法是跳表在创建节点的时候随机生成每个节点的层数并没有严格维持相邻两层的节点数量比例为的情况具体的做法是跳表在创建节点时候会生成范围为的一个随机数如果这个随机数小于相当于概率那么层数就增加层然后继续生成下一个随机数直到随机数的结果大于结束最终确定该节点的层数这样的做法相当于每增加一层的概率不超过层数越高概率越低层高最大限制是为什么使用跳表不用平衡树简单翻译一下主要是从内存占用对范围查找的支持实现难易程度这三方面总结的原因它们不是非常内存密集型的基本上由你决定改变关于节点具有给定级别数的概率的参数将使其比占用更少的内存经常需要执行或的命令即作为链表遍历跳表通过此操作跳表的缓存局部性至少与其他类型的平衡树一样好它们更易于实现调试等例如由于跳表的简单性我收到了一个补丁已经在中其中扩展了跳表在中实现了它只需要对代码进行少量修改我再详细补充点从内存占用上来比较跳表比平衡树更灵活一些平衡树每个节点包含个指针分别指向左右子树而跳表每个节点包含的指针数目平均为具体取决于参数的大小如果像里的实现一样取那么平均每个节点包含个指针比平衡树更有优势在做范围查找的时候跳表比平衡树操作要简单在平衡树上我们找到指定范围的小值之后还需要以中序遍历的顺序继续寻找其它不超过大值的节点如果不对平衡树进行一定的改造这里的中序遍历并不容易实现而在跳表上进行范围查找就非常简单只需要在找到小值之后对第层链表进行若干步的遍历就可以实现从算法实现难度上来比较跳表比平衡树要简单得多平衡树的插入和删除操作可能引发子树的调整逻辑复杂而跳表的插入和删除只需要修改相邻节点的指针操作简单又快速的结构体跟链表的结构体类似都包含了表头和表尾区别在于的节点是的链表头的链表头的链表尾所有压缩列表中的总元素个数的个数接下来看看的结构定义前一个前一个下一个后一个指向的压缩列表压缩列表的的字节大小压缩列表的元素个数中的元素个数前一个前一个下一个后一个指向的压缩列表压缩列表的的字节大小压缩列表的元素个数中的元素个数可以看到结构体里包含了前一个节点和下一个节点指针这样每个形成了一个双向链表但是链表节点的元素不再是单纯保存元素值而是保存了一个压缩列表所以结构体里有个指向压缩列表的指针虽然通过控制结构里的压缩列表的大小或者元素个数来减少连锁更新带来的性能影响但是并没有完全解决连锁更新的问题采用了压缩列表的很多优秀的设计比如还是用一块连续的内存空间来紧凑地保存数据并且为了节省内存的开销节点会采用不同的编码方式保存不同大小的数据我们先看看结构头包含两个属性分别记录了总字节数和元素数量然后末尾也有个结尾标识图中的就是的节点了每个节点结构如下主要包含三个方面内容定义该元素的编码类型会对不同长度的整数和字符串进行编码实际存放的数据的总长度可以看到没有压缩列表中记录前一个节点长度的字段了只记录当前节点的长度当我们向加入一个新元素的时候不会影响其他节点的长度字段的变化从而避免了压缩列表的连锁更新问题常见数据类型和应用场景缓存对象常规计数分布式锁消息队列如何保证消息满足需求本身就是按先进先出的顺序对数据进行存取的所以如果使用作为消息队列保存消息的话就已经能满足消息保序的需求了可以使用或者反过来命令实现消息队列不过在消费者读取数据时有一个潜在的性能风险点在生产者往中写入数据时并不会主动地通知消费者有新消息写入如果消费者想要及时处理消息就需要在程序中不停地调用命令比如使用一个循环如果有新消息写入命令就会返回结果否则命令返回空值再继续循环所以即使没有新消息写入消费者也要不停地调用命令这就会导致消费者程序的一直消耗在执行命令上带来不必要的性能损失为了解决这个问题提供了命令命令也称为阻塞式读取客户端在没有读到队列数据时自动阻塞直到有新的数据写入队列再开始读取新数据和消费者程序自己不停地调用命令相比这种方式能节省开销如何处理重复的消息首先消息的重复性有方面的需求每个消息都有一个全局的消费者要记录已经处理过的消息的当收到一条消息后消费者程序就可以对比收到的消息和记录的已处理过的消息来判断当前收到的消息有没有经过处理如果已经处理过那么消费者程序就不再进行处理了并不会为每个消息生成号所以我们需要自行为每个消息生成一个全局唯一生成之后我们在用命令把消息插入时需要在消息中包含这个全局唯一如何保证消息的可靠性当消费者程序从中读取一条消息后就不会再留存这条消息了所以如果消费者程序在处理消息的过程出现了故障或宕机就会导致消息没有处理完成那么消费者程序再次启动后就没法再次从中读取消息了为了留存消息类型提供了命令这个命令的作用是让消费者程序从一个中读取消息同时会把这个消息再插入到另一个可以叫作备份留存消息保序使用阻塞读取使用重复消息处理生产者自行实现全局唯一消息的可靠性使用缺点不支持多个消费者消费同一条消息因为一旦消费者拉取一条消息后这条消息就从中删除了无法被其它消费者再次消费要实现一条消息可以被多个消费者消费那么就要将多个消费者组成一个消费组使得多个消费者可以消费同一条消息但是类型并不支持消费组的实现缓存对象购物车涉及的命令如下添加商品用户商品添加数量用户商品商品总数用户删除商品用户商品获取购物车所有商品用户点赞类型可以保证一个用户只能点一个赞这里举例子一个场景是文章是用户三个用户分别对文章点赞了共同关注类型支持交集运算所以可以用来计算共同关注的好友公众号等可以是用户则是已关注的公众号的用户关注公众号为用户关注公众号为抽奖活动如果允许重复中奖可以使用命令如果不允许重复中奖可以使用命令排行榜有序集合比较典型的使用场景就是排行榜例如学生成绩的排名榜游戏积分排行榜视频播放排名电商系统中商品的销量排名等电话姓名的排序签到统计判断用户登录状态连续签到用户总数百万级网页计数滴滴叫车消息队列生产者通过命令插入一条消息前面介绍的这些操作也支持的接下来看看特有的功能可以以使用创建消费组创建消费组之后可以使用命令让消费组内的消费者读取消息创建两个消费组这两个消费组消费的消息队列是都指定从第一条消息开始读取基于实现的消息队列如何保证消费者在发生故障或宕机再次重启后仍然可以读取未处理完的消息会自动使用内部队列也称为留存消费组里每个消费者读取的消息直到消费者使用命令通知消息已经处理完成消费确认增加了消息的可靠性一般在业务处理完成之后需要执行命令确认消息已经被消费完成整个流程的执行如下图所示如果消费者没有成功处理消息它就不会给发送命令消息仍然会留存此时消费者可以在重启后用命令查看已读取但尚未确认处理完成的消息好了基于实现的消息队列就说到这里了小结一下消息保序阻塞读取重复消息处理在使用命令会自动生成全局唯一消息可靠性内部使用自动保存消息使用命令查看消费组已经读取但是未被确认的消息消费者使用确认消息支持消费组形式消费数据的过期策略与内存淘汰策略有什么区别使用的过期删除策略是惰性删除定期删除删除的对象是已过期的内存淘汰策略是解决内存过大的问题当的运行内存超过最大运行内存时就会触发内存淘汰策略之后共实现了种内存淘汰策略我也对这种的策略进行分类如下的缓存策略由于数据存储受限系统并不是将所有数据都需要存放到缓存中的而只是将其中一部分热点数据缓存起来所以我们要设计一个热点数据动态缓存的策略热点数据动态缓存的策略总体思路通过数据最新访问时间来做排名并过滤掉不常访问的数据只留下经常访问的数据以电商平台场景中的例子现在要求只缓存用户经常访问的的商品具体细节如下先通过缓存系统做一个排序队列比如存放个商品系统会根据商品的访问时间更新队列信息越是最近访问的商品排名越靠前同时系统会定期过滤掉队列中排名最后的个商品然后再从数据库中随机读取出个商品加入队列中这样当请求每次到达的时候会先从队列中获取商品如果命中就根据再从另一个缓存数据结构中读取实际的商品信息并返回在中可以用方法和方法来完成排序队列和获取个商品的操作实战如何实现延迟队列采用来实现管道有什么作用管道技术是客户端提供的一种批处理技术用于一次处理多个命令从而提高整个交互的性能普通命令模式如下图所示管道模式如下图所示使用管道技术可以解决多个命令执行时的网络等待它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端这样就免去了每条命令执行后都要等待的情况从而有效地提高了程序的执行效率但使用管道技术也要注意避免发送的命令过大或管道内的数据太多而导致的网络阻塞要注意的是管道技术本质上是客户端提供的功能而非服务器端的功能如何使用实现分布式锁分布式锁是用于分布式环境下并发控制的一种机制用于控制某个资源在同一时刻只能被一个应用所使用的命令有一个的参数正好就是一个共享存储系统可以用来保存分布式锁而且的去写性能高可以应对高并发的锁场景就是键是客户端生成的唯一的标识区分来自不同客户端的锁操作代表只在不存在时才对进行设置操作表示设置的过期时间为这是为了避免客户端发生异常而无法释放锁而解锁的过程就是将键删除但不能乱删要保证执行操作的客户端就是加锁的客户端所以解锁的时候我们要先判断锁的是否为加锁客户端是的话才将键删除可以看到解锁是有两个操作这时就需要脚本来保证解锁的原子性因为在执行脚本时可以以原子性的方式执行保证了锁释放操作的原子性释放锁时先比较是否相等避免锁的误释放这样一来就通过使用命令和脚本在单节点上完成了分布式锁的加锁和解锁基于实现分布式锁有什么优缺点优点性能高效这是选择缓存实现分布式锁最核心的出发点实现方便很多研发工程师选择使用来实现分布式锁很大成分上是因为提供了方法实现分布式锁很方便避免单点故障因为是跨集群部署的自然就避免了单点故障缺点超时时间不好设置如果锁的超时时间设置过长会影响性能如果设置的超时时间过短会保护不到共享资源比如在有些场景中一个线程获取到了锁之后由于业务代码执行时间可能比较长导致超过了锁的超时时间自动失效注意线程没执行完后续线程又意外的持有了锁意味着可以操作共享资源那么两个线程之间的共享资源就没办法进行保护了那么如何合理设置超时时间呢我们可以基于续约的方式设置超时时间先给锁设置一个超时时间然后启动一个守护线程让守护线程在一段时间后重新设置这个锁的超时时间实现方式就是写一个守护线程然后去判断锁的情况当锁快失效的时候再次进行续约加锁当主线程执行完成后销毁续约锁即可不过这种方式实现起来相对复杂主从复制模式中的数据是异步复制的这样导致分布式锁的不可靠性如果在主节点获取到锁后在没有同步到其他节点时主节点宕机了此时新的主节点依然可以获取锁所以多个应用服务就可以同时获取到锁如何解决集群情况下分布式锁的可靠性为了保证集群环境下分布式锁的可靠性官方已经设计了一个分布式锁算法红锁它是基于多个节点的分布式锁即使有节点发生了故障锁变量仍然是存在的客户端还是可以完成锁操作官方推荐是至少部署个节点而且都是主节点它们之间没有任何关系都是一个个孤立的节点算法的基本思路是让客户端和多个独立的节点依次请求申请加锁如果客户端能够和半数以上的节点成功地完成加锁操作那么我们就认为客户端成功地获得分布式锁否则加锁失败这样一来即使有某个节点发生故障因为锁的数据在其他节点上也有保存所以客户端仍然可以正常地进行锁操作锁的数据也不会丢失算法加锁三个过程第一步是客户端获取当前时间第二步是客户端按顺序依次向个节点执行加锁操作加锁操作使用命令带上选项以及带上客户端的唯一标识如果某个节点发生故障了为了保证在这种情况下算法能够继续运行我们需要给加锁操作设置一个超时时间不是对锁设置超时时间而是对加锁操作设置超时时间加锁操作的超时时间需要远远地小于锁的过期时间一般也就是设置为几十毫秒第三步是一旦客户端从超过半数大于等于的节点上成功获取到了锁就再次获取当前时间然后计算计算整个加锁过程的总耗时如果锁的过期时间此时认为客户端加锁成功否则认为加锁失败可以看到加锁成功要同时满足两个条件简述如果有超过半数的节点成功的获取到了锁并且总耗时没有超过锁的有效时间那么就是加锁成功条件一客户端从超过半数大于等于的节点上成功获取到了锁条件二客户端从大多数节点获取锁的总耗时小于锁设置的过期时间加锁成功后客户端需要重新计算这把锁的有效时间计算的结果是锁最初设置的过期时间减去客户端从大多数节点获取锁的总耗时如果计算的结果已经来不及完成共享数据的操作了我们可以释放锁以免出现还没完成数据操作锁就过期了的情况加锁失败后客户端向所有节点发起释放锁的操作释放锁的操作和在单节点上释放锁的操作一样只要执行释放锁的脚本就可以了计算机网络计算机网络的各层协议及作用计算机网络体系可以分为三种七层模型四层模型五层模型模型总共有四层分别是应用层专注于为用户提供应用的功能如等传输层负责端到端的通信应用层的数据包会传给传输层传输层为应用层提供网络支持给数据添加头部网络层负责网络包的封装分片路由转发在应用间数据传输的媒介帮助应用到应用的通信实际的传输功能由网络层提供在数据上添加头部网络接口层负责网络包在物理网络中的传输在头部前面加上头部并封装成数据帧发送到网络上注意网络接口层的传输单位是数据帧层的传输代为是包的层的传输单位是段的传输单位是消息或报文但这些名词并没有什么本质的区分可以统称为数据包字节一个请求报文由四个部分组成请求行请求头部空行请求数据常见的状态码和的区别对比如下是否连接无连接面向连接是否可靠不可靠传输不使用流量控制和拥塞控制可靠传输使用流量控制和拥塞控制是否有序无序有序消息在传输过程中可能会乱序会重新排序传输速度快慢连接对象个数支持一对一一对多多对一和多对多交互通信只能是一对一通信传输方式面向报文面向字节流首部开销首部开销小仅字节首部最小字节最大字节适用场景适用于实时应用电话视频会议直播等适用于要求可靠传输的应用例如文件传输总结用于在传输层有必要实现可靠传输的情况用于对高速传输和实时性有较高要求的通信和应该根据应用目的按需使用什么事洪泛攻击如何防范洪泛攻击属于攻击的一种它利用协议缺陷通过发送大量的半连接请求耗费和内存资源原理在三次握手过程中服务器发送包第二个包之后收到客户端的包第三个包之前的连接称为半连接此时服务器处于等待客户端响应状态如果接收到客户端的则连接成功如果未接受到则会不断重发请求直至成功攻击的攻击者在短时间内伪造大量不存在的地址向服务器不断地发送包服务器回复包并等待客户的确认由于源地址是不存在的服务器需要不断的重发直至超时这些伪造的包将长时间占用未连接队列影响了正常的导致目标系统运行缓慢网络堵塞甚至系统瘫痪检测当在服务器上看到大量的半连接状态时特别是源地址是随机的基本上可以断定这是一次攻击防范通过防火墙路由器等过滤网关防护通过加固协议栈防范如增加最大半连接数缩短超时时间技术是对服务器端的三次握手做一些修改专门用来防范洪泛攻击的一种手段协议如何保证可靠性主要提供了检验和序列号确认应答超时重传滑动窗口拥塞控制和流量控制等方法实现了可靠性传输检验和通过检验和的方式接收端可以检测出来数据是否有差错和异常假如有差错就会直接丢弃段重新发送序列号确认应答序列号的作用不仅仅是应答的作用有了序列号能够将接收到的数据根据序列号排序并且去掉重复序列号的数据传输的过程中每次接收方收到数据后都会对传输方进行确认应答也就是发送报文这个报文当中带有对应的确认序列号告诉发送方接收到了哪些数据下一次的数据从哪里发滑动窗口滑动窗口既提高了报文传输的效率也避免了发送方发送过多的数据而导致接收方无法正常处理的异常超时重传超时重传是指发送出去的数据包到接收到确认包之间的时间如果超过了这个时间会被认为是丢包了需要重传最大超时时间是动态计算的拥塞控制在数据传输过程中可能由于网络状态的问题造成网络拥堵此时引入拥塞控制机制在保证可靠性的同时提高性能流量控制如果主机一直向主机发送数据不考虑主机的接受能力则可能导致主机的接受缓冲区满了而无法再接受数据从而会导致大量的数据丢包引发重传机制而在重传的过程中若主机的接收缓冲区情况仍未好转则会将大量的时间浪费在重传数据上降低传送数据的效率所以引入流量控制机制主机通过告诉主机自己接收缓冲区的大小来使主机控制发送的数据量流量控制与协议报头中的窗口大小有关常见的状态码有哪些常见状态码服务器已成功处理了请求通常这表示服务器提供了请求的网页永久移动请求的网页已永久移动到新位置服务器返回此响应对或请求的响应时会自动将请求者转到新位置临时移动服务器目前从不同位置的网页响应请求但请求者应继续使用原有位置来进行以后的请求客户端请求有语法错误不能被服务器所理解服务器收到请求但是拒绝提供服务未找到服务器找不到请求的网页服务器内部错误服务器遇到错误无法完成请求状态码和的区别是什么共同点和状态码都表示重定向就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的地址这个地址可以从响应的首部中获取用户看到的效果就是他输入的地址瞬间变成了另一个地址不同点表示旧地址的资源已经被永久地移除了这个资源不可访问了搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址表示旧地址的资源还在仍然可以访问这个重定向只是临时地从旧地址跳转到地址搜索引擎会抓取新的内容而保存旧的网址中好于补充重定向原因网站调整如改变网页目录结构网页被移到一个新地址网页扩展名改变如应用需要把改成或请求和请求的区别使用上的区别使用或传参而将数据放在中这个是因为协议用法的约定方式提交的数据有长度限制则的数据则可以非常大这个是因为它们使用的操作系统和浏览器设置的不同引起的区别比安全因为数据在地址栏上不可见这个说法没毛病但依然不是和本身的区别本质区别和最大的区别主要是请求是幂等性的请求不是这个是它们本质区别幂等性是指一次和多次请求某一个资源应该具有同样的副作用简单来说意味着对同一的多个请求应该返回同样的结果解释一下长连接和短链接在中默认使用的是短连接也就是说浏览器和服务器每进行一次操作就建立一次连接但任务结束就中断连接如果客户端浏览器访问的某个或其他类型的页中包含有其他的资源如文件图像文件文件等当浏览器每遇到这样一个资源就会建立一个会话但从起默认使用长连接用以保持连接特性使用长连接的协议会在响应头有加入这行代码在使用长连接的情况下当一个网页打开完成后客户端和服务器之间用于传输数据的连接不会关闭如果客户端再次访问这个服务器上的网页会继续使用这一条已经建立的连接不会永久保持连接它有一个保持时间可以在不同的服务器软件如中设定这个时间实现长连接要客户端和服务端都支持长连接协议的长连接和短连接实质上是协议的长连接和短连接请求报文和响应报文的格式请求报文格式请求行请求方法协议版本请求头部空行请求主体请求行请求头部响应报文状态行版本状态码原因短句响应首部空行响应主体响应示例介绍一下缓存缓存有种实现方式强制缓存浏览器判断缓存没有过期直接使用浏览器本地的缓存主动性在浏览器这边协商缓存字段来实现的强制缓存强缓存是利用下面这两个响应头部字段实现的它们都用来表示资源在客户端缓存的有效期是一个相对时间是一个绝对时间协商缓存第一种请求头部中的字段与响应头部中的字段实现这两个字段的意思是响应头部中的标示这个响应资源的最后修改时间请求头部中的当资源过期了发现响应头中具有声明则再次发起请求的时候带上的时间服务器收到请求后发现有则与被请求资源的最后修改时间进行对比如果最后修改时间较新大说明资源又被改过则返回最新资源如果最后修改时间较旧小说明资源无新修改响应走缓存第二种请求头部中的字段与响应头部中的字段这两个字段的意思是响应头部中唯一标识响应资源请求头部中的当资源过期时浏览器发现响应头里有则再次向服务器发起请求时会将请求头值设置为的值服务器收到请求后进行比对如果资源没有变化返回如果资源变化了返回如何优化尽量避免发送请求通过缓存技术减少请求次数减少重定向请求合并请求延迟发送请求减少响应的数据大小无损压缩有损压缩重定向请求交给代理服务器代理服务器知晓了重定向规则后合并请求把多个访问小文件的请求合并成一个大的请求虽然传输的总资源还是一样但是减少请求也就意味着减少了重复发送的头部通过将多个小图片合并成一个大图片来减少请求的次数以减少请求的次数从而减少网络的开销还可以将图片的二进制数据用编码后以的形式嵌入到文件跟随文件一并发送合并请求的方式就是合并资源以一个大资源的请求替换多个小资源的请求但是这样的合并请求会带来新的问题当大资源中的某一个小资源发生变化后客户端必须重新下载整个完整的大资源文件这显然带来了额外的网络消耗延迟发送请求一般里会含有很多的当前不需要的资源我们没必要也获取过来于是可以通过按需获取的方式来减少第一时间的请求次数如何减少响应的数据大小压缩无损压缩有损压缩无损压缩就是比较常见的无损压缩客户端支持的压缩算法会在请求中通过头部中的字段告诉服务器服务器收到后会从中选择一个服务器支持的或者合适的压缩算法然后使用此压缩算法对响应资源进行压缩最后通过响应头部中的字段告诉客户端该资源使用的压缩算法的压缩效率相比推出的算法还是差点意思也就是上文中的所以如果可以服务器应该选择压缩效率更高的压缩算法有损压缩有损压缩主要将次要的数据舍弃牺牲一些质量来减少数据量提高压缩比这种方法经常用于压缩多媒体数据比如音频视频图片可以通过请求头部中的字段里的质量因子告诉服务器期望的资源质量握手解析过程官方介绍加密算法是一种非对称加密算法握手过程客户端提交请求服务器响应客户并把服务器公钥发给客户端客户端验证公钥的有效性有效后客户端会生成一个会话密钥一个随机数用服务器公钥加密这个会话密钥后发送给服务器服务器收到公钥加密的密钥后用私钥解密获取会话密钥客户端与服务器利用会话密钥对传输数据进行对称加密通信客户端如何检查公钥是否合法客户端拿着服务器发来的公钥再发请求去那做检验客户端其实需要预置签发的根证书这个根证书中保存了的公钥而且在之前的第步中服务器发的并不是服务器公钥而是由签发的服务器证书这个证书包括了两部分用私钥对服务器公钥以及其他网站信息加密后得到的的密文对服务器公钥后的摘要服务器将证书发给客户端以后客户端从根证书中获取公钥对服务器证书的密文进行解密得到服务器公钥当然还有网站的其他信息这里先忽略然后再一次公钥比较得到的结果和证书携带的摘要是否一致持久连接引入了持久连接在一个连接上可以执行多个请求减少了建立新连接的开销缓存控制增强了缓存机制提供了更精细的缓存控制指令如头部字段管道化虽然实际应用中存在限制允许在一个连接上连续发送多个请求不过响应仍然按照请求顺序返回多路复用同一连接上可以并行处理多个请求和响应避免了中的队头阻塞问题极大地提高了页面加载速度二进制分帧将消息分解为二进制帧使得不同类型的资源可以在同一个连接上交错传输头部压缩使用算法对头部进行压缩减少不必要的带宽消耗服务器推送服务器能够预测客户端可能需要的资源并提前将其推送给客户端基于是基于协议的而运行在用户数据报协议之上解决了的某些延迟问题更快的连接建立实现了零往返时间连接重用即在已有连接上下文中快速恢复会话无需等待握手完成就可以开始数据传输多路复用增强继承了的多路复用特性但在传输层更加可靠即使个别数据包丢失也能确保其他数据流不受影响安全性内置了加密功能所有传输数据都在保护下提供更安全的传输保障拥塞控制优化包含了改进的拥塞控制算法能更好地应对网络状况的变化综上所述每一代协议都在前一代的基础上针对性能瓶颈做了重大改进特别针对网络延迟连接效率和安全性方面做出了显著提升和的区别是超文本传输协议信息是明文传输存在安全风险的问题则解决不安全的缺陷在和网络层之间加入了安全协议使得报文能够加密传输连接建立相对简单三次握手之后便可进行的报文传输而在三次握手之后还需进行的握手过程才可进入加密报文传输两者的默认端口不一样默认端口号是默认端口号是协议需要向证书权威机构申请数字证书来保证服务器的身份是可信的和的区别长连接支持长连接和请求的流水线处理在一个连接上可以传送多个请求和响应减少了建立和关闭连接的消耗和延迟在中默认开启一定程度上弥补了每次请求都要创建连接的缺点缓存处理在中主要使用里的来做为缓存判断的标准则引入了更多的缓存控制策略可供选择的缓存头来控制缓存策略贷款优化以及网络连接的使用中存在一些浪费带宽的现象例如客户端只是需要某个对象的一部分而服务器却将整个对象送过来了并且不支持断点续传功能则在请求头引入了头域它允许只请求资源的某个部分即返回码是这样就方便了开发者自由的选择以便于充分利用带宽和连接错误通知的管理在中新增了个错误状态响应码如表示请求的资源与资源的当前状态发生冲突表示服务器上的某个资源被永久性的删除头处理在中认为每台服务器都绑定一个唯一的地址因此请求消息中的并没有传递主机名但随着虚拟主机技术的发展在一台物理服务器上可以存在多个虚拟主机并且它们共享一个地址的请求消息和响应消息都应支持头域且请求消息中如果没有头域会报告一个错误和的区别相比支持的特性新的二进制格式的解析是基于文本基于文本协议的格式解析存在天然缺陷文本的表现形式有多样性要做到健壮性考虑的场景必然很多二进制则不同只认和的组合基于这种考虑的协议解析决定采用二进制格式实现方便且健壮多路复用即连接共享即每一个都是用作连接共享机制的一个对应一个这样一个连接上可以有多个每个连接的可以随机的混杂在一起接收方可以根据的将再归属到各自不同的服务端请求里面头部压缩的头部带有大量信息而且每次都要重复发送使用来减少需要传输的大小通讯双方各自一份表既避免了重复的传输又减小了需要传输的大小服务端推送服务器除了对最初请求的响应外服务器还可以额外的向客户端推送资源而无需客户端明确的请求解决了的哪些问题窃听风险比如通信链路上可以获取通信内容用户号容易没篡改风险比如强制植入垃圾广告视觉污染用户眼容易瞎冒充风险比如冒充淘宝网站用户钱容易没在与层之间加入了协议可以很好的解决了上述的风险信息加密交互信息无法被窃取但你的号会因为自身忘记账号而没校验机制无法篡改通信内容篡改了就不能正常显示但百度竞价排名依然可以搜索垃圾广告身份证书证明淘宝是真的淘宝网但你的钱还是会因为剁手而没是如何解决上面的三个风险的混合加密的方式实现信息的机密性解决了窃听的风险摘要算法的方式来实现完整性它能够为数据生成独一无二的指纹指纹用于校验数据的完整性解决了篡改的风险将服务器公钥放入到数字证书中解决了冒充的风险那相比性能上的改进头部压缩二进制格式并发传输服务器主动推送资源有什么缺陷对头阻塞问题只不过问题不是在这一层面而是在这一层是基于协议来传输数据的是字节流协议层必须保证收到的字节数据是完整且连续的这样内核才会将缓冲区里的数据返回给应用那么当前个字节数据没有到达时后收到的字节数据只能存放在内核缓冲区里只有等到这个字节数据到达时应用层才能从内核中拿到数据这就是队头阻塞问题优化前面我们知道了和都有队头阻塞的问题中的管道虽然解决了请求的队头阻塞但是没有解决响应的队头阻塞因为服务端需要按顺序响应收到的请求如果服务端处理某个请求消耗的时间比较长那么只能等响应完这个请求后才能处理下一个请求这属于层队头阻塞虽然通过多个请求复用一个连接解决了的队头阻塞但是一旦发生丢包就会阻塞住所有的请求这属于层队头阻塞队头阻塞的问题是因为所以把下层的协议改成了发送是不管顺序也不管丢包的所以不会出现像队头阻塞的问题大家都知道是不可靠传输的但基于的协议可以实现类似的可靠性传输有以下个特点无队头阻塞更快的连接建立连接迁移有自己的一套机制可以保证传输的可靠性的当某个流发生丢包时只会阻塞这个流其他流不会受到影响因此不存在队头阻塞问题这与不同只要某个流中的数据包丢失了其他流也会因此受影响所以是一个在之上的伪的多路复用的协议谈一谈网址到页面显示期间发生了什么过程浏览器对进行解析生成发送给服务器的请求信息通过查询服务器的域名对应的地址查找过程本地服务器根域名服务器顶级域名查找到的服务器返回的地址经过连接给数据添加头部头部地址通过网卡发送请求在网络中传输经过交换机和路由器找到将请求发送到服务器服务器响应请求返回数据浏览器进行页面渲染在浏览器中输入后执行的全部过程域名解析域名变为地址浏览器搜索自己的缓存维护一张域名与的对应表若没有则搜索操作系统的缓存维护一张域名与的对应表若没有则搜索操作系统的文件维护一张域名与的对应表若都没有则找参数中设置的首选服务器即本地服务器递归查询本地域名服务器查询自己的缓存如果没有则进行迭代查询将本地服务器将返回给操作系统同时缓存发起的三次握手建立连接浏览器会以一个随机端口向服务端的程序端口发起的连接建立连接后发起请求服务器响应请求客户端得到代码服务器应用程序收到请求后就开始处理请求处理之后就返回给浏览器文件浏览器解析代码并请求中的资源浏览器对页面进行渲染并呈现给用户与的区别的语义从服务器获取指定的资源的语义根据请求负载报文对指定的资源做出处理按照语义来说请求是安全且等幂的请求不是安全的也不是等幂的谈谈和有区别是超文本传输协议信息的传输时明文传输的存在风险解决了不完全的缺陷主要时在和网络层之间增加了一个的安全协议使得报文能够加密传输建立连接相对比较简单通过的三次握手就行而在三次握手基础上还多了一个的握手过程才能进行加密传输两个的默认端口也不同默认时端口默认时端口还要向证书权威机构申请数字证书来确认服务器的身份是可信的什么是和什么是也叫或浏览器是服务器发送到用户浏览器并保存在本地的一小块数据它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上通常它用于告知服务端两个请求是否来自同一浏览器如保持用户的登录状态使基于无状态的协议记录稳定的状态信息成为了可能主要用于以下三个方面会话状态管理如用户登录状态购物车游戏分数或其它需要记录的信息个性化设置如用户自定义设置主题等浏览器行为跟踪如跟踪分析用户行为等什么是代表着服务器和客户端一次会话的过程对象存储特定用户会话所需的属性及配置信息这样当用户在应用程序的页之间跳转时存储在对象中的变量将不会丢失而是在整个用户会话中一直存在下去当客户端关闭会话或者超时失效时会话结束和是何如配合的呢用户第一次请求服务器的时候服务器根据用户提交的相关信息创建对应的请求返回时将此的唯一标识信息返回给浏览器浏览器接收到服务器返回的信息后会将此信息存入到中同时记录此属于哪个域名当用户第二次访问服务器的时候请求会自动判断此域名下是否存在信息如果存在自动将信息也发送给服务端服务端会从中获取再根据查找对应的信息如果没有找到说明用户没有登录或者登录失效如果找到证明用户已经登录可执行后面操作根据以上流程可知是连接和的一道桥梁大部分系统也是根据此原理来验证用户登录状态和的区别作用范围不同保存在客户端浏览器保存在服务器端存取方式的不同只能保存可以存任意数据类型一般情况下我们可以在中保持一些常用变量信息比如说等有效期不同可设置为长时间保持比如我们经常使用的默认登录功能一般失效时间较短客户端关闭或者超时都会失效隐私策略不同存储在客户端比较容易遭到不法获取早期有人将用户的登录名和密码存储在中导致信息被窃取存储在服务端安全性相对要好一些存储大小不同单个保存的数据不能超过可存储数据远高于如何考虑吧分布式问题在互联网公司为了可以支撑更大的流量后端往往需要多台服务器共同来支撑前端用户请求那如果用户在服务器登录了第二次请求跑到服务就会出现登录失效问题分布式一般会有以下几种解决方案客户端存储直接将信息存储在中是存储在客户端上的一小段数据客户端通过协议和服务器进行交互通常用来存储一些不敏感信息策略服务端使用代理每个请求按访问的分配这样来自同一固定访问一个后台服务器避免了在服务器创建第二次分发到服务器的现象复制任何一个服务器上的发生改变增删改该节点会把这个的所有内容序列化然后广播给所有其它节点共享服务端无状态话将用户的等信息使用缓存中间件如来统一管理保障分发到每一个服务器的响应结果都一致建议采用共享的方案什么是攻击全称分布式拒绝服务攻击最基本的攻击过程如下客户端向服务端发送请求链接数据包服务端向客户端发送确认数据包客户端不向服务端发送确认数据包服务器一直等待来自客户端的确认则是采用分布式的方法通过在网络上占领多台肉鸡用多台计算机发起攻击攻击现在基本没啥作用了因为服务器的性能都很好而且是多台服务器共同作用的模式黑客无法占上风对于攻击预防方法有减少时间在握手的第三步服务器会等待秒秒的时间减少这个等待时间就能释放更多的资源限制同时打开的半连接数目什么是攻击也称跨站脚本这种攻击是由于服务器将攻击者存储的数据原原本本地显示给其他用户所致的比如一个存在漏洞的论坛用户发帖时就可以引入带有标签的代码导致恶意代码的执行预防措施有前端过滤后端转义比如自带的处理器就具有转义功能注入是什么如何避免注入就是在用户输入的字符串中加入语句如果在设计不良的程序中忽略了检查那么这些注入进去的语句就会被数据库服务器误认为是正常的语句而运行攻击者就可以执行计划外的命令或访问未被授权的数据注入的原理主要有以下点恶意拼接查询利用注释执行非法命令传入非法参数添加额外条件避免注入的一些方法限制数据库权限给用户提供仅仅能够满足其工作的最低权限对进入数据库的特殊字符尖括号等转义处理提供参数化查询接口不要直接使用原生为什么又了协议还有协议和都是基于协议上的的话叫做远程服务调用从发展上来说的话主要使用在架构而更多的话是用于架构出现是比要早的且比目前主流的性能要更好所以大部分公司内部都还在使用什么是和连接是面向连接的可靠的基于字节流的传输层通信协议面向连接一定是一对一才能连接可靠的无论网络链路中出现什么情况都能够保证一个报文一定能够到达接收端字节流通过协议传输时消息可能会被操作系统分组成多个报文如果接受方不知道消息边界是无法读出一个有效的消息的报文时有序的当一个报文没有收到时即使它先收到后面的报文那么也不能交给应用层处理同时重复的报文会自动丢弃连接用于保证可靠性和流量控制维护的某些信息包括序列号窗口大小称为连接建立一个连接是需要客户端与服务端达成上述三个信息的共识由地址和端口号组成序列号用来解决乱序问题等窗口大小用来做流量控制为什么三次握手四次挥手三次握手以三个方面分析三次握手的原因三次握手才可以阻止重复历史连接的初始化主要原因三次握手才可以同步双方的初始序列号三次握手才可以避免资源浪费客户端服务器两次握手只保证了一方的初始序列号能被对方成功接收没办法保证双方的初始序列号都能被确认接收四次挥手第四次挥手要等个客户端发送收到收到经过个服务器收到信号发送发送收到报文最长生存时间聊一聊的重传机制超时重传指的是数据发送时刻到接收到确认的时刻的差值也就是包的往返时间超时重传时间是以超时重传时间表示超时重传的时间略大于快速重传快速重传的工作方式是当收到三个相同的报文时会在定时器过期之前重传丢失的报文段选择性确认在头部选项字段里面加一个的东西将已收到的数据的信息发送给发送方可以让发送方知道是发出去的包丢了还是接收方回应的包丢了可以知道是不是发送方的数据包被网络延迟了可以知道网络中是不是把发送方的数据包给复制了你知道滑动窗口吗图中的确认应答报文丢失也没关系因为可以通过下一个确认应答进行确认只要发送方收到了确认应答就意味着之前的所有数据接收方都收到了这个模式就叫累计确认或者累计应答发送窗口接收窗口如何做的流量控制和拥塞控制拥塞窗口拥塞窗口变化的规则只要网络中没有出现拥塞就会增大但网络中出现了拥塞就减少拥塞控制主要是四个算法慢启动拥塞避免拥塞发生快速恢复慢启动那慢启动涨到什么时候是个头呢有一个叫慢启动门限状态变量当时使用慢启动算法当时就会使用拥塞避免算法拥塞避免算法拥塞发生算法超时重传重置为快速重传超时重传快速重传快速恢复协议相关技术域名解析的功能可以将域名网站制动转换成地址域名的层级关系例如在域名中越靠右的位置表示层级越高根域名在最顶层它的下一层就是顶级域名再下一层是所以域名的层级关系类似一个树状的结构根服务器顶级域服务器权威服务器协议在我们生活中十分常见我们的电脑通常都是通过动态获取地址大大省去了配置信息繁琐的过程网络地址转换的话是一种网络地址转换技术提出的元婴的地址是非常紧缺的的提出缓解了地址耗尽的问题简单的来说就是同个公司家庭教室内的主机对外部通信时把私有地址转换成公有地址由于都依赖于自己的转换表因此会有以下的问题外部无法主动与内部服务器建立连接因为转换表没有转换记录转换表的生成与转换操作都会产生性能开销通信过程中如果路由器重启了所有的连接都将被重置如何解决潜在的问题穿透技术协议互联网控制报文协议主要的功能包括确认包是否成功送达目标地址报告发送过程中包被废弃的原因和改善网络设置等大致可以分为两大类一类是用于诊断的查询消息也就是查询报文类型另一类是通知出错原因的错误消息也就是差错报文类型聊一聊你对跨域的看法是一个标准全称是跨域资源共享需要浏览器和服务器同时支持目前所有浏览器都支持该功能浏览器不能低于整个通信过程都是浏览器自动完成不需要用户参与对于开发者来说通信与同源的通信没有差别代码完全一样浏览器一旦发现请求跨源就会自动添加一些附加的头信息有时还会多出一次附加的请求但用户不会有感觉因此实现通信的关键是服务器只要服务器实现了接口就可以跨源通信两种请求浏览器将请求分成两类简单请求和非简单请求只要同时满足以下两大条件就属于简单请求请求方法是以下三种方法之一的头信息不超出以下几种字段只限于三个值这是为了兼容表单因为历史上表单一直可以发出跨域请求的跨域设计就是只要表单可以发就可以直接发凡是不同时满足上面两个条件就属于非简单请求浏览器对这两种请求的处理是不一样的简单请求对于简单请求浏览器直接发出请求具体来说就是在头信息之中增加一个字段下面是一个例子浏览器发现这次跨源请求是简单请求就自动在头信息之中添加一个字段上面的头信息中字段用来说明本次请求来自哪个源协议域名端口服务器根据这个值决定是否同意这次请求如果指定的源不在许可范围内服务器会返回一个正常的回应浏览器发现这个回应的头信息没有包含字段详见下文就知道出错了从而抛出一个错误被的回调函数捕获注意这种错误无法通过状态码识别因为回应的状态码有可能是如果指定的域名在许可范围内服务器返回的响应会多出几个头信息字段上面的头信息之中有三个与请求相关的字段都以开头该字段是必须的它的值要么是请求时字段的值要么是一个表示接受任意域名的请求该字段可选它的值是一个布尔值表示是否允许发送默认情况下不包括在请求之中设为即表示服务器明确许可可以包含在请求中一起发给服务器这个值也只能设为如果服务器不要浏览器发送删除该字段即可该字段可选请求时对象的方法只能拿到个基本字段如果想拿到其他字段就必须在里面指定上面的例子指定可以返回字段的值属性上面说到请求默认不发送和认证信息如果要把发到服务器一方面要服务器同意指定字段另一方面开发者必须在请求中打开属性否则即使服务器同意发送浏览器也不会发送或者服务器要求设置浏览器也不会处理但是如果省略设置有的浏览器还是会一起发送这时可以显式关闭需要注意的是如果要发送就不能设为星号必须指定明确的与请求网页一致的域名同时依然遵循同源政策只有用服务器域名设置的才会上传其他域名的并不会上传且跨源原网页代码中的也无法读取服务器域名下的非简单请求预检请求非简单请求是那种对服务器有特殊要求的请求比如请求方法是或或者字段的类型是非简单请求的请求会在正式通信之前增加一次查询请求称为预检请求浏览器先询问服务器当前网页所在的域名是否在服务器的许可名单之中以及可以使用哪些动词和头信息字段只有得到肯定答复浏览器才会发出正式的请求否则就报错下面是一段浏览器的脚本上面代码中请求的方法是并且发送一个自定义头信息浏览器发现这是一个非简单请求就自动发出一个预检请求要求服务器确认可以这样请求下面是这个预检请求的头信息预检请求用的请求方法是表示这个请求是用来询问的头信息里面关键字段是表示请求来自哪个源除了字段预检请求的头信息包括两个特殊字段该字段是必须的用来列出浏览器的请求会用到哪些方法上例是该字段是一个逗号分隔的字符串指定浏览器请求会额外发送的头信息字段上例是预检请求的回应服务器收到预检请求以后检查了和字段以后确认允许跨源请求就可以做出回应上面的回应中关键的是字段表示可以请求数据该字段也可以设为星号表示同意任意跨源请求如果服务器否定了预检请求会返回一个正常的回应但是没有任何相关的头信息字段这时浏览器就会认定服务器不同意预检请求因此触发一个错误被对象的回调函数捕获控制台会打印出如下的报错信息服务器回应的其他相关字段如下该字段必需它的值是逗号分隔的一个字符串表明服务器支持的所有跨域请求的方法注意返回的是所有支持的方法而不单是浏览器请求的那个方法这是为了避免多次预检请求如果浏览器请求包括字段则字段是必需的它也是一个逗号分隔的字符串表明服务器支持的所有头信息字段不限于浏览器在预检中请求的字段该字段与简单请求时的含义相同该字段可选用来指定本次预检请求的有效期单位为秒上面结果中有效期是天秒即允许缓存该条回应秒即天在此期间不用发出另一条预检请求浏览器的正确请求和回应一旦服务器通过了预检请求以后每次浏览器正常的请求就都跟简单请求一样会有一个头信息字段服务器的回应也都会有一个头信息字段下面是预检请求之后浏览器的正常请求上面头信息的字段是浏览器自动添加的下面是服务器正常的回应上面头信息中字段是每次回应都必定包含的执行语句发生了什么执行流程可以看到的架构共分为两层层和存储引擎层层负责建立连接分析和执行大多数的核心功能模块都在这实现主要包括连接器查询缓存解析器预处理器优化器执行器等另外所有的内置函数如日期时间数学和加密函数等和所有跨存储引擎的功能如存储过程触发器视图等都在层实现存储引擎层负责数据的存储和提取支持等多个存储引擎不同的存储引擎共用一个层现在最常用的存储引擎是从版本开始成为了的默认存储引擎我们常说的索引数据结构就是由存储引擎层实现的不同的存储引擎支持的索引类型也不相同比如支持索引类型是树且是默认使用也就是说在数据表中创建的主键索引和二级索引默认使用的是树索引第一步连接器空闲连接会一直占用着吗当然不是了定义了空闲连接的最大空闲时长由参数控制的默认值是小时秒如果空闲连接超过了这个时间连接器就会自动将它断开的连接数有限制吗服务支持的最大连接数由参数控制比如我的服务默认是个超过这个值系统就会拒绝接下来的连接请求并报错提示的连接也跟一样有短连接和长连接的概念它们的区别如下短连接连接服务三次握手执行断开服务四次挥手长连接连接服务三次握手执行执行执行断开服务四次挥手可以看到使用长连接的好处就是可以减少建立连接和断开连接的过程所以一般是推荐使用长连接怎么解决长连接占用内存的问题有两种解决方式第一种定期断开长连接既然断开连接后就会释放连接占用的内存资源那么我们可以定期断开长连接第二种客户端主动重置连接版本实现了函数的接口注意这是接口函数不是命令那么当客户端执行了一个很大的操作后在代码里调用函数来重置连接达到释放内存的效果这个过程不需要重连和重新做权限验证但是会将连接恢复到刚刚创建完时的状态至此连接器的工作做完了简单总结一下与客户端进行三次握手建立连接校验客户端的用户名和密码如果用户名或密码不对则会报错如果用户名和密码都对了会读取该用户的权限然后后面的权限逻辑判断都基于此时读取到的权限第二步查询缓存对于更新比较频繁的表查询缓存的命中率很低的因为只要一个表有更新操作那么这个表的查询缓存就会被清空如果刚缓存了一个查询结果很大的数据还没被使用的时候刚好这个表有更新操作查询缓冲就被清空了相当于缓存了个寂寞所以版本直接将查询缓存删掉了也就是说开始执行一条查询语句不会再走到查询缓存这个阶段了对于之前的版本如果想关闭查询缓存我们可以通过将参数设置成这里说的查询缓存是层的也就是版本移除的是层的查询缓存并不是存储引擎中的第三步解析解析器在正式执行查询语句之前会先对语句做解析这个工作交由解析器来完成解析器解析器会做如下两件事情第一件事情词法分析会根据你输入的字符串识别出关键字出来例如语句在分析之后会得到个其中有个分别为和关键字非关键字关键字非关键字第二件事情语法分析根据词法分析的结果语法解析器会根据语法规则判断你输入的这个语句是否满足语法如果没问题就会构建出语法树这样方便后面模块获取类型表名字段名条件等等通过词法分析和语法分析构建语法树第四步执行语句经过解析器后接着就要进入执行查询语句的流程了每条查询语句流程主要可以分为下面这三个阶段阶段也就是预处理阶段预处理器阶段也就是优化阶段优化器阶段也就是执行阶段执行器经历完优化器后就确定了执行方案接下来就真正开始执行语句了这个工作是由执行器完成的在执行的过程中执行器就会和存储引擎交互了交互是以记录为单位的接下来用三种方式执行过程跟大家说一下执行器和存储引擎的交互过程主键索引查询全表扫描索引下推总结执行一条查询语句期间发生了什么连接器建立连接管理连接校验用户身份查询缓存查询语句如果命中查询缓存则直接返回否则继续往下执行已删除该模块解析通过解析器对查询语句进行词法分析语法分析然后构建语法树方便后续模块读取表名字段语句类型执行执行共有三个阶段预处理阶段检查表或字段是否存在将中的符号扩展为表上的所有列优化阶段基于查询成本的考虑选择查询成本最小的执行计划执行阶段根据执行计划执行查询语句从存储引擎读取记录返回给客户端的一行记录时如何存储的的数据存放在哪个文件我们每创建一个数据库都会在目录里面创建一个以为名的目录然后保存表结构和表数据的文件都会存放在这个目录里用来存储当前数据库的默认字符集和字符校验规则的表结构会保存在这个文件在中建立一张表都会生成一个文件该文件是用来保存每个表的元数据信息的主要包含表结构定义的表数据会保存在这个文件表数据既可以存在共享表空间文件文件名里也可以存放在独占表空间文件文件名表名字这个行为是由参数控制的若设置了参数为则会将存储的数据索引等信息单独存储在一个独占表空间从版本开始它的默认值就是了因此从这个版本之后中每一张表的数据都存放在一个独立的文件好了现在我们知道了一张数据库表的数据是保存在表名字的文件里的这个文件也称为独占表空间文件表空间文件的结构是怎么样的呢表空间由段区页行组成存储引擎的逻辑存储结构大致如下图行数据库表中的记录都是按行进行存放的每行记录根据不同的行格式有不同的存储结构后面我们详细介绍存储引擎的行格式也是本文重点介绍的内容页记录是按照行来存储的但是数据库的读取并不以行为单位否则一次读取也就是一次操作只能处理一行数据效率会非常低因此的数据是按页为单位来读写的也就是说当需要读一条记录的时候并不是将这个行记录从磁盘读出来而是以页为单位将其整体读入内存默认每个页的大小为也就是最多能保证的连续存储空间页是存储引擎磁盘管理的最小单元意味着数据库每次读写都是以为单位的一次最少从磁盘中读取的内容到内存中一次最少把内存中的内容刷新到磁盘中页的类型有很多常见的有数据页日志页溢出页等等数据表中的行记录是用数据页来管理的数据页的结构这里我就不讲细说了之前文章有说过感兴趣的可以去看这篇文章换一个角度看树总之知道表中的记录存储在数据页里面就行区我们知道存储引擎是用树来组织数据的树中每一层都是通过双向链表连接起来的如果是以页为单位来分配存储空间那么链表中相邻的两个页之间的物理位置并不是连续的可能离得非常远那么磁盘查询时就会有大量的随机随机是非常慢的解决这个问题也很简单就是让链表中相邻的页的物理位置也相邻这样就可以使用顺序了那么在范围查询扫描叶子节点的时候性能就会很高那具体怎么解决呢在表中数据量大的时候为某个索引分配空间的时候就不再按照页为单位分配了而是按照区为单位分配每个区的大小为对于的页来说连续的个页会被划为一个区这样就使得链表中相邻的页的物理位置也相邻就能使用顺序了段表空间是由各个段组成的段是由多个区组成的段一般分为数据段索引段和回滚段等索引段存放树的非叶子节点的区的集合数据段存放树的叶子节点的区的集合回滚段存放的是回滚数据的区的集合之前讲事务隔离的时候就介绍到了利用了回滚段实现了多版本查询数据好了终于说完表空间的结构了接下来就具体讲一下的行格式了之所以要绕一大圈才讲行记录的格式主要是想让大家知道行记录是存储在哪个文件以及行记录在这个表空间文件中的哪个区域有一个从上往下切入的视角这样理解起来不会觉得很抽象行格式有哪些行格式就是一条记录的存储结构提供了种行格式分别是和行格式是很古老的行格式了版本之前用的行格式现在基本没人用了由于不是一种紧凑的行格式所以之后引入了行记录存储方式是一种紧凑的行格式设计的初衷就是为了让一个数据页中可以存放更多的行记录从版本之后行格式默认设置成和两个都是紧凑的行格式它们的行格式都和差不多因为都是基于改进一点东西从版本之后默认使用行格式行格式我这里就不讲了因为现在基本没人用了这次重点介绍行格式因为和这两个行格式跟非常像所以弄懂了行格式之后你们在去了解其他行格式很快也能看懂行格式长什么样呢先跟行格式混个脸熟它长这样一行行溢出后是怎么处理的中磁盘和内存交互的基本单位是页一个页的大小一般是也就是字节而一个类型的列最多可以存储字节一些大对象如可能存储更多的数据这时一个页可能就存不了一条记录这个时候就会发生行溢出多的数据就会存到另外的溢出页中如果一个数据页存不了一条记录存储引擎会自动将溢出的数据存放到溢出页中在一般情况下的数据都是存放在数据页中但是当发生行溢出时溢出的数据会存放到溢出页中当发生行溢出时在记录的真实数据处只会保存该列的一部分数据而把剩余的数据放在溢出页中然后真实数据处用字节存储指向溢出页的地址从而可以找到剩余数据所在的页大致如下图所示上面这个是行格式在发生行溢出后的处理和这两个行格式和非常类似主要的区别在于处理行溢出数据时有些区别这两种格式采用完全的行溢出方式记录的真实数据处不会存储该列的一部分数据只存储个字节的指针来指向溢出页而实际的数据都存储在溢出页中看起来就像下面这样总结的值是怎么存放的的行格式中会用值列表来标记值为的列值并不会存储在行格式中的真实数据部分值列表会占用字节空间当表中所有字段都定义成行格式中就不会有值列表这样可节省字节的空间怎么知道实际占用数据的大小的行格式中会用变长字段长度列表存储变长字段实际占用的数据大小中最大取值为多少一行记录最大能存储字节的数据但是这个是包含变长字段字节数列表所占用的字节数和值列表所占用的字节数所以我们在算中最大值时需要减去这两个列表所占用的字节数如果一张表只有一个字段且允许为字符集为中最大取值为计算公式变长字段字节数列表所占用的字节数值列表所占用的字节数如果有多个字段的话要保证所有字段的长度变长字段字节数列表所占用的字节数值列表所占用的字节数行溢出后是怎么处理的如果一个数据页存不了一条记录存储引擎会自动将溢出的数据存放到溢出页中行格式针对行溢出的处理是这样的当发生行溢出时在记录的真实数据处只会保存该列的一部分数据而把剩余的数据放在溢出页中然后真实数据处用字节存储指向溢出页的地址从而可以找到剩余数据所在的页和这两种格式采用完全的行溢出方式记录的真实数据处不会存储该列的一部分数据只存储个字节的指针来指向溢出页而实际的数据都存储在溢出页中索引什么是索引当你想查阅书中某个知识的内容你会选择一页一页的找呢还是在书的目录去找呢傻瓜都知道时间是宝贵的当然是选择在书的目录去找找到后再翻到对应的页书中的目录就是充当索引的角色方便我们快速查找书中的内容所以索引是以空间换时间的设计思想那换到数据库中索引的定义就是帮助存储引擎快速获取数据的一种数据结构形象的说就是索引是数据的目录所谓的存储引擎说白了就是如何存储数据如何为存储的数据建立索引和如何更新查询数据等技术的实现方法存储引擎有其中是在之后成为默认的存储引擎下图是的结构图索引和数据就是位于存储引擎中索引的分类我们可以按照四个角度来分类索引按数据结构分类索引索引索引按物理存储分类聚簇索引主键索引二级索引辅助索引按字段特性分类主键索引唯一索引普通索引前缀索引按字段个数分类单列索引联合索引西湖业务除了大数据树是如何存储数据的支持多种存储引擎不同的存储引擎存储数据的方式也是不同的我们最常使用的是存储引擎所以就跟大家图解下是如何存储数据的记录是按照行来存储的但是数据库的读取并不以行为单位否则一次读取也就是一次操作只能处理一行数据效率会非常低因此的数据是按数据页为单位来读写的也就是说当需要读一条记录的时候并不是将这个记录本身从磁盘读出来而是以页为单位将其整体读入内存数据库的操作的最小单位是页数据页的默认大小是意味着数据库每次读写都是以为单位的一次最少从磁盘中读取的内容到内存中一次最少把内存中的内容刷新到磁盘中页目录创建的过程如下将所有的记录划分成几个组这些记录包括最小记录和最大记录但不包括标记为已删除的记录每个记录组的最后一条记录就是组内最大的那条记录并且最后一条记录的头信息中会存储该组一共有多少条记录作为字段上图中粉红色字段页目录用来存储每组最后一条记录的地址偏移量这些地址偏移量会按照先后顺序存储起来每组的地址偏移量也被称之为槽每个槽相当于指针指向了不同组的最后一个记录从图可以看到页目录就是由多个槽组成的槽相当于分组记录的索引然后因为记录是按照主键值从小到大排序的所以我们通过槽查找记录时可以使用二分法快速定位要查询的记录在哪个槽哪个记录分组定位到槽后再遍历槽内的所有记录找到对应的记录无需从最小记录开始遍历整个页中的记录链表以上面那张图举个例子个槽的编号分别为我想查找主键为的用户记录先二分得出槽中间位是号槽里最大的记录为因为所以需要从号槽后继续搜索记录再使用二分搜索出号和槽的中间位是号槽里最大的记录为因为所以主键为的记录在号槽里这里有个问题槽对应的值都是这个组的主键最大的记录如何找到组里最小的记录比如槽对应最大主键是的记录那如何找到最小记录解决办法是通过槽找到槽对应的记录也就是主键为的记录主键为的记录的下一条记录就是槽当中主键最小的记录然后开始向下搜索次定位到主键为的记录取出该条记录的信息即为我们想要查找的内容看到第三步的时候可能有的同学会疑问如果某个槽内的记录很多然后因为记录都是单向链表串起来的那这样在槽内查找某个记录的时间复杂度不就是了吗这点不用担心对每个分组中的记录条数都是有规定的槽内的记录就只有几条第一个分组中的记录只能有条记录最后一个分组中的记录条数范围只能在条之间剩下的分组中记录条数范围只能在条之间树是如何进行查询的呢的数据是按数据页为单位来读写的默认数据页大小为每个数据页之间通过双向链表的形式组织起来物理上不连续但是逻辑上连续数据页内包含用户记录每个记录之间用单向链表的方式组织起来为了加快在数据页内高效查询记录设计了一个页目录页目录存储各个槽分组且主键值是有序的于是可以通过二分查找法的方式进行检索从而提高效率为了高效查询记录所在的数据页采用树作为索引每个节点都是一个数据页如果叶子节点存储的是实际数据的就是聚簇索引一个表只能有一个聚簇索引如果叶子节点存储的不是实际数据而是主键值则就是二级索引一个表中可以有多个二级索引在使用二级索引进行查找数据时如果查询的数据能在二级索引找到那么就是索引覆盖操作如果查询的数据不在二级索引里就需要先在二级索引找到主键值需要去聚簇索引中获得数据行这个过程就叫作回表为什么采用树作为索引是会将数据持久化在硬盘而存储功能是由存储引擎实现的所以讨论使用哪种数据结构作为索引实际上是在讨论存储引使用哪种数据结构作为索引是默认的存储引擎它就是采用了树作为索引的数据结构要设计一个的索引数据结构不仅仅考虑数据结构增删改的时间复杂度更重要的是要考虑磁盘的操作次数因为索引和记录都是存放在硬盘硬盘是一个非常慢的存储设备我们在查询数据的时候最好能在尽可能少的磁盘的操作次数内完成二分查找树虽然是一个天然的二分结构能很好的利用二分查找快速定位数据但是它存在一种极端的情况每当插入的元素都是树内最大的元素就会导致二分查找树退化成一个链表此时查询复杂度就会从降低为为了解决二分查找树退化成链表的问题就出现了自平衡二叉树保证了查询操作的时间复杂度就会一直维持在但是它本质上还是一个二叉树每个节点只能有个子节点随着元素的增多树的高度会越来越高而树的高度决定于磁盘操作的次数因为树是存储在磁盘中的访问每个节点都对应一次磁盘操作也就是说树的高度就等于每次查询数据时磁盘操作的次数所以树的高度越高就会影响查询性能树和都是通过多叉树的方式会将树的高度变矮所以这两个数据结构非常适合检索存于磁盘中的数据但是默认的存储引擎采用的是作为索引的数据结构原因有树的非叶子节点不存放实际的记录数据仅存放索引因此数据量相同的情况下相比存储即存索引又存记录的树树的非叶子节点可以存放更多的索引因此树可以比树更矮胖查询底层节点的磁盘次数会更少树有大量的冗余节点所有非叶子节点都是冗余索引这些冗余索引让树在插入删除的效率都更高比如删除根节点的时候不会像树那样会发生复杂的树的变化树叶子节点之间用链表连接了起来有利于范围查询而树要实现范围查询因此只能通过树的遍历来完成范围查询这会涉及多个节点的磁盘操作范围查询效率不如树事务事务隔离级别是如何实现的事务有哪些特性呢事务是由的引擎来实现的我们常见的引擎它是支持事务的不过并不是所有的引擎都能支持事务比如原生的引擎就不支持事务也正是这样所以大多数的引擎都是用事务看起来感觉简单但是要实现事务必须要遵守个特性分别如下原子性一个事务中的所有操作要么全部完成要么全部不完成不会结束在中间某个环节而且事务在执行过程中发生错误会被回滚到事务开始前的状态就像这个事务从来没有执行过一样就好比买一件商品购买成功时则给商家付了钱商品到手购买失败时则商品在商家手中消费者的钱也没花出去一致性是指事务操作前和操作后数据满足完整性约束数据库保持一致性状态比如用户和用户在银行分别有元和元总共元用户给用户转账元分为两个步骤从的账户扣除元和对的账户增加元一致性就是要求上述步骤操作后最后的结果是用户还有元用户有元总共元而不会出现用户扣除了元但用户未增加的情况该情况用户和均为元总共元隔离性数据库允许多个并发事务同时对其数据进行读写和修改的能力隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致因为多个事务同时使用相同的数据时不会相互干扰每个事务都有一个完整的数据空间对其他并发事务是隔离的也就是说消费者购买商品这个事务是不影响其他消费者购买的持久性事务处理结束后对数据的修改就是永久的即便系统故障也不会丢失引擎通过什么技术来保证事务的这四个特性的呢持久性是通过重做日志来保证的原子性是通过回滚日志来保证的隔离性是通过多版本并发控制或锁机制来保证的一致性则是通过持久性原子性隔离性来保证这次将重点介绍事务的隔离性这也是面试时最常问的知识的点为什么事务要有隔离性我们就要知道并发事务时会引发什么问题事务隔离级别有哪些前面我们提到当多个事务并发执行时可能会遇到脏读不可重复读幻读的现象这些现象会对事务的一致性产生不同程序的影响脏读读到其他事务未提交的数据不可重复读前后读取的数据不一致幻读前后读取的记录数量不一致这三个现象的严重性排序如下标准提出了四种隔离级别来规避这些现象隔离级别越高性能效率就越低这四个隔离级别如下读未提交指一个事务还没提交时它做的变更就能被其他事务看到读提交指一个事务提交之后它做的变更才能被其他事务看到可重复读指一个事务执行过程中看到的数据一直跟这个事务启动时看到的数据是一致的引擎的默认隔离级别串行化会对记录加上读写锁在多个事务对这条记录进行读写操作时如果发生了读写冲突的时候后访问的事务必须等前一个事务执行完成才能继续执行总结事务是在引擎层实现的我们常见的引擎是支持事务的事务的四大特性是原子性一致性隔离性持久性我们这次主要讲的是隔离性当多个事务并发执行的时候会引发脏读不可重复读幻读这些问题那为了避免这些问题提出了四种隔离级别分别是读未提交读已提交可重复读串行化从左往右隔离级别顺序递增隔离级别越高意味着性能越差引擎的默认隔离级别是可重复读要解决脏读现象就要将隔离级别升级到读已提交以上的隔离级别要解决不可重复读现象就要将隔离级别升级到可重复读以上的隔离级别而对于幻读现象不建议将隔离级别升级为串行化因为这会导致数据库并发时性能很差引擎的默认隔离级别虽然是可重复读但是它很大程度上避免幻读现象并不是完全解决了详见这篇文章解决的方案有两种针对快照读普通语句是通过方式解决了幻读因为可重复读隔离级别下事务执行过程中看到的数据一直跟这个事务启动时看到的数据是一致的即使中途有其他事务插入了一条数据是查询不出来这条数据的所以就很好了避免幻读问题针对当前读等语句是通过记录锁间隙锁方式解决了幻读因为当执行语句的时候会加上如果有其他事务在锁范围内插入了一条记录那么这个插入语句就会被阻塞无法成功插入所以就很好了避免幻读问题对于读提交和可重复读隔离级别的事务来说它们是通过来实现的它们的区别在于创建的时机不同读提交隔离级别是在每个都会生成一个新的也意味着事务期间的多次读取同一条数据前后两次读的数据可能会出现不一致因为可能这期间另外一个事务修改了该记录并提交了事务可重复读隔离级别是启动事务时生成一个然后整个事务期间都在用这个这样就保证了在事务期间读到的数据都是事务启动前的记录这两个隔离级别实现是通过事务的里的字段和记录中的两个隐藏列的比对来控制并发事务访问同一个记录时的行为这就叫多版本并发控制在可重复读隔离级别中普通的语句就是基于实现的快照读也就是不会加锁的而语句就不是快照读了而是当前读了也就是每次读都是拿到最新版本的数据但是它会对读到的记录加上锁引擎的可重复读隔离级别默认隔离级根据不同的查询方式分别提出了避免幻读的方案针对快照读普通语句是通过方式解决了幻读针对当前读等语句是通过记录锁间隙锁方式解决了幻读我举例了两个发生幻读场景的例子第一个例子对于快照读并不能完全避免幻读现象因为当事务更新了一条事务插入的记录那么事务前后两次查询的记录条目就不一样了所以就发生幻读第二个例子对于当前读如果事务开启后并没有执行当前读而是先快照读然后这期间如果其他事务插入了一条记录那么事务后续使用当前读进行查询的时候就会发现两次查询的记录条目就不一样了所以就发生幻读所以可重复读隔离级别并没有彻底解决幻读只是很大程度上避免了幻读现象的发生要避免这类特殊场景下发生幻读的现象的话就是尽量在开启事务之后马上执行这类当前读的语句因为它会对记录加从而避免其他事务插入一条新记录锁全局锁全局锁是怎么用的要使用全局锁则要执行这条命令执行后整个数据库就处于只读状态了这时其他线程执行以下操作都会被阻塞对数据的增删改操作比如等语句对表结构的更改操作比如等语句全局锁应用场景是什么全局锁主要应用于做全库逻辑备份这样在备份数据库期间不会因为数据或表结构的更新而出现备份文件的数据与预期的不一样举个例子大家就知道了在全库逻辑备份期间假设不加全局锁的场景看看会出现什么意外的情况如果在全库逻辑备份期间有用户购买了一件商品一般购买商品的业务逻辑是会涉及到多张数据库表的更新比如在用户表更新该用户的余额然后在商品表更新被购买的商品的库存那么有可能出现这样的顺序先备份了用户表的数据然后有用户发起了购买商品的操作接着再备份商品表的数据也就是在备份用户表和商品表之间有用户购买了商品这种情况下备份的结果是用户表中该用户的余额并没有扣除反而商品表中该商品的库存被减少了如果后面用这个备份文件恢复数据库数据的话用户钱没少而库存少了等于用户白嫖了一件商品所以在全库逻辑备份期间加上全局锁就不会出现上面这种情况了加全局锁又会带来什么缺点呢加上全局锁意味着整个数据库都是只读状态那么如果数据库里有很多数据备份就会花费很多的时间关键是备份期间业务只能读数据而不能更新数据这样会造成业务停滞既然备份数据库数据的时候使用全局锁会影响业务那有什么其他方式可以避免有的如果数据库的引擎支持的事务支持可重复读的隔离级别那么在备份数据库之前先开启事务会先创建然后整个事务执行期间都在用这个而且由于的支持备份期间业务依然可以对数据进行更新操作因为在可重复读的隔离级别下即使其他事务更新了表的数据也不会影响备份数据库时的这就是事务四大特性中的隔离性这样备份期间备份的数据一直是在开启事务时的数据备份数据库的工具是在使用时加上参数的时候就会在备份数据库之前先开启事务这种方法只适用于支持可重复读隔离级别的事务的存储引擎存储引擎默认的事务隔离级别正是可重复读因此可以采用这种方式来备份数据库但是对于这种不支持事务的引擎在备份数据库时就要使用全局锁的方法表级锁表级锁有哪些具体怎么用的里面表级别的锁有这几种表锁元数据锁锁结构的每个语句执行的时候都会拿到这个锁意向锁锁的是一种表锁不需要显式使用在访问一个表的时候会被自动加上的作用是保证读写的正确性简单的理解就是用线程在访问一张表的数据查询或者操作时是不允许其他线程修改此表的结构的这个限制就是通过来实现的对于表数据的操作查询获取的是读锁对于表结构的修改操作会有写锁和读锁主要是为了并发高效性和数据一致性会有锁的降级和升级过程行锁引擎是支持行级锁的而引擎并不支持行级锁前面也提到普通的语句是不会对记录加锁的因为它属于快照读如果要在查询时对记录加行锁可以使用下面这两个方式这种查询会加锁的语句称为锁定读对读取的记录加共享锁对读取的记录加独占锁上面这两条语句必须在一个事务中因为当事务提交了锁就会被释放所以在使用这两条语句的时候要加上或者共享锁锁满足读读共享读写互斥独占锁锁满足写写互斥读写互斥行级锁的类型主要有三类记录锁也就是仅仅把一条记录锁上间隙锁锁定一个范围但是不包含记录本身的组合锁定一个范围并且锁定记录本身是如何枷锁的不要小看一条语句在生产机上使用不当可能会导致业务停滞甚至崩溃当我们要执行语句的时候确保条件中带上了索引列并且在测试机确认该语句是否走的是索引扫描防止因为扫描全表而对表中的所有记录加上锁我们可以打开参数这样可以预防操作时条件没有带上索引列如果发现即使在条件中带上了列索引列优化器走的还是全标扫描这时我们就要使用可以告诉优化器使用哪个索引这次就说到这啦下次要小心点别再被老板挨骂啦死锁了该怎么办死锁的四个必要条件互斥占有且等待不可强占用循环等待只要系统发生死锁这些条件必然成立但是只要破坏任意一个条件就死锁就不会成立在数据库层面有两种策略通过打破循环等待条件来解除死锁状态设置事务等待锁的超时时间当一个事务的等待时间超过该值后就对这个事务进行回滚于是锁就释放了另一个事务就可以继续执行了在中参数是用来设置超时时间的默认值时秒当发生超时后就出现下面这个提示开启主动死锁检测主动死锁检测在发现死锁后主动回滚死锁链条中的某一个事务让其他事务得以继续执行将参数设置为表示开启这个逻辑默认就开启当检测到死锁后就会出现下面这个提示上面这个两种策略是当有死锁发生时的避免方式我们可以回归业务的角度来预防死锁对订单做幂等性校验的目的是为了保证不会出现重复的订单那我们可以直接将字段设置为唯一索引列利用它的唯一性来保证订单表不会出现重复的订单不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常日志实现这一机制就是回滚日志它保证了事务的特性中的原子性是一种用于撤销回退的日志在事务没提交之前会先记录更新前的数据到日志文件里面当事务回滚时可以利用来进行回滚如下图每当引擎对一条记录进行操作修改删除新增时要把回滚时需要的信息都记录到里比如在插入一条记录时要把这条记录的主键值记下来这样之后回滚时只需要把这个主键值对应的记录删掉就好了在删除一条记录时要把这条记录中的内容都记下来这样之后回滚时再把由这些内容组成的记录插入到表中就好了在更新一条记录时要把被更新的列的旧值记下来这样之后回滚时再把这些列更新为旧值就好了一条记录的每一次更新操作产生的格式都有一个指针和一个事务通过可以知道该记录是被哪个事务修改的通过指针可以将这些串成一个链表这个链表就被称为版本链另外还有一个作用通过实现多版本并发控制对于读提交和可重复读隔离级别的事务来说它们的快照读普通语句是通过来实现的它们的区别在于创建的时机不同读提交隔离级别是在每个都会生成一个新的也意味着事务期间的多次读取同一条数据前后两次读的数据可能会出现不一致因为可能这期间另外一个事务修改了该记录并提交了事务可重复读隔离级别是启动事务时生成一个然后整个事务期间都在用这个这样就保证了在事务期间读到的数据都是事务启动前的记录这两个隔离级别实现是通过事务的里的字段和记录中的两个隐藏列和的比对如果不满足可见行就会顺着版本链里找到满足其可见性的记录从而控制并发事务访问同一个记录时的行为这就叫多版本并发控制具体的实现可以看我这篇文章事务隔离级别是怎么实现的因此两大作用实现事务回滚保障事务的原子性事务处理过程中如果出现了错误或者用户执行了语句可以利用中的历史数据将数据恢复到事务开始之前的状态实现多版本并发控制关键因素之一是通过实现的为每条记录保存多份历史数据在执行快照读普通语句的时候会根据事务的里的信息顺着的版本链找到满足其可见性的记录为了防止断电导致数据丢失的问题当有一条记录需要更新的时候引擎就会先更新内存同时标记为脏页然后将本次对这个页的修改以的形式记录下来这个时候更新就算完成了后续引擎会在适当的时候由后台线程将缓存在的脏页刷新到磁盘里这就是技术技术指的是的写操作并不是立刻写到磁盘上而是先写日志然后在合适的时间再写到磁盘上是物理日志记录了某个数据页做了什么修改比如对表空间中的数据页偏移量的地方做了更新每当执行一个事务就会产生这样的一条或者多条物理日志在事务提交时只要先将持久化到磁盘即可可以不需要等到将缓存在里的脏页数据持久化到磁盘当系统崩溃时虽然脏页数据没有持久化但是已经持久化接着重启后可以根据的内容将所有数据恢复到最新的状态被修改页面需要记录对应吗需要的开启事务后层更新记录前首先要记录相应的如果是更新操作需要把被更新的列的旧值记下来也就是要生成一条会写入中的页面不过在内存修改该页面后需要记录对应的和区别在哪这两种日志是属于存储引擎的日志它们的区别在于记录了此次事务完成后的数据状态记录的是更新之后的值记录了此次事务开始前的数据状态记录的是更新之前的值事务提交之前发生了崩溃重启后会通过回滚事务事务提交之后发生了崩溃重启后会通过恢复事务如下图要写到磁盘数据也要写磁盘为什么要多此一举写入的方式使用了追加操作所以磁盘操作是顺序写而写入数据需要先找到写入位置然后才写到磁盘所以磁盘操作是随机写磁盘的顺序写比随机写高效的多因此写入磁盘的开销更小针对顺序写为什么比随机写更快这个问题可以比喻为你有一个本子按照顺序一页一页写肯定比写一个字都要找到对应页写快得多可以说这是技术的另外一个优点的写操作从磁盘的随机写变成了顺序写提升语句的执行性能这是因为的写操作并不是立刻更新到磁盘上而是先记录在日志上然后在合适的时间再更新到磁盘上至此针对为什么需要这个问题我们有两个答案实现事务的持久性让有的能力能够保证在任何时间段突然崩溃重启后之前已提交的记录都不会丢失将写操作从随机写变成了顺序写提升写入磁盘的性能产生的是直接写入磁盘的吗不是的实际上执行一个事务的过程中产生的也不是直接写入磁盘的因为这样会产生大量的操作而且磁盘的运行速度远慢于内存所以也有自己的缓存每当产生一条时会先写入到后续在持久化到磁盘如下图默认大小可以通过参数动态的调整大小增大它的大小可以让处理大事务是不必写入磁盘进而提升写性能什么时候刷盘缓存在里的还是在内存中它什么时候刷新到磁盘主要有下面几个时机正常关闭时当中记录的写入量大于内存空间的一半时会触发落盘的后台线程每隔秒将持久化到磁盘每次事务提交时都将缓存在里的直接持久化到磁盘这个策略可由参数控制下面会说文件写满了怎么办默认情况下存储引擎有个重做日志文件组重做日志文件组由有个文件组成这两个日志的文件名叫和在重做日志组中每个的大小是固定且一致的假设每个设置的上限是那么总共就可以记录的操作重做日志文件组是以循环写的方式工作的从头开始写写到末尾就又回到开头相当于一个环形所以存储引擎会先写文件当文件被写满的时候会切换至文件当文件也被写满时会切换回文件我们知道是为了防止中的脏页丢失而设计的那么如果随着系统运行的脏页刷新到了磁盘中那么对应的记录也就没用了这时候我们擦除这些旧记录以腾出空间记录新的更新操作是循环写的方式相当于一个环形用表示当前记录写到的位置用表示当前要擦除的位置如下图图中的和的移动都是顺时针方向之间的部分图中的红色部分用来记录新的更新操作之间的部分图中蓝色部分待落盘的脏数据页记录如果追上了就意味着文件满了这时不能再执行新的更新操作也就是说会被阻塞因此所以针对并发量大的系统适当设置的文件大小非常重要此时会停下来将中的脏页刷新到磁盘中然后标记哪些记录可以被擦除接着对旧的记录进行擦除等擦除完旧记录腾出了空间就会往后移动图中顺时针然后恢复正常运行继续执行新的更新操作所以一次的过程就是脏页刷新到磁盘中变成干净页然后标记哪些记录可以被覆盖的过程在完成一条更新操作后层还会生成一条等之后事务提交的时候会将该事物执行过程中产生的所有统一写入文件文件是记录了所有数据库表结构变更和表数据修改的日志不会记录查询类的操作比如和操作为什么有了还要有这个问题跟的时间线有关系最开始里并没有引擎自带的引擎是但是没有的能力日志只能用于归档而是另一个公司以插件形式引入的既然只依靠是没有能力的所以使用来实现能力这两个日志有四个区别适用对象不同是的层实现的日志所有存储引擎都可以使用是存储引擎实现的日志文件格式不同有种格式类型分别是默认格式区别如下每一条修改数据的都会被记录到中相当于记录了逻辑操作所以针对这种格式可以称为逻辑日志主从复制中端再根据语句重现但有动态函数的问题比如你用了或者这些函数你在主库上执行的结果并不是你在从库执行的结果这种随时在变的函数会导致复制的数据不一致记录行数据最终被修改成什么样了这种格式的日志就不能称为逻辑日志了不会出现下动态函数的问题但的缺点是每行数据的变化结果都会被记录比如执行批量语句更新多少行数据就会产生多少条记录使文件过大而在格式下只会记录一个语句而已包含了和模式它会根据不同的情况自动使用模式和模式是物理日志记录的是在某个数据页做了什么修改比如对表空间中的数据页偏移量的地方做了更新写入方式不同是追加写写满一个文件就创建一个新的文件继续写不会覆盖以前的日志保存的是全量的日志是循环写日志空间大小是固定全部写满就从头开始保存未被刷入磁盘的脏页日志用途不同用于备份恢复主从复制用于掉电等故障恢复如果不小心整个数据库的数据被删除了能使用文件恢复数据吗不可以使用文件恢复只能使用文件恢复因为文件是循环写是会边写边擦除日志的只记录未被刷入磁盘的数据的物理日志已经刷入磁盘的数据都会从文件里擦除文件保存的是全量的日志也就是保存了所有数据变更的情况理论上只要记录在上的数据都可以恢复所以如果不小心整个数据库的数据被删除了得用文件恢复数据的数据都是存在磁盘中的那么我们要更新一条记录的时候得先要从磁盘读取该记录然后在内存中修改这条记录那修改完这条记录是选择直接写回到磁盘还是选择缓存起来呢当然是缓存起来好这样下次有查询语句命中了这条记录直接读取缓存中的记录就不需要从磁盘获取数据了为此存储引擎设计了一个缓冲池来提高数据库的读写性能有了后当读取数据时如果数据存在于中客户端就会直接读取中的数据否则再去磁盘中读取当修改数据时如果数据存在于中那直接修改中数据所在的页然后将其页设置为脏页该页的内存数据和磁盘上的数据已经不一致为了减少磁盘不会立即将脏页写入磁盘后续由后台线程选择一个合适的时机将脏页写入到磁盘主从复制的实现的主从复制依赖于也就是记录上的所有变化并以二进制形式保存在磁盘上复制的过程就是将中的数据从主库传输到从库上这个过程一般是异步的也就是主库上执行事务操作的线程不会等待复制的线程同步完成集群的主从复制过程梳理成个阶段写入主库写日志提交事务并更新本地存储数据同步把复制到所有从库上每个从库把写到暂存日志中回放回放并更新存储引擎中的数据具体详细过程如下主库在收到客户端提交事务的请求之后会先写入再提交事务更新存储引擎中的数据事务提交完成后返回给客户端操作成功的响应从库会创建一个专门的线程连接主库的线程来接收主库的日志再把信息写入的中继日志里再返回给主库复制成功的响应从库会创建一个用于回放的线程去读中继日志然后回放更新存储引擎中的数据最终实现主从的数据一致性在完成主从复制之后你就可以在写数据时只写主库在读数据时只读从库这样即使写请求会锁表或者锁记录也不会影响读请求的执行从库是不是越多越好不是的因为从库数量增加从库连接上来的线程也比较多主库也要创建同样多的线程来处理复制的请求对主库资源消耗比较高同时还受限于主库的网络带宽所以在实际使用中一个主库一般跟个从库套数据库主从备主这就是一主多从的集群结构主从复制还有哪些模型主要有三种同步复制主库提交事务的线程要等待所有从库的复制成功响应才返回客户端结果这种方式在实际项目中基本上没法用原因有两个一是性能很差因为要复制到所有节点才返回响应二是可用性也很差主库和所有从库任何一个数据库出问题都会影响业务异步复制默认模型主库提交事务的线程并不会等待同步到各从库就返回客户端结果这种模式一旦主库宕机数据就会发生丢失半同步复制版本之后增加的一种复制方式介于两者之间事务线程不用等待所有的从库复制成功响应只要一部分复制成功响应回来就行比如一主二从的集群只要数据成功复制到任意一个从库上主库的事务线程就可以返回给客户端这种半同步复制的方式兼顾了异步复制和同步复制的优点即使出现主库宕机至少还有一个从库有最新的数据不存在数据丢失的风险过程种三个日志三个日志讲完了至此我们可以先小结下语句的执行过程当优化器分析出成本最小的执行计划后执行器就按照执行计划开始进行更新操作具体更新一条记录的流程如下执行器负责具体执行会调用存储引擎的接口通过主键索引树搜索获取这一行记录如果这一行所在的数据页本来就在中就直接返回给执行器更新如果记录不在将数据页从磁盘读入到返回记录给执行器执行器得到聚簇索引记录后会看一下更新前的记录和更新后的记录是否一样如果一样的话就不进行后续更新流程如果不一样的话就把更新前的记录和更新后的记录都当作参数传给层让真正的执行更新记录的操作开启事务层更新记录前首先要记录相应的因为这是更新操作需要把被更新的列的旧值记下来也就是要生成一条会写入中的页面不过在内存修改该页面后需要记录对应的层开始更新记录会先更新内存同时标记为脏页然后将记录写到里面这个时候更新就算完成了为了减少磁盘不会立即将脏页写入磁盘后续由后台线程选择一个合适的时机将脏页写入到磁盘这就是技术的写操作并不是立刻写到磁盘上而是先写日志然后在合适的时间再将修改的行数据写到磁盘上至此一条记录更新完了在一条更新语句执行完成后然后开始记录该语句对应的此时记录的会被保存到并没有刷新到硬盘上的文件在事务提交时才会统一将该事务运行过程中的所有刷新到硬盘事务提交剩下的就是两阶段提交的事情了接下来就讲这个为什么需要两段提交事务提交后和都要持久化到磁盘但是这两个是独立的逻辑可能出现半成功的状态这样就造成两份日志之间的逻辑不一致举个例子假设这行数据的字段的值原本是然后执行如果在持久化和两个日志的过程中出现了半成功状态那么就有两种情况如果在将刷入到磁盘之后突然宕机了而还没有来得及写入重启后通过能将中这行数据的字段恢复到新值但是里面没有记录这条更新语句在主从架构中会被复制到从库由于丢失了这条更新语句从库的这一行字段是旧值与主库的值不一致性如果在将刷入到磁盘之后突然宕机了而还没有来得及写入由于还没写崩溃恢复以后这个事务无效所以这行数据的字段还是旧值而里面记录了这条更新语句在主从架构中会被复制到从库从库执行了这条更新语句那么这一行字段是新值与主库的值不一致性可以看到在持久化和这两份日志的时候如果出现半成功的状态就会造成主从环境的数据不一致性这是因为影响主库的数据影响从库的数据所以和必须保持一致才能保证主从数据一致为了避免出现两份日志之间的逻辑不一致的问题使用了两阶段提交来解决两阶段提交其实是分布式事务一致性协议它可以保证多个逻辑操作要不全部成功要不全部失败不会出现半成功的状态两阶段提交把单个事务的提交拆分成了个阶段分别是准备阶段和提交阶段每个阶段都由协调者和参与者共同完成注意不要把提交阶段和语句混淆了语句执行的时候会包含提交阶段举个拳击比赛的例子两位拳击手参与者开始比赛之前裁判协调者会在中间确认两位拳击手的状态类似于问你准备好了吗准备阶段裁判协调者会依次询问两位拳击手参与者是否准备好了然后拳击手听到后做出应答如果觉得自己准备好了就会跟裁判说准备好了如果没有自己还没有准备好比如拳套还没有带好就会跟裁判说还没准备好提交阶段如果两位拳击手参与者都回答准备好了裁判协调者宣布比赛正式开始两位拳击手就可以直接开打如果任何一位拳击手参与者回答没有准备好裁判协调者会宣布比赛暂停对应事务中的回滚操作两段提交的过程是怎样的在的存储引擎中开启的情况下会同时维护日志与的为了保证这两个日志的一致性使用了内部事务是的也有外部事务跟本文不太相关我就不介绍了内部事务由作为协调者存储引擎是参与者当客户端执行语句或者在自动提交的情况下内部开启一个事务分两阶段来完成事务的提交如下图从图中可看出事务的提交过程有两个阶段就是将的写入拆成了两个步骤和中间再穿插写入具体如下阶段将内部事务的写入到同时将对应的事务状态设置为然后将持久化到磁盘的作用阶段把写入到然后将持久化到磁盘的作用接着调用引擎的提交事务接口将状态设置为此时该状态并不需要持久化到磁盘只需要到文件系统的中就够了因为只要写磁盘成功就算的状态还是也没有关系一样会被认为事务已经执行成功异常重启会出现什么现象段提交我们来看看在两阶段提交的不同时刻异常重启会出现什么现象下图中有时刻和时刻都有可能发生崩溃不管是时刻已经写入磁盘还没写入磁盘还是时刻和都已经写入磁盘还没写入标识崩溃此时的都处于状态在重启后会按顺序扫描文件碰到处于状态的就拿着中的去查看是否存在此如果中没有当前内部事务的说明完成刷盘但是还没有刷盘则回滚事务对应时刻崩溃恢复的情况如果中有当前内部事务的说明和都已经完成了刷盘则提交事务对应时刻崩溃恢复的情况可以看到对于处于阶段的即可以提交事务也可以回滚事务这取决于是否能在中查找到与相同的如果有就提交事务如果没有就回滚事务这样就可以保证和这两份日志的一致性了所以说两阶段提交是以写成功为事务提交成功的标识因为写成功了就意味着能在中查找到与相同的处于阶段的加上完整重启就提交事务为什么要这么设计已经写入了之后就会被从库或者用这个恢复出来的库使用所以在主库上也要提交这个事务采用这个策略主库和备库的数据就保证了一致性事务没提交的时候会被持久化到磁盘吗会的事务执行中间过程的也是直接写在中的这些缓存在里的也会被后台线程每隔一秒一起持久化到磁盘也就是说事务没提交的时候也是可能被持久化到磁盘的有的同学可能会问如果崩溃了还没提交事务的已经被持久化磁盘了重启后数据不就不一致了放心这种情况重启会进行回滚操作因为事务没提交的时候是还没持久化到磁盘的所以可以在事务没提交之前持久化到磁盘但是必须在事务提交之后才可以持久化到磁盘两段提交有什么问题两阶段提交虽然保证了两个日志文件的数据一致性但是性能很差主要有两个方面的影响磁盘次数高对于双配置每个事务提交都会进行两次刷盘一次是刷盘另一次是刷盘锁竞争激烈两阶段提交虽然能够保证单事务两个日志的内容一致但在多事务的情况下却不能保证两者的提交顺序一致因此在两阶段提交的流程基础上还需要加一个锁来保证提交的原子性从而保证多事务的情况下两个日志的提交顺序一致为什么两阶段提交的磁盘次数会很高和在内存中都对应的缓存空间会缓存在会缓存在它们持久化到磁盘的时机分别由下面这两个参数控制一般我们为了避免日志丢失的风险会将这两个参数设置为当的时候表示每次提交事务都会将里的直接持久到磁盘当时表示每次事务提交时都将缓存在里的直接持久化到磁盘可以看到如果和当都设置为那么在每个事务提交过程中都会至少调用次刷盘操作一次是刷盘一次是落盘所以这会成为性能瓶颈为什么锁竞争激烈在早期的版本中通过使用锁来保证事务提交的顺序在一个事务获取到锁时才能进入阶段一直到阶段结束才能释放锁下个事务才可以继续进行操作通过加锁虽然完美地解决了顺序一致性的问题但在并发量较大的时候就会导致对锁的争用性能不佳减少磁盘次数的组提交引入了组提交机制当有多个事务提交的时候会将多个刷盘操作合并成一个从而减少磁盘的次数如果说个事务依次排队刷盘的时间成本是那么将这个事务一次性一起刷盘的时间成本则近似于引入了组提交机制后阶段不变只针对阶段将阶段拆分为三个过程阶段多个事务按进入的顺序将从写入文件不刷盘阶段对文件做操作多个事务的合并一次刷盘阶段各个事务按顺序做操作上面的每个阶段都有一个队列每个阶段有锁进行保护因此保证了事务写入的顺序第一个进入队列的事务会成为领导所在队列的所有事务全权负责整队的操作完成后通知队内其他事务操作结束对每个阶段引入了队列后锁就只针对每个队列进行保护不再锁住提交事务的整个过程可以看的出来锁粒度减小了这样就使得多个阶段可以并发执行从而提升效率有组提交那有组提交吗这个要看版本没有组提交有组提交在的组提交逻辑中每个事务各自执行阶段也就是各自将刷盘这样就没办法对进行组提交所以在版本中做了个改进在阶段不再让事务各自执行刷盘操作而是推迟到组提交的阶段也就是说阶段融合在了阶段这个优化是将的刷盘延迟到了阶段之中阶段之前通过延迟写的方式为做了一次组写入这样和都进行了优化接下来介绍每个阶段的过程注意下面的过程针对的是双配置和都配置为阶段第一个事务会成为阶段的此时后面到来的事务都是接着获取队列中的事务组由绿色事务组的对做一次即一次将同组事务的刷盘完成了阶段后将绿色这一组事务执行过程中产生的写入文件调用不会调用所以不会刷盘缓存在操作系统的文件系统中从上面这个过程可以知道阶段队列的作用是用于支撑的组提交如果在这一步完成后数据库崩溃由于中没有该组事务的记录所以会在重启后回滚该组事务阶段绿色这一组事务的写入到文件后并不会马上执行刷盘的操作而是会等待一段时间这个等待的时长由参数控制目的是为了组合更多事务的然后再一起刷盘如下过程不过在等待的过程中如果事务的数量提前达到了参数设置的值就不用继续等待了就马上将刷盘如下图从上面的过程可以知道阶段队列的作用是用于支持的组提交如果想提升组提交的效果可以通过设置下面这两个参数来实现表示在等待微妙后直接调用将处于文件系统中中的刷盘也就是将文件持久化到磁盘表示如果队列中的事务数达到个就忽视的设置直接调用将处于文件系统中中的刷盘如果在这一步完成后数据库崩溃由于中已经有了事务记录会在重启后通过刷盘的数据继续进行事务的提交阶段最后进入阶段调用引擎的提交事务接口将状态设置为阶段队列的作用是承接阶段的事务完成最后的引擎提交使得可以尽早的处理下一组事务最大化组提交的效率磁盘很高有什么优化的方法现在我们知道事务在提交的时候需要将和持久化到磁盘那么如果出现磁盘很高的现象我们可以通过控制以下参数来延迟和刷盘的时机从而降低磁盘的频率设置组提交的两个参数和参数延迟刷盘的时机从而减少的刷盘次数这个方法是基于额外的故意等待来实现的因此可能会增加语句的响应时间但即使进程中途挂了也没有丢失数据的风险因为早被写入到了只要系统没有宕机缓存在里的就会被持久化到磁盘将设置为大于的值比较常见是表示每次提交事务都但累积个事务后才相当于延迟了刷盘的时机但是这样做的风险是主机掉电时会丢个事务的日志将设置为表示每次事务提交时都只是缓存在里的写到文件注意写入到文件并不意味着写入到了磁盘因为操作系统的文件系统中有个专门用来缓存文件数据的所以写入文件意味着写入到了操作系统的文件缓存然后交由操作系统控制持久化到磁盘的时机但是这样做的风险是主机掉电的时候会丢数据一条语句流程具体更新一条记录的流程如下执行器负责具体执行会调用存储引擎的接口通过主键索引树搜索获取这一行记录如果这一行所在的数据页本来就在中就直接返回给执行器更新如果记录不在将数据页从磁盘读入到返回记录给执行器执行器得到聚簇索引记录后会看一下更新前的记录和更新后的记录是否一样如果一样的话就不进行后续更新流程如果不一样的话就把更新前的记录和更新后的记录都当作参数传给层让真正的执行更新记录的操作开启事务层更新记录前首先要记录相应的因为这是更新操作需要把被更新的列的旧值记下来也就是要生成一条会写入中的页面不过在内存修改该页面后需要记录对应的层开始更新记录会先更新内存同时标记为脏页然后将记录写到里面这个时候更新就算完成了为了减少磁盘不会立即将脏页写入磁盘后续由后台线程选择一个合适的时机将脏页写入到磁盘这就是技术的写操作并不是立刻写到磁盘上而是先写日志然后在合适的时间再将修改的行数据写到磁盘上至此一条记录更新完了在一条更新语句执行完成后然后开始记录该语句对应的此时记录的会被保存到并没有刷新到硬盘上的文件在事务提交时才会统一将该事务运行过程中的所有刷新到硬盘事务提交为了方便说明这里不说组提交的过程只说两阶段提交阶段将对应的事务状态设置为然后将刷新到硬盘阶段将刷新到磁盘接着调用引擎的提交事务接口将状态设置为将事务设置为状态后刷入到磁盘文件至此一条更新语句执行完成各个字段的意思执行计划中包含的信息如下查询序列号查询类型表名或者别名匹配的分区访问类型可能用到的索引实际用到的索引索引长度与索引比较的列估算的行数按表条件筛选的行百分比额外信息聊一聊项目中用到的远程过程调用通过进行通信让调用远程函数就像调用本地函数一样是的一种由提出典型特征就是使用座位接口定义语言是什么有哪些优点是一种高性能开源的远程过程调用框架它可以使不同平台和语言之间的服务相互通信它的优点包括高效性跨平台异步流处理支持多种语言安全易于使用和开源和的区别是什么是基于协议的一种风格而是一个独立于协议的框架基于资源的状态转移使用标准的方法而使用协议缓冲区进行序列化和反序列化支持异步流处理和双向流而通常只支持请求响应模式是什么为什么它被用于中是一种语言中立平台中立可扩展的序列化格式它可以用于数据交换和持久化它被用于中因为它可以实现高效的序列化和反序列化从而提高了的性能和效率的流程是什么流程分为四个步骤定义服务生成源代码实现服务启动服务首先需要定义要实现的服务及其接口使用编写接口定义文件其次使用编译器生成客户端和服务器端的源代码然后实现生成的接口最后启动服务器并将其部署在适当的位置支持哪些类型的序列化支持两种类型的序列化二进制使用和其中二进制序列化在效率和性能方面比序列化更优秀但是序列化在可读性方面更好可以方便地进行调试和测试分布式理论在理论计算机科学中定理又被称作布鲁尔定理它指出对于一个分布式计算系统来说不可能同时满足以下三点一致性等同于所有节点访问同一份最新的数据副本可用性每次请求都能获取到非错的响应但是不保证获取的数据为最新数据分区容错性以实际效果而言分区相当于对通信的时限要求系统如果不能在时限内达成数据一致性就意味着发生了分区的情况必须就当前操作在和之间做出选择根据定理分布式系统只能满足三项中的两项而不可能满足全部三项理解理论的最简单方式是想象两个节点分处分区两侧允许至少一个节点更新状态会导致数据不一致即丧失了性质如果为了保证数据一致性将分区一侧的节点设置为不可用那么又丧失了性质除非两个节点可以互相通信才能既保证又保证这又会导致丧失性质分布式锁的使用场景缓存击穿保护当缓存中的某个热点数据过期失效时多台服务器上的请求可能会同时穿透缓存直接访问数据库造成数据库压力过大甚至崩溃通过使用分布式锁仅允许一个请求去更新缓存其他请求等待锁释放后再读取已更新的缓存数据限流控制在高并发环境下为了防止系统被瞬时大量请求压垮可以使用分布式锁作为令牌桶或漏桶算法的一部分限制同一时刻能够执行特定操作的并发数分布式任务调度在分布式系统中确保某些任务只执行一次比如定时任务或一次性初始化任务可以通过分布式锁确保只有一个节点获得执行权限分布式事务一致性在分布式事务中为保证多服务协同修改共享资源的一致性分布式锁可用于协调跨多个数据库或服务的操作顺序实现类似于两阶段提交或多阶段提交的逻辑防止并发竞争条件在多节点环境下若多个节点可能同时访问同一资源如数据库行文件全局生成器等为避免并发冲突导致的数据不一致分布式锁可以用来保护关键资源的访问确保同一时刻只有一个节点对其进行操作分布式队列消费在消息队列处理中为防止同一条消息被多个消费者重复消费可以利用分布式锁确保每条消息只被一个消费者领取并处理游戏排行榜实时更新在网络游戏场景中每当玩家得分发生变化时需要实时更新排行榜为了避免多台服务器同时更新排行榜产生数据混乱可以使用分布式锁确保同一时间只有一个更新操作生效段提交和端提交以及所谓的两个阶段是指第一阶段投票阶段第二阶段提交阶段事务协调者给每个参与者发送消息每个参与者要么直接返回失败如权限验证失败要么在本地执行事务写本地的和日志但不提交到达一种万事俱备只欠东风的状态三阶段提交也叫三阶段提交协议是二阶段提交的改进版本也就是说除了引入超时机制之外把的投票阶段再次一分为二这样三阶段提交就有三个阶段指的就是三个操作基本类似两阶段提交由事务管理方发起向所有参与者发起请求根据请求的结果决定全部或是全部框架一般需要使用数据库持久化记录事务数据跟踪整个事务的执行状态并在事务失败后补偿重试具有一定的容灾能力在框架内所有的参与者的业务逻辑都需按照二阶段设计一阶段锁定和预备资源二阶段执行提交或释放资源算法和共识性算法的步骤算法共识算法是一种用于在分布式系统中实现一致性状态机复制的协议它通过一系列有序步骤确保了集群中的节点能够达成一致以下是算法的基本步骤概述领导者选举在中所有节点初始时处于跟随者状态每个跟随者都有一个随机的选举超时时间在超时后会变成候选人状态并开始新的选举轮次候选人向其他节点发送请求投票的消息收到大多数节点包括自己的投票后该候选人成为领导者如果一个任期内没有候选人在规定时间内获得多数票则重新进入选举过程日志复制领导者负责接收来自客户端的所有写入请求并将这些请求作为日志条目追加到自己的日志中领导者按顺序将新日志条目复制到跟随者节点上通过调用完成跟随者必须响应领导者并确认它们已经正确地将日志条目附加到了本地日志中并遵循领导者的日志完整性约束如日志索引和任期号匹配提交日志当一条日志条目已经被复制到大多数节点上时领导者认为这条日志是已提交意味着它可以安全地应用于状态机进行状态更新领导者通知跟随者可以提交特定的日志条目跟随者根据领导者的指示更新其已提交日志的边界安全性保证确保不会出现同一索引位置有两个不同的日志条目通过领导者的强领导力和日志匹配规则来实现即使发生领导人变更新的领导人也只会提交已经复制到大多数节点上的日志条目以确保在整个集群中的一致性集群成员变更还定义了一种机制来安全地更改集群的成员资格即添加或移除节点这个过程同样需要在领导者控制下按照严格的协议执行通过上述步骤能够在面临网络分区消息丢失等故障的情况下保持集群的一致性和可用性算法算法是一种分布式一致性算法它用于解决在存在网络延迟部分节点失效等异步环境下的共识问题通常被描述为具有多个阶段以确保即使在网络不稳定的情况下也能达成一致的决策例如选择一个提案以下是简化版的两阶段过程准备阶段选择一个新的提案编号向集群中的大多数发送一个其中包含这个提议编号如果一个收到一个编号大于其之前已经响应过的任何请求的编号则它会承诺不再接受编号小于的提案如果它之前已经接受了某个提案则回复已经接受的提案值及其对应的提案编号如果有接受阶段当收到来自大多数对于其请求的确认后它可以进入阶段会选择一个值来提出可能是从收到的回复中已接受的最高编号提案的值如果没有这样的值则由自行决定一个值向大多数发送包括提案编号和选定的值如果一个收到一个提案并且该提案的编号是它所承诺过的即它没有对更高编号的请求做出过承诺那么它将接受这个提案并回复确认学习阶段当收到了大多数对其提案的确认后意味着提案已经被接受了因为大多数都同意了同一个提案值这时该提案可以被认为已被提交也就是说它是最终的决策通知所有通常是系统中的其他节点或客户端告诉他们提案的值已被确定根据接收到的通知更新状态算法的关键在于只有当一个提案获得了大多数的批准后才能被认为是有效的通过这种方式即使部分节点失败或消息丢失系统仍然能够保证安全性和最终一致性实际应用中为了提高效率和应对复杂场景可能会扩展成多轮投票或者优化为更高效的变种如或等区别算法的优点与缺点算法和算法都是分布式一致性算法用于在分布式系统中达成共识并确保数据的一致性尽管它们解决的问题相同但在设计哲学实现复杂度和易理解性方面存在显著差异算法的特点与优势易于理解与实现算法的设计目标之一就是清晰性和易理解性它将复杂的共识过程分解为几个明确的子模块如领导者选举日志复制和安全性保证等并且每个步骤都有详细的伪代码描述领导者的强化角色协议强调一个强领导的概念系统在任何时刻都只有一个明确的领导者负责处理客户端请求和日志同步日志复制简化通过日志连续性来简化了状态机复制的过程确保领导者的日志总是最新的并且严格要求所有节点按相同的顺序复制日志条目当新领导者被选举出来时它已经包含了所有已提交的日志条目明确定义的状态机转移将一致性算法划分为三种明确的角色状态以及几种明确的转换条件使协议流程更加直观算法的特点理论基础深厚由提出其初衷是解决非常理论化的一致性问题对于工程实践中的具体实现较为抽象多阶段过程原始的算法通常需要两个或更多的阶段并且为了提高效率在实际应用中往往采用变种该变种在一个领导者持续存在的前提下简化了多个提案的处理更灵活但较难理解允许更为灵活的领导者变更和日志结构比如日志可能存在空洞但这也导致了在实现时可能遇到的复杂性增加特别是在理解和调试阶段没有明确的角色划分中的角色功能不如那样明确分离例如和的角色可以在不同的提议过程中重叠增加了理解和实施的难度总结起来相对于的主要区别在于通过简化的设计使其更容易实现和教学对领导者的管理更为明确和单一从而降低了复杂性的日志管理规则比更为严格以减少不一致性的可能性在理论上更为通用和灵活而则牺牲了一定的灵活性换取了更高的可操作性和可维护性一致性算法算法分配的问题虚拟结点分布均匀个槽位不同的负载均衡算法适用的业务场景也不同的轮询这类的策略只能适用与每个节点的数据都是相同的场景访问任意节点都能请求到数据但是不适用分布式系统因为分布式系统意味着数据水平切分到了不同的节点上访问数据的时候一定要寻址存储该数据的节点哈希算法虽然能建立数据和节点的映射关系但是每次在节点数量发生变化的时候最坏情况下所有数据都需要迁移这样太麻烦了所以不适用节点数量变化的场景为了减少迁移的数据量就出现了一致性哈希算法一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上如果增加或者移除一个节点仅影响该节点在哈希环上顺时针相邻的后继节点其它数据也不会受到影响但是一致性哈希算法不能够均匀的分布节点会出现大量请求都集中在一个节点的情况在这种情况下进行容灾与扩容时容易出现雪崩的连锁反应为了解决一致性哈希算法不能够均匀的分布节点的问题就需要引入虚拟节点对一个真实节点做多个副本不再将真实节点映射到哈希环上而是将虚拟节点映射到哈希环上并将虚拟节点映射到实际节点所以这里有两层映射关系引入虚拟节点后可以会提高节点的均衡度还会提高系统的稳定性所以带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景而且适合节点规模会发生变化的场景操作系统缓存一致性由于和内存的访问性能相差比较大引入了高速缓存写入缓存后什么时候将缓存写回内存写直达把数据同时写入内存和每次都要写回内存操作费时写回新数据仅仅写入只有在被修改时才写回内存写回策略什么是缓存不一致问题由于现在的基本都是多核的那么会带来多核的缓存不一致问题解决思路第一点某个核心里的数据更新时必须要传播到其他核心的这个称为写传播第二点某个核心里对数据的操作顺序必须在其他核心看起来顺序是一样的这个称为事务的串行化实现事务的串行化核心对于中数据的操作需要同步给其他核心要引入锁的概念如果两个核心里有相同数据的那么对于这个数据的更新只有拿到了锁才能进行对应的数据更新基于总线嗅探机制的协议就满足上面了这两点因此它是保障缓存一致性的协议协议是已修改独占共享已失效这四个状态如何选择线程实时任务普通任务调度一种相对公平的调度策略希望给每个线程相同的运行时间运行时间权重每个都会有自己的运行队列值优先级优先级优先级什么是软中断中断操作系统为了响应硬件设备的请求操作系统收到硬件的中断请求会打断正在运行的进程然后调用内核中的中断处理程序来响应请求中断处理程序的上部分和下半部可以理解为上半部直接处理硬件请求也就是硬中断主要是负责耗时短的工作特点是快速执行下半部是由内核触发也就说软中断主要是负责上半部未完成的工作通常都是耗时比较长的事情特点是延迟执行中的软中断包括网络收发定时调度锁等各种类型聊一聊虚拟内存操作系统的保护模式和实模式实模式将整个物理内存看成分段的区域程序代码和数据位于不同区域系统程序和用户程序并没有区别对待而且每一个指针都是指向实际的物理地址这样一来用户程序的一个指针如果指向了系统程序区域或其他用户程序区域并修改了内容那么对于这个被修改的系统程序或用户程序其后果就很可能是灾难性的再者随着软件的发展的寻址空间已经远远不能满足实际的需求了最后对处理器多任务支持需求也日益紧迫所有这些都促使新技术的出现为了克服实模式下的内存非法访问问题并满足飞速发展的内存寻址和多任务需求处理器厂商开发出保护模式在保护模式中除了内存寻址空间大大提高提供了硬件对多任务的支持物理内存地址也不能直接被程序访问程序内部的地址虚拟地址要由操作系统转化为物理地址去访问程序对此一无所知至此进程程序的运行态有了严格的边界任何其他进程根本没有办法访问不属于自己的物理内存区域甚至在自己的虚拟地址范围内也不是可以任意访问的因为有一些虚拟区域已经被放进一些公共系统运行库这些区域也不能随便修改若修改就会有出现中的段错误或中的非法内存访问对话框虚拟内存它的内存布局大概是什么样子的我们程序所使用的内存地址叫做虚拟内存地址实际存在硬件里面的空间地址叫物理内存地址虚拟地址是操作系统给将内存的物理地址映射成一块虚拟地址分配给进程的一个进程就只知道虚拟地址而对操作系统的物理地址全然不知这样就不会发生冲突了每个进程都会有自己的虚拟空间而物理内存只有一个所以启动大量的进程的时候物理内存紧张于是操作系统会通过内存交换技术把不常用的内存暂时放到硬盘在需要的时候再装入物理内存最后说下虚拟内存有什么作用第一虚拟内存可以使得进程对运行内存超过物理内存大小因为程序运行符合局部性原理访问内存会有很明显的重复访问的倾向性对于那些没有被经常使用到的内存我们可以把它换出到物理内存之外比如硬盘上的区域第二由于每个进程都有自己的页表所以每个进程的虚拟内存空间就是相互独立的进程也没有办法访问其他进程的页表所以这些页表是私有的这就解决了多进程之间地址冲突的问题第三页表里的页表项中除了物理地址之外还有一些标记属性的比特比如控制一个页的读写权限标记该页是否存在等在内存访问方面操作系统提供了更好的安全性聊一聊进程和线程线程与进程的比较如下进程是资源包括内存打开的文件等分配的单位线程是调度的单位进程拥有一个完整的资源平台而线程只独享必不可少的资源如寄存器和栈线程同样具有就绪阻塞执行三种基本状态同样具有状态之间的转换关系线程能减少并发执行的时间和空间开销对于线程相比进程能减少开销体现在线程的创建时间比进程快因为进程在创建的过程中还需要资源管理信息比如内存管理信息文件管理信息而线程在创建的过程中不会涉及这些资源管理信息而是共享它们线程的终止时间比进程快因为线程释放的资源相比进程少很多同一个进程内的线程切换比进程切换快因为线程具有相同的地址空间虚拟内存共享这意味着同一个进程的线程都具有同一个页表那么在切换的时候不需要切换页表而对于进程之间的切换切换的时候要把页表给切换掉而页表的切换过程开销是比较大的由于同一进程的各线程间共享内存和文件资源那么在线程之间数据传递的时候就不需要经过内核了这就使得线程之间的数据交互效率更高了所以不管是时间效率还是空间效率线程比进程都要高说一说常见的调度算法先来先服务最短作业优先高响应比优先时间片轮转最高优先级多级反馈队列进程间的通信有哪些方式呢管道消息队列共享内存信号量信号怎么避免死锁两个线程都在等待对方释放锁在没有外力的作用下这些线程会一直相互等待就没办法继续运行这种情况就是发生了死锁死锁只有同时满足以下四个条件才会发生互斥条件持有并且等待不可剥夺条件环路等待网络系统什么是同步异步阻塞非阻塞同步与异步主要是从消息通知机制角度来说的关键在于调用者是否有等待这个行为出现同步主要靠调用者自己盯进度看被调用者的工作是否完成异步主要靠被调用者以某种方式来通知调用者它的任务完成了同步和异步关注点是消息通信机制是一种编程模型阻塞和非阻塞关注的是线程在等待调用结果消息结果时的状态阻塞调用是指调用结果返回之前当前线程做不了其他事情被挂起或者自旋调用线程只有在得到结果之后才会返回非阻塞调用指在不能立刻得到结果之前该调用不会阻塞当前线程例如返回一个结果代理对象或者错误码异步非阻塞效率是最高的体现在调用者没等被调用对象有机制提醒调用者活干完了同步阻塞编程比较简单体现在调用者等待被调用对象没有提醒调用者活干完的机制靠调用者盯进度同步非阻塞因为调用者不断分心在两件事间跳来跳去所以其实效率是不高的体现在调用者边等边做自己的事被调用对象没有提醒机制也靠调用者盯进度异步阻塞这种情况一般不存在实际上调用者还是在等被调用者因为尽管被调用对象有机制提醒调用者自己活干完了调用者还是什么都不干傻傻地在等待那我先讲下同步异步和阻塞非阻塞这两大块之间的区别他们针对的对象不同好比调用同步异步针对的是被调用者也就是阻塞非阻塞针对的是调用者也就是然后我们再来讲一下什么是同步和异步调用同步异步针对得是调用方如果是同步的话处理完后有结果了才通知如果是异步的话在接到请求后先告诉我已经接到请求了然后有结果后再通过通知或者状态等方式再通知同步和异步最大的区别就是被调用方的执行方式和返回时机什么是阻塞和非阻塞调用我们针对得是调用方如果是阻塞的话只能等待返回结果后才能去干别的事情如果是非阻塞得话就是不用等着返回结果可以先去做别的事情指的时用户空间和内核空间数据交互的方式同步用户空间要的数据必须等到内核空间给她做完才做其他事情而异步用户空间要的数据不需要等待内核空间给它才做其他事情内核空间会异步通知用户进程并把数据直接给到用户空间阻塞非阻塞指的是用户就和内核空间操作的方式阻塞用户空间通过系统调用和内核空间发送操作时该调用时阻塞的非阻塞用户空间通过系统调用和内核空间发送操作时该调用时不阻塞的直接返回的只是返回时可能没有数据而已所谓同步就是在发送出一个功能调用的时候在没有得到结果之前该调用就不返回当一个一步过程调用发出后调用者不会立刻得到结果实际出路这个调用的不见实在调用发出后通过状态通知来通知调用者或通过回调函数来处理这个调用看一个例子年我是一名党的高级特工受组织派遣深入敌后展开卧底行动同步组织在得到我的结果前不做事情等待我的结果然后做出行动异步组织可以去干一些不依赖我结果的事情截个道啊抢个仓啊同步消息通知机制好比简单的操作我们需要等待这两个操作完成才能返回同步是由处理消息者自己去等待消息是否被触发异步消息通知机制类似于之类的多路复用操作当所关注的消息被触发时由消息触发机制通知触发对消息的出路异步由触发机制来通知处理消息着阻塞非阻塞它们是程序在等待消息无所谓同步或异步时的状态阻塞阻塞调用是指调用结果返回之前当前线程会被挂起函数只有在得到结果之后才会返回有人也许会把阻塞调用和同步调用等同起来实际上他是不同的对于同步调用来说很多时候当前线程还是激活的只是从逻辑上当前函数没有返回而已非阻塞非阻塞和阻塞的概念相对应指在不能立刻得到结果之前该函数不会阻塞当前线程而会立刻返回例子继续上面的那个例子不论是叫个人天天蹲着等消息还是使用等待通知如果在这个等待的过程中等待者除了等待消息之外不能做其它的事情那么该机制就是阻塞的表现在程序中也就是该程序一直阻塞在该函数调用处不能继续往下执行相反在等待的时候我们可以磨磨枪埋埋雷这样的状态就是非阻塞的因为他等待者没有阻塞在这个消息通知上而是一边做自己的事情一边等待同步阻塞形式效率是最低的拿上面的例子来说就是你专心等待什么别的事都不做实际程序中就是未对设置标志位的操作异步阻塞形式异步操作是可以被阻塞住的只不过它不是在处理消息时阻塞而是在等待消息被触发时被阻塞比如函数假如传入的最后一个参数为那么如果所关注的事件没有一个被触发程序就会一直阻塞在这个调用处同步非阻塞形式实际上是效率低下的想象一下你一边做着事情一边看消息到了没有如果把磨枪和观察消息是程序的两个操作的话这个程序需要在这两种不同的行为之间来回的切换效率可想而知是低下的很多人会写阻塞的操作但是别忘了可以对设置标志位这样就可以将同步操作变成非阻塞的了什么是零拷贝在进行设备和内存的数据传输的时候数据搬运的工作全部交给控制器而不再参与任何与数据搬运相关的事情这样就可以去处理别的事务基于实现零拷贝实现零拷贝在内核版本中提供了一个专门发送文件的系统调用函数但是这还不是真正的零拷贝技术如果网卡支持技术和普通的有所不同我们可以进一步减少通过把内核缓冲区里的数据拷贝到缓冲区的过程于是从内核版本开始起对于支持网卡支持技术的情况下系统调用的过程发生了点变化具体过程如下第一步通过将磁盘上的数据拷贝到内核缓冲区里第二步缓冲区描述符和数据长度传到缓冲区这样网卡的控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里此过程不需要将数据从操作系统内核缓冲区拷贝到缓冲区中这样就减少了一次数据拷贝多路复用最基础的模型多进程模型多线程模型多路复用实现多路复用的方式是将已连接的都放到一个文件描述符集合然后调用函数将文件描述符集合拷贝到内核里让内核来检查是否有网络事件产生检查的方式很粗暴就是通过遍历文件描述符集合的方式当检查到有事件产生后将此标记为可读或可写接着再把整个文件描述符集合拷贝回用户态里然后用户态还需要再通过遍历的方法找到可读或可写的然后再对其处理所以对于这种方式需要进行次遍历文件描述符集合一次是在内核态里一个次是在用户态里而且还会发生次拷贝文件描述符集合先从用户空间传入内核空间由内核修改后再传出到用户空间中使用固定长度的表示文件描述符集合而且所支持的文件描述符的个数是有限制的在系统中由内核中的限制默认最大值为只能监听的文件描述符不再用来存储所关注的文件描述符取而代之用动态数组以链表形式来组织突破了的文件描述符个数限制当然还会受到系统文件描述符限制但是和并没有太大的本质区别都是使用线性结构存储进程关注的集合因此都需要遍历文件描述符集合来找到可读或可写的时间复杂度为而且也需要在用户态与内核态之间拷贝文件描述符集合这种方式随着并发数上来性能的损耗会呈指数级增长是解决问题的利器通过两个方面解决了的问题在内核里使用红黑树来关注进程所有待检测的红黑树是个高效的数据结构增删改一般时间复杂度是通过对这棵黑红树的管理不需要像在每次操作时都传入整个集合减少了内核和用户空间大量的数据拷贝和内存分配使用事件驱动的机制内核里维护了一个链表来记录就绪事件只将有事件发生的集合传递给应用程序不需要像那样轮询扫描整个集合包含有和无事件的大大提高了检测的效率而且支持边缘触发和水平触发的方式而只支持水平触发一般而言边缘触发的方式会比水平触发的效率高和是非阻塞同步网络模式感知的是就绪可读写事件在每次感知到有事件发生比如可读就绪事件后就需要应用进程主动调用方法来完成数据的读取也就是要应用进程主动将接收缓存中的数据读到应用进程内存中这个过程是同步的读取完数据后应用进程才能处理数据是异步网络模式感知的是已完成的读写事件在发起异步读写请求时需要传入数据缓冲区的地址用来存放结果数据等信息这样系统内核才可以自动帮我们把数据的读写工作完成这里的读写工作全程由操作系统来做并不需要像那样还需要应用进程主动发起来读写数据操作系统完成读写工作后就会通知应用进程直接处理数据常见的实现方案有三种第一种方案单单进程线程不用考虑进程间通信以及数据同步的问题因此实现起来比较简单这种方案的缺陷在于无法充分利用多核而且处理业务逻辑的时间不能太长否则会延迟响应所以不适用于计算机密集型的场景适用于业务处理快速的场景比如之前采用的是单单进程的方案第二种方案单多线程通过多线程的方式解决了方案一的缺陷但它离高并发还差一点距离差在只有一个对象来承担所有事件的监听和响应而且只在主线程中运行在面对瞬间高并发的场景时容易成为性能的瓶颈的地方第三种方案多多进程线程通过多个来解决了方案二的缺陷主只负责监听事件响应事件的工作交给了从和都采用了多多线程的方案则采用了类似于多多进程的方案可以理解为来了事件操作系统通知应用进程让应用进程来处理而可以理解为来了事件操作系统来处理处理完再通知应用进程因此真正的大杀器还是它是采用异步实现的异步网络模型感知的是已完成的读写事件而不需要像感知到事件后还需要调用来从内核中获取数据不过无论是还是都是一种基于事件分发的网络编程模式区别在于模式是基于待完成的事件而模式则是基于已完成的事件什么是一致性哈希系列是一个分布式的可扩展的容错的支持分区的多副本的基于框架的发布订阅消息系统适合离线和在线消息消费的设计是将消息以为单位进行归纳发布消息的程序称为消费消息的程序成为是以集群的方式运行的它可以由一个或多个服务组成每个服务叫做一个通过网络将消息发送到集群集群向消费者提供消息在中间起到一个代理保存消息的中间站消息生产者发布消息到集群的终端或服务一个节点就是一个多个可组成一个集群如果某个下有个且集群有个那么每个会存储该下的一个如果某个下有个且集群中有个那么只有个会存储该下的一个如果某个下有个且集群中的数量小于那么一个会存储该下的一个或多个这种情况尽量避免会导致集群数据不均衡消息主题每条发布到集群的消息都会归集于此是面向的是在物理上的分区一个可以分为多个每个是一个有序的不可变的记录序列单一主题中的分区有序但无法保证主题中所有分区的消息有序从集群中消费消息的终端或服务每个都属于一个每条消息只能被中的一个消费但可以被多个消费的副本用来保障的高可用性集群中的其中一个服务器用来进行以及各种操作通过来存储集群中的消息性能高原因探究利用了缓存磁盘顺序写零拷贝技术拉模式文件高效存储设计原理把中的一个大文件分成很多个小文件段通过多个小文件段就很容易定期清除或删除已完成消费完成的文件减少磁盘占用通过索引信息可以快速定位和确定的最大大小通过将索引元数据全部映射到可以避免文件的磁盘操作通过索引文件稀疏存储可以大幅度降低索引文件元数据占用空间大小的优缺点优点高性能高吞吐量低延迟生产和消费消息的速度都达到每秒万级高可用所有消息持久化存储到磁盘并支持数据备份防止数据丢失高并发支持数千个客户端同时读写容错性允许集群中节点失败若副本数量为则允许个节点失败高扩展性集群支持热伸缩无须停机缺点没有完整的监控工具集不支持通配符主题选择的应用场景日志聚合可收集各种服务的日志写入的消息队列进行存储消息系统广泛用于消息中间件系统解耦在重要操作完成后发送消息由别的服务系统来完成其他操作流量削峰一般用于秒杀或抢购活动中来缓冲网站短时间内高流量带来的压力异步处理通过异步处理机制可以把一个消息放入队列中但不立即处理它在需要的时候再进行处理为什么要把消息分区方便在集群中扩展每个可用通过调整以适应它所在的机器而一个又可以有多个组成因此整个集群就可以适应任意大小的数据了可以提高并发因为可以以为单位进行读写消息的消费模式采用大部分消息系统遵循的传统模式将消息推送到从获取消息如果采用模式则难以处理不同速率的上游推送消息采用模式的好处是可以自主决定是否批量的从拉取数据模式有个缺点是如果没有可供消费的消息将导致不断在循环中轮询直到新消息到达为了避免这点有个参数可以让阻塞直到新消息到达如何实现负载均衡和故障转移负载均衡是指让系统的负载根据一定的规则均衡地分配在所有参与工作的服务器上从而最大限度保证系统整体运行效率与稳定性负载均衡的负载均衡就是每个都有均等的机会为的客户端生产者与消费者提供服务可以负载分散到所有集群中的机器上通过智能化的分区领导者选举来实现负载均衡提供智能化的选举算法可在集群的所有机器上均匀分散各个的从而整体上实现负载均衡故障转移的故障转移是通过使用会话机制实现的每台服务器启动后会以会话的形式把自己注册到服务器上一旦服务器运转出现问题就会导致与的会话不能维持从而超时断连此时集群会选举出另一台服务器来完全替代这台服务器继续提供服务中的作用是一个使用构建的分布式系统的各在启动时都要在上注册由统一协调管理如果任何节点失败可通过从先前提交的偏移量中恢复因为它会做周期性提交偏移量工作同一个的消息会被分成多个分区并将其分布在多个上这些分区信息及与的对应关系也是在维护工作原理的高级概述客户端将任务放入队列服务器从队列中拉取任务并为每个任务启动一个工作协程任务由多个同时处理任务队列用作跨多台机器分配工作的机制一个系统可以由多个工作服务器和代理组成使其具有高可用性和水平扩展特性特性有很多易用的特性下面简单列举几个任务调度保证任务至少执行一次失败任务重试自动恢复优先级队列使用唯一选项对任务进行重复数据删除周期性任务可视化的管理界面支持集群和哨兵模式与集成以收集和可视化队列指标用于检查和远程控制队列和任务的用于检查和远程控制队列和任务的架构图里面包含了四个主要部分集群集群集群集群为什么使用而不是是专为设计的轻量级名称服务为和提供路由信息具有简单可集群横吐扩展无状态节点之间互不通信等特点而的架构设计决定了只需要一个轻量级的元数据服务器就足够了只需要保持最终一致而不需要这样的强一致性解决方案不需要再依赖另一个中间件从而减少整体维护成本如何防止消息丢失丢消息的场景生产者向发送消息时主节点向从节点同步消息时消费者向拉取消息消费时生产者端使用事务消息机制防止消息丢失端使用同步刷盘和主从架构防止消息丢失消费者端使用同步消费机制消费者从拉取消息然后执行相应的业务逻辑一旦执行成功将会返回状态给如果未收到消费确认响应或收到其他状态消费者下次还会再次拉取到该条消息进行重试如何保证消息有序全局有序整个系统的所有消息严格按照队列先入先出顺序进行消费局部有序只保证一部分关键消息的消费顺序对于局部有序只需要将有序的一组消息都存入同一个里这样的设计就可以保证这一组消息的有序即可以在发送者发送消息时指定一个对象让这个对象来决定消息发入哪一这样就可以保证一组有序的消息能够发到同一个里消费端是使用则已经默认实现了顺序消费如果是使用了则只需把线程池改成单线程模式如何实现延迟消息临时存储定时任务收到延时消息了会先发送到主题的相应时间段的中然后通过一个定时任务轮询这些队列到期后把消息投递到目标的队列中然后消费者就可以正常消费这些消息消费消息是还是没有真正意义的都是虽然有类但实际底层实现采用的是长轮询机制即拉取方式如何对消息去重只要通过网络交换数据就无法避免因为网络不可靠而造成的消息重复这个问题比如说中当消费完消息后因为网络问题未及时发送到就不会删掉当前已经消费过的消息那么该消息将会被重复投递给消费者去消费虽然保证了同一个消费组只能消费一次但会被不同的消费组重复消费因此这种重复消费的情况不可避免本身并不保证消息不重复这样肯定会因为每次的判断导致性能打折扣所以它将去重操作直接放在了消费端消费端处理消息的业务逻辑保持幂等性那么不管来多少条重复消息可以实现处理的结果都一样还可以建立一张日志表使用消息主键作为表的主键在处理消息前先表再做消息处理这样可以避免消息重复消费有几种模式模式模式轮询分发公平分发模式发布订阅模式路由模式主题模式模式常见限流算法那么我们先来看什么是限流通过对并发访问请求进行限速或者对一个时间窗口内的请求进行限速来保护系统一旦达到限制速率则可以拒绝服务排队或等待降级等处理避免瞬间流量过大冲垮系统应用场景一般在秒杀抢购爬虫等使用非常广泛那为什么我们需要限流呢流量不应该越大越好吗因为后台服务能力的局限性需要限流否则服务会崩掉可以根据测试性能去评估限流的设置例如测试最大连接数数量每秒钟能处理的最大请求数防止爬虫恶意攻击固定窗口窗口计数法最常用的是使用计数器来控制设置固定的时间内处理固定的请求数上图所示固定时间窗口来做限制内最多只能处理个请求红色请求则会被直接丢弃固定每秒限制同时请求数为上述红色部分的请求会被扔掉扔掉之后整个服务负荷可能会降低但是这个会丢掉请求对于体验不好固定窗口限流器窗口请求上限窗口时间大小计数器上一次请求的时间避免并发问题获取当前时间如果当前窗口失效计数器清开启新的窗口若到达窗口请求上限请求失败若没到窗口请求上限计数器请求成功该算法的问题主要是会存在临界问题如果流量都集中在两个窗口的交界处那么突发流量会是设置上限的两倍还是没有避免掉可能的瞬时流量的问题滑动窗口能够去平滑一下处理的任务数量滑动窗口计数器是通过将窗口再细分并且按照时间滑动这种算法避免了固定窗口算法带来的双倍突发请求但时间区间精度越高算法所需的空间容量越大将时间划分为多个区间在每个区间内每有一次请求就讲计数器加维持一个时间窗口占据多个区间每经过一个区间的时间则抛弃最老的一个区间并纳入最新的一个区间若当前的窗口内区间的请求总数和超过了限制数量则本窗口内的请求都被丢弃该算法虽然解决了固定窗口的边界问题但是还是存在限流不够平滑的问题例如限流是每秒个在第一毫秒发送了个请求达到限流剩余窗口时间的请求都将会被拒绝体验不好那我们继续看下面的算法漏桶算法漏桶算法是网络世界中流量整形或速率限制时经常使用的一种算法它的主要目的是控制数据注入到网络的速率平滑网络上的突发流量漏桶算法提供了一种机制通过它突发流量可以被整形以便为网络提供一个稳定的流量该算法的优势平滑流量由于漏桶算法以固定的速率处理请求可以有效地平滑和整形流量避免流量的突发和波动类似于消息队列的削峰填谷的作用防止过载当流入的请求超过桶的容量时可以直接丢弃请求防止系统过载该算法的缺点无法处理突发流量由于漏桶的出口速度是固定的无法处理突发流量例如即使在流量较小的时候也无法以更快的速度处理请求可能会丢失数据如果入口流量过大超过了桶的容量那么就需要丢弃部分请求在一些不能接受丢失请求的场景中这可能是一个问题不适合速率变化大的场景如果速率变化大或者需要动态调整速率那么漏桶算法就无法满足需求令牌桶算法令牌桶算法是网络流量整形和速率限制中最常使用的一种算法典型情况下令牌桶算法用来控制发送到网络上的数据的数目并允许突发数据的发送令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌而如果请求需要被处理则需要先从桶里获取一个令牌当桶里没有令牌可取时则拒绝服务从原理上看令牌桶算法和漏桶算法是相反的一个进水一个是漏水算法原理令牌桶算法可控制发送到网络上数据的数目并允许突发数据的发送大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌令牌桶中的每一个令牌都代表一个字节如果令牌桶中存在令牌则允许发送流量如果令牌桶中不存在令牌则不允许发送流量若令牌不被消耗或被消耗速度小于产生速度令牌就会不断地增多直到把桶填满传送到令牌桶的数据包需要消耗令牌不同大小的数据包消耗的令牌数量不同令牌桶算法的优势可以处理突发流量令牌桶算法可以处理突发流量当桶满时能够以最大速度处理请求这对于需要处理突发流量的应用场景非常有用限制平均速率在长期运行中数据的传输率会被限制在预定义的平均速率即生成令牌的速率灵活性与漏桶算法相比令牌桶算法提供了更大的灵活性例如可以动态地调整生成令牌的速率该算法的缺点导致过载的可能性要控制令牌的产生速度如果令牌产生的速度过快可能会导致大量的突发流量这可能会使网络或服务过载内存资源限制令牌桶需要一定的存储空间来保存令牌可能会导致内存资源的浪费总结计数器漏桶令牌桶算法限流有各自的特点及应用场景不能单一维度地判断哪个算法最好计数器算法实现简单适用于对接口频次的限制如防恶意刷帖限制等漏桶限流适用于处理流量突刺现象因为只要桶为空就可以接受请求令牌桶限流适用于应对突发流量也是目前互联网架构中最常用的一种限流方式只要能取到令牌即可处理请求相关的问题是什么有哪些优点是一种高性能开源的远程过程调用框架它可以使不同平台和语言之间的服务相互通信它的优点包括高效性跨平台异步流处理支持多种语言安全易于使用和开源和的区别是什么是基于协议的一种风格而是一个独立于协议的框架基于资源的状态转移使用标准的方法而使用协议缓冲区进行序列化和反序列化支持异步流处理和双向流而通常只支持请求响应模式是什么为什么它被用于中是一种语言中立平台中立可扩展的序列化格式它可以用于数据交换和持久化它被用于中因为它可以实现高效的序列化和反序列化从而提高了的性能和效率的流程是什么流程分为四个步骤定义服务生成源代码实现服务启动服务首先需要定义要实现的服务及其接口使用编写接口定义文件其次使用编译器生成客户端和服务器端的源代码然后实现生成的接口最后启动服务器并将其部署在适当的位置支持哪些类型的序列化支持两种类型的序列化二进制使用和其中二进制序列化在效率和性能方面比序列化更优秀但是序列化在可读性方面更好可以方便地进行调试和测试是什么它的主要功能是是什么它与其他框架有什么不同是一个基于语言的微服务开发框架它旨在提供简单高效和可靠的微服务开发解决方案主要功能包括缓存限流熔断监控等相较于其他框架如或更加专注于微服务开发并提供了更多的开箱即用的功能如何使用实现异步任务中提供了包来实现异步任务具体步骤如下创建一个连接池通过创建一个队列实例通过创建一个生产者实例通过创建一个消费者实例通过将任务放入队列通过处理队列中的任务如何实现限流中提供了包来实现限流具体步骤如下通过创建一个限流器实例限制每秒处理个请求通过方法判断当前请求是否被允许若被允许则处理请求否则返回错误提示的微服务面经和原理服务基本架构包含了四个核心的组件分别是以及让远程调用就像本地调用一样其调用过程可拆解为以下步骤流行的框架目前流行的框架有很多下面介绍常见的三种是公布的开源项目基于协议并支持常见的众多编程语言协议是基于二进制的协议的升级版本底层使用了框架是的一个开源项目主要是一个跨语言的服务开发框架它有一个代码生成器来对它所定义的文件自动生成服务代码框架对于底层的通讯都是透明的用户只需要对其进行二次开发即可省去了一系列重复的前置基础开发工作是阿里集团开源的一个极为出名的框架在很多互联网公司和企业应用中广泛使用协议和序列化框架都可以插拔是及其鲜明的特色面经分享字节二面进制转进制奇怪的问题在程序中一般溢出的处理数据怎么存储的原码补码反码系统设计类的问题系统设计答题思路使用场景和限制条件这个系统是在什么地方使用的比如短网址系统提供给站内各种服务生成短网址限制条件用户估计多少至少要能支撑多少用户估算并发峰值平均数据库存储按需设计数据库表需要哪些字段使用什么类型数据增长规模数据库选型是否需要持久化使用关系型还是如何优化如何设计索引是否可以使用缓存算法模块设计算法解决问题的核心程序算法数据结构系统服务存储需要哪些接口接口如何设计使用什么算法或模型不同实现方法之间的优劣势对比如何取舍延伸考点如果回答不错可能会问一些深入的问题扩展容错用户多了高了如何处理数据存储多了不够存了如何处理故障如何处理单点失败多点失败雪崩问题短链路系统如何设计一个短网址服务使用场景微博和都有字数的限制如果分享一个长网址很容易就超出限制发布出去短网址服务可以把一个长网址变成短网址方便在社交网络上传播需求很显然要尽可能的短长度设计为多少才合适呢微博的短网址服务用的是长度为的字符串这个字符串可以看做是进制的数那么最大能表示个网址远远大于亿所以长度为就足够了一个位整数如何转化为字符串呢假设我们只是用大小写字母加数字那么可以看做是进制数即字符串最长就足够了实际生产中还可以再短一点比如新浪微博采用的长度就是因为这个量级远远超过互联网上的总数了绝对够用了现代的服务器例如大部分都区分里的大小写了所以用大小写字母来区分不同的是没问题的因此正确答案长度不超过的字符串由大小写字母加数字共个字母组成一对一还是一对多映射一个长网址对应一个短网址还是可以对应多个短网址这也是个重大选择问题一般而言一个长网址在不同的地点不同的用户等情况下生成的短网址应该不一样这样在后端数据库中可以更好的进行数据分析如果一个长网址与一个短网址一一对应那么在数据库中仅有一行数据无法区分不同的来源就无法做数据分析了以这个位长度的短网址作为唯一这个下可以挂各种信息比如生成该网址的用户名所在网站头部的等信息收集了这些信息才有可能在后面做大数据分析挖掘数据的价值短网址服务商的一大盈利来源就是这些数据正确答案一对多如何计算网址现在我们设定了短网址是一个长度为的字符串如何计算得到这个短网址呢最容易想到的办法是哈希先得到一个位整数将它转化为进制整截取低位即可但是哈希算有冲突如何处理冲突呢又是一个麻烦这个方法只是转移了矛盾没有解决矛盾抛弃正确答案分布式生成器如何存储如果存储短网址和长网址的对应关系以短网址为长网址为可以用传统的关系数据库存起来例如也可以用任意一个分布式数据库例如如果你手痒想要手工设计这个存储那就是另一个话题了你需要完整地造一个存储引擎轮子当前流行的存储引擎有和去读它们的源码吧还是重定向这也是一个有意思的问题这个问题主要是考察你对和的理解以及浏览器缓存机制的理解是永久重定向是临时重定向短地址一经生成就不会变化所以用是符合语义的但是如果用了百度等搜索引擎搜索的时候会直接展示真实地址那我们就无法统计到短地址被点击的次数了也无法收集用户的等信息这些信息可以用来做很多有意思的大数据分析也是短网址服务商的主要盈利来源所以正确答案是重定向预防攻击如果一些别有用心的黑客短时间内向服务器发送大量的请求会迅速耗光怎么办呢首先限制的单日请求总数超过阈值则直接拒绝服务光限制的请求数还不够因为黑客一般手里有上百万台肉鸡的地址大大的有所以光限制作用不大可以用一台作为缓存服务器存储的不是长网址而是长网址仅存储一天以内的数据用机制进行淘汰这样如果黑客大量发同一个长网址过来直接从缓存服务器里返回短网址即可他就无法耗光我们的了设计秒杀系统参考链接瞬间高并发页面静态化秒杀按钮读多写少缓存问题库存问题分布式锁异步处理如何限流瞬间高并发一般在秒杀时间点比如点前几分钟用户并发量才真正突增达到秒杀时间点时并发量会达到顶峰像这种瞬时高并发的场景传统的系统很难应对我们需要设计一套全新的系统可以从以下几个方面入手页面静态化加速缓存异步处理限流分布式锁页面静态化活动页面是用户流量的第一入口所以是并发量最大的地方如果这些流量都能直接访问服务端恐怕服务端会因为承受不住这么大的压力而直接挂掉活动页面绝大多数内容是固定的比如商品名称商品描述图片等为了减少不必要的服务端请求通常情况下会对活动页面做静态化处理用户浏览商品等常规操作并不会请求到服务端只有到了秒杀时间点并且用户主动点了秒杀按钮才允许访问服务端这样能过滤大部分无效请求但只做页面静态化还不够因为用户分布在全国各地有些人在北京有些人在成都有些人在深圳地域相差很远网速各不相同如何才能让用户最快访问到活动页面呢这就需要使用它的全称是即内容分发网络使用户就近获取所需内容降低网络拥塞提高用户访问响应速度和命中率秒杀按钮大部分用户怕错过秒杀时间点一般会提前进入活动页面此时看到的秒杀按钮是置灰不可点击的只有到了秒杀时间点那一时刻秒杀按钮才会自动点亮变成可点击的但此时很多用户已经迫不及待了通过不停刷新页面争取在第一时间看到秒杀按钮的点亮从前面得知该活动页面是静态的那么我们在静态页面中如何控制秒杀按钮只在秒杀时间点时才点亮呢没错使用文件控制为了性能考虑一般会将和图片等静态资源文件提前缓存到上让用户能够就近访问秒杀页面看到这里有些聪明的小伙伴可能会问上的文件是如何更新的秒杀开始之前标志为还有另外一个随机参数当秒杀开始的时候系统会生成一个新的文件此时标志为并且随机参数生成一个新值然后同步给由于有了这个随机参数不会缓存数据每次都能从中获取最新的代码此外前端还可以加一个定时器控制比如秒之内只允许发起一次请求如果用户点击了一次秒杀按钮则在秒之内置灰不允许再次点击等到过了时间限制又允许重新点击该按钮读多写少在秒杀的过程中系统一般会先查一下库存是否足够如果足够才允许下单写数据库如果不够则直接返回该商品已经抢完由于大量用户抢少量商品只有极少部分用户能够抢成功所以绝大部分用户在秒杀时库存其实是不足的系统会直接返回该商品已经抢完这是非常典型的读多写少的场景如果有数十万的请求过来同时通过数据库查缓存是否足够此时数据库可能会挂掉因为数据库的连接资源非常有限比如无法同时支持这么多的连接而应该改用缓存比如即便用了也需要部署多个节点缓存问题通常情况下我们需要在中保存商品信息里面包含商品商品名称规格属性库存等信息同时数据库中也要有相关信息毕竟缓存并不完全可靠用户在点击秒杀按钮请求秒杀接口的过程中需要传入的商品参数然后服务端需要校验该商品是否合法大致流程如下图所示根据商品先从缓存中查询商品如果商品存在则参与秒杀如果不存在则需要从数据库中查询商品如果存在则将商品信息放入缓存然后参与秒杀如果商品不存在则直接提示失败这个过程表面上看起来是的但是如果深入分析一下会发现一些问题缓存击穿比如商品第一次秒杀时缓存中是没有数据的但数据库中有虽说上面有如果从数据库中查到数据则放入缓存的逻辑然而在高并发下同一时刻会有大量的请求都在秒杀同一件商品这些请求同时去查缓存中没有数据然后又同时访问数据库结果悲剧了数据库可能扛不住压力直接挂掉如何解决这个问题呢这就需要加锁最好使用分布式锁当然针对这种情况最好在项目启动之前先把缓存进行预热即事先把所有的商品同步到缓存中这样商品基本都能直接从缓存中获取到就不会出现缓存击穿的问题了是不是上面加锁这一步可以不需要了表面上看起来确实可以不需要但如果缓存中设置的过期时间不对缓存提前过期了或者缓存被不小心删除了如果不加速同样可能出现缓存击穿其实这里加锁相当于买了一份保险缓存击穿如果有大量的请求传入的商品在缓存中和数据库中都不存在这些请求不就每次都会穿透过缓存而直接访问数据库了由于前面已经加了锁所以即使这里的并发量很大也不会导致数据库直接挂掉但很显然这些请求的处理性能并不好有没有更好的解决方案这时可以想到布隆过滤器系统根据商品先从布隆过滤器中查询该是否存在如果存在则允许从缓存中查询数据如果不存在则直接返回失败虽说该方案可以解决缓存穿透问题但是又会引出另外一个问题布隆过滤器中的数据如何更缓存中的数据保持一致这就要求如果缓存中数据有更新则要及时同步到布隆过滤器中如果数据同步失败了还需要增加重试机制而且跨数据源能保证数据的实时一致性吗显然是不行的所以布隆过滤器绝大部分使用在缓存数据更新很少的场景中如果缓存数据更新非常频繁又该如何处理呢这时就需要把不存在的商品也缓存起来下次再有该商品的请求过来则也能从缓存中查到数据只不过该数据比较特殊表示商品不存在需要特别注意的是这种特殊缓存设置的超时时间应该尽量短一点库存问题对于库存问题看似简单实则里面还是有些东西真正的秒杀商品的场景不是说扣完库存就完事了如果用户在一段时间内还没完成支付扣减的库存是要加回去的所以在这里引出了一个预扣库存的概念预扣库存的主要流程如下扣减库存中除了上面说到的预扣库存和回退库存之外还需要特别注意的是库存不足和库存超卖问题数据库扣减库存使用数据库扣减库存是最简单的实现方案了假设扣减库存的如下这种写法对于扣减库存是没有问题的但如何控制库存不足的情况下不让用户操作呢这就需要在之前先查一下库存是否足够了只需将上面的稍微调整一下在最后加上就能保证不会出现超卖的情况但需要频繁访问数据库我们都知道数据库连接是非常昂贵的资源在高并发的场景下可能会造成系统雪崩而且容易出现多个请求同时竞争行锁的情况造成相互等待从而出现死锁的问题扣减库存的方法是原子性的可以用该方法扣减库存伪代码如下代码流程如下先判断该用户有没有秒杀过该商品如果已经秒杀过则直接返回查询库存如果库存小于等于则直接返回表示库存不足如果库存充足则扣减库存然后将本次秒杀记录保存起来然后返回表示成功估计很多小伙伴一开始都会按这样的思路写代码但如果仔细想想会发现这段代码有问题有什么问题呢如果在高并发下有多个请求同时查询库存当时都大于由于查询库存和更新库存非原则操作则会出现库存为负数的情况即库存超卖该代码主要流程如下先判断该用户有没有秒杀过该商品如果已经秒杀过则直接返回扣减库存判断返回值是否小于如果小于则直接返回表示库存不足如果扣减库存后返回值大于或等于则将本次秒杀记录保存起来然后返回表示成功该方案咋一看好像没问题但如果在高并发场景中有多个请求同时扣减库存大多数请求的操作之后结果都会小于虽说库存出现负数不会出现超卖的问题但由于这里是预减库存如果负数值负的太多的话后面万一要回退库存时就会导致库存不准那么有没有更好的方案呢基于脚本扣减库存我们都知道脚本是能够保证原子性的它跟一起配合使用能够完美解决上面的问题脚本有段非常经典的代码该代码的主要流程如下先判断商品是否存在如果不存在则直接返回获取该商品的库存判断库存如果是则直接返回表示不限制库存如果库存大于则扣减库存如果库存等于是直接返回表示库存不足分布式锁之前我提到过在秒杀的时候需要先从缓存中查商品是否存在如果不存在则会从数据库中查商品如果数据库中则将该商品放入缓存中然后返回如果数据库中没有则直接返回失败大家试想一下如果在高并发下有大量的请求都去查一个缓存中不存在的商品这些请求都会直接打到数据库数据库由于承受不住压力而直接挂掉那么如何解决这个问题呢这就需要用分布式锁了可以采用的分布式锁自旋锁异步我们都知道在真实的秒杀场景中有三个核心流程而这三个核心流程中真正并发量大的是秒杀功能下单和支付功能实际并发量很小所以我们在设计秒杀系统时有必要把下单和支付功能从秒杀的主流程中拆分出来特别是下单功能要做成异步处理的而支付功能比如支付宝支付是业务场景本身保证的异步于是秒杀后下单的流程变成如下如果使用需要关注以下几个问题消息丢失问题秒杀成功了往发送下单消息的时候有可能会失败原因有很多比如网络问题挂了服务端磁盘问题等这些情况都可能会造成消息丢失那么如何防止消息丢失呢答加一张消息发送表在生产者发送消息之前先把该条消息写入消息发送表初始状态是待处理然后再发送消息消费者消费消息时处理完业务逻辑之后再回调生产者的一个接口修改消息状态为已处理如果生产者把消息写入消息发送表之后再发送消息到服务端的过程中失败了造成了消息丢失这时候要如何处理呢答使用增加重试机制用每隔一段时间去查询消息发送表中状态为待处理的数据然后重新发送消息重复消费问题本来消费者消费消息时在应答的时候如果网络超时本身就可能会消费重复的消息但由于消息发送者增加了重试机制会导致消费者重复消息的概率增大那么如何解决重复消息问题呢答加一张消息处理表消费者读到消息之后先判断一下消息处理表是否存在该消息如果存在表示是重复消费则直接返回如果不存在则进行下单操作接着将该消息写入消息处理表中再返回有个比较关键的点是下单和写消息处理表要放在同一个事务中保证原子操作垃圾消息问题这套方案表面上看起来没有问题但如果出现了消息消费失败的情况比如由于某些原因消息消费者下单一直失败一直不能回调状态变更接口这样会不停的重试发消息最后会产生大量的垃圾消息那么如何解决这个问题呢每次在重试时需要先判断一下消息发送表中该消息的发送次数是否达到最大限制如果达到了则直接返回如果没有达到则将次数加然后发送消息这样如果出现异常只会产生少量的垃圾消息不会影响到正常的业务延迟消费问题通常情况下如果用户秒杀成功了下单之后在分钟之内还未完成支付的话该订单会被自动取消回退库存那么在分钟内未完成支付订单被自动取消的功能要如何实现呢我们首先想到的可能是因为它比较简单但有个问题需要每隔一段时间处理一次实时性不太好还有更好的方案答使用延迟队列我们都知道自带了延迟队列的功能下单时消息生产者会先生成订单此时状态为待支付然后会向延迟队列中发一条消息达到了延迟时间消息消费者读取消息之后会查询该订单的状态是否为待支付如果是待支付状态则会更新订单状态为取消状态如果不是待支付状态说明该订单已经支付过了则直接返回还有个关键点用户完成支付之后会修改订单状态为已支付如何限流实现框架动态路由实现前缀树待匹配路由例如路由中的一部分例如子节点例如是否精确匹配含有或时为第一个匹配成功的节点用于插入所有匹配成功的节点用于查找',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-03 11:28:35',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/header.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://Kiritoabc.github.io" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">菠萝萝のBLOG</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/UML/" style="font-size: 1.05rem;">UML<sup>1</sup></a><a href="/tags/WBS/" style="font-size: 1.05rem;">WBS<sup>1</sup></a><a href="/tags/go/" style="font-size: 1.05rem;">go<sup>3</sup></a><a href="/tags/redis/" style="font-size: 1.05rem;">redis<sup>3</sup></a><a href="/tags/sql/" style="font-size: 1.05rem;">sql<sup>1</sup></a><a href="/tags/why-what-how/" style="font-size: 1.05rem;">why? what? how?<sup>1</sup></a><a href="/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" style="font-size: 1.05rem;">中间件<sup>2</sup></a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="font-size: 1.05rem;">云原生<sup>2</sup></a><a href="/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 1.05rem;">前端开发小技巧<sup>3</sup></a><a href="/tags/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/" style="font-size: 1.05rem;">前端知识<sup>1</sup></a><a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 1.05rem;">博客<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size: 1.05rem;">后端<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AFGo/" style="font-size: 1.05rem;">后端Go<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AFgo/" style="font-size: 1.05rem;">后端go<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 1.05rem;">后端开发小技巧<sup>5</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86/" style="font-size: 1.05rem;">后端开发知识<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/" style="font-size: 1.05rem;">后端知识<sup>4</sup></a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9F%A5%E8%AF%86/" style="font-size: 1.05rem;">大数据知识<sup>1</sup></a><a href="/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" style="font-size: 1.05rem;">学习记录<sup>1</sup></a><a href="/tags/%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/" style="font-size: 1.05rem;">安卓开发<sup>1</sup></a><a href="/tags/%E6%9C%BA%E8%80%83/" style="font-size: 1.05rem;">机考<sup>1</sup></a><a href="/tags/%E6%B5%8B%E8%AF%95/" style="font-size: 1.05rem;">测试<sup>2</sup></a><a href="/tags/%E6%B5%8B%E8%AF%95%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 1.05rem;">测试小技巧<sup>1</sup></a><a href="/tags/%E7%AE%80%E5%8E%86%E5%88%B6%E4%BD%9C/" style="font-size: 1.05rem;">简历制作<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 1.05rem;">计网<sup>1</sup></a><a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 1.05rem;">设计模式<sup>1</sup></a><a href="/tags/%E9%9D%A2%E7%BB%8F/" style="font-size: 1.05rem;">面经<sup>2</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 1.05rem;">面试<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">12</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">十二月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">9</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">十一月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">十月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95/" itemprop="url">面试</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E9%9D%A2%E7%BB%8F/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>面经</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Golang面经</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-03-30T13:49:49.000Z" title="发表于 2024-03-30 13:49:49">2024-03-30</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2024-04-03T11:28:35.399Z" title="更新于 2024-04-03 11:28:35">2024-04-03</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">79k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>250分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="Golang面经"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为杭州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>杭州</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=51754bf9-ed78-4d2b-fbe8-4e9699cf5ca3"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/"><header><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95/" itemprop="url">面试</a><a href="/tags/%E9%9D%A2%E7%BB%8F/" tabindex="-1" itemprop="url">面经</a><h1 id="CrawlerTitle" itemprop="name headline">Golang面经</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">菠萝</span><time itemprop="dateCreated datePublished" datetime="2024-03-30T13:49:49.000Z" title="发表于 2024-03-30 13:49:49">2024-03-30</time><time itemprop="dateCreated datePublished" datetime="2024-04-03T11:28:35.399Z" title="更新于 2024-04-03 11:28:35">2024-04-03</time></header><p><a name="zHxrg"></a></p>
<h1 id="数组和切片"><a href="#数组和切片" class="headerlink" title="数组和切片"></a>数组和切片</h1><p><a name="UY2el"></a></p>
<h2 id="1-数组和切片有什么不同"><a href="#1-数组和切片有什么不同" class="headerlink" title="1.数组和切片有什么不同"></a>1.数组和切片有什么不同</h2><ul>
<li>slice 的底层数据是数组，slice 是对数组的封装，它描述一个数组的片段</li>
<li>数组是定长的，长度定义好之后，不能再更改。</li>
<li>数组就是一片连续的内存， slice 实际上是一个结构体，包含三个字段：长度、容量、底层数组。</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// runtime/slice.go</span></span><br><span class="line"><span class="keyword">type</span> slice <span class="keyword">struct</span> &#123;</span><br><span class="line">    array unsafe.Pointer <span class="comment">// 元素指针</span></span><br><span class="line">    <span class="built_in">len</span>   <span class="type">int</span> <span class="comment">// 长度 </span></span><br><span class="line">    <span class="built_in">cap</span>   <span class="type">int</span> <span class="comment">// 容量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="A2w4w"></a></p>
<h2 id="2-切片的容量是怎么增长的"><a href="#2-切片的容量是怎么增长的" class="headerlink" title="2.切片的容量是怎么增长的"></a>2.切片的容量是怎么增长的</h2><p>一般都是在向 slice 追加了元素之后，才会引起扩容。追加元素调用的是 append 函数。</p>
<blockquote>
<p>使用 append 可以向 slice 追加元素，实际上是往底层数组添加元素。但是底层数组的长度是固定的，如果索引 len-1 所指向的元素已经是底层数组的最后一个元素，就没法再添加了。</p>
</blockquote>
<blockquote>
<p>这时，slice 会迁移到新的内存位置，新底层数组的长度也会增加，这样就可以放置新增的元素。同时，为了应对未来可能再次发生的 append 操作，新的底层数组的长度，也就是新 slice 的容量是留了一定的 buffer 的。否则，每次添加元素的时候，都会发生迁移，成本太高。</p>
</blockquote>
<p><strong>新 slice 预留的 buffer 大小是有一定规律的。在golang1.18版本更新之前网上大多数的文章都是这样描述slice的扩容策略的：</strong></p>
<blockquote>
<p>当原 slice 容量小于 1024 的时候，新 slice 容量变成原来的 2 倍；原 slice 容量超过 1024，新 slice 容量变成原来的1.25倍。</p>
</blockquote>
<p><strong>在1.18版本更新之后，slice的扩容策略变为了：</strong></p>
<blockquote>
<p>当原slice容量(oldcap)小于256的时候，新slice(newcap)容量为原来的2倍；原slice容量超过256，新slice容量newcap &#x3D; oldcap+(oldcap+3*256)&#x2F;4</p>
</blockquote>
<ul>
<li>最后newcap 要通过 **runupsize()**计算得到</li>
<li>这个runupsize（）就是内存对齐的策略 – 为了避免内存碎片，最后会进行 内存对齐计算</li>
</ul>
<p>runupsize() 进行内存对齐的计算<br>hello world</p>
<p><a name="un0Jg"></a></p>
<h2 id="3-切片作为函数参数"><a href="#3-切片作为函数参数" class="headerlink" title="3.切片作为函数参数"></a>3.切片作为函数参数</h2><p>前面我们说到，slice 其实是一个结构体，包含了三个成员：len, cap, array。分别表示切片长度，容量，底层数据的地址。<br>当 slice 作为函数参数时，就是一个普通的结构体。其实很好理解：若直接传 slice，在调用者看来，实参 slice 并不会被函数中的操作改变；若传的是 slice 的指针，在调用者看来，是会被改变原 slice 的。<br>值得注意的是，不管传的是 slice 还是 slice 指针，如果改变了 slice 底层数组的数据，会反应到实参 slice 的底层数据。为什么能改变底层数组的数据？很好理解：底层数据在 slice 结构体里是一个指针，尽管 slice 结构体自身不会被改变，也就是说底层数据地址不会被改变。 但是通过指向底层数据的指针，可以改变切片的底层数据，没有问题。</p>
<p><a name="vmoca"></a></p>
<h2 id="4-指针在go中的作用？"><a href="#4-指针在go中的作用？" class="headerlink" title="4.指针在go中的作用？"></a>4.指针在go中的作用？</h2><ol>
<li><strong>引用传递</strong><ul>
<li>在函数调用时，通过指针可以实现引用传递。这意味着当你将一个变量的地址作为参数传递给函数时，函数可以直接操作该变量的原始值，而非创建一个新的副本。这提高了效率，特别是在处理大数据结构（如数组、切片、结构体等）时，避免了不必要的内存拷贝，降低了开销。</li>
</ul>
</li>
<li><strong>动态内存分配</strong><ul>
<li>使用内建的 new 函数或 make 函数（对于slice、map和channel这类复合类型），Go语言可以动态地在堆上分配内存，并返回指向新分配内存的指针。通过指针，我们可以方便地创建和管理生命周期不受函数范围约束的变量。</li>
</ul>
</li>
<li><strong>修改函数外部变量</strong><ul>
<li>Go函数默认是值传递的，但通过传递变量的指针，函数可以修改外部作用域内的变量值。这对于需要改变原始数据的函数设计至关重要。</li>
</ul>
</li>
<li><strong>数据结构底层操作</strong><ul>
<li>在开发诸如链表、树、图等高级数据结构时，指针是构建这些结构的基础，因为它们依赖于节点间的引用关系。</li>
</ul>
</li>
<li><strong>低级内存操作</strong><ul>
<li>尽管Go语言的设计理念倾向于抽象掉大部分底层细节，但在一些高级或系统级编程场景中，指针仍然可以用于直接操作内存地址，以满足特定的性能要求或与其他语言库进行交互。</li>
</ul>
</li>
<li><strong>接口实现</strong><ul>
<li>在Go语言的接口类型中，虽然接口变量本身不包含指针，但是在实现接口时，结构体指针经常被用来实现方法集，这样可以避免方法接收者复制带来的额外开销，并且更容易满足接口的语义。</li>
</ul>
</li>
</ol>
<p>总之，Go语言中的指针极大地增强了程序设计的灵活性和效率，它是实现高性能和低延迟代码的关键工具之一，同时也要求开发者谨慎使用以避免潜在的悬挂指针、内存泄漏和其他因不当使用指针引起的错误。</p>
<p><a name="UFeb5"></a></p>
<h1 id="谈谈go中比较相等"><a href="#谈谈go中比较相等" class="headerlink" title="谈谈go中比较相等"></a>谈谈go中比较相等</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qmhball/article/details/113771087">https://blog.csdn.net/qmhball/article/details/113771087</a></p>
<p><a name="UPrWW"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h1><p><a name="LmCZi"></a></p>
<h2 id="1-map的实现原理"><a href="#1-map的实现原理" class="headerlink" title="1.map的实现原理"></a>1.map的实现原理</h2><p>hmap 的结构<br>[]bmap  buckets：主要用来存储数据的<br><a name="rtqrA"></a></p>
<h3 id="1-1-map的内存模型"><a href="#1-1-map的内存模型" class="headerlink" title="1.1 map的内存模型"></a>1.1 map的内存模型</h3><blockquote>
<p>map 的设计也被称为 “The dictionary problem”，它的任务是设计一种数据结构用来维护一个集合的数据，并且可以同时对集合进行增删查改的操作。最主要的数据结构有两种：哈希查找表（Hash table）、搜索树（Search tree）。</p>
</blockquote>
<p>哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。</p>
<p>哈希查找表一般会存在“碰撞”的问题，就是说不同的 key 被哈希到了同一个 bucket。一般有两种应对方法：<strong>链表法</strong>和<strong>开放地址法</strong>。链表法将一个 bucket 实现成一个链表，落在同一个 bucket 中的 key 都会插入这个链表。开放地址法则是碰撞发生后，通过一定的规律，在数组的后面挑选“空位”，用来放置新的 key。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1707736365056-6aa32234-ad06-4cff-9e10-edbaf7f35e72.png#averageHue=%23fefdfb&clientId=u837611a0-3122-4&from=paste&height=520&id=ue80771bf&originHeight=650&originWidth=1043&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=97478&status=done&style=none&taskId=u583e6ba5-15a8-4edf-b439-003df3348bf&title=&width=834.4" alt="image.png"></p>
<p>:::success<br>当 map 的 key 和 value 都不是指针，并且 size 都小于 128 字节的情况下，会把 bmap 标记为不含指针，这样可以避免 gc 时扫描整个 hmap。但是，我们看 bmap 其实有一个 overflow 的字段，是指针类型的，破坏了 bmap 不含指针的设想，这时会把 overflow 移动到 extra 字段来。<br>:::<br><a name="aiGZU"></a></p>
<h3 id="1-2-创建map"><a href="#1-2-创建map" class="headerlink" title="1.2 创建map"></a>1.2 创建map</h3><p>从语法层面上来说，创建 map 很简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">ageMp := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span>)</span><br><span class="line"><span class="comment">// 指定 map 长度</span></span><br><span class="line">ageMp := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ageMp 为 nil，不能向其添加元素，会直接panic</span></span><br><span class="line"><span class="keyword">var</span> ageMp <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过汇编语言可以看到，实际上底层调用的是 **makemap **函数，主要做的工作就是初始化 hmap 结构体的各种字段，例如计算 B 的大小，设置哈希种子 hash0 等等。</p>
</blockquote>
<p><strong>通过汇编语言可以看到，实际上底层调用的是 makemap 函数，主要做的工作就是初始化 hmap 结构体的各种字段，例如计算 B 的大小，设置哈希种子 hash0 等等。</strong></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makemap</span><span class="params">(t *maptype, hint <span class="type">int64</span>, h *hmap, bucket unsafe.Pointer)</span></span> *hmap &#123;</span><br><span class="line">	<span class="comment">// 省略各种条件检查...</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 找到一个 B，使得 map 的装载因子在正常范围内</span></span><br><span class="line">	B := <span class="type">uint8</span>(<span class="number">0</span>)</span><br><span class="line">	<span class="keyword">for</span> ; overLoadFactor(hint, B); B++ &#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 初始化 hash table</span></span><br><span class="line">	<span class="comment">// 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配</span></span><br><span class="line">	<span class="comment">// 如果长度比较大，分配内存会花费长一点</span></span><br><span class="line">	buckets := bucket</span><br><span class="line">	<span class="keyword">var</span> extra *mapextra</span><br><span class="line">	<span class="keyword">if</span> B != <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">var</span> nextOverflow *bmap</span><br><span class="line">		buckets, nextOverflow = makeBucketArray(t, B)</span><br><span class="line">		<span class="keyword">if</span> nextOverflow != <span class="literal">nil</span> &#123;</span><br><span class="line">			extra = <span class="built_in">new</span>(mapextra)</span><br><span class="line">			extra.nextOverflow = nextOverflow</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 初始化 hamp</span></span><br><span class="line">	<span class="keyword">if</span> h == <span class="literal">nil</span> &#123;</span><br><span class="line">		h = (*hmap)(newobject(t.hmap))</span><br><span class="line">	&#125;</span><br><span class="line">	h.count = <span class="number">0</span></span><br><span class="line">	h.B = B</span><br><span class="line">	h.extra = extra</span><br><span class="line">	h.flags = <span class="number">0</span></span><br><span class="line">	h.hash0 = fastrand()</span><br><span class="line">	h.buckets = buckets</span><br><span class="line">	h.oldbuckets = <span class="literal">nil</span></span><br><span class="line">	h.nevacuate = <span class="number">0</span></span><br><span class="line">	h.noverflow = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> h</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>【引申1】slice 和 map 分别作为函数参数时有什么区别？<br>注意，这个函数返回的结果：*hmap，它是一个指针，而我们之前讲过的 makeslice 函数返回的是 Slice 结构体：</p>
<p>| &#96;&#96;&#96;go<br>func makeslice(et *_type, len, cap int) slice</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> |</span><br><span class="line">| --- |</span><br><span class="line"></span><br><span class="line">回顾一下 slice 的结构体定义：</span><br><span class="line"></span><br><span class="line">| ```go</span><br><span class="line">// runtime/slice.go</span><br><span class="line">type slice struct &#123;</span><br><span class="line">    array unsafe.Pointer // 元素指针</span><br><span class="line">    len   int // 长度 </span><br><span class="line">    cap   int // 容量</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<table>
<thead>
<tr>
<th></th>
</tr>
</thead>
</table>
<p>结构体内部包含底层的数据指针。<br>makemap 和 makeslice 的区别，带来一个不同点：当 map 和 slice 作为函数参数时，在函数参数内部对 map 的操作会影响 map 自身；而对 slice 却不会（之前讲 slice 的文章里有讲过）。<br><strong>主要原因：一个是指针（<em>hmap），一个是结构体（slice）。Go 语言中的函数传参都是值传递，在函数内部，参数会被 copy 到本地。</em>hmap指针 copy 完之后，仍然指向同一个 map，因此函数内部对 map 的操作会影响实参。而 slice 被 copy 后，会成为一个新的 slice，对它进行的操作不会影响到实参。</strong></p>
<p><a name="RUSSW"></a></p>
<h3 id="1-3-哈希函数"><a href="#1-3-哈希函数" class="headerlink" title="1.3 哈希函数"></a>1.3 哈希函数</h3><p>map 的一个关键点在于，哈希函数的选择。在程序启动时，会检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。这是在函数 alginit() 中完成，位于路径：src&#x2F;runtime&#x2F;alg.go 下。</p>
<blockquote>
<p>hash 函数，有加密型和非加密型。 加密型的一般用于加密数据、数字摘要等，典型代表就是 md5、sha1、sha256、aes256 这种； 非加密型的一般就是查找。在 map 的应用场景中，用的是查找。 选择 hash 函数主要考察的是两点：性能、碰撞概率。</p>
</blockquote>
<p><a name="b8Y6Q"></a></p>
<h3 id="1-4-key-定位过程"><a href="#1-4-key-定位过程" class="headerlink" title="1.4 key 定位过程"></a>1.4 key 定位过程</h3><p>key 经过哈希计算后得到哈希值，共 64 个 bit 位（64位机，32位机就不讨论了，现在主流都是64位机），计算它到底要落在哪个桶时，只会用到最后 B 个 bit 位。还记得前面提到过的 B 吗？如果 B &#x3D; 5，那么桶的数量，也就是 buckets 数组的长度是 2^5 &#x3D; 32。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711342431556-0338b0ec-2976-4d33-a6bc-810de5584725.png#averageHue=%23f8f1e1&clientId=u5abd9b27-d228-4&from=paste&height=962&id=u965f75cc&originHeight=1203&originWidth=945&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=112839&status=done&style=none&taskId=u69ca3392-788a-4fb5-9848-f5e6ed45b4d&title=&width=756" alt="image.png"></p>
<p><a name="pmAak"></a></p>
<h2 id="2-扩容过程"><a href="#2-扩容过程" class="headerlink" title="2.扩容过程"></a>2.扩容过程</h2><p>好的！<br>对于map的扩容<br>触发条件：</p>
<ol>
<li>超过了负载因子的大小 6.5 那么一般会发生扩容   双倍扩容</li>
<li>当overflow的buckets数量过多的时候，会发生扩容  等量扩容</li>
</ol>
<p>主要是申请到了新的 buckets 空间，把相关的标志位都进行了处理：例如标志 nevacuate 被置为 0， 表示当前搬迁进度为 0。</p>
<p><a name="q6H8R"></a></p>
<h2 id="3-key为什么是无序的"><a href="#3-key为什么是无序的" class="headerlink" title="3.key为什么是无序的"></a>3.key为什么是无序的</h2><p>map 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。<br>当然，如果我就一个 hard code 的 map，我也不会向 map 进行插入删除的操作，按理说每次遍历这样的 map 都会返回一个固定顺序的 key&#x2F;value 序列吧。的确是这样，但是 Go 杜绝了这种做法，因为这样会给新手程序员带来误解，以为这是一定会发生的事情，在某些情况下，可能会酿成大错。<br>当然，Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。这样，即使你是一个写死的 map，仅仅只是遍历它，也不太可能会返回一个固定序列的 key&#x2F;value 对了。<br>多说一句，“迭代 map 的结果是无序的”这个特性是从 go 1.0 开始加入的。</p>
<p><a name="PEoOn"></a></p>
<h2 id="4-float类型可以作为map的key吗？"><a href="#4-float类型可以作为map的key吗？" class="headerlink" title="4.float类型可以作为map的key吗？"></a>4.float类型可以作为map的key吗？</h2><blockquote>
<p><strong>最后说结论：float 型可以作为 key，但是由于精度的问题，会导致一些诡异的问题，慎用之。</strong></p>
</blockquote>
<p>由于 NAN 的特性：</p>
<p>| &#96;&#96;&#96;go<br>NAN !&#x3D; NAN<br>hash(NAN) !&#x3D; hash(NAN)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> |</span><br><span class="line">| --- |</span><br><span class="line"></span><br><span class="line">因此向 map 中查找的 key 为 NAN 时，什么也查不到；如果向其中增加了 4 次 NAN，遍历会得到 4 个 NAN。</span><br><span class="line">最后说结论：float 型可以作为 key，但是由于精度的问题，会导致一些诡异的问题，慎用之。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;a name=&quot;mYheS&quot;&gt;&lt;/a&gt;</span><br><span class="line">## 5.如何比较2个map是否相等</span><br><span class="line">map 深度相等的条件：</span><br><span class="line">```shell</span><br><span class="line">1、都为 nil</span><br><span class="line">2、非空、长度相等，指向同一个 map 实体对象</span><br><span class="line">3、相应的 key 指向的 value “深度”相等</span><br></pre></td></tr></table></figure>

<p>直接将使用 map1 &#x3D;&#x3D; map2 是错误的。这种写法只能比较 map 是否为 nil。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> m <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> n <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    fmt.Println(m == <span class="literal">nil</span>)</span><br><span class="line">    fmt.Println(n == <span class="literal">nil</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 不能通过编译</span></span><br><span class="line">    <span class="comment">//fmt.Println(m == n)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">true</span><br><span class="line">true</span><br></pre></td></tr></table></figure>

<p>因此只能是遍历map 的每个元素，比较元素是否都是深度相等。</p>
<p><a name="ctd0k"></a></p>
<h2 id="6-map是线程安全的吗？"><a href="#6-map是线程安全的吗？" class="headerlink" title="6.map是线程安全的吗？"></a>6.map是线程安全的吗？</h2><p>map 不是线程安全的。<br>在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（等于1），则直接 panic。赋值和删除函数在检测完写标志是复位之后，先将写标志位置位，才会进行之后的操作。<br>检测写标志：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting == <span class="number">0</span> &#123;</span><br><span class="line">    throw(<span class="string">&quot;concurrent map writes&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置写标志：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">h.flags |= hashWriting</span><br></pre></td></tr></table></figure>

<p><a name="ehnu5"></a></p>
<h1 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h1><p><a name="JXtlw"></a></p>
<h2 id="1-值接收者和指针接收者的区别"><a href="#1-值接收者和指针接收者的区别" class="headerlink" title="1.值接收者和指针接收者的区别"></a>1.值接收者和指针接收者的区别</h2><blockquote>
<p>方法能给用户自定义的类型添加新的行为。它和函数的区别在于方法有一个接收者，给一个函数添加一个接收者，那么它就变成了方法。接收者可以是值接收者，也可以是指针接收者。<br>在调用方法的时候，值类型既可以调用值接收者的方法，也可以调用指针接收者的方法；指针类型既可以调用指针接收者的方法，也可以调用值接收者的方法。<br>也就是说，不管方法的接收者是什么类型，该类型的值和指针都可以调用，不必严格符合接收者的类型。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708063414631-c6a82c2b-95c9-473e-81fa-6a9946eeee84.png#averageHue=%23efeff0&clientId=u10e25113-1fbf-4&from=paste&height=254&id=u5ca141e4&originHeight=317&originWidth=887&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=48073&status=done&style=none&taskId=ubfe9f830-15bf-4102-9516-bdbdf7aaf51&title=&width=709.6" alt="image.png"></p>
<p>前面说过，不管接收者类型是值类型还是指针类型，都可以通过值类型或指针类型调用，这里面实际上通过语法糖起作用的。<br>先说结论：<strong>实现了接收者是值类型的方法，相当于自动实现了接收者是指针类型的方法；而实现了接收者是指针类型的方法，不会自动生成对应接收者是值类型的方法。</strong></p>
<blockquote>
<p>如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的方法。</p>
</blockquote>
<p><a name="QdfRY"></a></p>
<h3 id="两者分别在何时使用"><a href="#两者分别在何时使用" class="headerlink" title="两者分别在何时使用"></a>两者分别在何时使用</h3><p>如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；如果方法的接收者是指针类型，则调用者修改的是指针指向的对象本身。<br>使用指针作为方法的接收者的理由：</p>
<ul>
<li>方法能够修改接收者指向的值。</li>
<li>避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。</li>
</ul>
<p>是使用值接收者还是指针接收者，不是由该方法是否修改了调用者（也就是接收者）来决定，而是应该基于该类型的本质。<br>如果类型具备“原始的本质”，也就是说它的成员都是由 Go 语言里内置的原始类型，如字符串，整型值等，那就定义值接收者类型的方法。像内置的引用类型，如 slice，map，interface，channel，这些类型比较特殊，声明他们的时候，实际上是创建了一个 header， 对于他们也是直接定义值接收者类型的方法。这样，调用函数时，是直接 copy 了这些类型的 header，而 header 本身就是为复制设计的。<br>如果类型具备非原始的本质，不能被安全地复制，这种类型总是应该被共享，那就定义指针接收者的方法。比如 go 源码里的文件结构体（struct File）就不应该被复制，应该只有一份实体。</p>
<p><a name="In8Nr"></a></p>
<h2 id="接口的实现-iface-和-eface-以及-itab"><a href="#接口的实现-iface-和-eface-以及-itab" class="headerlink" title="接口的实现 iface 和 eface 以及 itab"></a>接口的实现 iface 和 eface 以及 itab</h2><p>iface {<br>itab<br>data<br>}</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710212824390-a14f5dcf-ebff-4508-84a8-881bc37fc2d8.png#averageHue=%23fdfbf8&clientId=u3862322c-e6d6-4&from=paste&height=792&id=u4e0483e5&originHeight=792&originWidth=772&originalType=binary&ratio=1&rotation=0&showTitle=false&size=81952&status=done&style=none&taskId=ufe919460-e463-43ab-b13e-f23fb2d999d&title=&width=772" alt="image.png"></p>
<p>eface {<br>type<br>data<br>}<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710212849543-693776d9-3129-4f58-bdd5-509bb089b27b.png#averageHue=%23fcf7ed&clientId=u3862322c-e6d6-4&from=paste&height=369&id=ucd7955a5&originHeight=369&originWidth=869&originalType=binary&ratio=1&rotation=0&showTitle=false&size=23540&status=done&style=none&taskId=ufea197ce-d6c3-4618-872b-a5a7f02ff45&title=&width=869" alt="image.png"></p>
<p>接口的动态类型和动态值：<br>动态类型：itab<br>动态值：data</p>
<p>_类型转换_、_类型断言_本质都是把一个类型转换成另外一个类型。不同之处在于，类型断言是对接口变量进行的操作。</p>
<p>接口转换的原理：<br>当判定一种类型是否满足某个接口时，Go 使用类型的方法集和接口所需要的方法集进行匹配，如果类型的方法集完全包含接口的方法集，则可认为该类型实现了该接口。</p>
<ol>
<li>具体类型转空接口时，_type 字段直接复制源类型的 _type；调用 mallocgc 获得一块新内存，把值复制进去，data 再指向这块新内存。</li>
<li>具体类型转非空接口时，入参 tab 是编译器在编译阶段预先生成好的，新接口 tab 字段直接指向入参 tab 指向的 itab；调用 mallocgc 获得一块新内存，把值复制进去，data 再指向这块新内存。</li>
<li>而对于接口转接口，itab 调用 getitab 函数获取。只用生成一次，之后直接从 hash 表中获取。</li>
</ol>
<p><a name="P7rSP"></a></p>
<h1 id="谈一谈GO-的GPM模型"><a href="#谈一谈GO-的GPM模型" class="headerlink" title="谈一谈GO 的GPM模型"></a>谈一谈GO 的GPM模型</h1><p>好的。<br>G: groutine  —– 协程<br>P: proceccor  —-  保存了一个可以运行的G的队列<br>M: machine —– os 中的 线程</p>
<p>每个p的话，它会绑定M才能去执行G</p>
<p>M执行调度G的任务</p>
<p>M再空闲的时候，可能会去全局的G的队列中获取可以处于GRungable的G来运行<br>同时，如果全局的队列中没有G了，我们可以去其他M绑定的P的LRQ中去抢G来运行</p>
<p><a name="lwMcK"></a></p>
<h3 id="聊一聊协程和线程的区别"><a href="#聊一聊协程和线程的区别" class="headerlink" title="聊一聊协程和线程的区别"></a>聊一聊协程和线程的区别</h3><p>好的<br>从几个方面：</p>
<ol>
<li>内存消耗</li>
<li>创建和销毁</li>
<li>切换</li>
</ol>
<p>内存占用的话：<br>一个goroutine一般是分配2KB的内存消耗<br>一个线程的话一般是分配1MB的内存</p>
<p>创建和销毁<br>threaad的创建和销毁都比计较繁琐，由于线程是操作系统级别的<br>他的创建和销毁会于os kernel 进行交互</p>
<p>调度<br>goroutine 是由goruntime来进行管理的，相当于他是用户级别的概念<br>创建和销毁有goruntime来进行，不需要于内核进行交互。更快</p>
<p>切换</p>
<p><a name="kL8g6"></a></p>
<h1 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h1><p>目前的垃圾回收器采用的垃圾回收方式基本是2大类</p>
<ol>
<li>追踪式– 标记清除 标记整理  增量式 增量整理</li>
<li>引用计数</li>
<li>分代</li>
</ol>
<p>目前go采用的式追踪式的垃圾回收方式<br>标记类的回收<br><strong>三色标记法</strong><br>三种颜色的对象<br><strong>黑色对象</strong><br><strong>灰色对象</strong><br>白色对象<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711518789349-d1cce1d6-28e2-4743-b6d0-4a1fae5a6ede.png#averageHue=%23f3f4f4&clientId=uc4b3b2b3-ab6a-4&from=paste&height=431&id=u572bd87a&originHeight=539&originWidth=885&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=63363&status=done&style=none&taskId=ud22fa045-4d41-4c80-ac3d-20a63c2ca1a&title=&width=708" alt="image.png"><br>在1.8的时候提出了混合屏障技术<br>Go 语言的垃圾回收（GC）过程可以概括为以下几个关键步骤，尽管实际实现包含了许多复杂的优化和技术细节：</p>
<ol>
<li><strong>初始标记（Initial Marking）</strong>:<ul>
<li>GC 开始时，首先进行根扫描，标记所有活跃的“根对象”。根对象包括<strong>全局变量</strong>、<strong>栈上的局部变量</strong>、goroutine 的上下文以及其他一些内部数据结构引用的对象。</li>
</ul>
</li>
<li><strong>并发标记（Concurrent Marking）</strong>:<ul>
<li>Go 语言的 GC 使用并发标记算法来减少停顿时间。在这个阶段，程序继续执行，同时垃圾回收器并发地追踪从根对象开始的所有可达对象，并标记它们为“存活”。</li>
</ul>
</li>
<li><strong>标记终止（Stop-The-World Mark Termination）</strong>:<ul>
<li>为了保证一致性，GC 必须在某一时刻暂停所有的 goroutine，进行所谓的“STW”（Stop-The-World）阶段，完成剩余的标记工作，<strong>解决可能存在的并发标记期间产生的数据竞争问题</strong>。</li>
</ul>
</li>
<li><strong>标记整理（Mark &amp; Sweep or Mark &amp; Compact）</strong>:<ul>
<li>标记完成后，进入清除阶段。在传统的标记-清除（Mark-and-Sweep）算法中，未被标记的对象被视为垃圾并回收它们占用的内存。</li>
<li>在某些 Go 版本中，为了减少内存碎片，采用了标记-压缩（Mark-and-Compact）策略，移动所有存活对象到连续的空间，使得内存更加紧凑。</li>
</ul>
</li>
<li><strong>写屏障（Write Barrier）</strong>:<ul>
<li>在并发标记阶段，为了保持标记集合的一致性，Go 的 GC 引入了写屏障技术。当程序在并发标记期间修改对象引用时，写屏障会记录这种变化，以便后续处理。</li>
</ul>
</li>
<li><strong>内存分配与清扫（Allocation &amp; Sweeping）</strong>:<ul>
<li>清理阶段之后，GC 会重新组织内存区域，使其能够用于新的分配。清理阶段也可能在并发模式下进行，部分区域在不阻塞程序执行的情况下完成清扫。</li>
</ul>
</li>
<li><strong>增量清扫与并发清扫（Incremental Sweeping &#x2F; Concurrent Sweeping）</strong>:<ul>
<li>为了进一步减少 STW 时间，Go 的 GC 可能采用增量清扫策略，分散清扫过程在整个程序执行过程中进行。</li>
</ul>
</li>
<li><strong>自适应调整（Adaptive Tuning）</strong>:</li>
</ol>
<p><a name="UMix3"></a></p>
<h1 id="聊一聊你对go的context的理解"><a href="#聊一聊你对go的context的理解" class="headerlink" title="聊一聊你对go的context的理解"></a>聊一聊你对go的context的理解</h1><p>context式在go1.7中加入的<br>context被叫做上下文，包含Ggroutine的运行状态，环境，现场信息等。<br>context可以存储一些变量。可以用来goroutine之间通知退出和元数据传递的功能。</p>
<p>context 用来 goroutine 之间传递上下文信息，包括：取消信号、超时信号，截止时间，k-v等。</p>
<p>context<br>WithCancle()<br>WithDeadline()<br>WithTimeout()<br>WithValue()</p>
<p>Context: 定义了Context接口的四个方法<br>emptyCtx：空context<br>cancleCtx：可以取消的<br>timerCtx：定时context<br>valueCtx：存储的context<br>todoCtx：不知道干嘛的时候，后面可能需要传递参数，暂时不知道要干嘛的时候可以使用，用来标志。<br>cancler： 取消的接口</p>
<p><a name="plu0f"></a></p>
<h1 id="聊一聊反射"><a href="#聊一聊反射" class="headerlink" title="聊一聊反射"></a>聊一聊反射</h1><blockquote>
<p>在计算机科学中，反射是指计算机程序在运行时（Run time）可以访问、检测和修改它本身状态或行为的一种能力。用比喻来说，反射就是程序在运行的时候能够“观察”并且修改自己的行为。</p>
</blockquote>
<p><strong>在计算机中，反射是指在计算机程序运行过程中，能够访问，检测和修改程程序本身状态或行为的一种能力。</strong></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;reflect&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Dog <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Dog)</span></span> HelloDog()&#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;hello dog&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> dog = Dog&#123;&#125;</span><br><span class="line">    fdog := reflect.ValueOf(&amp;dog)</span><br><span class="line">    helloDog := fdog.MethodByName(<span class="string">&quot;HelloDog&quot;</span>)</span><br><span class="line"></span><br><span class="line">    helloDog.Call(<span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用反射的常见场景有以下两种：</p>
<ol>
<li>不能明确接口调用哪个函数，需要根据传入的参数在运行时决定。</li>
<li>不能明确传入函数的参数类型，需要在运行时处理任意对象。</li>
</ol>
<p><a name="eY02K"></a></p>
<h1 id="聊一聊go中make和new"><a href="#聊一聊go中make和new" class="headerlink" title="聊一聊go中make和new"></a>聊一聊go中make和new</h1><p>’<br>首先我们知道变量的初始化分为2个过程</p>
<ol>
<li>变量的声明</li>
<li>分配内存空间</li>
</ol>
<p>声明指类型变量的时候，系统会默认给他们分配内存空间，并且赋值该类型的零值。</p>
<p>new 和 make 都是内置函数<br>他们都是用来给变量分配内存空间的。</p>
<p><strong>使用场景区别：</strong><br>make 一般都是使用 slice map channel 这三种<br>new 的话可以分配任意类型的数据，并赋值0值<br><strong>返回值区别：</strong><br>make 函数返回的是 slice map channel 类型本身<br>new 返回的是内存地址的指针</p>
<p><a name="i6gde"></a></p>
<h1 id="聊一聊TCMalloc"><a href="#聊一聊TCMalloc" class="headerlink" title="聊一聊TCMalloc"></a>聊一聊TCMalloc</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29216091">https://zhuanlan.zhihu.com/p/29216091</a></p>
<p>说一下微对象，小对象，大对象<br>0，16B<br>16，32KB<br>32KB<br>span</p>
<p>mcache  线程的内存管理<br>mcentral  中央内存管理<br>mheap  堆内存管理</p>
<p><a name="QCD9H"></a></p>
<h1 id="go语言里面的空结构体用来做什么"><a href="#go语言里面的空结构体用来做什么" class="headerlink" title="go语言里面的空结构体用来做什么"></a>go语言里面的空结构体用来做什么</h1><p>struct{}不占据任何内存空间<br>一般有三个用途：</p>
<ol>
<li>实现set集合</li>
<li>和channel配合使用，不具备任何意义，但除用作goroutine之间通知</li>
<li>实现一个不带字段，仅包含方法的结构体</li>
</ol>
<p><a name="rGBpk"></a></p>
<h1 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h1><p><a name="nxOeH"></a></p>
<h2 id="redis-如何实现好友功能"><a href="#redis-如何实现好友功能" class="headerlink" title="redis 如何实现好友功能"></a>redis 如何实现好友功能</h2><p>总体思路我们采用redis里面的zset完成整个功能, 原因是zset有排序(我们要按照关注时间的倒序排列), 去重(我们不能多次关注同一用户)功能. 一个用户我们存贮两个集合, 一个是保存用户关注的人 另一个是保存关注用户的人.<br>用到的命令是:<br>1、 zadd 添加成员：命令格式:zadd key score member [[score][member] …]<br>2、zrem 移除某个成员：命令格式:zrem key member [member …]<br>3、 zcard 统计集合内的成员数：命令格式:zcard key<br>4、 zrange 查询集合内的成员：命令格式:ZRANGE key start stop [WITHSCORES]<br>描述：返回指定区间的成员。其中成员位置按 score 值递增(从小到大)来排序。 WITHSCORES选项是用来让成员和它的score值一并返回.<br>5、 zrevrange跟zrange作用相反<br>6、zrank获取成员的排名：命令格式：zrank key member<br>描述：返回有序集key中成员member的排名。成员按 score 值递增(从小到大)顺序排列。排名以0开始，也就是说score 值最小的为0。返回值：返回成员排名，member不存在返回nil.<br>7、 zinterstore 取两个集合的交集：命令格式：ZINTERSTORE destination numkeys key [key …][WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]<br>描述：计算给定的一个或多个有序集的交集。其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination 。默认情况下，结果集中某个成员的 score 值是所有给定集下该成员 score 值之 和 。<br>返回值：保存到 destination 的结果集成员数。<br>在Go语言中，我们可以使用Redigo库与Redis进行交互来实现好友功能，例如关注&#x2F;取关、获取关注列表和共同关注等功能。以下是一个简单的示例框架，展示如何使用Redis的集合（Set）结构来存储和查询用户的关注关系：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/gomodule/redigo/redis&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Redis连接</span></span><br><span class="line"><span class="keyword">var</span> pool = &amp;redis.Pool&#123;</span><br><span class="line">	Dial: <span class="function"><span class="keyword">func</span><span class="params">()</span></span> (redis.Conn, <span class="type">error</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> redis.Dial(<span class="string">&quot;tcp&quot;</span>, <span class="string">&quot;localhost:6379&quot;</span>)</span><br><span class="line">	&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加关注关系，将粉丝添加到博主的关注者集合中</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">follow</span><span class="params">(followerId <span class="type">string</span>, followedId <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">	conn := pool.Get()</span><br><span class="line">	<span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 将followerId添加到followedId的关注集合中</span></span><br><span class="line">	_, err := conn.Do(<span class="string">&quot;SADD&quot;</span>, fmt.Sprintf(<span class="string">&quot;followers:%s&quot;</span>, followedId), followerId)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 反向添加，也将followedId添加到followerId的关注对象集合中</span></span><br><span class="line">	_, err = conn.Do(<span class="string">&quot;SADD&quot;</span>, fmt.Sprintf(<span class="string">&quot;following:%s&quot;</span>, followerId), followedId)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 取消关注关系</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">unfollow</span><span class="params">(followerId <span class="type">string</span>, followedId <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">	conn := pool.Get()</span><br><span class="line">	<span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 从followedId的关注集合中移除followerId</span></span><br><span class="line">	_, err := conn.Do(<span class="string">&quot;SREM&quot;</span>, fmt.Sprintf(<span class="string">&quot;followers:%s&quot;</span>, followedId), followerId)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 从followerId的关注对象集合中移除followedId</span></span><br><span class="line">	_, err = conn.Do(<span class="string">&quot;SREM&quot;</span>, fmt.Sprintf(<span class="string">&quot;following:%s&quot;</span>, followerId), followedId)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取用户的关注列表</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getFollowing</span><span class="params">(userId <span class="type">string</span>)</span></span> ([]<span class="type">string</span>, <span class="type">error</span>) &#123;</span><br><span class="line">	conn := pool.Get()</span><br><span class="line">	<span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">	followingList, err := redis.Strings(conn.Do(<span class="string">&quot;SMEMBERS&quot;</span>, fmt.Sprintf(<span class="string">&quot;following:%s&quot;</span>, userId)))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> followingList, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取用户的粉丝列表</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getFollowers</span><span class="params">(userId <span class="type">string</span>)</span></span> ([]<span class="type">string</span>, <span class="type">error</span>) &#123;</span><br><span class="line">	conn := pool.Get()</span><br><span class="line">	<span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">	followerList, err := redis.Strings(conn.Do(<span class="string">&quot;SMEMBERS&quot;</span>, fmt.Sprintf(<span class="string">&quot;followers:%s&quot;</span>, userId)))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> followerList, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取两个用户之间的共同关注</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getCommonFollowings</span><span class="params">(userId1 <span class="type">string</span>, userId2 <span class="type">string</span>)</span></span> ([]<span class="type">string</span>, <span class="type">error</span>) &#123;</span><br><span class="line">	conn := pool.Get()</span><br><span class="line">	<span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">	commonFollowingKeys := []<span class="keyword">interface</span>&#123;&#125;&#123;fmt.Sprintf(<span class="string">&quot;following:%s&quot;</span>, userId1), fmt.Sprintf(<span class="string">&quot;following:%s&quot;</span>, userId2)&#125;</span><br><span class="line">	intersection, err := redis.Strings(conn.Do(<span class="string">&quot;SINTER&quot;</span>, commonFollowingKeys...))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> intersection, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// 示例调用</span></span><br><span class="line">	err := follow(<span class="string">&quot;userA&quot;</span>, <span class="string">&quot;userB&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 获取共同关注</span></span><br><span class="line">	common, err := getCommonFollowings(<span class="string">&quot;userA&quot;</span>, <span class="string">&quot;userC&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(<span class="string">&quot;Common followers:&quot;</span>, common)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>数据库的设计<br>好友功能的记录在开发社交应用时通常是要放入数据库进行存储的，以便于管理和维护用户间的好友关系。在设计数据库时，可以采用不同的策略来存储好友关系数据：<br>一对一冗余存储：为每个用户创建一个字段来存储其所有好友的ID列表。这种方法直观简单，但在处理大量好友关系时会导致数据冗余和更新困难。<br>一对多关联表：创建一个中间关联表（Friendship表或Relationship表），包含两个字段分别对应用户ID（如UserID, FriendID），这样每对好友之间存在一条记录。这种方式消除了数据冗余，并且易于添加、删除好友关系以及查询用户的社交网络。<br>例如，在SQL中，中间关联表的设计可能如下所示：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Friendship (</span><br><span class="line">  UserID <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  FriendID <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="comment">-- 其他可选字段，比如添加时间、好友备注等</span></span><br><span class="line">  CreatedAt <span class="type">TIMESTAMP</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  Nickname <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (UserID, FriendID),</span><br><span class="line">  <span class="keyword">FOREIGN</span> KEY (UserID) <span class="keyword">REFERENCES</span> Users(UserID),</span><br><span class="line">  <span class="keyword">FOREIGN</span> KEY (FriendID) <span class="keyword">REFERENCES</span> Users(UserID)</span><br><span class="line">);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a name="GKrQr"></a></p>
<h2 id="redis的持久化"><a href="#redis的持久化" class="headerlink" title="redis的持久化"></a>redis的持久化</h2><p><strong>aof：</strong>操作日志。以追加写的方式<br><strong>rdb：</strong>快照机制，记录所有键值对的快照。<br><strong>混合模式：</strong>aof和rdb两种一起使用。</p>
<p><a name="nNiZQ"></a></p>
<h2 id="redis-缓存"><a href="#redis-缓存" class="headerlink" title="redis 缓存"></a>redis 缓存</h2><p><a name="NTqIP"></a></p>
<h3 id="什么是缓存雪崩，击穿，穿透"><a href="#什么是缓存雪崩，击穿，穿透" class="headerlink" title="什么是缓存雪崩，击穿，穿透"></a>什么是缓存雪崩，击穿，穿透</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708617628883-11a7fa2c-7443-4fb2-9a5c-dcc2aebb287f.png#averageHue=%23ede1be&clientId=u4cfdbc89-b6bf-4&from=paste&id=u49787c08&originHeight=622&originWidth=1080&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u3e228634-43dc-48fe-b051-f41730f7c4b&title="></p>
<p><a name="DM2UM"></a></p>
<h3 id="数据库和缓存如何保证一致性"><a href="#数据库和缓存如何保证一致性" class="headerlink" title="数据库和缓存如何保证一致性"></a>数据库和缓存如何保证一致性</h3><p>「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。<br>所以，<strong>如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况</strong>。<br>但是这个方案前面我们也分析过，在两个更新请求并发执行的时候，会出现数据不一致的问题，因为更新数据库和更新缓存这两个操作是独立的，而我们又没有对操作做任何并发控制，那么当两个线程并发更新它们的话，就会因为写入顺序的不同造成数据的不一致。<br>所以我们得增加一些手段来解决这个问题，这里提供两种做法：</p>
<ul>
<li>在更新缓存前先加个<strong>分布式锁</strong>，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。</li>
<li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</li>
</ul>
<p>对了，针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「<strong>延迟双删</strong>」。<br>延迟双删实现的伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#删除缓存</span><br><span class="line">redis.delKey(X)</span><br><span class="line">#更新数据库</span><br><span class="line">db.update(X)</span><br><span class="line">#睡眠</span><br><span class="line">Thread.sleep(N)</span><br><span class="line">#再删除缓存</span><br><span class="line">redis.delKey(X)</span><br></pre></td></tr></table></figure>

<p>加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。<br>所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。<br>但是具体睡眠多久其实是个<strong>玄学</strong>，很难评估出来，所以这个方案也只是<strong>尽可能</strong>保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。<br>因此，还是比较建议用「先更新数据库，再删除缓存」的方案。</p>
<p><a name="AYHnC"></a></p>
<h4 id="如何保证-2个操作都能执行成功？"><a href="#如何保证-2个操作都能执行成功？" class="headerlink" title="如何保证 2个操作都能执行成功？"></a>如何保证 2个操作都能执行成功？</h4><p>问题原因知道了，该怎么解决呢？有两种方法：</p>
<ul>
<li>重试机制。</li>
<li>订阅 MySQL binlog，再操作缓存。</li>
</ul>
<p><a name="OKDe4"></a></p>
<h2 id="redis的线程模型"><a href="#redis的线程模型" class="headerlink" title="redis的线程模型"></a>redis的线程模型</h2><p><strong>IO多路复用</strong><br>redis的主要工作线程是单线程。<br>IO多路复用<br>edis 6.0 版本之前的单线模式如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710157697915-c135cd77-807e-4b94-b99d-0924e0dc7c85.png#averageHue=%2398cc8a&clientId=u7be26187-811a-4&from=paste&id=u0fe88596&originHeight=1547&originWidth=1622&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u18a0cef3-7f1a-4224-a972-050ccb04ca9&title="><br>首先在Redis初始化的时候，会做以下几件事</p>
<ul>
<li>首先，调用epoll_create()创建一个epoll 对象和调用 socket() 创建一个服务端 socket</li>
<li>然后，调用bind() 绑定端口和调用 listen() 监听该 socket</li>
<li>然后，将调用epoll_ctl（） 将 listen socket 加入到epoll，同时注册 【连接事件】处理函数</li>
</ul>
<p>初始化完成后呢？就会进入到一个 事件循环函数，主要会做以下事情：</p>
<ul>
<li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
<li>接着，调用 epoll_wait 函数等待事件的到来<ul>
<li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li>
<li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; **将客户端对象添加到发送队列 **-&gt; <strong>将执行结果写到发送缓存区等待发送</strong>；</li>
<li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
</ul>
</li>
</ul>
<p><a name="gWFAx"></a></p>
<h2 id="Redis-采用单线程为什么还那么快？"><a href="#Redis-采用单线程为什么还那么快？" class="headerlink" title="Redis 采用单线程为什么还那么快？"></a>Redis 采用单线程为什么还那么快？</h2><ol>
<li>Redis的大部分操作都在内存中完成，并且采用了高校的数据结构，因此，Redis瓶颈可能是机器的内存或者网络带宽，而并非CPU，既然CPU不是性能瓶颈，那么自然就采用单线程的解决方案了；</li>
<li>Redis采用单线程模型可以避免多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁的问题。</li>
<li>Redis采用了I&#x2F;O多路复用机制处理大量的客户端 Socket请求，IO多路复用机制是指一个线程出路多个IO流，就是我们经常听到的select&#x2F;epoll机制，在Redis只运行单线程的情况下，该机制允许内核中，同时存在多个监听Socket和已连接的Socket。内核会一只监听这些Socket上的连接请求或数据请求，一旦有请求打倒，就会交给Redis线程处理，这就实现了一个Redis线程处理多个IO流的效果。’</li>
<li>丰富的数据结构。</li>
<li>渐进式的ReHash，缓存时间戳设计</li>
</ol>
<p><a name="ICDHt"></a></p>
<h2 id="Redis-6-0之后为什么引入了多线程？"><a href="#Redis-6-0之后为什么引入了多线程？" class="headerlink" title="Redis 6.0之后为什么引入了多线程？"></a>Redis 6.0之后为什么引入了多线程？</h2><p>虽然 Redis 的主要工作（网络 I&#x2F;O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I&#x2F;O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I&#x2F;O 的处理上</strong>。<br>所以为了提高网络 I&#x2F;O 的并行度，Redis 6.0 对于网络 I&#x2F;O 采用多线程来处理。<strong>但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解</strong> Redis 有多线程同时执行命令。</p>
<p>因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会<strong>额外创建 6 个线程</strong>（_这里的线程数不包括主线程_）：</p>
<ul>
<li>Redis-server ： Redis的主线程，主要负责执行命令；</li>
<li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li>
<li>io_thd_1、io_thd_2、io_thd_3：三个 I&#x2F;O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I&#x2F;O 多线程，用来分担 Redis 网络 I&#x2F;O 的压力。</li>
</ul>
<p><a name="gEyxn"></a></p>
<h2 id="redis的持久化是如何实现的？"><a href="#redis的持久化是如何实现的？" class="headerlink" title="redis的持久化是如何实现的？"></a>redis的持久化是如何实现的？</h2><p>aof日志 和 rdb快照</p>
<p><a name="FiNyQ"></a></p>
<h2 id="redis的集群模式模式"><a href="#redis的集群模式模式" class="headerlink" title="redis的集群模式模式"></a>redis的集群模式模式</h2><p>想要设计一个高可用的Redis服务，一定要从Redis的多服务借点来考虑：</p>
<ol>
<li>主从复制</li>
<li>哨兵模式</li>
<li>切片模式</li>
</ol>
<p><a name="VvF61"></a></p>
<h3 id="主从的实现："><a href="#主从的实现：" class="headerlink" title="主从的实现："></a><strong>主从的实现：</strong></h3><p>采用一主多从的模式，且主从服务器之间采用的时【读写分离】的方式<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709816765570-9c2881ee-bfcc-4684-9a2a-d33c343d0098.png#averageHue=%23faf9f8&clientId=u8d88e84c-6e84-4&from=paste&height=482&id=ua6a64fdd&originHeight=482&originWidth=1109&originalType=binary&ratio=1&rotation=0&showTitle=false&size=114114&status=done&style=none&taskId=ueae1b274-64a0-4ded-ab07-35bd8b759b8&title=&width=1109" alt="image.png"></p>
<p>主从服务器间的第一次同步的过程可分为三个阶段：</p>
<ul>
<li><strong>第一阶段是建立链接、协商同步</strong>；</li>
<li><strong>第二阶段是主服务器同步数据给从服务器；</strong></li>
<li><strong>第三阶段是主服务器发送新写操作命令给从服务器。</strong></li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710907449732-30a8b8f8-4643-40b4-8375-807f2a25605c.png#averageHue=%23f7f0e7&clientId=u54fe126c-6b6a-4&from=paste&id=ub658da5c&originHeight=555&originWidth=1080&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ua064b7b0-698c-4667-ae49-f81aaf22912&title="></p>
<p>主从复制共有三种模式：<strong>全量复制、基于长连接的命令传播、增量复制</strong>。<br>主从服务器第一次同步的时候，就是采用<strong>全量复制</strong>，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。<br><strong>第一次同步完成后，主从服务器都会维护着一个长连接</strong>，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。<br><strong>如果遇到网络断开，增量复制就可以上场了</strong>，不过这个还跟 repl_backlog_size 这个大小有关系。<br>如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。</p>
<p>replication buffer 、repl backlog buffer 区别如下：</p>
<ul>
<li>出现的阶段不一样：<ul>
<li>repl backlog buffer 是在增量复制阶段出现，<strong>一个主节点只分配一个 repl backlog buffer</strong>；</li>
<li>replication buffer 是在全量复制阶段和增量复制阶段都会出现，<strong>主节点会给每个新连接的从节点，分配一个 replication buffer</strong>；</li>
</ul>
</li>
<li>这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：<ul>
<li>当 repl backlog buffer 满了，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>;</li>
<li>当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，<strong>重新开始全量复制</strong>。</li>
</ul>
</li>
</ul>
<p><a name="ot4WQ"></a></p>
<h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a><strong>哨兵模式</strong></h3><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/cluster/sentinel.html#%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB">https://xiaolincoding.com/redis/cluster/sentinel.html#%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB</a><br>由于主从模式会出现，再主从服务器出现宕机的时候，需要手动进行恢复，出现了哨兵模式。</p>
<p>Redis Sentinel<br>哨兵模式可与监控主从服务器，并提供主从结点故障转移的功能。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709816941354-44b782c7-f857-4bd3-8506-29e878e02fe9.png#averageHue=%23f7f6f4&clientId=u8d88e84c-6e84-4&from=paste&height=501&id=u3a3dfeb9&originHeight=501&originWidth=1019&originalType=binary&ratio=1&rotation=0&showTitle=false&size=119351&status=done&style=none&taskId=u40dc025e-26c5-42ed-8e72-39f3f06d03c&title=&width=1019" alt="image.png"></p>
<p><strong>哨兵机制是基于发布订阅来实现的。</strong><br>哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。<br>当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。<br>哨兵节点主要负责三件事情：<strong>监控、选主、通知</strong>。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710907699863-78577840-b9bf-438c-a10b-593c5451e9df.png#averageHue=%23fdf9f5&clientId=u54fe126c-6b6a-4&from=paste&id=u2647a445&originHeight=326&originWidth=912&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ufe41a467-15b6-466c-a63c-9620020f875&title="></p>
<p><a name="stJCL"></a></p>
<h3 id="切片模式"><a href="#切片模式" class="headerlink" title="切片模式"></a><strong>切片模式</strong></h3><p>当Redis缓存数据量大到一台服务器无法缓存时，就需要使用Redis切片集群（Redis Cluster）方案。</p>
<p>Redis Cluster方案采用哈希槽（Hash Slot），来处理数据结点之间的映射关系。<br>再Redis Cluster方案中，一个切片集群有16384个哈希槽。每个键值对，会根据他的key，被映射到一个哈希槽中，具体步骤：</p>
<ul>
<li>更具键值对的Key，按照CRC16算法，计算一个16bit的值</li>
<li>在对16bit的值取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</li>
</ul>
<p>接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：</p>
<ul>
<li><strong>平均分配：</strong> 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384&#x2F;9 个。</li>
<li><strong>手动分配：</strong> 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709817224814-634accf4-59bc-4e83-8870-86804c99a703.png#averageHue=%23dfd8ca&clientId=u8d88e84c-6e84-4&from=paste&height=535&id=u1985e345&originHeight=535&originWidth=1149&originalType=binary&ratio=1&rotation=0&showTitle=false&size=132239&status=done&style=none&taskId=ube9fa897-be9f-484b-9d8b-97ffe79018b&title=&width=1149" alt="image.png"></p>
<p><a name="cIlzQ"></a></p>
<h2 id="集群脑裂导致数据丢失怎么办？"><a href="#集群脑裂导致数据丢失怎么办？" class="headerlink" title="集群脑裂导致数据丢失怎么办？"></a>集群脑裂导致数据丢失怎么办？</h2><p>脑裂：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。</p>
<p>解决方案：<br>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。<br>在 Redis 的配置文件中有两个参数我们可以设置：</p>
<ul>
<li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li>
<li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li>
</ul>
<p><a name="o7plF"></a></p>
<h2 id="Redis过期删除与内存淘汰"><a href="#Redis过期删除与内存淘汰" class="headerlink" title="Redis过期删除与内存淘汰"></a>Redis过期删除与内存淘汰</h2><p>Redis使用的删除策略是【惰性删除+定期删除】这两种策略配合使用。<br>惰性删除: 不主动删除过期键，每次从数据库访问Key时，都检测Key是否过期，如果过期则删除该key<br>定期删除: 每隔一段时间【随机】从数据库中取出一定数量的Key进行检查，并删除其中的过期key</p>
<p><a name="V6FI3"></a></p>
<h2 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h2><ul>
<li>String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。</li>
<li>List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li>
<li>Hash 类型：缓存对象、购物车等。</li>
<li>Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</li>
<li>Zset 类型：排序场景，比如排行榜、电话和姓名排序等。</li>
<li>BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</li>
<li>HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；</li>
<li>GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；</li>
<li>Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。</li>
</ul>
<p><a name="w7FFo"></a></p>
<h2 id="五种常见的Redis数据库是怎么实现的？"><a href="#五种常见的Redis数据库是怎么实现的？" class="headerlink" title="五种常见的Redis数据库是怎么实现的？"></a>五种常见的Redis数据库是怎么实现的？</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709975287127-f0b2c01d-4b4e-4b59-91f9-e9f36252099f.png#averageHue=%23faf8ef&clientId=uf0c0aeab-6997-4&from=paste&height=586&id=u59b1c7e8&originHeight=586&originWidth=1045&originalType=binary&ratio=1&rotation=0&showTitle=false&size=159413&status=done&style=none&taskId=ufbd177ec-e014-48fb-a475-7af5838cbc7&title=&width=1045" alt="image.png"></p>
<p><a name="ocmXq"></a></p>
<h3 id="redis-的键值对数据库是怎么实现的"><a href="#redis-的键值对数据库是怎么实现的" class="headerlink" title="redis 的键值对数据库是怎么实现的"></a>redis 的键值对数据库是怎么实现的</h3><p>在开始讲数据结构之前，先给介绍下 Redis 是怎样实现键值对（key-value）数据库的。<br>Redis 的键值对中的 key 就是字符串对象，而 <strong>value 可以是字符串对象，也可以是集合数据类型的对象</strong>，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。</p>
<p>Redis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。<br>Redis 的哈希桶是怎么保存键值对数据的呢？<br>哈希桶存放的是指向键值对数据的指针（dictEntry*），这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void * value 指针找到。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710834892948-0b5f0d24-b4ae-4c51-857f-027a6fed7900.png#averageHue=%23f9f6f3&clientId=u7103f469-2912-4&from=paste&id=ua9ecb679&originHeight=662&originWidth=1637&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u605a58b6-77ae-4cd2-aed5-f5fad8ccc25&title="></p>
<ul>
<li>redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针；</li>
<li>dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用，具体什么是 rehash，我在本文的哈希表数据结构会讲；</li>
<li>ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针；</li>
<li>dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void * key 和 void * value 指针， _key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象_。</li>
</ul>
<p><a name="bSHHJ"></a></p>
<h3 id="SDS-string的实现"><a href="#SDS-string的实现" class="headerlink" title="SDS  string的实现"></a>SDS  string的实现</h3><p>Redis 是用 C 语言实现的，但是它没有直接使用 C 语言的 char* 字符数组来实现字符串，而是自己封装了一个名为简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串，也就是 Redis 的 String 数据类型的底层数据结构是 SDS。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710835132398-5d66913d-3bb2-4c11-b2b2-01593640ed8c.png#averageHue=%23eaeaea&clientId=u7103f469-2912-4&from=paste&id=u482c1d03&originHeight=347&originWidth=407&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ue6d64ba7-ec33-40f1-ba34-b8a3d8618dd&title="><br>结构中的每个成员变量分别介绍下：</p>
<ul>
<li><strong>len，记录了字符串长度</strong>。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。</li>
<li><strong>alloc，分配给字符数组的空间长度</strong>。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。</li>
<li><strong>flags，用来表示不同类型的 SDS</strong>。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面在说明区别之处。</li>
<li><strong>buf[]，字符数组，用来保存实际数据</strong>。不仅可以保存字符串，也可以保存二进制数据。</li>
</ul>
<p>总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷</p>
<p><strong>好处</strong>：</p>
<ol>
<li>O(1)复杂度获取字符串长度</li>
<li>二进制安全</li>
<li>不会发生缓冲区溢出</li>
</ol>
<ul>
<li>如果所需的 sds 长度<strong>小于 1 MB</strong>，那么最后的扩容是按照<strong>翻倍扩容</strong>来执行的，即 2 倍的newlen</li>
<li>如果所需的 sds 长度<strong>超过 1 MB</strong>，那么最后的扩容长度应该是 newlen <strong>+ 1MB</strong>。</li>
</ul>
<ol start="4">
<li>节省内存SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。</li>
</ol>
<p>Redis 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。<br>这 5 种类型的主要<strong>区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同</strong>。</p>
<p><a name="AefnE"></a></p>
<h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><p>先来看看「链表节点」结构的样子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//前置节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="comment">//后置节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="comment">//节点的值</span></span><br><span class="line">    <span class="type">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure>

<p>有前置节点和后置节点，可以看的出，这个是一个双向链表。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710835560718-1eba3f58-ee86-4a93-b4e9-63614887b56f.png#averageHue=%23f2f0e7&clientId=u7103f469-2912-4&from=paste&id=u18cb5eaa&originHeight=272&originWidth=1127&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u878a63ea-10e4-4432-bf91-c3ab1c7f562&title="><br>不过，Redis 在 listNode 结构体基础上又封装了 list 这个数据结构，这样操作起来会更方便，链表结构如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span> &#123;</span></span><br><span class="line">    <span class="comment">//链表头节点</span></span><br><span class="line">    listNode *head;</span><br><span class="line">    <span class="comment">//链表尾节点</span></span><br><span class="line">    listNode *tail;</span><br><span class="line">    <span class="comment">//节点值复制函数</span></span><br><span class="line">    <span class="type">void</span> *(*dup)(<span class="type">void</span> *ptr);</span><br><span class="line">    <span class="comment">//节点值释放函数</span></span><br><span class="line">    <span class="type">void</span> (*<span class="built_in">free</span>)(<span class="type">void</span> *ptr);</span><br><span class="line">    <span class="comment">//节点值比较函数</span></span><br><span class="line">    <span class="type">int</span> (*match)(<span class="type">void</span> *ptr, <span class="type">void</span> *key);</span><br><span class="line">    <span class="comment">//链表节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;</span><br><span class="line">&#125; <span class="built_in">list</span>;</span><br></pre></td></tr></table></figure>

<p>list 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup、free、match 函数。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710835938054-ca8e89cd-4333-410b-bd0b-041d3d480fe2.png#averageHue=%23f9f3f2&clientId=u7103f469-2912-4&from=paste&id=uabebb6b0&originHeight=512&originWidth=1449&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ue84c67d3-d718-4227-a47a-f1a2ebd4981&title="></p>
<p><strong>链表的优势和劣势</strong><br><strong>Redis 的链表实现优点如下：</strong></p>
<ul>
<li>listNode 链表节点的结构里带有 prev 和 next 指针，<strong>获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表</strong>；</li>
<li>list 结构因为提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；</li>
<li>list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；</li>
<li>listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此<strong>链表节点可以保存各种不同类型的值</strong>；</li>
</ul>
<p><strong>链表的缺陷也是有的：</strong></p>
<ul>
<li>链表每个节点之间的内存都是不连续的，意味着<strong>无法很好利用 CPU 缓存</strong>。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。</li>
<li>还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，<strong>内存开销较大</strong>。</li>
</ul>
<p><a name="kO6CA"></a></p>
<h3 id="压缩链表"><a href="#压缩链表" class="headerlink" title="压缩链表"></a>压缩链表</h3><p><strong>压缩列表的最大特点</strong>，就是它被设计成一种<strong>内存紧凑型的数据结构</strong>，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。<br>但是，压缩列表的缺陷也是有的：</p>
<ul>
<li>不能保存过多的元素，否则查询效率就会降低；</li>
<li>新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题。</li>
</ul>
<p>因此，Redis 对象（List 对象、Hash 对象、Zset 对象）包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。</p>
<p>压缩列表是 Redis 为了节约内存而开发的，它是<strong>由连续内存块组成的顺序型数据结构</strong>，有点类似于数组。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710836447374-69e85f13-8ca2-4eb5-bbf1-d9b4fc2c311a.png#averageHue=%23cce1ca&clientId=u7103f469-2912-4&from=paste&id=u6a128f16&originHeight=62&originWidth=962&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u558ff954-a166-42b7-9d79-2c37487870c&title="><br>压缩列表在表头有三个字段：</p>
<ul>
<li>_<strong>zlbytes</strong>_，记录整个压缩列表占用对内存字节数；</li>
<li>_<strong>zltail</strong>_，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；</li>
<li>_<strong>zllen</strong>_，记录压缩列表包含的节点数量；</li>
<li>_<strong>zlend</strong>_，标记压缩列表的结束点，固定值 0xFF（十进制255）。</li>
</ul>
<p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zllen）的长度直接定位，复杂度是 O(1)。而<strong>查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素</strong>。<br>另外，压缩列表节点（entry）的构成如下：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710836592715-169171a3-f055-48be-bf78-e81bd3972630.png#averageHue=%23fbf8f6&clientId=u7103f469-2912-4&from=paste&id=uee2c85e8&originHeight=302&originWidth=962&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ue4cf88f7-616b-498c-9fce-d9d6e91604d&title="><br>压缩列表节点包含三部分内容：</p>
<ul>
<li>_<strong>prevlen</strong>_，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；</li>
<li>_<strong>encoding</strong>_，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。</li>
<li>_<strong>data</strong>_，记录了当前节点的实际数据，类型和长度都由 encoding 决定；</li>
</ul>
<p>当我们往压缩列表中插入数据时，压缩列表就会根据数据类型是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，<strong>这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的</strong>。<br>分别说下，prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配。<br>压缩列表里的每个节点中的 prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如：</p>
<ul>
<li>如果<strong>前一个节点的长度小于 254 字节</strong>，那么 prevlen 属性需要用 <strong>1 字节的空间</strong>来保存这个长度值；</li>
<li>如果<strong>前一个节点的长度大于等于 254 字节</strong>，那么 prevlen 属性需要用 <strong>5 字节的空间</strong>来保存这个长度值；</li>
</ul>
<p><strong>连锁更新问题</strong><br><strong>压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降</strong>。</p>
<p><a name="bM57u"></a></p>
<h3 id="哈希表-1"><a href="#哈希表-1" class="headerlink" title="哈希表"></a>哈希表</h3><p>哈希表是一种保存键值对（key-value）的数据结构。<br><strong>Redis 采用了「链式哈希」来解决哈希冲突</strong>，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接起，以便这些数据在表中仍然可以被查询到。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    <span class="comment">//哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">//哈希表大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> size;  </span><br><span class="line">    <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> sizemask;</span><br><span class="line">    <span class="comment">//该哈希表已有的节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure>

<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710836777027-3b68941c-046f-4e1e-a818-c181f67827a6.png#averageHue=%23faf0ec&clientId=u7103f469-2912-4&from=paste&id=ua414477a&originHeight=587&originWidth=1052&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u6ceaea78-177d-4469-b6f7-899d0124a7f&title="></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="comment">//键值对中的键</span></span><br><span class="line">    <span class="type">void</span> *key;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//键值对中的值</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="type">void</span> *val;</span><br><span class="line">        <span class="type">uint64_t</span> u64;</span><br><span class="line">        <span class="type">int64_t</span> s64;</span><br><span class="line">        <span class="type">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">//指向下一个哈希表节点，形成链表</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<p><strong>哈希冲突</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710836963816-30b717e1-0207-460f-bb5b-703496ae90ff.png#averageHue=%23edc3c1&clientId=u7103f469-2912-4&from=paste&id=u7d27ecd1&originHeight=527&originWidth=812&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ueb026312-0ed9-4323-96e8-f368ff4cb22&title="></p>
<p><strong>链式哈希</strong><br>Redis 采用了「<strong>链式哈希</strong>」的方法来解决哈希冲突。<br>链式哈希是怎么实现的？<br>实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，<strong>被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来</strong>，这样就解决了哈希冲突。<br>还是用前面的哈希冲突例子，key1 和 key9 经过哈希计算后，都落在同一个哈希桶，链式哈希的话，key1 就会通过 next 指针指向 key9，形成一个单向链表。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710837000567-d128660e-44ee-46cd-b6e0-e4ac09866a29.png#averageHue=%23f8f8f8&clientId=u7103f469-2912-4&from=paste&id=u79b684c6&originHeight=527&originWidth=1067&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uba1b5557-2ad3-42e3-a952-fab276fe802&title="><br>不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)。<br>要想解决这一问题，就需要进行 rehash，也就是对哈希表的大小进行扩展。<br>接下来，看看 Redis 是如何实现的 rehash 的。</p>
<p><a name="zeHnY"></a></p>
<h3 id="redis的rehash"><a href="#redis的rehash" class="headerlink" title="redis的rehash"></a>redis的rehash</h3><p>哈希表结构设计的这一小节，我给大家介绍了 Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了<strong>两个哈希表（ht[2]）</strong>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span></span><br><span class="line">    …</span><br><span class="line">    <span class="comment">//两个Hash表，交替使用，用于rehash操作</span></span><br><span class="line">    dictht ht[<span class="number">2</span>]; </span><br><span class="line">    …</span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure>

<p>之所以定义了 2 个哈希表，是因为进行 rehash 的时候，需要用上 2 个哈希表了。<br>在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。<br>随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：</p>
<ul>
<li>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大一倍（两倍的意思）；</li>
<li>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。</li>
</ul>
<p>为了方便你理解，我把 rehash 这三个过程画在了下面这张图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710837141863-3ed3ef33-c6ce-4625-bf25-5db36a6a2278.png#averageHue=%23f8f6f0&clientId=u7103f469-2912-4&from=paste&id=ue84d40f1&originHeight=699&originWidth=1344&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u08503bfd-8b01-49ca-a81a-af2ed70323e&title="></p>
<p>为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了<strong>渐进式 rehash</strong>，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。<br><strong>渐进式 rehash 步骤如下：</strong></p>
<ul>
<li>给「哈希表 2」 分配空间；</li>
<li><strong>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上</strong>；</li>
<li>随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。</li>
</ul>
<p><strong>rehash的触发条件</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710837353339-8b862f4f-8717-4a95-b3ce-bcba6c2645d2.png#averageHue=%23ead1b4&clientId=u7103f469-2912-4&from=paste&id=u9df61241&originHeight=77&originWidth=617&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u792f1f78-bd70-4bdd-9efe-26413d913c5&title="><br>触发 rehash 操作的条件，主要有两个：</p>
<ul>
<li><strong>当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。</strong></li>
<li><strong>当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。</strong></li>
</ul>
<p><a name="NES7F"></a></p>
<h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>Redis 只有 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">    dict *dict;</span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure>

<p>zset 结构体里有两个数据结构：一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。<br>链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。<strong>跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表</strong>，这样的好处是能快读定位数据。<br>那跳表长什么样呢？我这里举个例子，下图展示了一个层级为 3 的跳表。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710837465224-ae5b163e-9836-421c-af98-7a055ccbf1c5.png#averageHue=%23f8f5f3&clientId=u7103f469-2912-4&from=paste&id=ucd625e61&originHeight=287&originWidth=1164&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u56d5a5e8-2a82-4d9b-9b60-11dd6f549cb&title="></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//Zset 对象的元素值</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//元素权重值</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure>

<p>Zset 对象要同时保存「元素」和「元素的权重」，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针（struct zskiplistNode *backward），指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。<br>跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的<strong>zskiplistLevel 结构体类型的 level 数组</strong>。<br>level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。</p>
<p><strong>跳表结点的查询过程</strong><br>查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：</p>
<ul>
<li>如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。</li>
<li>如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。</li>
</ul>
<p>如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710837553463-08243cba-110e-4de9-a0b2-d9f4df4f0cf4.png#averageHue=%23f8f5f3&clientId=u7103f469-2912-4&from=paste&id=ud7b4a376&originHeight=437&originWidth=2387&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ub1c18fef-92fc-4665-8df4-757fe511aca&title="><br>如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的：</p>
<ul>
<li>先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点；</li>
<li>但是该层的下一个节点是空节点（ leve[2]指向的是空节点），于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1];</li>
<li>「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，但是当前节点的 SDS 类型数据「大于」要查找的数据，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]；</li>
<li>「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束。</li>
</ul>
<p><strong>跳表层数的设置</strong><br>Redis 则采用一种巧妙的方法是，<strong>跳表在创建节点的时候，随机生成每个节点的层数</strong>，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。<br>具体的做法是，<strong>跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</strong>。<br>这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。</p>
<p><strong>为什么使用跳表不用平衡树</strong><br>简单翻译一下，主要是从内存占用、对范围查找的支持、实现难易程度这三方面总结的原因：</p>
<ul>
<li>它们不是非常内存密集型的。基本上由你决定。改变关于节点具有给定级别数的概率的参数将使其比 btree 占用更少的内存。</li>
<li>Zset 经常需要执行 ZRANGE 或 ZREVRANGE 的命令，即作为链表遍历跳表。通过此操作，跳表的缓存局部性至少与其他类型的平衡树一样好。</li>
<li>它们更易于实现、调试等。例如，由于跳表的简单性，我收到了一个补丁（已经在Redis master中），其中扩展了跳表，在 O(log(N) 中实现了 ZRANK。它只需要对代码进行少量修改。</li>
</ul>
<p>我再详细补充点：</p>
<ul>
<li><strong>从内存占用上来比较，跳表比平衡树更灵活一些</strong>。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li>
<li><strong>在做范围查找的时候，跳表比平衡树操作要简单</strong>。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li>
<li><strong>从算法实现难度上来比较，跳表比平衡树要简单得多</strong>。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li>
</ul>
<p><a name="S8K5o"></a></p>
<h3 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h3><p>quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    <span class="comment">//quicklist的链表头</span></span><br><span class="line">    quicklistNode *head;      <span class="comment">//quicklist的链表头</span></span><br><span class="line">    <span class="comment">//quicklist的链表尾</span></span><br><span class="line">    quicklistNode *tail; </span><br><span class="line">    <span class="comment">//所有压缩列表中的总元素个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> count;</span><br><span class="line">    <span class="comment">//quicklistNodes的个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;   </span><br><span class="line">    ...</span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure>

<p>接下来看看，quicklistNode 的结构定义：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//前一个quicklistNode</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span>     <span class="comment">//前一个quicklistNode</span></span><br><span class="line">    <span class="comment">//下一个quicklistNode</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span>     <span class="comment">//后一个quicklistNode</span></span><br><span class="line">    <span class="comment">//quicklistNode指向的压缩列表</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zl;          </span><br><span class="line">    <span class="comment">//压缩列表的的字节大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz;            </span><br><span class="line">    <span class="comment">//压缩列表的元素个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> count : <span class="number">16</span>;        <span class="comment">//ziplist中的元素个数 </span></span><br><span class="line">    ....</span><br><span class="line">&#125; quicklistNode;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//前一个quicklistNode</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span>     <span class="comment">//前一个quicklistNode</span></span><br><span class="line">    <span class="comment">//下一个quicklistNode</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span>     <span class="comment">//后一个quicklistNode</span></span><br><span class="line">    <span class="comment">//quicklistNode指向的压缩列表</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zl;          </span><br><span class="line">    <span class="comment">//压缩列表的的字节大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz;            </span><br><span class="line">    <span class="comment">//压缩列表的元素个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> count : <span class="number">16</span>;        <span class="comment">//ziplist中的元素个数 </span></span><br><span class="line">    ....</span><br><span class="line">&#125; quicklistNode;</span><br></pre></td></tr></table></figure>

<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710837947913-4cd70ba1-9d06-4e95-a3ab-d6931ec65560.png#averageHue=%23f6f5f2&clientId=u7103f469-2912-4&from=paste&id=u8e2d6fe0&originHeight=299&originWidth=944&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u390de269-4a38-44a4-9d97-25361c79ba3&title="><br>可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是<strong>保存了一个压缩列表</strong>，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。</p>
<p><a name="A5ekz"></a></p>
<h3 id="listpack"><a href="#listpack" class="headerlink" title="listpack"></a>listpack</h3><p>quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。</p>
<p><strong>listpack</strong> 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。<br>我们先看看 listpack 结构：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710838113325-468b6965-c20f-4bd2-83ca-2c9849838ad0.png#averageHue=%238893a2&clientId=u7103f469-2912-4&from=paste&id=u8538c578&originHeight=77&originWidth=1082&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ud28bf316-a77b-41e8-a42d-e91b29ec69e&title="><br>listpack 头包含两个属性，<strong>分别记录了 listpack 总字节数</strong>和<strong>元素数量</strong>，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。<br><strong>每个 listpack 节点结构如下：</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710838140848-abb1b9c4-a1c9-416c-a3a1-fce3e01290a3.png#averageHue=%23faedc8&clientId=u7103f469-2912-4&from=paste&id=u7d838e3e&originHeight=317&originWidth=1082&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ua4ed6c23-63b2-4782-8349-5c4190046e9&title="><br>主要包含三个方面内容：</p>
<ul>
<li><strong>encoding</strong>，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li>
<li><strong>data</strong>，实际存放的数据；</li>
<li><strong>len</strong>，<strong>encoding+data</strong>的总长度；</li>
</ul>
<p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
<p><a name="Ka1Qv"></a></p>
<h2 id="Redis常见数据类型和应用场景"><a href="#Redis常见数据类型和应用场景" class="headerlink" title="Redis常见数据类型和应用场景"></a>Redis常见数据类型和应用场景</h2><p><a name="wocbF"></a></p>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><ol>
<li>缓存对象</li>
<li>常规计数</li>
<li>分布式锁</li>
</ol>
<p><a name="oFZOH"></a></p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/data_struct/command.html#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-2">https://xiaolincoding.com/redis/data_struct&#x2F;command.html#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-2</a></p>
<ol>
<li>消息队列</li>
<li><strong>如何保证消息满足需求？</strong></li>
</ol>
<p>List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。<br>List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。<br><strong>不过，在消费者读取数据时，有一个潜在的性能风险点。</strong><br>在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP 命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。<br>所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。<br>为了解决这个问题，Redis提供了 BRPOP 命令。<strong>BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong>。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。</p>
<ol start="2">
<li><strong>如何处理重复的消息</strong></li>
</ol>
<p>首先消息的重复性有2方面的需求：</p>
<ul>
<li><strong>每个消息都有一个全局的 ID。</strong></li>
<li>消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了</li>
</ul>
<p><strong>List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID</strong>，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。</p>
<ol start="3">
<li><strong>如何保证消息的可靠性</strong></li>
</ol>
<p>当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。<br>为了留存消息，List 类型提供了** BRPOPLPUSH** 命令，这个命令的<strong>作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存</strong>。</p>
<ul>
<li>消息保序：使用 LPUSH + RPOP；</li>
<li>阻塞读取：使用 BRPOP；</li>
<li>重复消息处理：生产者自行实现全局唯一 ID；</li>
<li>消息的可靠性：使用 BRPOPLPUSH</li>
</ul>
<p><strong>缺点？</strong><br><strong>List 不支持多个消费者消费同一条消息</strong>，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。<br>要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 <strong>List 类型并不支持消费组的实现</strong>。</p>
<p><a name="rSZmY"></a></p>
<h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><ol>
<li>缓存对象</li>
<li>购物车</li>
</ol>
<p>涉及的命令如下：</p>
<ul>
<li>添加商品：HSET cart:{用户id} {商品id} 1</li>
<li>添加数量：HINCRBY cart:{用户id} {商品id} 1</li>
<li>商品总数：HLEN cart:{用户id}</li>
<li>删除商品：HDEL cart:{用户id} {商品id}</li>
<li>获取购物车所有商品：HGETALL cart:{用户id}</li>
</ul>
<p><a name="wGxQP"></a></p>
<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><ol>
<li><strong>点赞</strong>：Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。</li>
<li><strong>共同关注</strong>：Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。key 可以是用户id，value 则是已关注的公众号的id。uid:1 用户关注公众号 id 为 5、6、7、8、9，uid:2 用户关注公众号 id 为 7、8、9、10、11。</li>
<li><strong>抽奖活动：</strong>如果允许重复中奖，可以使用 SRANDMEMBER 命令。如果不允许重复中奖，可以使用 SPOP 命令。</li>
</ol>
<p><a name="g4ZYi"></a></p>
<h3 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h3><ol>
<li>排行榜：有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。</li>
<li>电话姓名的排序：</li>
</ol>
<p><a name="gUCec"></a></p>
<h3 id="BitMap"><a href="#BitMap" class="headerlink" title="BitMap"></a>BitMap</h3><ol>
<li>签到统计</li>
<li>判断用户登录状态</li>
<li>连续签到用户总数</li>
</ol>
<p><a name="ZlZzh"></a></p>
<h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><ol>
<li><strong>百万级网页UV计数</strong></li>
</ol>
<p><a name="WM6JX"></a></p>
<h3 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h3><ol>
<li><strong>滴滴叫车</strong></li>
</ol>
<p><a name="tkmEX"></a></p>
<h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><ol>
<li><strong>消息队列</strong></li>
</ol>
<p>生产者通过 XADD 命令插入一条消息：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710907263283-725a20e9-1ad7-4999-964c-040f7c3ab9ed.png#averageHue=%23ebebeb&clientId=u54fe126c-6b6a-4&from=paste&id=u40367fa7&originHeight=123&originWidth=577&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u4a2489c3-110e-43cf-a755-17708730d3a&title="></p>
<p>前面介绍的这些操作 List 也支持的，接下来看看 Stream 特有的功能。<br>Stream 可以以使用 <strong>XGROUP 创建消费组</strong>，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。<br>创建两个消费组，这两个消费组消费的消息队列是 mymq，都指定从第一条消息开始读取：</p>
<blockquote>
<p><strong>基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？</strong></p>
</blockquote>
<p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。<br>消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成，整个流程的执行如下图所示<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710907302262-eaed028f-9ea9-4b40-8b50-4c27bc64f3da.png#averageHue=%23fcfcfc&clientId=u54fe126c-6b6a-4&from=paste&id=u9a2dbb36&originHeight=482&originWidth=1170&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u9f53e70a-2d75-449c-a7e6-6f49e8d72c7&title="><br>如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，<strong>消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息</strong>。</p>
<p>好了，基于 Stream 实现的消息队列就说到这里了，小结一下：</p>
<ul>
<li>消息保序：XADD&#x2F;XREAD</li>
<li>阻塞读取：XREAD block</li>
<li>重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；</li>
<li>消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；</li>
<li>支持消费组形式消费数据</li>
</ul>
<p><a name="TfR4A"></a></p>
<h2 id="Redis的过期策略与内存淘汰策略有什么区别"><a href="#Redis的过期策略与内存淘汰策略有什么区别" class="headerlink" title="Redis的过期策略与内存淘汰策略有什么区别"></a>Redis的过期策略与内存淘汰策略有什么区别</h2><p>Redis 使用的过期删除策略是「惰性删除+定期删除」，删除的对象是已过期的 key。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710838718253-b06f7720-a7a3-42ef-bac9-1906f368cea3.png#averageHue=%23f1f1f1&clientId=u7103f469-2912-4&from=paste&id=uf8d0e7f5&originHeight=260&originWidth=1750&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u38a4a42e-f6ce-405b-a89d-154c92e9f4d&title="></p>
<p>内存淘汰策略是解决内存过大的问题，当 Redis 的运行内存超过最大运行内存时，就会触发内存淘汰策略，Redis 4.0 之后共实现了 8 种内存淘汰策略，我也对这 8 种的策略进行分类，如下：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710838730260-f8df0597-877b-4d8a-b27f-515e79bab7a6.png#averageHue=%23f6f6f6&clientId=u7103f469-2912-4&from=paste&id=ub11e793f&originHeight=804&originWidth=2540&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uf73af15f-19bc-49ff-855d-65968d9847b&title="></p>
<p><a name="AUM38"></a></p>
<h2 id="Redis的缓存策略"><a href="#Redis的缓存策略" class="headerlink" title="Redis的缓存策略"></a>Redis的缓存策略</h2><p>由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而<strong>只是将其中一部分热点数据缓存起来</strong>，所以我们要设计一个热点数据动态缓存的策略。<br>热点数据动态缓存的策略总体思路：<strong>通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据</strong>。<br>以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：</p>
<ul>
<li>先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；</li>
<li>同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；</li>
<li>这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。</li>
</ul>
<p>在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。</p>
<p><a name="sP67b"></a></p>
<h2 id="Redis实战"><a href="#Redis实战" class="headerlink" title="Redis实战"></a>Redis实战</h2><p><a name="EPDKv"></a></p>
<h3 id="Redis如何实现延迟队列"><a href="#Redis如何实现延迟队列" class="headerlink" title="Redis如何实现延迟队列"></a>Redis如何实现延迟队列</h3><p>采用zset来实现<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709827558195-bc773d8a-fb3d-45ee-aed2-df552014c436.png#averageHue=%23f5f5f5&clientId=u8d88e84c-6e84-4&from=paste&height=338&id=u80f6bbb1&originHeight=338&originWidth=1336&originalType=binary&ratio=1&rotation=0&showTitle=false&size=139001&status=done&style=none&taskId=u482a8dac-f9d6-43bd-af5b-d5550e3469a&title=&width=1336" alt="image.png"></p>
<p><a name="gYDRd"></a></p>
<h3 id="Redis管道有什么作用？"><a href="#Redis管道有什么作用？" class="headerlink" title="Redis管道有什么作用？"></a>Redis管道有什么作用？</h3><p>管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。<br>普通命令模式，如下图所示：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709827614080-7731ddab-98c2-4ba4-957f-b651c35762fe.png#averageHue=%23f5efdc&clientId=u8d88e84c-6e84-4&from=paste&height=443&id=u0c84b313&originHeight=443&originWidth=1008&originalType=binary&ratio=1&rotation=0&showTitle=false&size=59351&status=done&style=none&taskId=ub7654808-8d29-49c1-8feb-7c78ae1ad55&title=&width=1008" alt="image.png"></p>
<p>管道模式，如下图所示：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709827623821-b5a2622f-3632-475d-807c-92debd4a566c.png#averageHue=%23f5efdc&clientId=u8d88e84c-6e84-4&from=paste&height=449&id=ue93ee5de&originHeight=449&originWidth=990&originalType=binary&ratio=1&rotation=0&showTitle=false&size=56825&status=done&style=none&taskId=u30c64b03-8a34-4ae9-b6bf-18e19051053&title=&width=990" alt="image.png"></p>
<p>使用<strong>管道技术可以解决多个命令执行时的网络等待</strong>，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。<br>但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞。<br>要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。</p>
<p><a name="LRqjC"></a></p>
<h3 id="如何使用Redis实现分布式锁？"><a href="#如何使用Redis实现分布式锁？" class="headerlink" title="如何使用Redis实现分布式锁？"></a>如何使用Redis实现分布式锁？</h3><p>分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709827858378-a4f0c7d5-e2c6-4f88-96f4-5473e5db8cbe.png#averageHue=%23fbfafa&clientId=u8d88e84c-6e84-4&from=paste&height=456&id=u072938e4&originHeight=456&originWidth=1048&originalType=binary&ratio=1&rotation=0&showTitle=false&size=89202&status=done&style=none&taskId=u4edbd985-8c45-46ab-a565-591fe69a705&title=&width=1048" alt="image.png"></p>
<p>Redis 的set命令有一个 nx 的参数，正好就是一个共享存储系统，可以用来保存分布式锁，而且Redis 的去写性能高，可以应对高并发的锁场景。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">SET lock_key unique_value NX PX <span class="number">10000</span></span><br></pre></td></tr></table></figure>

<ul>
<li>lock_key 就是 key 键；</li>
<li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；</li>
<li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；</li>
<li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。</li>
</ul>
<p>而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。<br>可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">  <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<p>这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。</p>
<blockquote>
<p>基于Redis 实现分布式锁有什么优缺点？</p>
</blockquote>
<p>优点：</p>
<ol>
<li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。</li>
<li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。</li>
<li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</li>
</ol>
<p>缺点：</p>
<ul>
<li><strong>超时时间不好设置</strong>。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。<ul>
<li><strong>那么如何合理设置超时时间呢？</strong> 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</li>
</ul>
</li>
<li><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</li>
</ul>
<blockquote>
<p>如何解决 Redis 集群情况下 分布式锁的可靠性？</p>
</blockquote>
<p>为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。<br>它是基于<strong>多个 Redis 节点</strong>的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。<br>Redlock 算法的基本思路，<strong>是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败</strong>。<br>这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。<br>Redlock 算法加锁三个过程：</p>
<ul>
<li>第一步是，客户端获取当前时间（t1）。</li>
<li>第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：<ul>
<li>加锁操作使用 SET 命令，带上 NX，EX&#x2F;PX 选项，以及带上客户端的唯一标识。</li>
<li>如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。</li>
</ul>
</li>
<li>第三步是，一旦客户端从超过半数（大于等于 N&#x2F;2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li>
</ul>
<p>可以看到，加锁成功要同时满足两个条件（_简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功_）：</p>
<ul>
<li>条件一：客户端从超过半数（大于等于 N&#x2F;2+1）的 Redis 节点上成功获取到了锁；</li>
<li>条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。</li>
</ul>
<p>加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」。如果计算的结果已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。<br>加锁失败后，客户端向<strong>所有 Redis 节点发起释放锁的操作</strong>，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。<br><a name="VbMOY"></a></p>
<h1 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h1><p><a name="kXq3D"></a></p>
<h2 id="计算机网络的各层协议及作用？"><a href="#计算机网络的各层协议及作用？" class="headerlink" title="计算机网络的各层协议及作用？"></a>计算机网络的各层协议及作用？</h2><p>计算机网络体系可以分为三种：</p>
<ol>
<li>OSI七层模型</li>
<li>TCP&#x2F;IP四层模型</li>
<li>五层模型</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711119072985-bd4e7d0b-95bb-41ab-926b-0dcc7dbc09c8.png#averageHue=%23e7e7e7&clientId=u1ee109d9-61a1-4&from=paste&height=673&id=ua59b3841&originHeight=673&originWidth=1215&originalType=binary&ratio=1&rotation=0&showTitle=false&size=339315&status=done&style=none&taskId=u385db74c-cba3-48cb-82e8-ed7cc57b45f&title=&width=1215" alt="image.png"></p>
<p>TCP&#x2F;IP模型总共有四层分别是</p>
<ol>
<li>应用层：专注于为用户提供应用的功能。如：HTTP，FTP，SMTP等。</li>
<li>传输层：<strong>负责端到端的通信</strong>应用层的数据包会传给传输层，传输层为应用层提供网络支持。给数据添加TCP头部。</li>
<li>网络层：<strong>负责网络包的封装、分片、路由、转发，</strong>在应用间数据传输的媒介，帮助应用到应用的通信，实际的传输功能由网络层提供。在TCP数据上添加IP头部。</li>
<li>网络接口层：<strong>负责网络包在物理网络中的传输</strong>，在IP头部前面加上MAC头部，并封装成数据帧，发送到网络上。</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709359684846-12f4ce20-f49d-4a01-93fe-f48d87109afb.png#averageHue=%23e2e3cb&clientId=uc2325c82-c100-4&from=paste&height=442&id=ca74B&originHeight=553&originWidth=959&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=126985&status=done&style=none&taskId=ub4b9395b-6469-4fcd-9d19-29b15475e16&title=&width=767.2" alt="image.png"></p>
<p><strong>注意：</strong><br>网络接口层的传输单位是 数据帧（frame）<br>IP层的传输代为是 包（package）<br>TCP的层的传输单位是 段（segment）<br>HTTP的传输单位是消息或报文（message）<br>但这些名词并没有什么本质的区分，可以统称为数据包。</p>
<p>MSS<br><strong>MTU： 1500字节</strong></p>
<p>一个HTTP请求报文由四个部分组成：<strong>请求行、请求头部、空行、请求数据。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711013268777-edcb10b3-2bb5-4dcd-96ce-515f92f2e1f0.png#averageHue=%23f1f1f4&clientId=ucc0495bc-0f4f-4&from=paste&id=u656086da&originHeight=891&originWidth=1166&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=382120&status=done&style=none&taskId=u67656368-70cd-470c-a414-2dc73bf6131&title=" alt="image.png"><br>常见的HTTP状态码<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710312189616-3e19aa24-30c8-4497-abf9-a8dee673c5af.png#averageHue=%23e6e6d9&clientId=ue288f9df-c806-4&from=paste&height=294&id=ubf04b14f&originHeight=368&originWidth=1080&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=215069&status=done&style=none&taskId=ud68706f9-0a42-430a-8450-6755b090eba&title=&width=864" alt="image.png"></p>
<p><a name="PIVLs"></a></p>
<h2 id="TCP和UDP的区别"><a href="#TCP和UDP的区别" class="headerlink" title="TCP和UDP的区别"></a>TCP和UDP的区别</h2><p><strong>对比如下：</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>UDP</th>
<th>TCP</th>
</tr>
</thead>
<tbody><tr>
<td>是否连接</td>
<td>无连接</td>
<td>面向连接</td>
</tr>
<tr>
<td>是否可靠</td>
<td>不可靠传输，不使用流量控制和拥塞控制</td>
<td>可靠传输，使用流量控制和拥塞控制</td>
</tr>
<tr>
<td>是否有序</td>
<td>无序</td>
<td>有序，消息在传输过程中可能会乱序，TCP 会重新排序</td>
</tr>
<tr>
<td>传输速度</td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td>连接对象个数</td>
<td>支持一对一，一对多，多对一和多对多交互通信</td>
<td>只能是一对一通信</td>
</tr>
<tr>
<td>传输方式</td>
<td>面向报文</td>
<td>面向字节流</td>
</tr>
<tr>
<td>首部开销</td>
<td>首部开销小，仅8字节</td>
<td>首部最小20字节，最大60字节</td>
</tr>
<tr>
<td>适用场景</td>
<td>适用于实时应用（IP电话、视频会议、直播等）</td>
<td>适用于要求可靠传输的应用，例如文件传输</td>
</tr>
</tbody></table>
<p><strong>总结</strong>：<br><strong>TCP 用于在传输层有必要实现可靠传输的情况，UDP 用于对高速传输和实时性有较高要求的通信。TCP 和 UDP 应该根据应用目的按需使用。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711119372432-43baf6c0-d46b-4423-87b1-6b3319a45d6e.png#averageHue=%23e6e6e6&clientId=u1ee109d9-61a1-4&from=paste&height=767&id=u6d954f8a&originHeight=767&originWidth=944&originalType=binary&ratio=1&rotation=0&showTitle=false&size=231536&status=done&style=none&taskId=ub71414d0-0326-4282-9154-7c476a213f6&title=&width=944" alt="image.png"></p>
<p><a name="GoBQC"></a></p>
<h2 id="什么事SYN洪泛攻击？如何防范？"><a href="#什么事SYN洪泛攻击？如何防范？" class="headerlink" title="什么事SYN洪泛攻击？如何防范？"></a>什么事SYN洪泛攻击？如何防范？</h2><p>SYN洪泛攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源。<br>原理：</p>
<ul>
<li>在三次握手过程中，服务器发送 <code>[SYN/ACK]</code> 包（第二个包）之后、收到客户端的 <code>[ACK]</code> 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），此时服务器处于 <code>SYN_RECV</code>（等待客户端响应）状态。如果接收到客户端的 <code>[ACK]</code>，则 TCP 连接成功，如果未接受到，则会<strong>不断重发请求</strong>直至成功。</li>
<li>SYN 攻击的攻击者在短时间内<strong>伪造大量不存在的 IP 地址</strong>，向服务器不断地发送 <code>[SYN]</code> 包，服务器回复 <code>[SYN/ACK]</code> 包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时。</li>
<li>这些伪造的 <code>[SYN]</code> 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。</li>
</ul>
<p>检测：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。<br>防范：</p>
<ul>
<li>通过防火墙、路由器等过滤网关防护。</li>
<li>通过加固 TCP&#x2F;IP 协议栈防范，如增加最大半连接数，缩短超时时间。</li>
<li>SYN cookies技术。SYN Cookies 是对 TCP 服务器端的三次握手做一些修改，专门用来防范 SYN 洪泛攻击的一种手段。</li>
</ul>
<p><a name="jKVI6"></a></p>
<h2 id="TCP协议如何保证可靠性？"><a href="#TCP协议如何保证可靠性？" class="headerlink" title="TCP协议如何保证可靠性？"></a>TCP协议如何保证可靠性？</h2><p>TCP主要提供了<strong>检验和</strong>、<strong>序列号</strong>&#x2F;<strong>确认应答</strong>、<strong>超时重传</strong>、<strong>滑动窗口</strong>、<strong>拥塞控制</strong>和 <strong>流量控制</strong>等方法实现了可靠性传输。</p>
<ul>
<li>检验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。</li>
<li>序列号&#x2F;确认应答：<br>序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。<br>TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文，这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。</li>
<li>滑动窗口：滑动窗口既提高了报文传输的效率，也避免了发送方发送过多的数据而导致接收方无法正常处理的异常。</li>
<li>超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的。</li>
<li>拥塞控制：在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时引入拥塞控制机制，在保证TCP可靠性的同时，提高性能。</li>
<li>流量控制：如果主机A 一直向主机B发送数据，不考虑主机B的接受能力，则可能导致主机B的接受缓冲区满了而无法再接受数据，从而会导致大量的数据丢包，引发重传机制。而在重传的过程中，若主机B的接收缓冲区情况仍未好转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。所以引入流量控制机制，主机B通过告诉主机A自己接收缓冲区的大小，来使主机A控制发送的数据量。流量控制与TCP协议报头中的窗口大小有关。</li>
</ul>
<p><a name="I0r1a"></a></p>
<h2 id="HTTP常见的状态码有哪些？"><a href="#HTTP常见的状态码有哪些？" class="headerlink" title="HTTP常见的状态码有哪些？"></a>HTTP常见的状态码有哪些？</h2><p>常见状态码：</p>
<ul>
<li>200：服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。</li>
<li>301 ： (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。</li>
<li>302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</li>
<li>400 ：客户端请求有语法错误，不能被服务器所理解。</li>
<li>403 ：服务器收到请求，但是拒绝提供服务。</li>
<li>404 ：(未找到) 服务器找不到请求的网页。</li>
<li>500： (服务器内部错误) 服务器遇到错误，无法完成请求。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711119942082-fd615d57-8ba3-4c76-ae4f-0886a7a90d1a.png#averageHue=%23e4e8e7&clientId=u1ee109d9-61a1-4&from=paste&height=394&id=u31149953&originHeight=394&originWidth=1216&originalType=binary&ratio=1&rotation=0&showTitle=false&size=394590&status=done&style=none&taskId=ua417ea28-e883-451b-bd17-b20835fdc96&title=&width=1216" alt="image.png"></p>
<p><a name="uX5lu"></a></p>
<h2 id="状态码301和302的区别是什么？"><a href="#状态码301和302的区别是什么？" class="headerlink" title="状态码301和302的区别是什么？"></a>状态码301和302的区别是什么？</h2><p><strong>共同点</strong>：301和302状态码都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的<strong>Location</strong>首部中获取（<strong>用户看到的效果就是他输入的地址A瞬间变成了另一个地址B</strong>）。<br><strong>不同点</strong>：301表示旧地址A的资源已经被永久地移除了(这个资源不可访问了)，搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。 SEO中302好于301。<br><strong>补充，重定向原因</strong>：</p>
<ol>
<li>网站调整（如改变网页目录结构）；</li>
<li>网页被移到一个新地址；</li>
<li>网页扩展名改变(如应用需要把.php改成.Html或.shtml)。</li>
</ol>
<p><a name="ywRld"></a></p>
<h2 id="GET请求和POST请求的区别？"><a href="#GET请求和POST请求的区别？" class="headerlink" title="GET请求和POST请求的区别？"></a>GET请求和POST请求的区别？</h2><p><strong>使用上的区别</strong>：</p>
<ul>
<li>GET使用URL或Cookie传参，而POST将数据放在BODY中”，这个是因为HTTP协议用法的约定。</li>
<li>GET方式提交的数据有长度限制，则POST的数据则可以非常大”，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。</li>
<li>POST比GET安全，因为数据在地址栏上不可见”，这个说法没毛病，但依然不是GET和POST本身的区别。</li>
</ul>
<p><strong>本质区别</strong><br>GET和POST最大的区别主要是GET请求是幂等性的，POST请求不是。这个是它们本质区别。<br>幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。</p>
<p><a name="Gf5zB"></a></p>
<h2 id="解释一下HTTP长连接和短链接？"><a href="#解释一下HTTP长连接和短链接？" class="headerlink" title="解释一下HTTP长连接和短链接？"></a>解释一下HTTP长连接和短链接？</h2><p><strong>在HTTP&#x2F;1.0中，默认使用的是短连接</strong>。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。<br>但从 <strong>HTTP&#x2F;1.1起，默认使用长连接</strong>，用以保持连接特性。使用长连接的HTTP协议，会在<strong>响应头</strong>有加入这行代码：<code>_Connection:keep-alive_</code><br>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。<br><strong>HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接</strong>。</p>
<p><a name="tspF3"></a></p>
<h2 id="HTTP请求报文和响应报文的格式"><a href="#HTTP请求报文和响应报文的格式" class="headerlink" title="HTTP请求报文和响应报文的格式?"></a>HTTP请求报文和响应报文的格式?</h2><p><strong>请求报文格式：</strong></p>
<ol>
<li>请求行（请求方法+URL协议+版本）</li>
<li>请求头部</li>
<li>空行</li>
<li>请求主体</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET/sample.jspHTTP/1.1 请求行</span><br><span class="line">Accept:image/gif.image/jpeg, 请求头部</span><br><span class="line">Accept-Language:zh-cn</span><br><span class="line">Connection:Keep-Alive</span><br><span class="line">Host:localhost</span><br><span class="line">User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)</span><br><span class="line">Accept-Encoding:gzip,deflate</span><br></pre></td></tr></table></figure>

<p>响应报文：</p>
<ol>
<li>状态行（版本+状态码+原因短句）</li>
<li>响应首部</li>
<li>空行</li>
<li>响应主体</li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server:Apache Tomcat/5.0.12</span><br><span class="line">Date:Mon,6Oct2003 13:23:42 GMT</span><br><span class="line">Content-Length:112</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>HTTP响应示例<span class="tag">&lt;<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        Hello HTTP!</span><br><span class="line">      <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><a name="e4tMH"></a></p>
<h2 id="介绍一下HTTP缓存"><a href="#介绍一下HTTP缓存" class="headerlink" title="介绍一下HTTP缓存"></a>介绍一下HTTP缓存</h2><p>HTTP缓存有2种实现方式：</p>
<ol>
<li>强制缓存：浏览器判断缓存没有过期，直接使用浏览器本地的缓存，主动性在浏览器这边。</li>
<li>协商缓存：Etag, If-None-Match   If-Modfield-Since, Last-Modfield字段来实现的</li>
</ol>
<p>强制缓存：<br>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p>
<ul>
<li>Cache-Control， 是一个相对时间；</li>
<li>Expires，是一个绝对时间；</li>
</ul>
<p>协商缓存：<br>第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是：</p>
<ul>
<li>响应头部中的 Last-Modified：标示这个响应资源的最后修改时间；</li>
<li>请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</li>
</ul>
<p>第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是：</p>
<ul>
<li>响应头部中 Etag：唯一标识响应资源；</li>
<li>请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。<br><a name="P6YHD"></a></li>
</ul>
<h2 id="HTTP-1-1如何优化"><a href="#HTTP-1-1如何优化" class="headerlink" title="HTTP&#x2F;1.1如何优化"></a>HTTP&#x2F;1.1如何优化</h2><ol>
<li>尽量避免发送HTTP请求：通过缓存技术。</li>
<li>减少HTTP请求次数：减少重定向请求，合并请求，延迟发送请求。</li>
<li>减少HTTP响应的数据大小：无损压缩，有损压缩。</li>
</ol>
<p><strong>重定向请求交给代理服务器</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709683535009-1a2e371d-4af0-47fe-8a49-fa0226708081.png#averageHue=%23fafaf9&clientId=u631518c2-9940-4&from=paste&height=646&id=u0ed5d253&originHeight=808&originWidth=1110&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=174381&status=done&style=none&taskId=u5aea53f6-1383-4e7a-ae5d-32e68629f92&title=&width=888" alt="image.png"></p>
<p>代理服务器知晓了重定向规则后，<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709683597546-0ca9c2df-c65d-4c92-8efa-ac815d1f2ae5.png#averageHue=%23fafafa&clientId=u631518c2-9940-4&from=paste&height=500&id=u799c489c&originHeight=625&originWidth=1001&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=120138&status=done&style=none&taskId=ufa34d222-8a39-4125-b043-b320e711732&title=&width=800.8" alt="image.png"></p>
<p><strong>合并请求：</strong><br>把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着<strong>减少了重复发送的 HTTP 头部</strong>。<br><strong>通过将多个小图片合并成一个大图片来减少 HTTP 请求的次数，以减少 HTTP 请求的次数，从而减少网络的开销</strong>。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709683760102-dc5439e7-553c-4e3f-a4e5-c6c3d27d91b2.png#averageHue=%23faf9f9&clientId=u631518c2-9940-4&from=paste&height=342&id=ub768e1ab&originHeight=428&originWidth=1009&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=98792&status=done&style=none&taskId=u04badb64-fcb0-494f-9b30-1113323e5d0&title=&width=807.2" alt="image.png"><br>还可以将图片的二进制数据用 base64 编码后，以 URL 的形式嵌入到 HTML 文件，跟随 HTML 文件一并发送.</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">image</span> <span class="attr">src</span>=<span class="string">&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAFKCAIAAAC7M9WrAAAACXBIWXMAA ... /&gt;</span></span></span><br></pre></td></tr></table></figure>

<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709683905713-37d8bb5d-c694-4cb9-a96e-541cfa104146.png#averageHue=%23f4d6b4&clientId=u631518c2-9940-4&from=paste&height=411&id=u450c864b&originHeight=514&originWidth=1010&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=147954&status=done&style=none&taskId=u5907c8dc-8378-4a83-a76c-04d031842ef&title=&width=808" alt="image.png"><br><strong>合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求</strong>。<br>但是这样的合并请求会带来新的问题，<strong>当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件</strong>，这显然带来了额外的网络消耗。</p>
<p><strong>延迟发送请求：</strong><br>一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，于是可以通过「<strong>按需获取</strong>」的方式，来减少第一时间的 HTTP 请求次数。</p>
<p>如何减少HTTP响应的数据大小？<br>压缩：</p>
<ol>
<li>无损压缩</li>
<li>有损压缩</li>
</ol>
<p><strong>无损压缩</strong><br>gzip 就是比较常见的无损压缩。客户端支持的压缩算法，会在 HTTP 请求中通过头部中的 Accept-Encoding 字段告诉服务器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Accept-Encoding: gzip, deflate, br</span><br></pre></td></tr></table></figure>

<p>服务器收到后，会从中选择一个服务器支持的或者合适的压缩算法，然后使用此压缩算法对响应资源进行压缩，最后通过响应头部中的 Content-Encoding 字段告诉客户端该资源使用的压缩算法。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Content-Encoding: gzip</span><br></pre></td></tr></table></figure>

<p>gzip 的压缩效率相比 Google 推出的 Brotli 算法还是差点意思，也就是上文中的 br，所以如果可以，服务器应该选择压缩效率更高的 br 压缩算法。</p>
<p><strong>有损压缩</strong><br>有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如音频、视频、图片。<br>可以通过 HTTP 请求头部中的 Accept 字段里的「 q 质量因子」，告诉服务器期望的资源质量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Accept: audio/*; q=0.2, audio/basic</span><br></pre></td></tr></table></figure>

<p><a name="OD5kZ"></a></p>
<h2 id="HTTPS-RSA握手解析过程？"><a href="#HTTPS-RSA握手解析过程？" class="headerlink" title="HTTPS RSA握手解析过程？"></a>HTTPS RSA握手解析过程？</h2><p>RSA官方介绍</p>
<blockquote>
<p>RSA加密算法是一种<strong>非对称加密算法</strong>。</p>
</blockquote>
<p>握手过程<br>1.客户端提交https请求<br>2.服务器响应客户,并把服务器公钥发给客户端<br>3.客户端验证公钥的有效性<br>4.有效后，客户端会生成一个会话密钥(一个随机数)<br>5.用服务器公钥加密这个会话密钥后，发送给服务器<br>6.服务器收到公钥加密的密钥后，用私钥解密，获取会话密钥<br>7.客户端与服务器利用<strong>会话密钥</strong>对传输数据进行<strong>对称加密通信</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710049647380-f8aa0009-1ddd-4c56-8046-f2f292554d15.png#averageHue=%23d7dace&clientId=u9db7e599-f377-4&from=paste&id=ue22430e6&originHeight=723&originWidth=630&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=220932&status=done&style=none&taskId=u8874e9db-91db-47cf-b579-7b8f71a38c8&title=" alt="image.png"></p>
<p>客户端如何检查公钥是否合法？</p>
<p>客户端拿着服务器发来的公钥再发请求去CA那做检验？<br>客户端其实需要预置CA签发的根证书，这个根证书中保存了CA的公钥。<br>而且在之前的第2步中，服务器发的并不是服务器公钥，而是由CA签发的服务器证书，这个证书包括了两部分：用CA私钥对服务器公钥以及其他网站信息加密后得到的的密文+对服务器公钥hash后的摘要。<br><strong>服务器将证书发给客户端以后，客户端从CA根证书中获取CA公钥，对服务器证书的密文进行解密，得到服务器公钥(当然还有网站的其他信息，这里先忽略)，然后再hash一次公钥，比较得到的结果和证书携带的摘要是否一致。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710050886931-b44be309-ac2f-4ac2-b609-c2c0377ec2bd.png#averageHue=%23f0f0f0&clientId=u9db7e599-f377-4&from=paste&id=u910fc649&originHeight=630&originWidth=1200&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=362328&status=done&style=none&taskId=uab36c9f3-6cbe-46f8-af1f-8e152e59ad1&title=" alt="image.png"></p>
<p><a name="aLDZc"></a></p>
<h2 id="HTTP-1-0-，HTTP-1-1-HTTP-2-HTTP-3"><a href="#HTTP-1-0-，HTTP-1-1-HTTP-2-HTTP-3" class="headerlink" title="HTTP&#x2F;1.0 ，HTTP&#x2F;1.1 HTTP&#x2F;2 HTTP&#x2F;3"></a>HTTP&#x2F;1.0 ，HTTP&#x2F;1.1 HTTP&#x2F;2 HTTP&#x2F;3</h2><p><a name="kKY3h"></a></p>
<h3 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP&#x2F;1.1"></a>HTTP&#x2F;1.1</h3><ul>
<li><strong>持久连接</strong>：引入了持久连接（Keep-Alive），在一个TCP连接上可以执行多个HTTP请求，减少了建立新连接的开销。</li>
<li><strong>缓存控制</strong>：增强了缓存机制，提供了更精细的缓存控制指令，如Cache-Control头部字段。</li>
<li><strong>管道化</strong>（ Pipelining）：虽然实际应用中存在限制，HTTP&#x2F;1.1允许在一个连接上连续发送多个请求，不过响应仍然按照请求顺序返回。<br><a name="RhgPw"></a></li>
</ul>
<h3 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP&#x2F;2"></a>HTTP&#x2F;2</h3><ul>
<li><strong>多路复用</strong>（Multiplexing）：同一连接上可以并行处理多个请求和响应，避免了HTTP&#x2F;1.x中的“队头阻塞”问题，极大地提高了页面加载速度。</li>
<li><strong>二进制分帧</strong>：将HTTP消息分解为二进制帧，使得不同类型的资源可以在同一个TCP连接上交错传输。</li>
<li><strong>头部压缩</strong>：使用HPACK算法对头部进行压缩，减少不必要的带宽消耗。</li>
<li><strong>服务器推送</strong>：服务器能够预测客户端可能需要的资源，并提前将其推送给客户端。<br><a name="KUmBe"></a></li>
</ul>
<h3 id="HTTP-3"><a href="#HTTP-3" class="headerlink" title="HTTP&#x2F;3"></a>HTTP&#x2F;3</h3><ul>
<li><strong>基于QUIC</strong>：HTTP&#x2F;3 是基于QUIC协议的，而QUIC运行在用户数据报协议（UDP）之上，解决了TCP的某些延迟问题。</li>
<li><strong>更快的连接建立</strong>：QUIC实现了0-RTT（零往返时间）连接重用，即在已有连接上下文中快速恢复会话，无需等待握手完成就可以开始数据传输。</li>
<li><strong>多路复用增强</strong>：继承了HTTP&#x2F;2的多路复用特性，但在传输层更加可靠，即使个别数据包丢失也能确保其他数据流不受影响。</li>
<li><strong>安全性</strong>：QUIC内置了加密功能，所有传输数据都在TLS保护下，提供更安全的传输保障。</li>
<li><strong>拥塞控制优化</strong>：QUIC包含了改进的拥塞控制算法，能更好地应对网络状况的变化。</li>
</ul>
<p>综上所述，每一代HTTP协议都在前一代的基础上针对性能瓶颈做了重大改进，HTTP&#x2F;3特别针对网络延迟、连接效率和安全性方面做出了显著提升。<br><a name="sJEfg"></a></p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><a name="NdWES"></a></p>
<h3 id="HTTP和HTTPS的区别"><a href="#HTTP和HTTPS的区别" class="headerlink" title="HTTP和HTTPS的区别"></a>HTTP和HTTPS的区别</h3><ul>
<li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL&#x2F;TLS 安全协议，使得报文能够加密传输。</li>
<li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。</li>
<li>两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。</li>
<li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711122449771-f4926d70-ce2b-4320-b4ab-0296536ed663.png#averageHue=%23575a58&clientId=u1ee109d9-61a1-4&from=paste&height=491&id=u41edc32e&originHeight=491&originWidth=1060&originalType=binary&ratio=1&rotation=0&showTitle=false&size=52069&status=done&style=none&taskId=u08fbfbe8-9047-47fd-9248-df4f5923d2c&title=&width=1060" alt="image.png"></p>
<p><a name="JzDSR"></a></p>
<h3 id="HTTP1-0和HTTP1-1的区别？"><a href="#HTTP1-0和HTTP1-1的区别？" class="headerlink" title="HTTP1.0和HTTP1.1的区别？"></a>HTTP1.0和HTTP1.1的区别？</h3><ul>
<li><strong>长连接：</strong>HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启<code>Connection： keep-alive</code>，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。</li>
<li><strong>缓存处理：</strong>在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。</li>
<li><strong>贷款优化以及网络连接的使用：</strong>HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li>
<li><strong>错误通知的管理：</strong>在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</li>
<li><strong>Host头处理：</strong>在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。</li>
</ul>
<p><a name="TXtsT"></a></p>
<h3 id="HTTP1-1和HTTP2-0的区别？"><a href="#HTTP1-1和HTTP2-0的区别？" class="headerlink" title="HTTP1.1和HTTP2.0的区别？"></a>HTTP1.1和HTTP2.0的区别？</h3><p>HTTP2.0相比HTTP1.1支持的特性：</p>
<ul>
<li><strong>新的二进制格式</strong>：HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。</li>
<li><strong>多路复用</strong>，即连接共享，即每一个request都是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。</li>
<li><strong>头部压缩</strong>，HTTP1.1的头部（header）带有大量信息，而且每次都要重复发送；HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。</li>
<li><strong>服务端推送</strong>：服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。</li>
</ul>
<p><a name="jQN2A"></a></p>
<h3 id="HTTPS解决了HTTP的哪些问题？"><a href="#HTTPS解决了HTTP的哪些问题？" class="headerlink" title="HTTPS解决了HTTP的哪些问题？"></a>HTTPS解决了HTTP的哪些问题？</h3><ul>
<li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li>
<li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li>
<li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li>
</ul>
<p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 SSL&#x2F;TLS 协议，可以很好的解决了上述的风险：</p>
<ul>
<li><strong>信息加密</strong>：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。</li>
<li><strong>校验机制</strong>：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。</li>
<li><strong>身份证书</strong>：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。</li>
</ul>
<p>HTTPS 是如何解决上面的三个风险的？</p>
<ul>
<li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li>
<li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li>
<li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li>
</ul>
<p>那 HTTP&#x2F;2 相比 HTTP&#x2F;1.1 性能上的改进：</p>
<ul>
<li><strong>头部压缩</strong></li>
<li><strong>二进制格式</strong></li>
<li><strong>并发传输</strong></li>
<li><strong>服务器主动推送资源</strong></li>
</ul>
<p>HTTP&#x2F;2有什么缺陷？<br><strong>对头阻塞问题，</strong>只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。<br><strong>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP&#x2F;2 应用层才能从内核中拿到数据，这就是 HTTP&#x2F;2 队头阻塞问题。</strong></p>
<p><strong>HTTP&#x2F;3 优化</strong><br>前面我们知道了 HTTP&#x2F;1.1 和 HTTP&#x2F;2 都有队头阻塞的问题：</p>
<ul>
<li>HTTP&#x2F;1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是<strong>没有解决响应的队头阻塞</strong>，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 <strong>HTTP 层队头阻塞。</strong></li>
<li>HTTP&#x2F;2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是<strong>一旦发生丢包，就会阻塞住所有的 HTTP 请求</strong>，这属于 <strong>TCP 层队头阻塞。</strong></li>
</ul>
<p>HTTP&#x2F;2 队头阻塞的问题是因为 TCP，所以 <strong>HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710052164831-134c9b1a-94e9-4430-bb26-584a370b5195.jpeg#averageHue=%23d5d9a0&clientId=u9db7e599-f377-4&from=paste&id=ud5f6570a&originHeight=366&originWidth=782&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u852f3ccc-ac83-487c-9f01-d39cd034311&title="></p>
<p>UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP&#x2F;2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。<br>QUIC 有以下 3 个特点。</p>
<ul>
<li>无队头阻塞</li>
<li>更快的连接建立</li>
<li>连接迁移</li>
</ul>
<p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP&#x2F;2 不同，HTTP&#x2F;2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710052528175-5112afb2-38e5-4a3a-9c63-a9aa2c9169ad.jpeg#averageHue=%23f0e9d3&clientId=u9db7e599-f377-4&from=paste&id=ub9538433&originHeight=492&originWidth=742&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u51e4c01b-a9f8-456c-b746-a8fa099179e&title="><br>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP&#x2F;2 的多路复用的协议。</p>
<p><a name="aVap8"></a></p>
<h2 id="谈一谈网址到页面显示，期间发生了什么？"><a href="#谈一谈网址到页面显示，期间发生了什么？" class="headerlink" title="谈一谈网址到页面显示，期间发生了什么？"></a>谈一谈网址到页面显示，期间发生了什么？</h2><p>过程：</p>
<ol>
<li>浏览器对  URL 进行解析，生成发送给服务器的 请求信息</li>
<li>通过DNS查询服务器的域名对应的IP地址。DNS查找过程：本地DNS服务器 &#x3D;&gt; 根域名服务器www. &#x3D;&gt; 顶级域名.com &#x3D;&gt; 查找到<a target="_blank" rel="noopener" href="http://www.server.com的dns服务器/">www.server.com的DNS服务器</a> &#x3D;&gt; 返回<a target="_blank" rel="noopener" href="http://www.server.com的ip地址/">www.server.com的IP地址</a></li>
<li>经过TCP连接： 给数据添加TCP头部，IP头部，MAC地址</li>
<li>通过网卡 &#x3D;&gt; 发送HTTP请求</li>
<li>在网络中传输 经过 交换机和路由器 找到 将请求发送到服务器</li>
<li>服务器响应请求，返回数据</li>
<li>浏览器进行页面渲染</li>
</ol>
<p><strong>在浏览器中输入<a href="http://www.baidu.com后执行的全部过程？">www.baidu.com后执行的全部过程？</a></strong></p>
<ul>
<li>域名解析（域名 <a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com </a>变为 ip 地址）。<br><strong>浏览器搜索自己的DNS缓存</strong>（维护一张域名与IP的对应表）；若没有，则搜索<strong>操作系统的DNS缓存</strong>（维护一张域名与IP的对应表）；若没有，则搜索操作系统的<strong>hosts文件</strong>（维护一张域名与IP的对应表）。<br>若都没有，则找 tcp&#x2F;ip 参数中设置的首选 dns 服务器，即<strong>本地 dns 服务器</strong>（递归查询），<strong>本地域名服务器查询自己的dns缓存</strong>，如果没有，则进行迭代查询。将本地dns服务器将IP返回给操作系统，同时缓存IP。</li>
<li>发起 tcp 的三次握手，建立 tcp 连接。浏览器会以一个随机端口（1024-65535）向服务端的 web 程序 <strong>80</strong> 端口发起 tcp 的连接。</li>
<li>建立 tcp 连接后发起 http 请求。</li>
<li>服务器响应 http 请求，客户端得到 html 代码。服务器 web 应用程序收到 http 请求后，就开始处理请求，处理之后就返回给浏览器 html 文件。</li>
<li>浏览器解析 html 代码，并请求 html 中的资源。</li>
<li>浏览器对页面进行渲染，并呈现给用户。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711122586265-7bc6b184-1fa9-4087-8ea1-def7dd36bd57.png#averageHue=%23bad7e1&clientId=u1ee109d9-61a1-4&from=paste&id=u1e4dc4b5&originHeight=1193&originWidth=841&originalType=url&ratio=1&rotation=0&showTitle=false&size=596925&status=done&style=none&taskId=u2a0a75a4-7328-4b29-8210-d249e5a5e2e&title=" alt="image.png"><br><a name="Nd4nG"></a></p>
<h2 id="GET-与-POST-的区别"><a href="#GET-与-POST-的区别" class="headerlink" title="GET 与 POST 的区别"></a>GET 与 POST 的区别</h2><p><strong>GET的语义</strong>：从服务器获取指定的资源<br><strong>POST的语义</strong>：根据请求负载（报文body）对指定的资源做出处理</p>
<p>按照语义来说<br>GET请求是 安全且等幂的。<br>POST请求不是安全的也不是等幂的。</p>
<p><a name="NvtJc"></a></p>
<h2 id="谈谈HTTP和HTTPS有区别"><a href="#谈谈HTTP和HTTPS有区别" class="headerlink" title="谈谈HTTP和HTTPS有区别"></a>谈谈HTTP和HTTPS有区别</h2><ol>
<li>HTTP是超文本传输协议，信息的传输时明文传输的，存在风险，HTTPS解决了不完全的缺陷，主要时在TCP和HTTP网络层之间增加了一个SSL&#x2F;TLS的安全协议，使得报文能够加密传输。</li>
<li>HTTP建立连接相对比较简单，通过TCP的三次握手就行； 而HTTPS在三次握手基础上还多了一个。SSL&#x2F;TSL的握手过程，才能进行加密传输。</li>
<li>两个的默认端口也不同，HTTP默认时80端口，HTTPS默认时443端口。</li>
<li>HTTPS还要向CA（证书权威机构）申请数字证书，来确认服务器的身份是可信的。</li>
</ol>
<p><a name="xXwwd"></a></p>
<h2 id="什么是Cookie和Session？"><a href="#什么是Cookie和Session？" class="headerlink" title="什么是Cookie和Session？"></a>什么是Cookie和Session？</h2><p><strong>什么是 Cookie</strong><br>HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态<strong>。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。</strong><br>Cookie 主要用于以下三个方面：</p>
<ul>
<li>会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）</li>
<li>个性化设置（如用户自定义设置、主题等）</li>
<li>浏览器行为跟踪（如跟踪分析用户行为等）</li>
</ul>
<p><strong>什么是 Session</strong><br>Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。</p>
<p><a name="vkIOW"></a></p>
<h2 id="Cookie和Session是何如配合的呢？"><a href="#Cookie和Session是何如配合的呢？" class="headerlink" title="Cookie和Session是何如配合的呢？"></a>Cookie和Session是何如配合的呢？</h2><p>用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。<br>当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。<br>根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。</p>
<p><a name="Tzkb7"></a></p>
<h2 id="Cookie和Session的区别？"><a href="#Cookie和Session的区别？" class="headerlink" title="Cookie和Session的区别？"></a>Cookie和Session的区别？</h2><ul>
<li>作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。</li>
<li>存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。</li>
<li>有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。</li>
<li>隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。</li>
<li>存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。</li>
</ul>
<p><a name="hsjCp"></a></p>
<h2 id="如何考虑吧分布式Session问题？"><a href="#如何考虑吧分布式Session问题？" class="headerlink" title="如何考虑吧分布式Session问题？"></a>如何考虑吧分布式Session问题？</h2><p>在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。<br>分布式 Session 一般会有以下几种解决方案：</p>
<ul>
<li><strong>客户端存储</strong>：直接将信息存储在cookie中，cookie是存储在客户端上的一小段数据，客户端通过http协议和服务器进行cookie交互，通常用来存储一些不敏感信息</li>
<li><strong>Nginx ip_hash 策略</strong>：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。</li>
<li><strong>Session 复制</strong>：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。</li>
<li><strong>共享 Session</strong>：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。</li>
</ul>
<p>建议采用共享 Session的方案。</p>
<p><a name="jM3jl"></a></p>
<h2 id="什么是DDos攻击？"><a href="#什么是DDos攻击？" class="headerlink" title="什么是DDos攻击？"></a>什么是DDos攻击？</h2><p>DDos全称Distributed Denial of Service，分布式拒绝服务攻击。最基本的DOS攻击过程如下：</p>
<ol>
<li>客户端向服务端发送请求链接数据包。</li>
<li>服务端向客户端发送确认数据包。</li>
<li>客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认</li>
</ol>
<p>DDoS则是采用分布式的方法，通过在网络上占领多台“肉鸡”，用多台计算机发起攻击。<br>DOS攻击现在基本没啥作用了，因为服务器的性能都很好，而且是多台服务器共同作用，1V1的模式黑客无法占上风。对于DDOS攻击，预防方法有：</p>
<ul>
<li><strong>减少SYN timeout时间</strong>。在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源。</li>
<li><strong>限制同时打开的SYN半连接数目。</strong></li>
</ul>
<p><a name="hXU55"></a></p>
<h2 id="什么是XSS攻击？"><a href="#什么是XSS攻击？" class="headerlink" title="什么是XSS攻击？"></a>什么是XSS攻击？</h2><p>XSS也称 cross-site scripting，<strong>跨站脚本</strong>。这种攻击是<strong>由于服务器将攻击者存储的数据原原本本地显示给其他用户所致的</strong>。比如一个存在XSS漏洞的论坛，用户发帖时就可以引入<strong>带有＜script＞标签的代码</strong>，导致恶意代码的执行。<br>预防措施有：</p>
<ul>
<li>前端：过滤。</li>
<li>后端：转义，<strong>比如go自带的处理器就具有转义功能。</strong></li>
</ul>
<p><a name="DRctw"></a></p>
<h2 id="SQL注入是什么？如何避免？"><a href="#SQL注入是什么？如何避免？" class="headerlink" title="SQL注入是什么？如何避免？"></a>SQL注入是什么？如何避免？</h2><p>SQL 注入就是在用户输入的字符串中加入 SQL 语句，如果在设计不良的程序中忽略了检查，那么这些注入进去的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。<br><strong>SQL注入的原理主要有以下 4 点</strong></p>
<ul>
<li>恶意拼接查询</li>
<li>利用注释执行非法命令</li>
<li>传入非法参数</li>
<li>添加额外条件</li>
</ul>
<p><strong>避免SQL注入的一些方法</strong>：</p>
<ul>
<li>限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。</li>
<li>对进入数据库的特殊字符（’”\尖括号&amp;*;等）转义处理。</li>
<li>提供参数化查询接口，不要直接使用原生SQL。</li>
</ul>
<p><a name="QtGH0"></a></p>
<h2 id="为什么又了HTTP协议，还有RPC协议"><a href="#为什么又了HTTP协议，还有RPC协议" class="headerlink" title="为什么又了HTTP协议，还有RPC协议"></a>为什么又了HTTP协议，还有RPC协议</h2><p>HTTP和RPC都是基于TCP协议上的。<br>RPC的话，叫做 远程服务调用<br>从发展上来说的话，HTTP主要使用在B&#x2F;S架构，而RPC更多的话是用于C&#x2F;S架构。<br>RPC出现是比HTTP要早的，且比目前主流的 HTTP&#x2F;1.1 <strong>性能</strong>要更好，所以大部分公司内部都还在使用 RPC。</p>
<p><a name="lEOxS"></a></p>
<h2 id="什么是TCP和TCP连接"><a href="#什么是TCP和TCP连接" class="headerlink" title="什么是TCP和TCP连接"></a>什么是TCP和TCP连接</h2><p>TCP 是<strong>面向连接的</strong>，<strong>可靠的</strong>，<strong>基于字节流</strong>的传输层通信协议。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709362862376-3d0caad5-7348-4530-8666-55bc98b96312.png#averageHue=%23f6f79f&clientId=uc2325c82-c100-4&from=paste&height=160&id=SRH6L&originHeight=200&originWidth=568&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=52816&status=done&style=none&taskId=u1f881fe2-6b04-4554-b6ca-8621ebb65fa&title=&width=454.4" alt="image.png"></p>
<p>**面向连接： **一定是【一对一】才能连接<br><strong>可靠的</strong>：无论网络链路中出现什么情况，TCP都能够保证一个报文一定能够到达接收端。<br><strong>字节流</strong>：通过TCP协议传输时，消息可能会被操作系统【分组】成多个TCP报文，如果接受方不知道【消息边界】，是无法读出一个有效的消息的。TCP报文时【有序的】，当一个TCP报文没有收到时，即使它先收到后面的TCP报文，那么也不能交给应用层处理，同时【重复】的TCP报文会自动丢弃。</p>
<p>TCP连接：用于保证可靠性和流量控制维护的某些信息。包括Socket，序列号，窗口大小称为连接。<br>建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。</p>
<ul>
<li><strong>Socket</strong>：由 IP 地址和端口号组成</li>
<li><strong>序列号</strong>：用来解决乱序问题等</li>
<li><strong>窗口大小</strong>：用来做流量控制</li>
</ul>
<p><a name="QdeWO"></a></p>
<h2 id="为什么三次握手，四次挥手"><a href="#为什么三次握手，四次挥手" class="headerlink" title="为什么三次握手，四次挥手"></a>为什么三次握手，四次挥手</h2><p><strong>三次握手</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709462839600-29c2e4a9-9b9b-48a5-9706-404c1de44e99.png#averageHue=%23f9efd3&clientId=uc474559a-8b22-4&from=paste&height=643&id=NKUeS&originHeight=804&originWidth=1033&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=298458&status=done&style=none&taskId=u7cd7b7c7-bcab-4aab-ac8a-939db310c2b&title=&width=826.4" alt="image.png"><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708487536014-76964668-b672-4b09-8b86-777af7ee1f54.png#averageHue=%23d3eadc&clientId=u87a6036e-9e71-4&from=paste&height=524&id=fMrHA&originHeight=655&originWidth=1095&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=236640&status=done&style=none&taskId=u12f2a23e-78c2-4561-b7f5-1b40314275c&title=&width=876" alt="image.png"><br><strong>以三个方面分析三次握手的原因：</strong></p>
<ul>
<li>三次握手才可以阻止重复历史连接的初始化（主要原因）</li>
<li>三次握手才可以同步双方的初始序列号</li>
<li>三次握手才可以避免资源浪费</li>
</ul>
<p><strong>客户端</strong><br>close<br>syn_sent<br>established</p>
<p><strong>服务器</strong><br>close<br>listen<br>syn_rcvd<br>established</p>
<p>两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。</p>
<p><strong>四次挥手</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708487757441-d5ddedd1-1e6f-4cd8-9748-9ed3b124d724.png#averageHue=%23d3ead9&clientId=u87a6036e-9e71-4&from=paste&height=620&id=Z8V71&originHeight=775&originWidth=1277&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=385283&status=done&style=none&taskId=ud21cd58b-4b5a-4d6a-8ba1-fa2e9a4247e&title=&width=1021.6" alt="image.png"><br><strong>第四次挥手要等2个MSL。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709463083714-fb4c5e33-0a7c-4beb-a911-4f413c8d05e2.png#averageHue=%23f5e9d1&clientId=uc474559a-8b22-4&from=paste&height=787&id=nwTt5&originHeight=984&originWidth=994&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=323654&status=done&style=none&taskId=u7dfaac5a-002e-47c1-b58d-d7e4961f768&title=&width=795.2" alt="image.png"></p>
<p><strong>客户端</strong><br><strong>established</strong><br><strong>发送 FIN</strong><br><strong>FIN_WAIT_1</strong><br><strong>收到ACK</strong><br><strong>FIN_WAIT_2</strong><br><strong>收到FIN</strong><br><strong>TIME_WAIT</strong><br><strong>经过2个MSL</strong><br><strong>CLOSE</strong></p>
<p><strong>服务器</strong><br><strong>established</strong><br><strong>收到FIN信号</strong><br><strong>发送ACK</strong><br><strong>CLOSE_WAIT</strong><br><strong>发送FIN</strong><br><strong>LAST_ACK</strong><br><strong>收到ACK</strong><br><strong>close</strong></p>
<p><strong>MSL： 报文最长生存时间。</strong></p>
<p><a name="i6MSc"></a></p>
<h2 id="聊一聊TCP的重传机制"><a href="#聊一聊TCP的重传机制" class="headerlink" title="聊一聊TCP的重传机制"></a>聊一聊TCP的重传机制</h2><p><strong>超时重传</strong><br>RTT 指的是<strong>数据发送时刻到接收到确认的时刻的差值</strong>，也就是包的往返时间<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709364176531-5e5b2fc2-390d-4794-9163-e11cea0a3221.png#averageHue=%23faf8f4&clientId=uc2325c82-c100-4&from=paste&height=652&id=nck5F&originHeight=815&originWidth=958&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=199311&status=done&style=none&taskId=ub48f5822-6552-4bb8-b99e-40692f4b3ad&title=&width=766.4" alt="image.png"><br>超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709364227619-13a734b3-b768-4f61-90df-8cc719b2b8b1.png#averageHue=%23faf4f1&clientId=uc2325c82-c100-4&from=paste&height=433&id=xQxab&originHeight=541&originWidth=961&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=181556&status=done&style=none&taskId=ub51f3b8f-2f57-4314-9380-b419538c554&title=&width=768.8" alt="image.png"></p>
<p>超时重传的时间RTO略大于RTT</p>
<p><strong>快速重传</strong></p>
<p>快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709365125790-61cb15e2-5fce-4f8d-9a7b-6725751f4969.png#averageHue=%23f9f8f6&clientId=uc2325c82-c100-4&from=paste&height=579&id=ciOsT&originHeight=724&originWidth=1073&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=201355&status=done&style=none&taskId=u72c5263a-80be-49a2-ae92-2e06c44b528&title=&width=858.4" alt="image.png"></p>
<p><strong>SACK（选择性确认）</strong><br>在TCP头部【选项】字段里面加一个 SACK 的东西，将 已收到的数据的信息发送给 【发送方】。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709365411804-80969bca-e65a-410f-aaa2-1e0652a44821.png#averageHue=%23fbfbfb&clientId=uc2325c82-c100-4&from=paste&height=457&id=UQpCF&originHeight=571&originWidth=1042&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=198901&status=done&style=none&taskId=ub6e65fa8-abcc-436d-9420-931a162101a&title=&width=833.6" alt="image.png"></p>
<p>D-SACK</p>
<ol>
<li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li>
<li>可以知道是不是「发送方」的数据包被网络延迟了;</li>
<li>可以知道网络中是不是把「发送方」的数据包给复制了;</li>
</ol>
<p><a name="wSsHb"></a></p>
<h2 id="你知道滑动窗口吗？"><a href="#你知道滑动窗口吗？" class="headerlink" title="你知道滑动窗口吗？"></a>你知道滑动窗口吗？</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709365934409-e7dadc52-99f9-4982-bbff-0bd9b137e2ff.png#averageHue=%23faf7f6&clientId=uc2325c82-c100-4&from=paste&height=559&id=upI37&originHeight=699&originWidth=1009&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=270158&status=done&style=none&taskId=u6e6be0ff-d3cd-420c-bbe4-5d2f4d1b904&title=&width=807.2" alt="image.png"><br>图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫<strong>累计确认</strong>或者<strong>累计应答</strong>。</p>
<p><strong>swnd 发送窗口</strong><br><strong>rwnd 接收窗口</strong></p>
<p><a name="Pl7wF"></a></p>
<h2 id="TCP如何做的-流量控制和拥塞控制？"><a href="#TCP如何做的-流量控制和拥塞控制？" class="headerlink" title="TCP如何做的 流量控制和拥塞控制？"></a>TCP如何做的 流量控制和拥塞控制？</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709366930291-4bdcc0f8-5336-4395-84c9-e9f29ad2a00f.png#averageHue=%23f5f5f5&clientId=uc2325c82-c100-4&from=paste&height=643&id=XHsls&originHeight=804&originWidth=954&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=331586&status=done&style=none&taskId=ua7ff9bb7-d940-4a8b-ac2e-5738576697a&title=&width=763.2" alt="image.png"></p>
<p><strong>拥塞窗口 cwnd</strong><br>拥塞窗口 cwnd 变化的规则：</p>
<ul>
<li>只要网络中没有出现拥塞，cwnd 就会增大；</li>
<li>但网络中出现了拥塞，cwnd 就减少；</li>
</ul>
<p><strong>拥塞控制主要是四个算法：</strong></p>
<ul>
<li>慢启动</li>
<li>拥塞避免</li>
<li>拥塞发生</li>
<li>快速恢复</li>
</ul>
<p><strong>慢启动</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709367182087-c0502802-d8a5-4d52-ab63-d02f9e414ebd.png#averageHue=%23fafafa&clientId=uc2325c82-c100-4&from=paste&height=534&id=qkTUp&originHeight=667&originWidth=1012&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=190421&status=done&style=none&taskId=ub78ca314-6991-4637-8f5b-47b4acdab83&title=&width=809.6" alt="image.png"></p>
<p>那慢启动涨到什么时候是个头呢？<br>有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。</p>
<ul>
<li>当 cwnd &lt; ssthresh 时，使用慢启动算法。</li>
<li>当 cwnd &gt;&#x3D; ssthresh 时，就会使用「拥塞避免算法」。</li>
</ul>
<p><strong>拥塞避免算法</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709367332612-8f387917-779b-4ba1-9d08-fe5ff8fae930.png#averageHue=%23fbf9f7&clientId=uc2325c82-c100-4&from=paste&height=650&id=jvdAW&originHeight=812&originWidth=1083&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=179450&status=done&style=none&taskId=u6331e98e-ad48-4ef1-9122-d55cee895f5&title=&width=866.4" alt="image.png"></p>
<p><strong>拥塞发生算法</strong></p>
<ul>
<li>超时重传：ssthresh &#x3D; cwmd&#x2F;2， cwnd重置为1</li>
<li>快速重传：</li>
</ul>
<p><strong>超时重传</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709367502034-4fcf6e04-6b92-4c27-81b1-b1d64869db8a.png#averageHue=%23faf7f6&clientId=uc2325c82-c100-4&from=paste&height=632&id=BeJRQ&originHeight=790&originWidth=1126&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=234900&status=done&style=none&taskId=u963450e0-2928-442c-b5a6-d9a59c70737&title=&width=900.8" alt="image.png"><br><strong>快速重传</strong></p>
<ul>
<li>cwnd &#x3D; cwnd&#x2F;2</li>
<li>ssthresh &#x3D; cwnd</li>
</ul>
<p><strong>快速恢复</strong><br><strong>cwnd &#x3D; ssthresh + 3</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709368816331-4010c712-e044-4e2c-8051-c9101efe8e7e.png#averageHue=%23f9f6f2&clientId=uc2325c82-c100-4&from=paste&height=512&id=ssH4M&originHeight=640&originWidth=1053&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=233112&status=done&style=none&taskId=uf93b63a5-5cac-4b96-87ec-956ca7430e7&title=&width=842.4" alt="image.png"></p>
<p><a name="LHSDK"></a></p>
<h2 id="IP"><a href="#IP" class="headerlink" title="IP"></a>IP</h2><p><a name="vrlPj"></a></p>
<h3 id="IP协议相关技术"><a href="#IP协议相关技术" class="headerlink" title="IP协议相关技术"></a>IP协议相关技术</h3><p><a name="zF77j"></a></p>
<h4 id="DNS-域名解析"><a href="#DNS-域名解析" class="headerlink" title="DNS 域名解析"></a>DNS 域名解析</h4><p>DNS的功能：DNS可以将域名网站制动转换成IP地址。</p>
<p>域名的层级关系<br>例如： <a target="_blank" rel="noopener" href="http://www.server.com/">www.server.com</a><br>在域名中，<strong>越靠右</strong>的位置表示层级<strong>越高</strong></p>
<p>根域名在最顶层，它的下一层就是com顶级域名，再下一层是 server.com<br>所以域名的层级关系类似一个树状的结构：</p>
<ul>
<li>根DNS服务器</li>
<li>顶级域 DNS 服务器(com)</li>
<li>权威DNS 服务器（server.com）</li>
</ul>
<p><a name="z7tu7"></a></p>
<h4 id="DHCP-协议"><a href="#DHCP-协议" class="headerlink" title="DHCP 协议"></a>DHCP 协议</h4><p>DHCP在我们生活中十分常见，我们的电脑通常都是通过DHCP动态获取IP地址，大大省去了配置IP信息繁琐的过程。</p>
<p><a name="uuAQg"></a></p>
<h4 id="NAT-网络地址转换NAT"><a href="#NAT-网络地址转换NAT" class="headerlink" title="NAT  网络地址转换NAT"></a>NAT  网络地址转换NAT</h4><p>NAT的话，是一种网络地址转换技术<br>提出NAT的元婴<br>IPv4的地址是非常紧缺的，NAT的提出，缓解了IPv4地址耗尽的问题。<br>简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710054634725-e2249f45-5dd2-451e-a931-c21e1abc3018.png#averageHue=%23f6f5f4&clientId=u9db7e599-f377-4&from=paste&id=nq6jC&originHeight=617&originWidth=1562&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u5c80cc0a-b289-4cf0-99e4-084563fec12&title="></p>
<p>由于 NAT&#x2F;NAPT 都依赖于自己的转换表，因此会有以下的问题：</p>
<ul>
<li>外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。</li>
<li>转换表的生成与转换操作都会产生性能开销。</li>
<li>通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。</li>
</ul>
<p>如何解决NAT潜在的问题？</p>
<ol>
<li>IPv6</li>
<li>NAT穿透技术</li>
</ol>
<p><a name="hvTmZ"></a></p>
<h4 id="ICMP协议-互联网控制报文协议"><a href="#ICMP协议-互联网控制报文协议" class="headerlink" title="ICMP协议 互联网控制报文协议"></a>ICMP协议 互联网控制报文协议</h4><p>ICMP 主要的功能包括：<strong>确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。</strong><br>ICMP 大致可以分为两大类：</p>
<ul>
<li>一类是用于诊断的查询消息，也就是「<strong>查询报文类型</strong>」</li>
<li>另一类是通知出错原因的错误消息，也就是「<strong>差错报文类型</strong>」</li>
</ul>
<p><a name="wEgzW"></a></p>
<h2 id="聊一聊你对跨域的看法。CORS"><a href="#聊一聊你对跨域的看法。CORS" class="headerlink" title="聊一聊你对跨域的看法。CORS"></a>聊一聊你对跨域的看法。CORS</h2><blockquote>
<p>CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。</p>
</blockquote>
<p>CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。<br>整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。<br>因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。</p>
<p><strong>两种请求</strong><br>浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。<br>只要同时满足以下两大条件，就属于简单请求。<br>（1) 请求方法是以下三种方法之一：</p>
<ul>
<li>HEAD</li>
<li>GET</li>
<li>POST</li>
</ul>
<p>（2）HTTP的头信息不超出以下几种字段：</p>
<ul>
<li>Accept</li>
<li>Accept-Language</li>
<li>Content-Language</li>
<li>Last-Event-ID</li>
<li>Content-Type：只限于三个值application&#x2F;x-www-form-urlencoded、multipart&#x2F;form-data、text&#x2F;plain</li>
</ul>
<p>这是为了兼容表单（form），因为历史上表单一直可以发出跨域请求。AJAX 的跨域设计就是，只要表单可以发，AJAX 就可以直接发。<br>凡是不同时满足上面两个条件，就属于非简单请求。<br>浏览器对这两种请求的处理，是不一样的。</p>
<p><a name="vJcnB"></a></p>
<h3 id="简单请求"><a href="#简单请求" class="headerlink" title="简单请求"></a><strong>简单请求</strong></h3><p>对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个<strong>Origin</strong>字段。<br>下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个<strong>Origin</strong>字段。</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/cors</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Origin</span><span class="punctuation">: </span>http://api.bob.com</span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>api.alice.com</span><br><span class="line"><span class="attribute">Accept-Language</span><span class="punctuation">: </span>en-US</span><br><span class="line"><span class="attribute">Connection</span><span class="punctuation">: </span>keep-alive</span><br><span class="line"><span class="attribute">User-Agent</span><span class="punctuation">: </span>Mozilla/5.0...</span><br></pre></td></tr></table></figure>

<p>上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。<br>如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。<br>如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Access-Control-Allow-Origin</span><span class="punctuation">: </span>http://api.bob.com</span><br><span class="line"><span class="attribute">Access-Control-Allow-Credentials</span><span class="punctuation">: </span>true</span><br><span class="line"><span class="attribute">Access-Control-Expose-Headers</span><span class="punctuation">: </span>FooBar</span><br><span class="line"><span class="attribute">Content-Type</span><span class="punctuation">: </span>text/html; charset=utf-8</span><br></pre></td></tr></table></figure>

<p>上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。<br><strong>（1）Access-Control-Allow-Origin</strong><br>该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。<br><strong>（2）Access-Control-Allow-Credentials</strong><br>该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。<br><strong>（3）Access-Control-Expose-Headers</strong><br>该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(‘FooBar’)可以返回FooBar字段的值。</p>
<p><strong>withCredentials 属性</strong><br>上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Access-Control-Allow-Credentials</span><span class="punctuation">: </span>true</span><br></pre></td></tr></table></figure>

<p>另一方面，开发者必须在AJAX请求中打开withCredentials属性。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> xhr = <span class="keyword">new</span> <span class="title class_">XMLHttpRequest</span>();</span><br><span class="line">xhr.<span class="property">withCredentials</span> = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。<br>但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">xhr.<span class="property">withCredentials</span> = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，如果要发送<strong>Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。</strong>同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。</p>
<p><a name="apkze"></a></p>
<h3 id="非简单请求"><a href="#非简单请求" class="headerlink" title="非简单请求"></a>非简单请求</h3><p><a name="GZdWN"></a></p>
<h4 id="预检请求"><a href="#预检请求" class="headerlink" title="预检请求"></a>预检请求</h4><p>非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application&#x2F;json。<br>非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”**预检”**请求（preflight）。<br>浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。<br>下面是一段浏览器的JavaScript脚本。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> url = <span class="string">&#x27;http://api.alice.com/cors&#x27;</span>;</span><br><span class="line"><span class="keyword">var</span> xhr = <span class="keyword">new</span> <span class="title class_">XMLHttpRequest</span>();</span><br><span class="line">xhr.<span class="title function_">open</span>(<span class="string">&#x27;PUT&#x27;</span>, url, <span class="literal">true</span>);</span><br><span class="line">xhr.<span class="title function_">setRequestHeader</span>(<span class="string">&#x27;X-Custom-Header&#x27;</span>, <span class="string">&#x27;value&#x27;</span>);</span><br><span class="line">xhr.<span class="title function_">send</span>();</span><br></pre></td></tr></table></figure>

<p>上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。<br>浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">OPTIONS</span> <span class="string">/cors</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Origin</span><span class="punctuation">: </span>http://api.bob.com</span><br><span class="line"><span class="attribute">Access-Control-Request-Method</span><span class="punctuation">: </span>PUT</span><br><span class="line"><span class="attribute">Access-Control-Request-Headers</span><span class="punctuation">: </span>X-Custom-Header</span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>api.alice.com</span><br><span class="line"><span class="attribute">Accept-Language</span><span class="punctuation">: </span>en-US</span><br><span class="line"><span class="attribute">Connection</span><span class="punctuation">: </span>keep-alive</span><br><span class="line"><span class="attribute">User-Agent</span><span class="punctuation">: </span>Mozilla/5.0...</span><br></pre></td></tr></table></figure>

<p>“预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。<br>除了Origin字段，”预检”请求的头信息包括两个特殊字段。<br><strong>（1）Access-Control-Request-Method</strong><br>该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。<br><strong>（2）Access-Control-Request-Headers</strong><br>该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。</p>
<p><a name="dmhUu"></a></p>
<h4 id="预检请求的回应"><a href="#预检请求的回应" class="headerlink" title="预检请求的回应"></a>预检请求的回应</h4><p>服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="meta">HTTP/1.1</span> <span class="number">200</span> OK</span><br><span class="line"><span class="attribute">Date</span><span class="punctuation">: </span>Mon, 01 Dec 2008 01:15:39 GMT</span><br><span class="line"><span class="attribute">Server</span><span class="punctuation">: </span>Apache/2.0.61 (Unix)</span><br><span class="line"><span class="attribute">Access-Control-Allow-Origin</span><span class="punctuation">: </span>http://api.bob.com</span><br><span class="line"><span class="attribute">Access-Control-Allow-Methods</span><span class="punctuation">: </span>GET, POST, PUT</span><br><span class="line"><span class="attribute">Access-Control-Allow-Headers</span><span class="punctuation">: </span>X-Custom-Header</span><br><span class="line"><span class="attribute">Content-Type</span><span class="punctuation">: </span>text/html; charset=utf-8</span><br><span class="line"><span class="attribute">Content-Encoding</span><span class="punctuation">: </span>gzip</span><br><span class="line"><span class="attribute">Content-Length</span><span class="punctuation">: </span>0</span><br><span class="line"><span class="attribute">Keep-Alive</span><span class="punctuation">: </span>timeout=2, max=100</span><br><span class="line"><span class="attribute">Connection</span><span class="punctuation">: </span>Keep-Alive</span><br><span class="line"><span class="attribute">Content-Type</span><span class="punctuation">: </span>text/plain</span><br></pre></td></tr></table></figure>

<p>上面的HTTP回应中，关键的是<strong>Access-Control-Allow-Origin</strong>字段，表示<a target="_blank" rel="noopener" href="http://api.bob.com可以请求数据.该字段也可以设为星号,表示同意任意跨源请求./">http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。</a></p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Access-Control-Allow-Origin</span><span class="punctuation">: </span>*</span><br></pre></td></tr></table></figure>

<p>如果服务器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">XMLHttpRequest cannot load http://api.alice.com.</span><br><span class="line">Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin.</span><br></pre></td></tr></table></figure>

<p>服务器回应的其他CORS相关字段如下。</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Access-Control-Allow-Methods</span><span class="punctuation">: </span>GET, POST, PUT</span><br><span class="line"><span class="attribute">Access-Control-Allow-Headers</span><span class="punctuation">: </span>X-Custom-Header</span><br><span class="line"><span class="attribute">Access-Control-Allow-Credentials</span><span class="punctuation">: </span>true</span><br><span class="line"><span class="attribute">Access-Control-Max-Age</span><span class="punctuation">: </span>1728000</span><br></pre></td></tr></table></figure>

<p><strong>（1）Access-Control-Allow-Methods</strong><br>该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。<br><strong>（2）Access-Control-Allow-Headers</strong><br>如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。<br><strong>（3）Access-Control-Allow-Credentials</strong><br>该字段与简单请求时的含义相同。<br><strong>（4）Access-Control-Max-Age</strong><br>该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。</p>
<p><a name="lUGJT"></a></p>
<h4 id="浏览器的正确请求和回应"><a href="#浏览器的正确请求和回应" class="headerlink" title="浏览器的正确请求和回应"></a>浏览器的正确请求和回应</h4><p>一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。<br><strong>下面是”预检”请求之后，浏览器的正常CORS请求。</strong></p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">PUT</span> <span class="string">/cors</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Origin</span><span class="punctuation">: </span>http://api.bob.com</span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>api.alice.com</span><br><span class="line"><span class="attribute">X-Custom-Header</span><span class="punctuation">: </span>value</span><br><span class="line"><span class="attribute">Accept-Language</span><span class="punctuation">: </span>en-US</span><br><span class="line"><span class="attribute">Connection</span><span class="punctuation">: </span>keep-alive</span><br><span class="line"><span class="attribute">User-Agent</span><span class="punctuation">: </span>Mozilla/5.0...</span><br></pre></td></tr></table></figure>

<p>上面头信息的<strong>Origin</strong>字段是浏览器自动添加的。<br><strong>下面是服务器正常的回应。</strong></p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Access-Control-Allow-Origin</span><span class="punctuation">: </span>http://api.bob.com</span><br><span class="line"><span class="attribute">Content-Type</span><span class="punctuation">: </span>text/html; charset=utf-8</span><br></pre></td></tr></table></figure>

<p>上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。</p>
<p><a name="sP2x4"></a></p>
<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p><a name="aOWaS"></a></p>
<h2 id="执行-select-语句发生了什么"><a href="#执行-select-语句发生了什么" class="headerlink" title="执行 select 语句发生了什么"></a>执行 select 语句发生了什么</h2><blockquote>
<p>MySQL执行流程</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708610339438-a0b171ee-0c1e-48e5-8bc2-06e05c1e10bd.png#averageHue=%23f3f0eb&clientId=u4cfdbc89-b6bf-4&from=paste&height=459&id=iOygd&originHeight=574&originWidth=984&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=220374&status=done&style=none&taskId=u5a7fad78-df9d-4854-ab43-1fd43c11bfc&title=&width=787.2" alt="image.png"><br>可以看到， MySQL 的架构共分为两层：<strong>Server 层和存储引擎层</strong>，</p>
<ul>
<li><strong>Server 层负责建立连接、分析和执行 SQL</strong>。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。</li>
<li><strong>存储引擎层负责数据的存储和提取</strong>。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。</li>
</ul>
<p><a name="YS9OB"></a></p>
<h3 id="第一步：连接器"><a href="#第一步：连接器" class="headerlink" title="第一步：连接器"></a>第一步：连接器</h3><p>空闲连接会一直占用着吗？<br>当然不是了，MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开。<br>MySQL 的连接数有限制吗？<br>MySQL 服务支持的最大连接数由 max_connections 参数控制，比如我的 MySQL 服务默认是 151 个,超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。</p>
<p>MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，它们的区别如下：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">/<span class="regexp">/ 短连接</span></span><br><span class="line"><span class="regexp">连接 mysql 服务（TCP 三次握手）</span></span><br><span class="line"><span class="regexp">执行sql</span></span><br><span class="line"><span class="regexp">断开 mysql 服务（TCP 四次挥手）</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">/</span><span class="regexp">/ 长连接</span></span><br><span class="line"><span class="regexp">连接 mysql 服务（TCP 三次握手）</span></span><br><span class="line"><span class="regexp">执行sql</span></span><br><span class="line"><span class="regexp">执行sql</span></span><br><span class="line"><span class="regexp">执行sql</span></span><br><span class="line"><span class="regexp">....</span></span><br><span class="line"><span class="regexp">  断开 mysql 服务（TCP 四次挥手）</span></span><br></pre></td></tr></table></figure>

<p>可以看到，使用长连接的好处就是可以减少建立连接和断开连接的过程，所以一般是推荐使用长连接。<br>怎么解决长连接占用内存的问题？<br>有两种解决方式。<br>第一种，<strong>定期断开长连接</strong>。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。<br>第二种，<strong>客户端主动重置连接</strong>。MySQL 5.7 版本实现了 mysql_reset_connection() 函数的接口，注意这是接口函数不是命令，那么当客户端执行了一个很大的操作后，在代码里调用 mysql_reset_connection 函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。<br>至此，连接器的工作做完了，简单总结一下：</p>
<ul>
<li>与客户端进行 TCP 三次握手建立连接；</li>
<li>校验客户端的用户名和密码，如果用户名或密码不对，则会报错；</li>
<li>如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；</li>
</ul>
<p><a name="u1Y6T"></a></p>
<h3 id="第二步：查询缓存"><a href="#第二步：查询缓存" class="headerlink" title="第二步：查询缓存"></a>第二步：查询缓存</h3><p>对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。<br>所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。<br>对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND。<br><strong>TIP</strong><br>这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool。</p>
<p><a name="f7CkT"></a></p>
<h3 id="第三步：解析SQL–解析器"><a href="#第三步：解析SQL–解析器" class="headerlink" title="第三步：解析SQL–解析器"></a>第三步：解析SQL–解析器</h3><p>在正式执行 SQL 查询语句之前， MySQL 会先对 SQL 语句做解析，这个工作交由「解析器」来完成。<br><strong>解析器</strong><br>解析器会做如下两件事情。<br>第一件事情，<strong>词法分析</strong>。MySQL 会根据你输入的字符串识别出关键字出来，例如，SQL语句 select username from userinfo，在分析之后，会得到4个Token，其中有2个Keyword，分别为select和from：</p>
<table>
<thead>
<tr>
<th>关键字</th>
<th>非关键字</th>
<th>关键字</th>
<th>非关键字</th>
</tr>
</thead>
<tbody><tr>
<td>select</td>
<td>username</td>
<td>from</td>
<td>userinfo</td>
</tr>
</tbody></table>
<p>第二件事情，<strong>语法分析</strong>。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。<br>通过词法分析和语法分析构建<strong>语法树</strong></p>
<p><a name="NMYjU"></a></p>
<h3 id="第四步：执行SQL语句"><a href="#第四步：执行SQL语句" class="headerlink" title="第四步：执行SQL语句"></a>第四步：执行SQL语句</h3><p>经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段：</p>
<ul>
<li>prepare 阶段，也就是预处理阶段；—<strong>预处理器</strong></li>
<li>optimize 阶段，也就是优化阶段；—- <strong>优化器</strong></li>
<li>execute 阶段，也就是执行阶段；—–** 执行器**</li>
</ul>
<p>经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。<br>接下来，用三种方式执行过程，跟大家说一下执行器和存储引擎的交互过程</p>
<ul>
<li>主键索引查询</li>
<li>全表扫描</li>
<li>索引下推</li>
</ul>
<p><strong>总结</strong><br>执行一条 SQL 查询语句，期间发生了什么？</p>
<ul>
<li>连接器：建立连接，管理连接、校验用户身份；</li>
<li>查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；</li>
<li>解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；</li>
<li>执行 SQL：执行 SQL 共有三个阶段：<ul>
<li>预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。</li>
<li>优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；</li>
<li>执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；</li>
</ul>
</li>
</ul>
<p><a name="eiUzW"></a></p>
<h2 id="MySQL的一行记录时如何存储的？"><a href="#MySQL的一行记录时如何存储的？" class="headerlink" title="MySQL的一行记录时如何存储的？"></a>MySQL的一行记录时如何存储的？</h2><p><a name="lJaDu"></a></p>
<h3 id="MySQL的数据存放在哪个文件？"><a href="#MySQL的数据存放在哪个文件？" class="headerlink" title="MySQL的数据存放在哪个文件？"></a>MySQL的数据存放在哪个文件？</h3><p>我们每创建一个 database（数据库） 都会在 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F; 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。</p>
<ul>
<li>db.opt，用来存储当前数据库的默认字符集和字符校验规则。</li>
<li>t_order.frm ，t_order 的<strong>表结构</strong>会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。</li>
<li>t_order.ibd，t_order 的<strong>表数据</strong>会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。</li>
</ul>
<p>好了，现在我们知道了一张数据库表的数据是保存在「 表名字.ibd 」的文件里的，这个文件也称为独占表空间文件。<br><a name="kWbIk"></a></p>
<h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><p><a name="OdKN4"></a></p>
<h3 id="表空间文件的结构是怎么样的呢？"><a href="#表空间文件的结构是怎么样的呢？" class="headerlink" title="表空间文件的结构是怎么样的呢？"></a>表空间文件的结构是怎么样的呢？</h3><p><strong>表空间由段（segment）、区（extent）、页（page）、行（row）组成</strong>，InnoDB存储引擎的逻辑存储结构大致如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708613120855-07dd8f15-2351-46e9-be1e-d208670038a7.png#averageHue=%23d2dbc3&clientId=u4cfdbc89-b6bf-4&from=paste&height=660&id=UQfKC&originHeight=825&originWidth=881&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=275782&status=done&style=none&taskId=u582bd5ff-391a-45af-abf5-e03846116c3&title=&width=704.8" alt="image.png"><br><a name="bZFUh"></a></p>
<h4 id="1、行（row）"><a href="#1、行（row）" class="headerlink" title="1、行（row）"></a>1、行（row）</h4><p>数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。<br>后面我们详细介绍 InnoDB 存储引擎的行格式，也是本文重点介绍的内容。<br><a name="swy9a"></a></p>
<h4 id="2、页（page）"><a href="#2、页（page）" class="headerlink" title="2、页（page）"></a>2、页（page）</h4><p>记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I&#x2F;O 操作）只能处理一行数据，效率会非常低。<br>因此，<strong>InnoDB 的数据是按「页」为单位来读写的</strong>，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。<br><strong>默认每个页的大小为 16KB</strong>，也就是最多能保证 16KB 的连续存储空间。<br>页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。<br>页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。数据表中的行记录是用「数据页」来管理的，数据页的结构这里我就不讲细说了，之前文章有说过，感兴趣的可以去看这篇文章：<a target="_blank" rel="noopener" href="https://xiaolincoding.com/mysql/index/page.html">换一个角度看 B+ 树(opens new window)</a><br>总之知道表中的记录存储在「数据页」里面就行。<br><a name="cxK7o"></a></p>
<h4 id="3、区（extent）"><a href="#3、区（extent）" class="headerlink" title="3、区（extent）"></a>3、区（extent）</h4><p>我们知道 InnoDB 存储引擎是用 B+ 树来组织数据的。<br>B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I&#x2F;O，随机 I&#x2F;O 是非常慢的。<br>解决这个问题也很简单，就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I&#x2F;O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。<br>那具体怎么解决呢？<br><strong>在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I&#x2F;O 了</strong>。<br><a name="RVBKm"></a></p>
<h4 id="4、段（segment）"><a href="#4、段（segment）" class="headerlink" title="4、段（segment）"></a>4、段（segment）</h4><p>表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。</p>
<ul>
<li>索引段：存放 B + 树的非叶子节点的区的集合；</li>
<li>数据段：存放 B + 树的叶子节点的区的集合；</li>
<li>回滚段：存放的是回滚数据的区的集合，之前讲<a target="_blank" rel="noopener" href="https://xiaolincoding.com/mysql/transaction/mvcc.html">事务隔离(opens new window)</a>的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。</li>
</ul>
<p>好了，终于说完表空间的结构了。接下来，就具体讲一下 InnoDB 的行格式了。<br>之所以要绕一大圈才讲行记录的格式，主要是想让大家知道行记录是存储在哪个文件，以及行记录在这个表空间文件中的哪个区域，有一个从上往下切入的视角，这样理解起来不会觉得很抽象。</p>
<p><a name="We10z"></a></p>
<h3 id="InnoDB-行格式有哪些？"><a href="#InnoDB-行格式有哪些？" class="headerlink" title="InnoDB 行格式有哪些？"></a>InnoDB 行格式有哪些？</h3><p>行格式（row_format），就是一条记录的存储结构。<br>InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。</p>
<ul>
<li>Redundant 是很古老的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。</li>
<li>由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式，Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。</li>
<li>Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。从 MySQL5.7 版本之后，默认使用 Dynamic 行格式。</li>
</ul>
<p>Redundant 行格式我这里就不讲了，因为现在基本没人用了，这次重点介绍 Compact 行格式，因为 Dynamic 和 Compressed 这两个行格式跟 Compact 非常像。<br>所以，弄懂了 Compact 行格式，之后你们在去了解其他行格式，很快也能看懂。</p>
<p><a name="KlI06"></a></p>
<h3 id="Compact行格式长什么样呢？"><a href="#Compact行格式长什么样呢？" class="headerlink" title="Compact行格式长什么样呢？"></a>Compact行格式长什么样呢？</h3><p>先跟 Compact 行格式混个脸熟，它长这样：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708613759738-1e41db8e-4744-4c5f-aea8-5338fd3d15a4.png#averageHue=%23faf4f3&clientId=u4cfdbc89-b6bf-4&from=paste&id=gWAd7&originHeight=562&originWidth=2336&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u2938f95d-056b-4202-bf61-14c9aafc4ce&title="><br>一行varchar（65532） 2 1<br><a name="mwSm1"></a></p>
<h3 id="行溢出后，MySQL是怎么处理的？"><a href="#行溢出后，MySQL是怎么处理的？" class="headerlink" title="行溢出后，MySQL是怎么处理的？"></a>行溢出后，MySQL是怎么处理的？</h3><p>MySQL 中磁盘和内存交互的基本单位是页，一个页的大小一般是 16KB，也就是 16384字节，而一个 varchar(n) 类型的列最多可以存储 65532字节，一些大对象如 TEXT、BLOB 可能存储更多的数据，这时一个页可能就存不了一条记录。这个时候就会<strong>发生行溢出，多的数据就会存到另外的「溢出页」中</strong>。<br>如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。在一般情况下，InnoDB 的数据都是存放在 「数据页」中。但是当发生行溢出时，溢出的数据会存放到「溢出页」中。<br>当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。大致如下图所示。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708614890564-4ec4339c-f92d-433f-9120-c5cebfc43d9d.png#averageHue=%23faf8f5&clientId=u4cfdbc89-b6bf-4&from=paste&id=whitr&originHeight=508&originWidth=1400&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u2d64971d-41c9-4ecd-9c38-4f968940bd0&title="><br>上面这个是 Compact 行格式在发生行溢出后的处理。<br>Compressed 和 Dynamic 这两个行格式和 Compact 非常类似，主要的区别在于处理行溢出数据时有些区别。<br>这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中，看起来就像下面这样：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708614926656-18992efd-5be3-4e18-a4ff-d0d50e088eb3.png#averageHue=%23faf6f3&clientId=u4cfdbc89-b6bf-4&from=paste&id=VizT2&originHeight=470&originWidth=1230&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u79e8ad15-3b0c-4e30-97c4-2d79cbf5cc6&title="></p>
<p><a name="YUvhO"></a></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>MySQL 的 NULL 值是怎么存放的？<br>MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。<br>NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。<br>MySQL 怎么知道 varchar(n) 实际占用数据的大小？<br>MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。<br>varchar(n) 中 n 最大取值为多少？<br>一行记录最大能存储 65535 字节的数据，但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。所以， 我们在算 varchar(n) 中 n 最大值时，需要减去这两个列表所占用的字节数。<br>如果一张表只有一个 varchar(n) 字段，且允许为 NULL，字符集为 ascii。varchar(n) 中 n 最大取值为 65532。<br>计算公式：65535 - 变长字段字节数列表所占用的字节数 - NULL值列表所占用的字节数 &#x3D; 65535 - 2 - 1 &#x3D; 65532。<br>如果有多个字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 &lt;&#x3D; 65535。<br>行溢出后，MySQL 是怎么处理的？<br>如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。<br>Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。<br>Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。</p>
<p><a name="FPnnp"></a></p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p><a name="vFuhL"></a></p>
<h3 id="什么是索引？"><a href="#什么是索引？" class="headerlink" title="什么是索引？"></a>什么是索引？</h3><p>当你想查阅书中某个知识的内容，你会选择一页一页的找呢？还是在书的目录去找呢？<br>傻瓜都知道时间是宝贵的，当然是选择在书的目录去找，找到后再翻到对应的页。书中的<strong>目录</strong>，就是充当<strong>索引</strong>的角色，方便我们快速查找书中的内容，所以索引是以空间换时间的设计思想。<br>那换到数据库中，索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是<strong>索引是数据的目录</strong>。<br>所谓的存储引擎，说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法。MySQL 存储引擎有 MyISAM 、InnoDB、Memory，其中 InnoDB 是在 MySQL 5.5 之后成为默认的存储引擎。<br>下图是 MySQL 的结构图，索引和数据就是位于存储引擎中：</p>
<p><a name="niFJ2"></a></p>
<h3 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h3><p>我们可以按照四个角度来分类索引。</p>
<ul>
<li>按「数据结构」分类：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</li>
<li>按「物理存储」分类：<strong>聚簇索引（主键索引）、二级索引（辅助索引）</strong>。</li>
<li>按「字段特性」分类：<strong>主键索引、唯一索引、普通索引、前缀索引</strong>。</li>
<li>按「字段个数」分类：<strong>单列索引、联合索引</strong>。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708616379400-c613611f-dec3-4b1a-beca-dad4a486b9a6.png#averageHue=%23dbe0e2&clientId=u4cfdbc89-b6bf-4&from=paste&id=WaRtJ&originHeight=1061&originWidth=711&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ubfbb1cca-2dcd-4727-a731-0f81fc67ccc&title="></p>
<p>&#x2F;&#x2F; 西湖<br>&#x2F;&#x2F; 业务 &#x3D;&#x3D; 除了大数据 java<br>&#x2F;&#x2F;   &#x3D;&gt;  k8s</p>
<p><a name="X4raZ"></a></p>
<h2 id="B-树？"><a href="#B-树？" class="headerlink" title="B+树？"></a>B+树？</h2><p><a name="RoMlM"></a></p>
<h3 id="InnoDB是如何存储数据的？"><a href="#InnoDB是如何存储数据的？" class="headerlink" title="InnoDB是如何存储数据的？"></a>InnoDB是如何存储数据的？</h3><p>MySQL 支持多种存储引擎，不同的存储引擎，存储数据的方式也是不同的，我们最常使用的是 InnoDB 存储引擎，所以就跟大家图解下InnoDB 是如何存储数据的。<br>记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I&#x2F;O 操作）只能处理一行数据，效率会非常低。<br>因此，<strong>InnoDB 的数据是按「数据页」为单位来读写的</strong>，也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。<br>数据库的 I&#x2F;O 操作的最小单位是页，<strong>InnoDB 数据页的默认大小是 16KB</strong>，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708665403921-bae2cf52-61d3-4686-82ef-6fab686ebcc6.png#averageHue=%23f4f2ef&clientId=u2fce1967-60af-4&from=paste&id=GzHsI&originHeight=843&originWidth=692&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u75f63393-1bd2-47f1-ae7a-06f9719029d&title="></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708665482283-965b5b1d-d509-40c6-9d63-382283325e00.png#averageHue=%23f2f0e7&clientId=u2fce1967-60af-4&from=paste&id=mWU83&originHeight=602&originWidth=962&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u19a9e62b-7126-4a5b-84b1-4bd2f482bd4&title="></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708665781924-ef528373-8779-4cec-8165-65551eb339e7.png#averageHue=%23f0f1e1&clientId=u2fce1967-60af-4&from=paste&id=n6aH7&originHeight=1228&originWidth=1080&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uee17b7ef-a5b9-40dc-9189-fd6799f40d2&title="></p>
<p>页目录创建的过程如下：</p>
<ol>
<li>将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；</li>
<li>每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段（上图中粉红色字段）</li>
<li>页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），<strong>每个槽相当于指针指向了不同组的最后一个记录</strong>。</li>
</ol>
<p>从图可以看到，<strong>页目录就是由多个槽组成的，槽相当于分组记录的索引</strong>。然后，因为记录是按照「主键值」从小到大排序的，所以<strong>我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录</strong>，无需从最小记录开始遍历整个页中的记录链表。<br>以上面那张图举个例子，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 11 的用户记录：</p>
<ul>
<li>先二分得出槽中间位是 (0+4)&#x2F;2&#x3D;2 ，2号槽里最大的记录为 8。因为 11 &gt; 8，所以需要从 2 号槽后继续搜索记录；</li>
<li>再使用二分搜索出 2 号和 4 槽的中间位是 (2+4)&#x2F;2&#x3D; 3，3 号槽里最大的记录为 12。因为 11 &lt; 12，所以主键为 11 的记录在 3 号槽里；</li>
<li>这里有个问题，<strong>「槽对应的值都是这个组的主键最大的记录，如何找到组里最小的记录」</strong>？比如槽 3 对应最大主键是 12 的记录，那如何找到最小记录 9。解决办法是：通过槽 3 找到 槽 2 对应的记录，也就是主键为 8 的记录。主键为 8 的记录的下一条记录就是槽 3 当中主键最小的 9 记录，然后开始向下搜索 2 次，定位到主键为 11 的记录，取出该条记录的信息即为我们想要查找的内容。</li>
</ul>
<p>看到第三步的时候，可能有的同学会疑问，如果某个槽内的记录很多，然后因为记录都是单向链表串起来的，那这样在槽内查找某个记录的时间复杂度不就是 O(n) 了吗？<br>这点不用担心，InnoDB 对每个分组中的记录条数都是有规定的，槽内的记录就只有几条：</p>
<ul>
<li>第一个分组中的记录只能有 1 条记录；</li>
<li>最后一个分组中的记录条数范围只能在 1-8 条之间；</li>
<li>剩下的分组中记录条数范围只能在 4-8 条之间。</li>
</ul>
<p><a name="kJVaQ"></a></p>
<h3 id="B-树是如何进行查询的呢？"><a href="#B-树是如何进行查询的呢？" class="headerlink" title="B+树是如何进行查询的呢？"></a>B+树是如何进行查询的呢？</h3><p>InnoDB 的数据是按「数据页」为单位来读写的，默认数据页大小为 16 KB。每个数据页之间通过双向链表的形式组织起来，物理上不连续，但是逻辑上连续。<br>数据页内包含用户记录，每个记录之间用单向链表的方式组织起来，为了加快在数据页内高效查询记录，设计了一个页目录，页目录存储各个槽（分组），且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率。<br>为了高效查询记录所在的数据页，InnoDB 采用 b+ 树作为索引，每个节点都是一个数据页。<br>如果叶子节点存储的是实际数据的就是聚簇索引，一个表只能有一个聚簇索引；如果叶子节点存储的不是实际数据，而是主键值则就是二级索引，一个表中可以有多个二级索引。<br>在使用二级索引进行查找数据时，如果查询的数据能在二级索引找到，那么就是「索引覆盖」操作，如果查询的数据不在二级索引里，就需要先在二级索引找到主键值，需要去聚簇索引中获得数据行，这个过程就叫作「回表」。</p>
<p><a name="GeTZl"></a></p>
<h3 id="MySQL为什么采用B-树作为索引？"><a href="#MySQL为什么采用B-树作为索引？" class="headerlink" title="MySQL为什么采用B+树作为索引？"></a>MySQL为什么采用B+树作为索引？</h3><p>MySQL 是会将数据持久化在硬盘，而存储功能是由 MySQL 存储引擎实现的，所以讨论 MySQL 使用哪种数据结构作为索引，实际上是在讨论存储引使用哪种数据结构作为索引，InnoDB 是 MySQL 默认的存储引擎，它就是采用了 B+ 树作为索引的数据结构。<br>要设计一个 MySQL 的索引数据结构，不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘 I&#x2F;0 的操作次数。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘 I&#x2F;0 的操作次数内完成。<br>二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端的情况，每当插入的元素都是树内最大的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从 O(logn)降低为 O(n)。<br>为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度就会一直维持在 O(logn) 。但是它本质上还是一个二叉树，每个节点只能有 2 个子节点，随着元素的增多，树的高度会越来越高。<br>而树的高度决定于磁盘 I&#x2F;O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I&#x2F;O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。<br>B 树和 B+ 都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。<br>但是 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：</p>
<ul>
<li>B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I&#x2F;O次数会更少。</li>
<li>B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；</li>
<li>B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I&#x2F;O 操作，范围查询效率不如 B+ 树。</li>
</ul>
<p><a name="VJybE"></a></p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p><a name="hCWQI"></a></p>
<h3 id="事务隔离级别是如何实现的？"><a href="#事务隔离级别是如何实现的？" class="headerlink" title="事务隔离级别是如何实现的？"></a>事务隔离级别是如何实现的？</h3><p><a name="mtUHE"></a></p>
<h4 id="事务有哪些特性呢？"><a href="#事务有哪些特性呢？" class="headerlink" title="事务有哪些特性呢？"></a>事务有哪些特性呢？</h4><p>事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。<br>不过并不是所有的引擎都能支持事务，比如 MySQL 原生的 MyISAM 引擎就不支持事务，也正是这样，所以大多数 MySQL 的引擎都是用 InnoDB。<br>事务看起来感觉简单，但是要实现事务必须要遵守 4 个特性，分别如下：</p>
<ul>
<li><strong>原子性（Atomicity）</strong>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。</li>
<li><strong>一致性（Consistency）</strong>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。</li>
<li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。</li>
<li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
<p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p>
<ul>
<li>持久性是通过 redo log （重做日志）来保证的；</li>
<li>原子性是通过 undo log（回滚日志） 来保证的；</li>
<li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li>
<li>一致性则是通过持久性+原子性+隔离性来保证；</li>
</ul>
<p>这次将<strong>重点介绍事务的隔离性</strong>，这也是面试时最常问的知识的点。<br>为什么事务要有隔离性，我们就要知道并发事务时会引发什么问题。</p>
<p><a name="gKd4C"></a></p>
<h4 id="事务隔离级别有哪些？"><a href="#事务隔离级别有哪些？" class="headerlink" title="事务隔离级别有哪些？"></a>事务隔离级别有哪些？</h4><p>前面我们提到，当多个事务并发执行时可能会遇到「脏读、不可重复读、幻读」的现象，这些现象会对事务的一致性产生不同程序的影响。</p>
<ul>
<li>脏读：读到其他事务未提交的数据；</li>
<li>不可重复读：前后读取的数据不一致；</li>
<li>幻读：前后读取的记录数量不一致。</li>
</ul>
<p>这三个现象的严重性排序如下<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708669652363-86aa4950-a035-497e-b314-0ce6f8479ee5.png#averageHue=%23f4e8e2&clientId=u2fce1967-60af-4&from=paste&id=Q0VL0&originHeight=140&originWidth=677&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u1c122537-d973-4268-a4f1-c0a22484fdf&title="></p>
<p>SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：</p>
<ul>
<li><strong>读未提交（_read uncommitted_）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到；</li>
<li><strong>读提交（_read committed_）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到；</li>
<li><strong>可重复读（_repeatable read_）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；</li>
<li><strong>串行化（<em>serializable</em> ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；<br><a name="je0Sc"></a></li>
</ul>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>事务是在 MySQL 引擎层实现的，我们常见的 InnoDB 引擎是支持事务的，事务的四大特性是原子性、一致性、隔离性、持久性，我们这次主要讲的是隔离性。<br>当多个事务并发执行的时候，会引发脏读、不可重复读、幻读这些问题，那为了避免这些问题，SQL 提出了四种隔离级别，分别是读未提交、读已提交、可重复读、串行化，从左往右隔离级别顺序递增，隔离级别越高，意味着性能越差，InnoDB 引擎的默认隔离级别是可重复读。<br>要解决脏读现象，就要将隔离级别升级到读已提交以上的隔离级别，要解决不可重复读现象，就要将隔离级别升级到可重复读以上的隔离级别。<br>而对于幻读现象，不建议将隔离级别升级为串行化，因为这会导致数据库并发时性能很差。MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了，详见这篇<a target="_blank" rel="noopener" href="https://xiaolincoding.com/mysql/transaction/phantom.html">文章(opens new window)</a>），解决的方案有两种：</p>
<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li>
</ul>
<p>对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同：</p>
<ul>
<li>「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</li>
<li>「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。</li>
</ul>
<p>这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。<br>在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的快照读，也就是不会加锁的。而 select .. for update 语句就不是快照读了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上 next-key lock 锁。</p>
<p>MySQL InnoDB 引擎的可重复读隔离级别（默认隔离级），根据不同的查询方式，分别提出了避免幻读的方案：</p>
<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是通过 MVCC 方式解决了幻读。</li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。</li>
</ul>
<p>我举例了两个发生幻读场景的例子。<br>第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。<br>第二个例子：对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。<br>所以，<strong>MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。</strong><br>要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。</p>
<p><a name="UXIDN"></a></p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p><a name="bBATO"></a></p>
<h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>全局锁是怎么用的？<br>要使用全局锁，则要执行这条命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">flush tables <span class="keyword">with</span> read lock</span><br></pre></td></tr></table></figure>

<p>执行后，<strong>整个数据库就处于只读状态了</strong>，这时其他线程执行以下操作，都会被阻塞：</p>
<ul>
<li>对数据的增删改操作，比如 insert、delete、update等语句；</li>
<li>对表结构的更改操作，比如 alter table、drop table 等语句。</li>
</ul>
<p>全局锁应用场景是什么？<br>全局锁主要应用于做<strong>全库逻辑备份</strong>，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。<br>举个例子大家就知道了。<br>在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。<br>如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据库表的更新，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。<br>那么，有可能出现这样的顺序：</p>
<ol>
<li>先备份了用户表的数据；</li>
<li>然后有用户发起了购买商品的操作；</li>
<li>接着再备份商品表的数据。</li>
</ol>
<p>也就是在备份用户表和商品表之间，有用户购买了商品。<br>这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。<br>所以，在全库逻辑备份期间，加上全局锁，就不会出现上面这种情况了。</p>
<p>加全局锁又会带来什么缺点呢？<br>加上全局锁，意味着整个数据库都是只读状态。<br>那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。</p>
<p>既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？<br>有的，如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。<br>因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。<br>备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。<br>InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。<br>但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。</p>
<p><a name="sGFeh"></a></p>
<h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>MySQL 表级锁有哪些？具体怎么用的。<br>MySQL 里面表级别的锁有这几种：</p>
<ul>
<li>表锁；</li>
<li>元数据锁（MDL）; 锁结构的，每个sql语句执行的时候都会拿到这个锁。</li>
<li>意向锁；</li>
<li>AUTO-INC 锁；</li>
</ul>
<p>MySQL的Online DDL</p>
<ol>
<li>MDL 是一种表锁，不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。</li>
<li>简单的理解就是用线程在访问一张表的数据(查询或者DML操作)时，是不允许其他线程修改此表的结构的，这个限制就是通过MDL来实现的</li>
<li>对于表数据的操作(查询or DML)获取的是MDL读锁</li>
<li>对于表结构的修改操作会有MDL写锁和读锁，主要是为了并发高效性和数据一致性，<strong>会有锁的降级和升级过程</strong></li>
</ol>
<p><a name="KP8tO"></a></p>
<h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。<br>前面也提到，普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为<strong>锁定读</strong>。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>对读取的记录加共享锁</span><br><span class="line"><span class="keyword">select</span> ... lock <span class="keyword">in</span> share mode;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>对读取的记录加独占锁</span><br><span class="line"><span class="keyword">select</span> ... <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<p>上面这两条语句必须在一个事务中，<strong>因为当事务提交了，锁就会被释放</strong>，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit &#x3D; 0。<br>共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708673274301-02c9e67f-3c67-40e4-ac20-1634cc1a0778.png#averageHue=%23faedce&clientId=u2fce1967-60af-4&from=paste&id=llLoX&originHeight=226&originWidth=572&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u6e9800c9-1e51-4bde-9493-d2b56cd1e35&title="></p>
<p>行级锁的类型主要有三类：</p>
<ul>
<li>Record Lock，记录锁，也就是仅仅把一条记录锁上；</li>
<li>Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；</li>
<li>Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li>
</ul>
<p><a name="WvdxA"></a></p>
<h3 id="MySQL是如何枷锁的"><a href="#MySQL是如何枷锁的" class="headerlink" title="MySQL是如何枷锁的"></a>MySQL是如何枷锁的</h3><p>不要小看一条 update 语句，在生产机上使用不当可能会导致业务停滞，甚至崩溃。<br>当我们要执行 update 语句的时候，确保 where 条件中带上了索引列，并且在测试机确认该语句是否走的是索引扫描，防止因为扫描全表，而对表中的所有记录加上锁。<br>我们可以打开 MySQL sql_safe_updates 参数，这样可以预防 update 操作时 where 条件没有带上索引列。<br>如果发现即使在 where 条件中带上了列索引列，优化器走的还是全标扫描，这时我们就要使用 force index([index_name]) 可以告诉优化器使用哪个索引。<br>这次就说到这啦，下次要小心点，别再被老板挨骂啦。</p>
<p><a name="KUZ6g"></a></p>
<h3 id="MySQL死锁了该怎么办？"><a href="#MySQL死锁了该怎么办？" class="headerlink" title="MySQL死锁了该怎么办？"></a>MySQL死锁了该怎么办？</h3><p>死锁的四个必要条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。<br>在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：</p>
<ul>
<li><strong>设置事务等待锁的超时时间</strong>。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。当发生超时后，就出现下面这个提示：</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708751631269-9e3e93fe-2394-4785-8d88-a554e99caa2d.png#averageHue=%2312141b&clientId=u4109e80c-3d52-4&from=paste&id=Q3QhO&originHeight=31&originWidth=1080&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u1244b2c2-0105-4b11-8908-690ea0ea270&title="></p>
<ul>
<li><strong>开启主动死锁检测</strong>。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。当检测到死锁后，就会出现下面这个提示：</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1708751631305-4f6e222c-24cd-4c91-949b-d6e4001c6e74.png#averageHue=%2312141c&clientId=u4109e80c-3d52-4&from=paste&id=ZRxYD&originHeight=28&originWidth=1080&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u5ce9ded9-a542-4fc1-acc8-043edaba054&title="><br>上面这个两种策略是「当有死锁发生时」的避免方式。<br>我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一性来保证订单表不会出现重复的订单，不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。</p>
<p><a name="y50ja"></a></p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p><a name="Ebg3D"></a></p>
<h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3><p>实现这一机制就是 **undo log（回滚日志），它保证了事务的 **<a target="_blank" rel="noopener" href="https://xiaolincoding.com/mysql/transaction/mvcc.html#%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7">ACID 特性(opens new window)</a><strong>中的原子性（Atomicity）</strong>。<br>undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710819283346-def5ce71-da54-433e-ac10-28128ed0ddf5.png#averageHue=%23f9f6ef&clientId=u278da3fc-d7ae-4&from=paste&id=atnb5&originHeight=571&originWidth=352&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u4aeb6148-02c5-4f02-ae0c-42a55cfc8a2&title="><br>每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：</p>
<ul>
<li>在<strong>插入</strong>一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录<strong>删掉</strong>就好了；</li>
<li>在<strong>删除</strong>一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录<strong>插入</strong>到表中就好了；</li>
<li>在<strong>更新</strong>一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列<strong>更新为旧值</strong>就好了。</li>
</ul>
<p>一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：</p>
<ul>
<li>通过 trx_id 可以知道该记录是被哪个事务修改的；</li>
<li>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710819332512-e117bf80-ba6a-4964-914f-0500e69b087d.png#averageHue=%23f5f3ec&clientId=u278da3fc-d7ae-4&from=paste&height=303&id=WnF8U&originHeight=379&originWidth=776&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=90582&status=done&style=none&taskId=u62dab22b-fe0e-46e6-8cc8-3467f2f2af7&title=&width=620.8" alt="image.png"><br>另外，<strong>undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）</strong>。<br>对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过 Read View + undo log 来实现的，它们的区别在于创建 Read View 的时机不同：</p>
<ul>
<li>「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</li>
<li>「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。</li>
</ul>
<p>这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列（trx_id 和 roll_pointer）」的比对，如果不满足可见行，就会顺着 undo log 版本链里找到满足其可见性的记录，从而控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。具体的实现可以看我这篇文章：<a target="_blank" rel="noopener" href="https://xiaolincoding.com/mysql/transaction/mvcc.html#%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E6%9C%89%E5%93%AA%E4%BA%9B">事务隔离级别是怎么实现的？(opens new window)</a><br>因此，undo log 两大作用：</p>
<ul>
<li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li>
<li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。<br><a name="yMW80"></a></li>
</ul>
<h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，<strong>这个时候更新就算完成了</strong>。<br>后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。<br><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710819756535-425d7f90-44c9-4529-abb1-a7e43afc3d27.png#averageHue=%23f8f3ec&clientId=u278da3fc-d7ae-4&from=paste&id=DBZ3V&originHeight=977&originWidth=1292&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u866b3fe5-0bf5-4db8-b284-f23ee896998&title="><br>redo log 是物理日志，记录了某个数据页做了什么修改，比如<strong>对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新</strong>，每当执行一个事务就会产生这样的一条或者多条物理日志。<br>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。<br>当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p>
<p>被修改 Undo 页面，需要记录对应 redo log 吗？<br>需要的。<br>开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。<br>不过，<strong>在内存修改该 Undo 页面后，需要记录对应的 redo log</strong>。</p>
<p>redo log 和 undo log 区别在哪？<br>这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：</p>
<ul>
<li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li>
<li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li>
</ul>
<p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710819850920-1a437ece-8b93-44c4-af7d-6c0ab2bbfdf3.png#averageHue=%23fbf7f3&clientId=u278da3fc-d7ae-4&from=paste&id=KUzH9&originHeight=601&originWidth=551&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u2e5cd4ad-9b21-44fe-bda5-2377601dc81&title="></p>
<blockquote>
<p><strong>redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</strong></p>
</blockquote>
<p>写入 redo log 的方式使用了追加操作， 所以磁盘操作是<strong>顺序写</strong>，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是<strong>随机写</strong>。<br>磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。<br>针对「顺序写」为什么比「随机写」更快这个问题，可以比喻为你有一个本子，按照顺序一页一页写肯定比写一个字都要找到对应页写快得多。<br>可以说这是 WAL 技术的另外一个优点：<strong>MySQL 的写操作从磁盘的「随机写」变成了「顺序写」</strong>，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上 。<br>至此， 针对为什么需要 redo log 这个问题我们有两个答案：</p>
<ul>
<li><strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</li>
<li><strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能。</li>
</ul>
<p>:::success<br>产生的 redo log 是直接写入磁盘的吗？<br>:::<br>不是的。<br>实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;O 操作，而且磁盘的运行速度远慢于内存。<br>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/webp/32717568/1710820061376-b84ded09-2f46-4c43-99b4-3457ad26210c.webp#averageHue=%23f1efec&clientId=u793a5aeb-0dd2-4&from=paste&id=UwjR2&originHeight=1344&originWidth=1398&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u4bd17ff8-82f8-4c61-9591-cf688bceebb&title="><br><strong>redo log buffer</strong> 默认大小** 16 MB**，可以通过 innodb_log_Buffer_size 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能</p>
<p><strong>redo log 什么时候刷盘？</strong><br>缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？<br>主要有下面几个时机：</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</li>
</ul>
<p><strong>redog log文件写满了怎么办？</strong><br>默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：ib_logfile0 和 ib_logfile1 。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710820230606-abeb3aba-1183-4a65-a348-5986ef6e225d.png#averageHue=%23eeeeee&clientId=u793a5aeb-0dd2-4&from=paste&id=XLcxO&originHeight=101&originWidth=350&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uaa4170ab-826f-466d-be53-401cd0c7352&title="><br>在重做日志组中，每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作。<br>重做日志文件组是以<strong>循环写</strong>的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。<br>所以 InnoDB 存储引擎会先写 ib_logfile0 文件，当 ib_logfile0 文件被写满的时候，会切换至 ib_logfile1 文件，当 ib_logfile1 文件也被写满时，会切换回 ib_logfile0 文件。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710820246304-7ea5bc1b-b9e7-4401-982b-8aa722a17322.png#averageHue=%23f6f4ea&clientId=u793a5aeb-0dd2-4&from=paste&id=OnL6o&originHeight=261&originWidth=441&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u7d9df9e2-7a6f-4ff5-ac57-9c98b5e9fbf&title="><br>我们知道 redo log 是为了防止 Buffer Pool 中的脏页丢失而设计的，那么如果随着系统运行，Buffer Pool 的脏页刷新到了磁盘中，那么 redo log 对应的记录也就没用了，这时候我们擦除这些旧记录，以腾出空间记录新的更新操作。<br>redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置，如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710820266669-5854c53a-de02-415a-9341-29d624d15d9f.png#averageHue=%23ede7e7&clientId=u793a5aeb-0dd2-4&from=paste&id=XXBKv&originHeight=906&originWidth=1362&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u70e36ffc-1c4f-4df9-88cc-c5256fbb5c8&title="><br>图中的：</p>
<ul>
<li>write pos 和 checkpoint 的移动都是顺时针方向；</li>
<li>write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作；</li>
<li>check point ～ write pos 之间的部分（图中蓝色部分）：待落盘的脏数据页记录；</li>
</ul>
<p>如果 write pos 追上了 checkpoint，就意味着 <strong>redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞</strong>（_因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要_），此时<strong>会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）</strong>，然后 MySQL 恢复正常运行，继续执行新的更新操作。<br>所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。</p>
<p><a name="KIrVc"></a></p>
<h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。<br>binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。<br>:::success<br><strong>为什么有了 binlog， 还要有 redo log？</strong><br>:::<br>这个问题跟 MySQL 的时间线有关系。<br>最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。<br>而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。</p>
<p><strong>这两个日志有四个区别。</strong><br><em>1、适用对象不同：</em></p>
<ul>
<li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li>
<li>redo log 是 Innodb 存储引擎实现的日志；</li>
</ul>
<p><em>2、文件格式不同：</em></p>
<ul>
<li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：<ul>
<li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li>
<li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li>
<li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li>
</ul>
</li>
<li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li>
</ul>
<p><em>3、写入方式不同：</em></p>
<ul>
<li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li>
<li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li>
</ul>
<p><em>4、用途不同：</em></p>
<ul>
<li>binlog 用于备份恢复、主从复制；</li>
<li>redo log 用于掉电等故障恢复。</li>
</ul>
<p><strong>如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？</strong><br>不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。<br>因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。<br>binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。</p>
<p><a name="syZhI"></a></p>
<h3 id="buffer-pool"><a href="#buffer-pool" class="headerlink" title="buffer pool"></a>buffer pool</h3><p>MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录是选择直接写回到磁盘，还是选择缓存起来呢？<br>当然是缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了。<br>为此，Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710819543344-a974eb8d-ea5d-4045-be7b-ab5e88549bcf.png#averageHue=%23f1ebd8&clientId=u278da3fc-d7ae-4&from=paste&id=fLMoG&originHeight=969&originWidth=725&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u2dd75fea-3a8b-46f9-99e7-7e27ef3d210&title="><br>有了 Buffer Poo 后：</p>
<ul>
<li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li>
<li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710819632089-27f4a133-56f2-4202-aa3c-a78e60e48473.png#averageHue=%23f8ebd8&clientId=u278da3fc-d7ae-4&from=paste&id=OMYOM&originHeight=377&originWidth=812&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u61ad4e71-57de-451b-9d8f-815a22ce3d6&title="></p>
<p><a name="NAJqU"></a></p>
<h3 id="主从复制的实现"><a href="#主从复制的实现" class="headerlink" title="主从复制的实现"></a>主从复制的实现</h3><p>MySQL 的主从复制依赖于** binlog** ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。<strong>复制的过程就是将 binlog 中的数据从主库传输到从库上。</strong><br>这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710821238019-db5322f1-daf5-407d-8d85-809d8d5790b6.png#averageHue=%23f7f2e5&clientId=u7103f469-2912-4&from=paste&id=ZD8AH&originHeight=401&originWidth=991&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u3bf46ec8-48b5-4380-8e35-d14167f81cd&title="></p>
<p>MySQL 集群的主从复制过程梳理成 3 个阶段：</p>
<ul>
<li><strong>写入 Binlog</strong>：主库写 <strong>binlog</strong> 日志，提交事务，并更新本地存储数据。</li>
<li><strong>同步 Binlog</strong>：把 <strong>binlog</strong> 复制到所有从库上，每个从库把 <strong>binlog</strong> 写到暂存日志中。</li>
<li><strong>回放 Binlog</strong>：回放 <strong>binlog</strong>，并更新存储引擎中的数据。</li>
</ul>
<p>具体详细过程如下：</p>
<ul>
<li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li>
<li><strong>从库会创建一个专门的 I&#x2F;O 线程</strong>，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li>
<li><strong>从库会创建一个用于回放 binlog 的线程</strong>，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li>
</ul>
<p>在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710821432925-32d16017-cebd-4b53-a2a2-29ac6ef526b0.png#averageHue=%23f8f5f1&clientId=u7103f469-2912-4&from=paste&id=yrn2H&originHeight=471&originWidth=451&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ua30031ff-96b5-4e9a-b1df-34a93c59bdc&title="></p>
<p><strong>从库是不是越多越好？</strong><br>不是的。<br>因为从库数量增加，从库连接上来的 I&#x2F;O 线程也比较多，<strong>主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽</strong>。<br>所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。<br><strong>MySQL 主从复制还有哪些模型？</strong><br>主要有三种：</p>
<ul>
<li><strong>同步复制</strong>：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。</li>
<li><strong>异步复制</strong>（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。</li>
<li><strong>半同步复制</strong>：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种<strong>半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险</strong>。</li>
</ul>
<p><a name="FUCaG"></a></p>
<h3 id="Update过程种三个日志"><a href="#Update过程种三个日志" class="headerlink" title="Update过程种三个日志"></a>Update过程种三个日志</h3><p><strong>三个日志讲完了，至此我们可以先小结下，update 语句的执行过程。</strong><br>当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。<br>具体更新一条记录 UPDATE t_user SET name &#x3D; ‘xiaolin’ WHERE id &#x3D; 1; 的流程如下:</p>
<ol>
<li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id &#x3D; 1 这一行记录：<ul>
<li>如果 id&#x3D;1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li>
<li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li>
</ul>
</li>
<li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul>
<li>如果一样的话就不进行后续更新流程；</li>
<li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li>
</ul>
</li>
<li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li>
<li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li>
<li>至此，一条记录更新完了。</li>
<li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li>
<li>事务提交，剩下的就是「两阶段提交」的事情了，接下来就讲这个。</li>
</ol>
<p><a name="YxsSu"></a></p>
<h3 id="为什么需要两段提交？2PC"><a href="#为什么需要两段提交？2PC" class="headerlink" title="为什么需要两段提交？2PC"></a>为什么需要两段提交？2PC</h3><p>事务提交后，<strong>redo log 和 binlog</strong> 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。<br>举个例子，假设 id &#x3D; 1 这行数据的字段 name 的值原本是 ‘jay’，然后执行 UPDATE t_user SET name &#x3D; ‘xiaolin’ WHERE id &#x3D; 1; 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：</p>
<ul>
<li><strong>如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入</strong>。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id &#x3D; 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；</li>
<li><strong>如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入</strong>。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id &#x3D; 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；</li>
</ul>
<p>可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。<br><strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。<br><strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。<br>举个拳击比赛的例子，两位拳击手（参与者）开始比赛之前，裁判（协调者）会在中间确认两位拳击手的状态，类似于问你准备好了吗？</p>
<ul>
<li><strong>准备阶段</strong>：裁判（协调者）会依次询问两位拳击手（参与者）是否准备好了，然后拳击手听到后做出应答，如果觉得自己准备好了，就会跟裁判说准备好了；如果没有自己还没有准备好（比如拳套还没有带好），就会跟裁判说还没准备好。</li>
<li><strong>提交阶段</strong>：如果两位拳击手（参与者）都回答准备好了，裁判（协调者）宣布比赛正式开始，两位拳击手就可以直接开打；如果任何一位拳击手（参与者）回答没有准备好，裁判（协调者）会宣布比赛暂停，对应事务中的回滚操作。</li>
</ul>
<p><a name="g5hdW"></a></p>
<h3 id="两段提交的过程是怎样的？"><a href="#两段提交的过程是怎样的？" class="headerlink" title="两段提交的过程是怎样的？"></a>两段提交的过程是怎样的？</h3><p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。<br>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710821826481-197fe5db-9b02-488a-a319-49a5b199b7b7.png#averageHue=%23cbe88a&clientId=u7103f469-2912-4&from=paste&id=GJgWd&originHeight=842&originWidth=1157&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u0c811a68-c6aa-499a-83a3-8c0735e2d60&title="><br>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p>
<ul>
<li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit &#x3D; 1 的作用）；</li>
<li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog &#x3D; 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</li>
</ul>
<p><a name="jzo8g"></a></p>
<h3 id="异常重启会出现什么现象？-2段提交"><a href="#异常重启会出现什么现象？-2段提交" class="headerlink" title="异常重启会出现什么现象？ 2段提交"></a>异常重启会出现什么现象？ 2段提交</h3><p>我们来看看在两阶段提交的不同时刻，<strong>MySQL</strong> 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710821958421-8badab33-4376-44d3-84e0-1b50954de4ca.png#averageHue=%23cce989&clientId=u7103f469-2912-4&from=paste&id=i5hwH&originHeight=842&originWidth=1175&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ud2c04f51-6bc8-4b11-80aa-dfc01dd52d6&title="><br>不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，<strong>此时的 redo log 都处于 prepare 状态</strong>。<br>在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</p>
<ul>
<li><strong>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务</strong>。对应时刻 A 崩溃恢复的情况。</li>
<li><strong>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务</strong>。对应时刻 B 崩溃恢复的情况。</li>
</ul>
<p>可以看到，<strong>对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。<br>所以说，<strong>两阶段提交是以 binlog 写成功为事务提交成功的标识</strong>，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。<br><strong>处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?</strong><br>binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。<br>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。<br><strong>事务没提交的时候，redo log 会被持久化到磁盘吗？</strong><br>会的。<br>事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。<br>也就是说，<strong>事务没提交的时候，redo log 也是可能被持久化到磁盘的</strong>。<br>有的同学可能会问，如果 mysql 崩溃了，还没提交事务的 redo log 已经被持久化磁盘了，mysql 重启后，数据不就不一致了？<br>放心，这种情况 mysql 重启会进行回滚操作，因为事务没提交的时候，binlog 是还没持久化到磁盘的。<br>所以， redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘。</p>
<p><a name="wJLdI"></a></p>
<h3 id="两段提交有什么问题？"><a href="#两段提交有什么问题？" class="headerlink" title="两段提交有什么问题？"></a>两段提交有什么问题？</h3><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p>
<ul>
<li><strong>磁盘 I&#x2F;O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li>
<li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li>
</ul>
<p>为什么两阶段提交的磁盘 I&#x2F;O 次数会很高？<br>binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1：</p>
<ul>
<li>当 sync_binlog &#x3D; 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；</li>
<li>当 innodb_flush_log_at_trx_commit &#x3D; 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；</li>
</ul>
<p>可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会<strong>至少调用 2 次刷盘操作</strong>，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。<br>为什么锁竞争激烈？<br>在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。<br>通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳。</p>
<p><a name="yKSN4"></a></p>
<h3 id="减少磁盘IO次数的-组提交"><a href="#减少磁盘IO次数的-组提交" class="headerlink" title="减少磁盘IO次数的 组提交"></a><strong>减少磁盘IO次数的 组提交</strong></h3><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I&#x2F;O 的次数</strong>，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。<br>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p>
<ul>
<li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li>
<li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li>
<li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li>
</ul>
<p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p>
<p>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。<br>有 binlog 组提交，那有 redo log 组提交吗？<br>这个要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。<br>在 MySQL 5.6 的组提交逻辑中，每个事务各自执行 prepare 阶段，也就是各自将 redo log 刷盘，这样就没办法对 redo log 进行组提交。<br>所以在 MySQL 5.7 版本中，做了个改进，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段。<br>这个优化是将 redo log 的刷盘延迟到了 flush 阶段之中，sync 阶段之前。通过延迟写 redo log 的方式，为 redolog 做了一次组写入，这样 binlog 和 redo log 都进行了优化。<br>接下来介绍每个阶段的过程，注意下面的过程针对的是“双 1” 配置（sync_binlog 和 innodb_flush_log_at_trx_commit 都配置为 1）。<br>flush 阶段<br>第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower ：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710822088669-e096b04f-0544-43d6-942e-842451b656ca.png#averageHue=%23fefefe&clientId=u7103f469-2912-4&from=paste&id=le5Ku&originHeight=862&originWidth=1192&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ub6906294-274f-4d50-bf5a-d574c96a594&title="><br>接着，获取队列中的事务组，由绿色事务组的 Leader 对 redo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710822101387-3fc6a60f-1b27-42c0-bf16-0ebeb4da11f8.png#averageHue=%23fdfefb&clientId=u7103f469-2912-4&from=paste&id=kTN1F&originHeight=494&originWidth=1144&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u7286124c-0315-4f91-a104-9957fc85e5b&title="><br>完成了 prepare 阶段后，将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710822117805-9a9e5c5f-d9f2-4de8-9d29-89e16dbdefea.png#averageHue=%23fdfefa&clientId=u7103f469-2912-4&from=paste&id=B8r0x&originHeight=478&originWidth=1392&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uff08c8cc-ef39-4492-9da2-c2f974db97c&title="><br>从上面这个过程，可以知道 flush 阶段队列的作用是<strong>用于支撑 redo log 的组提交</strong>。<br>如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。<br>sync 阶段<br>绿色这一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是<strong>会等待一段时间</strong>，这个等待的时长由 Binlog_group_commit_sync_delay 参数控制，<strong>目的是为了组合更多事务的 binlog，然后再一起刷盘</strong>，如下过程：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710822131020-f4871de1-89ab-4ca0-b488-2250a6fad10a.png#averageHue=%23fefefe&clientId=u7103f469-2912-4&from=paste&id=MFFjx&originHeight=1876&originWidth=1268&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u4c7c8107-68c5-4faa-a597-90525752663&title="><br>不过，在等待的过程中，如果事务的数量提前达到了 Binlog_group_commit_sync_no_delay_count 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘，如下图：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710822131098-14bc1418-325f-4883-a39b-426817da6fc8.png#averageHue=%23faf8ef&clientId=u7103f469-2912-4&from=paste&id=ic1fV&originHeight=702&originWidth=1910&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u2bf01ba4-4b6b-4834-b8d1-038dd92f3d7&title="><br>从上面的过程，可以知道 sync 阶段队列的作用是<strong>用于支持 binlog 的组提交</strong>。<br>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p>
<ul>
<li>binlog_group_commit_sync_delay&#x3D; N，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</li>
<li>binlog_group_commit_sync_no_delay_count &#x3D; N，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</li>
</ul>
<p>如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。<br>commit 阶段<br>最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710822131060-5a8acea3-1383-4aa6-8462-8210ae2f9cac.png#averageHue=%23fefefe&clientId=u7103f469-2912-4&from=paste&id=kJwfN&originHeight=1107&originWidth=1020&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u5d861b6b-e70e-4fe8-8064-3b704d8860f&title="><br>commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率。</p>
<p><a name="vhPup"></a></p>
<h3 id="MySQL磁盘I-O-很高，有什么优化的方法？"><a href="#MySQL磁盘I-O-很高，有什么优化的方法？" class="headerlink" title="MySQL磁盘I&#x2F;O 很高，有什么优化的方法？"></a>MySQL磁盘I&#x2F;O 很高，有什么优化的方法？</h3><p>现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I&#x2F;O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I&#x2F;O 的频率：</p>
<ul>
<li>设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。</li>
<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。</li>
<li>将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。</li>
</ul>
<p><a name="TJ1bb"></a></p>
<h2 id="一条Update语句流程"><a href="#一条Update语句流程" class="headerlink" title="一条Update语句流程"></a>一条Update语句流程</h2><p>具体更新一条记录 UPDATE t_user SET name &#x3D; ‘xiaolin’ WHERE id &#x3D; 1; 的流程如下:</p>
<ol>
<li><strong>执行器负责具体执行</strong>，会调用存储引擎的接口，通过主键索引树搜索获取 id &#x3D; 1 这一行记录：<ul>
<li>如果 id&#x3D;1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li>
<li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li>
</ul>
</li>
<li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul>
<li>如果一样的话就不进行后续更新流程；</li>
<li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li>
</ul>
</li>
<li><strong>开启事务</strong>， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li>
<li><strong>InnoDB 层开始更新记录</strong>，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li>
<li>至此，一条记录更新完了。</li>
<li>在一条更新语句执行完成后，然后开始记录该语句对应的** binlog**，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li>
<li><strong>事务提交</strong>（为了方便说明，这里不说组提交的过程，只说两阶段提交）：<ul>
<li><strong>prepare 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong>commit 阶段</strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li>
</ul>
</li>
<li>至此，一条更新语句执行完成。</li>
</ol>
<p><a name="v9kCE"></a></p>
<h2 id="explain各个字段的意思"><a href="#explain各个字段的意思" class="headerlink" title="explain各个字段的意思"></a>explain各个字段的意思</h2><p>explain执行计划中包含的信息如下：</p>
<ul>
<li>id:  查询序列号</li>
<li><strong>select_type: 查询类型</strong></li>
<li>table: 表名或者别名</li>
<li>partitions: 匹配的分区</li>
<li>type: 访问类型</li>
<li>possible_keys: 可能用到的索引</li>
<li><strong>key: 实际用到的索引</strong></li>
<li>key_len: 索引长度</li>
<li>ref: 与索引比较的列</li>
<li>rows: 估算的行数</li>
<li>filtered: 按表条件筛选的行百分比</li>
<li><strong>Extra: 额外信息</strong></li>
</ul>
<p><a name="PDVib"></a></p>
<h1 id="聊一聊项目中用到的grpc"><a href="#聊一聊项目中用到的grpc" class="headerlink" title="聊一聊项目中用到的grpc"></a>聊一聊项目中用到的grpc</h1><p>RPC 远程过程调用 通过RPC进行通信，让调用远程函数就像调用本地函数一样</p>
<p>gRPC是RPC的一种，由Google提出，<br>gRPC典型特征就是使用 protobuf 座位接口定义语言 IDL。</p>
<ol>
<li><strong>grpc是什么？有哪些优点</strong></li>
</ol>
<p>gRPC是一种高性能、开源的远程过程调用（RPC）框架，它可以使不同平台和语言之间的服务相互通信。它的优点包括：高效性、跨平台、异步流处理、支持多种语言、安全、易于使用和开源。</p>
<ol start="2">
<li><strong>gPRC和REST的区别是什么？</strong></li>
</ol>
<p>REST是基于HTTP协议的一种风格，而gRPC是一个独立于协议的RPC框架。 REST基于资源的状态转移，使用标准的HTTP方法，而gRPC使用协议缓冲区（Protocol Buffers）进行序列化和反序列化。 gRPC支持异步流处理和双向流，而REST通常只支持请求&#x2F;响应模式。</p>
<ol start="3">
<li><strong>Protocol Buffers是什么，为什么它被用于gRPC中？</strong></li>
</ol>
<p>Protocol Buffers是一种语言中立、平台中立、可扩展的序列化格式，它可以用于数据交换和持久化。它被用于gRPC中，因为它可以实现高效的序列化和反序列化，从而提高了gRPC的性能和效率。**</p>
<ol start="4">
<li><strong>gPRC的流程是什么？</strong></li>
</ol>
<p>gRPC流程分为四个步骤：定义服务、生成源代码、实现服务、启动服务。首先，需要定义要实现的服务及其接口，使用Protocol Buffers编写接口定义文件。其次，使用编译器生成客户端和服务器端的源代码。然后，实现生成的接口。最后，启动服务器并将其部署在适当的位置。<br>**<strong>5. gRPC支持哪些类型的序列化？</strong><br>gRPC支持两种类型的序列化：二进制（使用Protocol Buffers）和JSON。其中，二进制序列化在效率和性能方面比JSON序列化更优秀。但是，JSON序列化在可读性方面更好，可以方便地进行调试和测试。<br><a name="a8jwk"></a></p>
<h1 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h1><p><a name="WOOxj"></a></p>
<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><blockquote>
<p>在<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E7%90%86%E8%AB%96%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8">理论计算机科学</a>中，<strong>CAP定理</strong>（CAP theorem），又被称作<strong>布鲁尔定理</strong>（Brewer’s theorem），它指出对于一个<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97">分布式计算系统</a>来说，<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E4%B8%89%E9%9A%BE%E5%9B%B0%E5%A2%83">不可能同时满足以下三点</a>：<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86#cite_note-Lynch-1">[1]</a><a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86#cite_note-2">[2]</a></p>
<ul>
<li>一致性（<strong>C</strong>onsistency） （等同于所有节点访问同一份最新的数据副本）</li>
<li><a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/%E5%8F%AF%E7%94%A8%E6%80%A7">可用性</a>（<strong>A</strong>vailability）（每次请求都能获取到非错的响应———但是不保证获取的数据为最新数据）</li>
<li><a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/w/index.php?title=%E7%BD%91%E7%BB%9C%E5%88%86%E5%8C%BA&action=edit&redlink=1">分区容错性</a>（<strong>P</strong>artition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86#cite_note-3">[3]</a>。）</li>
</ul>
</blockquote>
<p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项<a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86#cite_note-4">[4]</a>。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。</p>
<p><a name="FeBPw"></a></p>
<h2 id="分布式锁的使用场景"><a href="#分布式锁的使用场景" class="headerlink" title="分布式锁的使用场景"></a>分布式锁的使用场景</h2><ol>
<li><strong>缓存击穿保护</strong>： 当缓存中的某个热点数据过期失效时，多台服务器上的请求可能会同时穿透缓存直接访问数据库，造成数据库压力过大甚至崩溃。通过使用分布式锁，仅允许一个请求去更新缓存，其他请求等待锁释放后再读取已更新的缓存数据。</li>
<li><strong>限流控制</strong>： 在高并发环境下，为了防止系统被瞬时大量请求压垮，可以使用分布式锁作为令牌桶或漏桶算法的一部分，限制同一时刻能够执行特定操作的并发数。</li>
<li><strong>分布式任务调度</strong>： 在分布式系统中，确保某些任务只执行一次，比如定时任务或一次性初始化任务，可以通过分布式锁确保只有一个节点获得执行权限。</li>
<li><strong>分布式事务一致性</strong>： 在分布式事务中，为保证多服务协同修改共享资源的一致性，分布式锁可用于协调跨多个数据库或服务的操作顺序，实现类似于两阶段提交（2PC）或多阶段提交的逻辑。</li>
<li><strong>防止并发竞争条件</strong>： 在多节点环境下，若多个节点可能同时访问同一资源（如数据库行、文件、全局ID生成器等），为避免并发冲突导致的数据不一致，分布式锁可以用来保护关键资源的访问，确保同一时刻只有一个节点对其进行操作。</li>
<li><strong>分布式队列消费</strong>： 在消息队列处理中，为防止同一条消息被多个消费者重复消费，可以利用分布式锁确保每条消息只被一个消费者领取并处理。</li>
<li><strong>游戏排行榜实时更新</strong>： 在网络游戏场景中，每当玩家得分发生变化时，需要实时更新排行榜。为了避免多台服务器同时更新排行榜产生数据混乱，可以使用分布式锁确保同一时间只有一个更新操作生效。</li>
</ol>
<p><a name="YycDU"></a></p>
<h2 id="2段提交和3端提交以及-TTC"><a href="#2段提交和3端提交以及-TTC" class="headerlink" title="2段提交和3端提交以及 TTC"></a>2段提交和3端提交以及 TTC</h2><p>2pc<br>3pc<br>ttc</p>
<p>所谓的两个阶段是指：</p>
<ul>
<li>第一阶段：voting phase <strong>投票阶段</strong></li>
<li>第二阶段：commit phase <strong>提交阶段</strong></li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710893211441-651fa440-91db-4cc7-aedb-f3f2a91b8701.png#averageHue=%23edf0f3&clientId=u93083698-3bc5-4&from=paste&id=Ycp9a&originHeight=147&originWidth=586&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=14131&status=done&style=none&taskId=ue46bc0a2-7c3a-46a7-97d9-ab597aea6ab&title=" alt="image.png"></p>
<p>事务<strong>协调者</strong>给每个<strong>参与者</strong>发送<strong>Prepare消息</strong>，每个参与者<strong>要么直接返回失败</strong>(如权限验证失败)，<strong>要么在本地执行事务，写本地的redo和undo日志，但不提交</strong>，到达一种“万事俱备，只欠东风”的状态。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710893243750-d9c580be-b7c6-413e-b79a-7dbff6f74ec7.png#averageHue=%23ebeff2&clientId=u93083698-3bc5-4&from=paste&id=R0ctP&originHeight=194&originWidth=586&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u6648762c-7a70-4daf-afd8-826dadd8e51&title="></p>
<blockquote>
<p>三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710893284925-b7a262be-5705-40e7-a9d1-07a86a9a38e6.png#averageHue=%23f1f4f6&clientId=u93083698-3bc5-4&from=paste&id=hV4VE&originHeight=201&originWidth=478&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u9437af21-3c14-4cc3-9895-fa7e22e9059&title="><br>也就是说，除了引入超时机制之外，3PC把<strong>2PC的投票阶段再次一分为二</strong>，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。</p>
<p>TCC 指的就是 Try、Confirm、Cancel 三个操作，基本类似两阶段提交。由事务管理方发起向所有参与者发起 try 请求，根据 try 请求的结果决定全部 confirm 或是全部 cancel。<br>TCC 框架一般需要使用数据库持久化记录事务数据，跟踪整个事务的执行状态，并在事务失败后补偿重试。具有一定的容灾能力。</p>
<p>在 TCC 框架内，所有的参与者的业务逻辑都需按照二阶段设计。一阶段锁定和预备资源、二阶段执行提交（confirm）或释放资源（cancel）。</p>
<p><a name="UfDyd"></a></p>
<h2 id="Raft算法和Paxos共识性算法的步骤"><a href="#Raft算法和Paxos共识性算法的步骤" class="headerlink" title="Raft算法和Paxos共识性算法的步骤"></a>Raft算法和Paxos共识性算法的步骤</h2><p><strong>Raft算法</strong><br>Raft共识算法是一种用于在分布式系统中实现一致性状态机复制的协议，它通过一系列有序步骤确保了集群中的节点能够达成一致。以下是Raft算法的基本步骤概述：<br>1.** 领导者选举（Leader Election）：**</p>
<ul>
<li>在Raft中，所有节点初始时处于跟随者（Follower）状态。</li>
<li>每个跟随者都有一个随机的选举超时时间，在超时后会变成候选人（Candidate）状态，并开始新的选举轮次。</li>
<li>候选人向其他节点发送请求投票的消息，收到大多数节点（包括自己）的投票后，该候选人成为领导者（Leader）。</li>
<li>如果一个任期内没有候选人在规定时间内获得多数票，则重新进入选举过程。</li>
</ul>
<p>2.** 日志复制（Log Replication）**：</p>
<ul>
<li>领导者负责接收来自客户端的所有写入请求，并将这些请求作为日志条目追加到自己的日志中。</li>
<li>领导者按顺序将新日志条目复制到跟随者节点上，通过AppendEntries RPC调用完成。</li>
<li>跟随者必须响应领导者并确认它们已经正确地将日志条目附加到了本地日志中，并遵循领导者的日志完整性约束（如日志索引和任期号匹配）。</li>
</ul>
<ol start="3">
<li><strong>提交日志（Log Commitment）：</strong></li>
</ol>
<ul>
<li>当一条日志条目已经被复制到大多数节点上时，领导者认为这条日志是已提交（committed），意味着它可以安全地应用于状态机进行状态更新。</li>
<li>领导者通知跟随者可以提交特定的日志条目，跟随者根据领导者的指示更新其已提交日志的边界。</li>
</ul>
<ol start="4">
<li><strong>安全性保证（Safety）</strong>：</li>
</ol>
<ul>
<li>Raft确保不会出现同一索引位置有两个不同的日志条目（通过领导者的强领导力和日志匹配规则来实现）。</li>
<li>即使发生领导人变更，新的领导人也只会提交已经复制到大多数节点上的日志条目，以确保在整个集群中的一致性。</li>
</ul>
<ol start="5">
<li><strong>集群成员变更（Membership Changes）</strong>：</li>
</ol>
<ul>
<li>Raft还定义了一种机制来安全地更改集群的成员资格，即添加或移除节点，这个过程同样需要在领导者控制下按照严格的协议执行。</li>
</ul>
<p>通过上述步骤，Raft能够在面临网络分区、消息丢失等故障的情况下保持集群的一致性和可用性。</p>
<p><strong>Paxos算法</strong><br>Paxos算法是一种分布式一致性算法，它用于解决在存在网络延迟、部分节点失效等异步环境下的共识问题。Paxos通常被描述为具有多个阶段，以确保即使在网络不稳定的情况下也能达成一致的决策（例如选择一个提案）。以下是简化版的两阶段Paxos过程：</p>
<ol>
<li><strong>准备阶段 (Prepare Phase)</strong>:<ul>
<li><strong>Proposer</strong> 选择一个新的提案编号 N。</li>
<li>Proposer 向集群中的大多数 <strong>Acceptor</strong> 发送一个 Prepare Request (N)，其中包含这个提议编号 N。</li>
<li>如果一个 Acceptor 收到一个编号大于其之前已经响应过的任何 Prepare 请求的编号 N，则它会：<ul>
<li>承诺不再接受编号小于 N 的提案。</li>
<li>如果它之前已经接受了某个提案，则回复 Proposer 已经接受的提案值及其对应的提案编号（如果有）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>接受阶段 (Accept Phase)</strong>:<ul>
<li>当 Proposer 收到来自大多数 Acceptor 对于其 Prepare 请求 N 的确认后，它可以进入 Accept 阶段。</li>
<li>Proposer 会选择一个值来提出（可能是从收到的 Acceptor 回复中已接受的最高编号提案的值，如果没有这样的值，则由 Proposer 自行决定一个值）。</li>
<li>Proposer 向大多数 Acceptor 发送 Accept Request (N, Value)，包括提案编号 N 和选定的值 Value。</li>
<li>如果一个 Acceptor 收到一个提案，并且该提案的编号 N 是它所承诺过的（即，它没有对更高编号的 Prepare 请求做出过承诺），那么它将接受这个提案并回复确认。</li>
</ul>
</li>
<li><strong>学习阶段 (Learn Phase &#x2F; Commit Phase)</strong>:<ul>
<li>当 Proposer 收到了大多数 Acceptor 对其提案 N 的确认后，意味着提案已经被“接受”（accepted）了，因为大多数 Acceptor 都同意了同一个提案值。</li>
<li>这时，该提案可以被认为已被“提交”（committed），也就是说，它是最终的决策。</li>
<li>Proposer 通知所有 Learner（通常是系统中的其他节点或客户端），告诉他们提案 N 的值已被确定，Learner 根据接收到的通知更新状态。</li>
</ul>
</li>
</ol>
<p>Paxos算法的关键在于，只有当一个提案获得了大多数 Acceptor 的批准后，才能被认为是有效的。通过这种方式，即使部分节点失败或消息丢失，系统仍然能够保证安全性和最终一致性。实际应用中，为了提高效率和应对复杂场景，Paxos可能会扩展成多轮投票或者优化为更高效的变种，如 Multi-Paxos 或 Fast Paxos 等。</p>
<p>区别：<br>Raft算法的优点与缺点：<br>Raft算法和Paxos算法都是分布式一致性算法，用于在分布式系统中达成共识并确保数据的一致性。尽管它们解决的问题相同，但在设计哲学、实现复杂度和易理解性方面存在显著差异：<br><strong>Raft算法的特点与优势：</strong></p>
<ol>
<li><strong>易于理解与实现</strong>：Raft算法的设计目标之一就是清晰性和易理解性，它将复杂的共识过程分解为几个明确的子模块，如领导者选举、日志复制和安全性保证等，并且每个步骤都有详细的伪代码描述。</li>
<li><strong>领导者的强化角色</strong>：Raft协议强调一个强领导（Leader）的概念，系统在任何时刻都只有一个明确的领导者负责处理客户端请求和日志同步。</li>
<li><strong>日志复制简化</strong>：Raft通过日志连续性来简化了状态机复制的过程，确保领导者的日志总是最新的，并且严格要求所有节点按相同的顺序复制日志条目。当新领导者被选举出来时，它已经包含了所有已提交的日志条目。</li>
<li><strong>明确定义的状态机转移</strong>：Raft将一致性算法划分为三种明确的角色状态（Follower、Candidate、Leader）以及几种明确的转换条件，使协议流程更加直观。</li>
</ol>
<p><strong>Paxos算法的特点：</strong></p>
<ol>
<li><strong>理论基础深厚</strong>：Paxos由Leslie Lamport提出，其初衷是解决非常理论化的一致性问题，对于工程实践中的具体实现较为抽象。</li>
<li><strong>多阶段过程</strong>：原始的Paxos算法通常需要两个或更多的阶段（Prepare、Promise、Accept、Learn），并且为了提高效率，在实际应用中往往采用Multi-Paxos变种，该变种在一个领导者持续存在的前提下简化了多个提案的处理。</li>
<li><strong>更灵活但较难理解</strong>：Paxos允许更为灵活的领导者变更和日志结构，比如日志可能存在空洞，但这也导致了在实现时可能遇到的复杂性增加，特别是在理解和调试阶段。</li>
<li><strong>没有明确的角色划分</strong>：Paxos中的角色功能不如Raft那样明确分离，例如Proposer和Acceptor的角色可以在不同的提议过程中重叠，增加了理解和实施的难度。</li>
</ol>
<p>总结起来，Raft相对于Paxos的主要区别在于：</p>
<ul>
<li>Raft通过简化的设计使其更容易实现和教学；</li>
<li>Raft对领导者的管理更为明确和单一，从而降低了复杂性；</li>
<li>Raft的日志管理规则比Paxos更为严格，以减少不一致性的可能性；</li>
<li>Paxos在理论上更为通用和灵活，而Raft则牺牲了一定的灵活性换取了更高的可操作性和可维护性。</li>
</ul>
<p><a name="JVXna"></a></p>
<h2 id="一致性Hash算法"><a href="#一致性Hash算法" class="headerlink" title="一致性Hash算法"></a>一致性Hash算法</h2><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/8_network_system/hash.html#%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E8%AF%B7%E6%B1%82">https://xiaolincoding.com/os/8_network_system&#x2F;hash.html#%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E8%AF%B7%E6%B1%82</a></p>
<p><strong>Hash算法分配的问题。</strong></p>
<ul>
<li><strong>虚拟结点</strong></li>
<li><strong>分布均匀</strong></li>
<li>16384个槽位</li>
</ul>
<p>不同的负载均衡算法适用的业务场景也不同的。<br>轮询这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。<br>哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。<br>为了减少迁移的数据量，就出现了一致性哈希算法。<br>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。<br>但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。<br>为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。<br>引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。</p>
<p><a name="QRmI3"></a></p>
<h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><p><a name="Q5FmL"></a></p>
<h2 id="CPU缓存一致性"><a href="#CPU缓存一致性" class="headerlink" title="CPU缓存一致性"></a>CPU缓存一致性</h2><p>由于CPU和内存的访问性能相差比较大，引入了 CPU Cache（高速缓存）<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709429174160-7cee551e-fbfe-4aa2-80d4-85a997d28520.png#averageHue=%23f9e0c3&clientId=ue55a4749-38fd-4&from=paste&height=533&id=duCIL&originHeight=666&originWidth=1006&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=114117&status=done&style=none&taskId=u5bcec540-e10c-44ed-8904-4f2b5783ff0&title=&width=804.8" alt="image.png"></p>
<p>写入缓存后，什么时候将 缓存写回内存</p>
<ul>
<li>写直达（Write Through）：把数据同时写入内存和Cache（每次都要写回内存，操作费时）</li>
<li>写回（Write Back）：新数据仅仅写入Cache Block，只有在被修改时才写回内存</li>
</ul>
<p>写回策略：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709430101470-9d86d27d-34bb-4c70-99ed-6334924e9e7e.png#averageHue=%23fbfaf5&clientId=ue55a4749-38fd-4&from=paste&height=858&id=cFC5z&originHeight=1073&originWidth=849&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=268631&status=done&style=none&taskId=uf6fd2362-03dc-4994-8362-2b4c3e8c9e8&title=&width=679.2" alt="image.png"></p>
<p>什么是缓存不一致问题？<br>由于现在的CPU基本都是多核的，那么会带来多核的缓存不一致问题。</p>
<p>解决思路：</p>
<ul>
<li>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为<strong>写传播（_Write Propagation_）</strong>；</li>
<li>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为<strong>事务的串行化（_Transaction Serialization_）</strong>。</li>
</ul>
<p>实现事务的串行化：</p>
<ul>
<li>CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心；</li>
<li>要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。</li>
</ul>
<p>基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。<br>MESI 协议，是已修改、独占、共享、已失效这四个状态<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709431032972-304e040d-4fd9-48dd-bcd8-573f753e893f.png#averageHue=%23fcf8f2&clientId=ue55a4749-38fd-4&from=paste&height=430&id=UMVFb&originHeight=538&originWidth=824&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=155756&status=done&style=none&taskId=ue484635c-b7e1-4dbe-b0b1-691b11223cd&title=&width=659.2" alt="image.png"></p>
<p><a name="cpmnu"></a></p>
<h2 id="CPU如何选择线程？"><a href="#CPU如何选择线程？" class="headerlink" title="CPU如何选择线程？"></a>CPU如何选择线程？</h2><p>实时任务 &gt; 普通任务</p>
<p>CFS调度: 一种相对公平的调度策略，希望给每个线程相同的运行时间<br>vruntime +&#x3D; 运行时间*nice &#x2F; 权重<br>每个CPU都会有自己的运行队列（Run Queue，rq）<br>nice值 （-20–19）<br>priority优先级(0–139)<br>优先级（new） &#x3D; 优先级（old）+ nice</p>
<p><a name="AoVjG"></a></p>
<h2 id="什么是软中断"><a href="#什么是软中断" class="headerlink" title="什么是软中断"></a>什么是软中断</h2><p><strong>中断</strong>：操作系统为了响应硬件设备的请求，操作系统收到硬件的中断请求，会打断正在运行的进程，然后调用内核中的中断处理程序来响应请求。</p>
<p>中断处理程序的上部分和下半部可以理解为：</p>
<ul>
<li><strong>上半部直接处理硬件请求，也就是硬中断</strong>，主要是负责耗时短的工作，特点是快速执行；</li>
<li><strong>下半部是由内核触发，也就说软中断</strong>，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；</li>
</ul>
<p>Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型</p>
<p><a name="ByJQ4"></a></p>
<h2 id="聊一聊虚拟内存"><a href="#聊一聊虚拟内存" class="headerlink" title="聊一聊虚拟内存"></a>聊一聊虚拟内存</h2><p><a name="zdLrN"></a></p>
<h3 id="操作系统的保护模式和实模式"><a href="#操作系统的保护模式和实模式" class="headerlink" title="操作系统的保护模式和实模式"></a>操作系统的保护模式和实模式</h3><ul>
<li><strong>实模式</strong>将整个物理内存看成分段的区域，程序代码和数据位于不同区域，系统程序和用户程序并没有区别对待，而且每一个指针都是指向实际的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么对于这个被修改的系统程序或用户程序，其后果就很可能是灾难性的。再者，随着软件的发展，1M的寻址空间已经远远不能满足实际的需求了。最后，对处理器多任务支持需求也日益紧迫，所有这些都促使新技术的出现。</li>
<li>为了克服实模式下的内存非法访问问题，并满足飞速发展的内存寻址和多任务需求，处理器厂商开发出<strong>保护模式</strong>。在保护模式中，除了内存寻址空间大大提高；提供了硬件对多任务的支持；<strong>物理内存地址也不能直接被程序访问，程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知</strong>。至此，进程(程序的运行态)有了严格的边界，任何其他进程根本没有办法访问不属于自己的物理内存区域，甚至在自己的虚拟地址范围内也不是可以任意访问的，因为有一些虚拟区域已经被放进一些公共系统运行库。这些区域也不能随便修改，若修改就会有出现linux中的段错误，或Windows中的非法内存访问对话框。</li>
</ul>
<p><a name="OHf3j"></a></p>
<h3 id="虚拟内存，它的内存布局大概是什么样子的？"><a href="#虚拟内存，它的内存布局大概是什么样子的？" class="headerlink" title="虚拟内存，它的内存布局大概是什么样子的？"></a>虚拟内存，它的内存布局大概是什么样子的？</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709434070467-8ad486d6-7b50-4daa-97bd-08966e678e8b.png#averageHue=%23f7f5f2&clientId=ue55a4749-38fd-4&from=paste&height=601&id=kUodC&originHeight=751&originWidth=639&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=85336&status=done&style=none&taskId=u7f5f0f3c-56c9-4237-857c-70b9182bd14&title=&width=511.2" alt="image.png"></p>
<ul>
<li>我们程序所使用的内存地址叫做<strong>虚拟内存地址</strong>（_Virtual Memory Address_）</li>
<li>实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（_Physical Memory Address_）。</li>
</ul>
<p><strong>虚拟地址</strong>是操作系统给将内存的物理地址映射成一块虚拟地址分配给进程的<br>一个进程就只知道虚拟地址，而对操作系统的物理地址全然不知，这样就不会发生冲突了。</p>
<p>每个进程都会有自己的虚拟空间，而物理内存只有一个，所以启动大量的进程的时候，物理内存紧张，于是操作系统会通过内存交换技术，把不常用的内存暂时放到硬盘，在需要的时候再装入物理内存。</p>
<p>最后，说下虚拟内存有什么作用？</p>
<ul>
<li>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。</li>
<li>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。</li>
<li>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。</li>
</ul>
<p><a name="CuEjs"></a></p>
<h2 id="聊一聊进程和线程"><a href="#聊一聊进程和线程" class="headerlink" title="聊一聊进程和线程"></a>聊一聊进程和线程</h2><p>线程与进程的比较如下：</p>
<ul>
<li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>对于，线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
<p>所以，不管是时间效率，还是空间效率线程比进程都要高。</p>
<p><a name="fljSf"></a></p>
<h2 id="说一说常见的调度算法"><a href="#说一说常见的调度算法" class="headerlink" title="说一说常见的调度算法"></a>说一说常见的调度算法</h2><ul>
<li>FCFS：先来先服务</li>
<li>SJF：最短作业优先</li>
<li>HRRN：高响应比优先</li>
<li>RR：时间片轮转</li>
<li>HPF：最高优先级</li>
<li><strong>MFQ：多级反馈队列</strong></li>
</ul>
<p><a name="ul8Wy"></a></p>
<h2 id="进程间的通信有哪些方式呢？"><a href="#进程间的通信有哪些方式呢？" class="headerlink" title="进程间的通信有哪些方式呢？"></a>进程间的通信有哪些方式呢？</h2><ol>
<li>管道pipe</li>
<li>消息队列message queue</li>
<li>共享内存share memory</li>
<li>信号量 semaphore</li>
<li>信号</li>
<li>Socket</li>
</ol>
<p><a name="GHU6p"></a></p>
<h2 id="怎么避免死锁？"><a href="#怎么避免死锁？" class="headerlink" title="怎么避免死锁？"></a>怎么避免死锁？</h2><p><strong>两个线程都在等待对方释放锁</strong>，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了<strong>死锁</strong>。<br>死锁只有<strong>同时满足</strong>以下四个条件才会发生：</p>
<ol>
<li>互斥条件</li>
<li>持有并且等待</li>
<li>不可剥夺条件</li>
<li>环路等待</li>
</ol>
<p><a name="cwVQe"></a></p>
<h2 id="网络系统"><a href="#网络系统" class="headerlink" title="网络系统"></a>网络系统</h2><p><a name="kUbCA"></a></p>
<h3 id="什么是同步，异步，阻塞，非阻塞"><a href="#什么是同步，异步，阻塞，非阻塞" class="headerlink" title="什么是同步，异步，阻塞，非阻塞"></a>什么是同步，异步，阻塞，非阻塞</h3><p>同步与异步主要是从消息通知机制角度来说的，关键在于调用者是否有等待这个行为出现。<br>同步主要靠调用者自己盯进度看被调用者的工作是否完成，异步主要靠被调用者以某种方式来通知调用者它的任务完成了。</p>
<p><strong>同步</strong>和<strong>异步</strong>关注点是<strong>消息通信机制</strong> (synchronous communication&#x2F; asynchronous communication)，是一种编程模型。<br>阻塞和非阻塞关注的是<strong>线程在等待调用结果（消息、结果）时的状态。</strong></p>
<ul>
<li>阻塞调用是指调用结果返回之前，当前线程做不了其他事情（**<em>被挂起或者自旋</em>**），调用线程只有在得到结果之后才会返回。</li>
<li>非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程（例如返回一个结果代理对象或者错误码）。</li>
<li>异步非阻塞<br>效率是最高的，体现在调用者没等，被调用对象有机制提醒调用者活干完了；</li>
<li>同步阻塞<br>编程比较简单，体现在调用者等待，被调用对象没有提醒调用者活干完的机制，靠调用者盯进度；</li>
<li>同步非阻塞<br>因为调用者不断分心在两件事间跳来跳去，所以其实效率是不高的，体现在调用者边等边做自己的事，被调用对象没有提醒机制，也靠调用者盯进度；</li>
<li>异步阻塞（这种情况一般不存在）<br>实际上调用者还是在等被调用者，因为尽管被调用对象有机制提醒调用者自己活干完了，调用者还是什么都不干，傻傻地在等待。</li>
</ul>
<p>那我先讲下同步异步和阻塞非阻塞这两大块之间的区别？<br>他们针对的对象不同，好比A调用B，同步异步针对的是被调用者也就是B，阻塞非阻塞针对的是调用者也就是A。<br>然后我们再来讲一下什么是同步和异步？<br>A调用B，同步异步针对得是调用方B<br>如果是同步的话，B处理完后有结果了才通知A.<br>如果是异步的话，B在接到请求后先告诉A我已经接到请求了，然后有结果后再通过callback、通知或者状态等方式再通知A。<br>同步和异步最大的区别就是被调用方B的执行方式和返回时机。<br>什么是阻塞和非阻塞？<br>A调用B，我们针对得是调用方A<br>如果是阻塞的话，A只能等待B返回结果后，才能去干别的事情<br>如果是非阻塞得话就是A不用等着B返回结果，可以先去做别的事情。</p>
<p>指的时用户空间和内核空间数据交互的方式：<br>同步：用户空间要的数据，必须等到内核空间给她做完才做其他事情<br>而异步：用户空间要的数据，不需要等待内核空间给它，才做其他事情。内核空间会异步通知用户进程并把数据直接给到用户空间。</p>
<p>阻塞非阻塞，<br>指的是用户就和内核空间IO操作的方式<br>阻塞：用户空间通过系统调用(systemcall)和内核空间发送IO操作时，该调用时阻塞的<br>非阻塞：用户空间通过系统调用（systemcall）和内核空间发送IO操作时，该调用时不阻塞的，直接返回的，只是返回时，可能没有数据而已。</p>
<blockquote>
<p>所谓同步，就是在发送出一个功能调用的时候，在没有得到结果之前，该调用就不返回。</p>
</blockquote>
<blockquote>
<p>当一个一步过程调用发出后，调用者不会立刻得到结果，实际出路这个调用的不见实在调用发出后，通过状态，通知来通知调用者，或通过回调函数来处理这个调用。</p>
</blockquote>
<p>看一个例子：1940 年，我是一名党的高级特工，受组织派遣，深入敌后，展开卧底行动。<br><strong>「同步」</strong>：组织在得到我的结果前，不做事情，等待我的结果，然后做出行动；<br><strong>「异步」</strong>：组织可以去干一些不依赖我结果的事情，截个道啊，抢个仓啊：</p>
<p><strong>同步消息通知机制：</strong></p>
<blockquote>
<p>“<br>好比简单的read&#x2F;write操作，我们需要等待这两个操作完成才能返回；<br>”</p>
</blockquote>
<blockquote>
<p>“<br>同步，是由处理消息者自己去等待消息是否被触发。<br>”</p>
</blockquote>
<p><strong>异步消息通知机制：</strong></p>
<blockquote>
<p>“<br>类似于select&#x2F;epoll之类的多路复用IO操作，当所关注的消息被触发时，由消息触发机制通知触发对消息的出路。<br>”</p>
</blockquote>
<blockquote>
<p>“<br>异步，由触发机制来通知处理消息着。<br>“</p>
</blockquote>
<p>阻塞&#x2F;非阻塞，它们是程序在等待消息（无所谓同步或异步）时的状态。</p>
<p><strong>阻塞：</strong><br>阻塞调用是指调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回。有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。</p>
<p><strong>非阻塞：</strong><br>非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。</p>
<p>例子：<br>继续上面的那个例子，不论是叫个人天天蹲着等消息，还是使用 call 等待通知，如果在这个等待的过程中，等待者除了等待消息之外不能做其它的事情，那么该机制就是阻塞的。<br>表现在程序中，也就是该程序一直阻塞在该函数调用处不能继续往下执行， 相反，在等待的时候我们可以磨磨枪，埋埋雷，，这样的状态就是非阻塞的，因为他(等待者)没有阻塞在这个消息通知上，而是一边做自己的事情一边等待。</p>
<p><strong>「同步阻塞形式：」</strong><br>效率是最低的，拿上面的例子来说，就是你专心等待，什么别的事都不做。实际程序中就是未对 fd 设置 O_NONBLOCK 标志位的 read&#x2F;write 操作。<br><strong>「异步阻塞形式：」</strong><br>异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息被触发时被阻塞，比如 select 函数，假如传入的最后一个 timeout 参数为 NULL，那么如果所关注的事件没有一个被触发，程序就会一直阻塞在这个 select 调用处。<br><strong>「同步非阻塞形式：」</strong><br>实际上是效率低下的，想象一下你一边做着事情一边看消息到了没有，如果把磨枪和观察消息是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的;很多人会写阻塞的 read&#x2F;write 操作，但是别忘了可以对 fd 设置 O_NONBLOCK 标志位，这样就可以将同步操作变成非阻塞的了。</p>
<p><a name="zJeKo"></a></p>
<h3 id="什么是零拷贝"><a href="#什么是零拷贝" class="headerlink" title="什么是零拷贝"></a>什么是零拷贝</h3><p><strong>DMA：在进行 I&#x2F;O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong>。</p>
<ol>
<li><strong>基于mmap+write实现零拷贝</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709449624687-49844506-4dee-49ab-97f9-74a9f40e6206.png#averageHue=%23f2eee2&clientId=ud1a37d8c-afb6-4&from=paste&height=604&id=eofvn&originHeight=604&originWidth=1073&originalType=binary&ratio=1&rotation=0&showTitle=false&size=190728&status=done&style=none&taskId=u9617a5d3-1eb7-4b9b-83f5-0846fb2fdde&title=&width=1073" alt="image.png"></p>
<ol start="2">
<li><strong>sendfile 实现零拷贝</strong></li>
</ol>
<p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709449745613-a52ecf75-05fa-4b2b-a228-888a78f6f815.png#averageHue=%23f2eee4&clientId=ud1a37d8c-afb6-4&from=paste&height=631&id=w8xJs&originHeight=631&originWidth=1073&originalType=binary&ratio=1&rotation=0&showTitle=false&size=195277&status=done&style=none&taskId=uc9e2fef4-a772-4a0f-a989-33ff79c3e22&title=&width=1073" alt="image.png"></p>
<p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（_The Scatter-Gather Direct Memory Access_）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。于是，从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下：</p>
<ul>
<li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li>
<li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709449888470-8f09aa94-22a8-4c67-9bee-3ea562bd027e.png#averageHue=%23efede0&clientId=ud1a37d8c-afb6-4&from=paste&height=604&id=Mmq9d&originHeight=604&originWidth=1046&originalType=binary&ratio=1&rotation=0&showTitle=false&size=190082&status=done&style=none&taskId=u9d208523-8789-48c8-a4f2-334ef542c24&title=&width=1046" alt="image.png"></p>
<p><a name="UgY5b"></a></p>
<h3 id="I-O多路复用：-select-poll-epoll"><a href="#I-O多路复用：-select-poll-epoll" class="headerlink" title="I&#x2F;O多路复用： select&#x2F;poll&#x2F;epoll"></a>I&#x2F;O多路复用： select&#x2F;poll&#x2F;epoll</h3><ol>
<li><strong>最基础的Socket模型</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709450484078-110146f8-bff9-40b3-9afd-5e6fd3497c27.png#averageHue=%23f9f7ee&clientId=ud1a37d8c-afb6-4&from=paste&height=964&id=NfG0a&originHeight=964&originWidth=583&originalType=binary&ratio=1&rotation=0&showTitle=false&size=143085&status=done&style=none&taskId=u5a703d1b-1477-4712-b909-ea4bbeb2060&title=&width=583" alt="image.png"></p>
<ol start="2">
<li><strong>多进程模型</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709450812722-9cbb5d7e-3c5a-4303-ae5f-cfa184cf2c7b.png#averageHue=%23edecd5&clientId=ud1a37d8c-afb6-4&from=paste&height=400&id=xg95c&originHeight=400&originWidth=982&originalType=binary&ratio=1&rotation=0&showTitle=false&size=140734&status=done&style=none&taskId=u9184c436-e35f-4bdb-ad4b-1b3c87de509&title=&width=982" alt="image.png"></p>
<ol start="3">
<li><strong>多线程模型</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709450961703-b37a6261-8f9d-4f5c-b54c-a4a419e876a5.png#averageHue=%23f6f4ea&clientId=ud1a37d8c-afb6-4&from=paste&height=340&id=DXIWG&originHeight=340&originWidth=1035&originalType=binary&ratio=1&rotation=0&showTitle=false&size=116836&status=done&style=none&taskId=uae19d227-570b-47fb-a434-b644098a1ed&title=&width=1035" alt="image.png"></p>
<ol start="4">
<li><strong>I&#x2F;O多路复用</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709451104538-b8bff555-0d12-4f85-a99d-d41637489ce3.png#averageHue=%23fdfbfa&clientId=ud1a37d8c-afb6-4&from=paste&height=635&id=igfD9&originHeight=635&originWidth=1070&originalType=binary&ratio=1&rotation=0&showTitle=false&size=73335&status=done&style=none&taskId=uf4826df7-5763-49c3-b2cc-2817893b9ee&title=&width=1070" alt="image.png"></p>
<ol start="5">
<li><strong>select&#x2F;poll</strong></li>
</ol>
<p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个<strong>文件描述符集合</strong>，然后调用 select 函数将文件描述符集合<strong>拷贝</strong>到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合<strong>拷贝</strong>回用户态里，然后用户态还需要再通过<strong>遍历</strong>的方法找到可读或可写的 Socket，然后再对其处理。<br>所以，对于 select 这种方式，需要进行 <strong>2 次「遍历」文件描述符集合</strong>，一次是在内核态里，一个次是在用户态里 ，而且还会发生 <strong>2 次「拷贝」文件描述符集合</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。<br>select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。<br>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。<br>但是 poll 和 select 并没有太大的本质区别，<strong>都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合</strong>，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p>
<ol start="6">
<li><strong>epoll</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709451512917-dee2f88e-6c4b-4e35-af4f-cdfd06ef2e44.png#averageHue=%23ebedd1&clientId=ud1a37d8c-afb6-4&from=paste&height=486&id=vKuDP&originHeight=486&originWidth=1038&originalType=binary&ratio=1&rotation=0&showTitle=false&size=122717&status=done&style=none&taskId=u999437d3-a961-4e6c-8010-52a1b35c5f1&title=&width=1038" alt="image.png"></p>
<p>epoll 是解决 C10K 问题的利器，通过两个方面解决了 select&#x2F;poll 的问题。</p>
<ul>
<li>epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select&#x2F;poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。</li>
<li>epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select&#x2F;poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。</li>
</ul>
<p>而且，epoll 支持边缘触发和水平触发的方式，而 select&#x2F;poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。</p>
<p><a name="BNlOC"></a></p>
<h2 id="Reactor和Proactor"><a href="#Reactor和Proactor" class="headerlink" title="Reactor和Proactor"></a>Reactor和Proactor</h2><ul>
<li><strong>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件</strong>。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。</li>
<li><strong>Proactor 是异步网络模式， 感知的是已完成的读写事件</strong>。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。</li>
</ul>
<p>常见的 Reactor 实现方案有三种。<br>第一种方案单 Reactor 单进程 &#x2F; 线程，不用考虑进程间通信以及数据同步的问题，因此实现起来比较简单，这种方案的缺陷在于无法充分利用多核 CPU，而且处理业务逻辑的时间不能太长，否则会延迟响应，所以不适用于计算机密集型的场景，适用于业务处理快速的场景，比如 Redis（6.0之前 ） 采用的是单 Reactor 单进程的方案。<br>第二种方案单 Reactor 多线程，通过多线程的方式解决了方案一的缺陷，但它离高并发还差一点距离，差在只有一个 Reactor 对象来承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。<br>第三种方案多 Reactor 多进程 &#x2F; 线程，通过多个 Reactor 来解决了方案二的缺陷，主 Reactor 只负责监听事件，响应事件的工作交给了从 Reactor，Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案，Nginx 则采用了类似于 「多 Reactor 多进程」的方案。<br>Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。</p>
<p>因此，真正的大杀器还是 Proactor，它是采用异步 I&#x2F;O 实现的异步网络模型，感知的是已完成的读写事件，而不需要像 Reactor 感知到事件后，还需要调用 read 来从内核中获取数据。<br>不过，无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件。<br><a name="ux2Jk"></a></p>
<h2 id="什么是一致性哈希"><a href="#什么是一致性哈希" class="headerlink" title="什么是一致性哈希"></a>什么是一致性哈希</h2><p><a name="bBwiJ"></a></p>
<h1 id="MQ系列"><a href="#MQ系列" class="headerlink" title="MQ系列"></a>MQ系列</h1><p><a name="ea7ju"></a></p>
<h2 id="KafKa"><a href="#KafKa" class="headerlink" title="KafKa"></a>KafKa</h2><p>Kafka 是一个分布式的、可扩展的、容错的、支持分区的（Partition）、多副本的（replica）、基于Zookeeper框架的发布-订阅消息系统，Kafka适合离线和在线消息消费。</p>
<p><a name="tHAZd"></a></p>
<h3 id="KafKa的设计"><a href="#KafKa的设计" class="headerlink" title="KafKa的设计"></a>KafKa的设计</h3><p>kafka是将消息以 <strong>topic</strong> 为单位进行归纳，发布消息的程序称为 <strong>Producer</strong>，消费消息的程序成为 <strong>Consumer</strong></p>
<p>kafka是以集群的方式运行的，它可以由一个或多个服务组成，每个服务叫做一个 **Broker **, Producer<br>通过网络将消息发送到Kafka集群，集群向消费者提供消息，broker在中间起到一个代理保存消息的中间站。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1709825103576-e66103c7-a4db-43ee-9a1d-1723f19a7bf9.png#averageHue=%23faf8f1&clientId=u8d88e84c-6e84-4&from=paste&height=851&id=G4WCQ&originHeight=851&originWidth=1514&originalType=binary&ratio=1&rotation=0&showTitle=false&size=952255&status=done&style=none&taskId=u3b10a333-6b7c-4cc6-a087-804065b8d74&title=&width=1514" alt="image.png"></p>
<p>_1）Producer_：消息生产者，发布消息到Kafka集群的终端或服务<br>_2）Broker_：一个 Kafka 节点就是一个 Broker，多个Broker可组成一个Kafka 集群。<br>如果某个 Topic 下有 n 个Partition 且集群有 n 个Broker，那么每个 Broker会存储该 Topic 下的一个 Partition<br>如果某个 Topic 下有 n 个Partition 且集群中有 m+n 个Broker，那么只有 n 个Broker会存储该Topic下的一个 Partition<br>如果某个 Topic 下有 n 个Partition 且集群中的Broker数量小于 n，那么一个 Broker 会存储该 Topic 下的一个或多个 Partition，这种情况尽量避免，会导致集群数据不均衡<br>_3）Topic_：消息主题，每条发布到Kafka集群的消息都会归集于此，Kafka是面向Topic 的<br>_4）Partition_：Partition 是Topic在物理上的分区，一个Topic可以分为多个Partition，每个Partition是一个有序的不可变的记录序列。单一主题中的分区有序，但无法保证主题中所有分区的消息有序。<br>_5）Consumer_：从Kafka集群中消费消息的终端或服务<br>_6）Consumer Group_：每个Consumer都属于一个Consumer Group，每条消息只能被Consumer Group中的一个Consumer消费，但可以被多个Consumer Group消费。<br>_7）Replica_：Partition 的副本，用来保障Partition的高可用性。<br><em>8）Controller：</em> Kafka 集群中的其中一个服务器，用来进行Leader election以及各种 Failover 操作。<br>_9）Zookeeper_：Kafka 通过Zookeeper来存储集群中的 meta 消息</p>
<p><a name="zqrMV"></a></p>
<h3 id="KafKa性能高原因"><a href="#KafKa性能高原因" class="headerlink" title="KafKa性能高原因"></a>KafKa性能高原因</h3><p>TODO：探究</p>
<ol>
<li>利用了 PageCache 缓存</li>
<li>磁盘顺序写</li>
<li>零拷贝技术</li>
<li>pull拉模式</li>
</ol>
<p><a name="qhQix"></a></p>
<h3 id="KafKa文件高效存储设计原理"><a href="#KafKa文件高效存储设计原理" class="headerlink" title="KafKa文件高效存储设计原理"></a>KafKa文件高效存储设计原理</h3><ol>
<li>Kafka把 Topic 中的一个Partition 大文件分成很多个小文件段，通过多个小文件段，就很容易定期清除或删除已完成消费完成的文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位Message和确定response的最大大小</li>
<li>通过将索引元数据全部映射到memory，可以避免Segment文件的磁盘I&#x2F;O操作</li>
<li>通过索引文件稀疏存储，可以大幅度降低索引文件元数据占用空间大小。</li>
</ol>
<p><a name="cgPSE"></a></p>
<h3 id="KafKa的优缺点"><a href="#KafKa的优缺点" class="headerlink" title="KafKa的优缺点"></a>KafKa的优缺点</h3><p><strong>优点</strong></p>
<ul>
<li>高性能、高吞吐量、低延迟：Kafka 生产和消费消息的速度都达到每秒10万级</li>
<li>高可用：所有消息持久化存储到磁盘，并支持数据备份防止数据丢失</li>
<li>高并发：支持数千个客户端同时读写</li>
<li>容错性：允许集群中节点失败（若副本数量为n，则允许 n-1 个节点失败）</li>
<li>高扩展性：Kafka 集群支持热伸缩，无须停机</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>没有完整的监控工具集</li>
<li>不支持通配符主题选择</li>
</ul>
<p><a name="kgbAe"></a></p>
<h3 id="KafKa的应用场景"><a href="#KafKa的应用场景" class="headerlink" title="KafKa的应用场景"></a>KafKa的应用场景</h3><ol>
<li><strong>日志聚合</strong>：可收集各种服务的日志写入kafka的消息队列进行存储</li>
<li><strong>消息系统</strong>：广泛用于消息中间件</li>
<li><strong>系统解耦</strong>：在重要操作完成后，发送消息，由别的服务系统来完成其他操作</li>
<li><strong>流量削峰</strong>：一般用于秒杀或抢购活动中，来缓冲网站短时间内高流量带来的压力</li>
<li><strong>异步处理</strong>：通过异步处理机制，可以把一个消息放入队列中，但不立即处理它，在需要的时候再进行处理</li>
</ol>
<p><a name="qLKfJ"></a></p>
<h3 id="KafKa为什么要把消息分区"><a href="#KafKa为什么要把消息分区" class="headerlink" title="KafKa为什么要把消息分区"></a>KafKa为什么要把消息分区</h3><ol>
<li>方便在集群中扩展，每个 Partition 可用通过调整以适应它所在的机器，而一个Topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了</li>
<li>可以提高并发，因为可以以Partition为单位进行读写</li>
</ol>
<p><a name="zJwCk"></a></p>
<h3 id="KafKa消息的消费模式"><a href="#KafKa消息的消费模式" class="headerlink" title="KafKa消息的消费模式"></a>KafKa消息的消费模式</h3><blockquote>
<p>Kafka采用大部分消息系统遵循的传统模式：Producer将消息推送到Broker，Consumer从Broker获取消息。</p>
</blockquote>
<p>如果采用 <strong>Push</strong> 模式，则Consumer难以处理不同速率的上游推送消息。<br>采用 Pull 模式的好处是Consumer可以自主决定是否批量的从Broker拉取数据。Pull模式有个缺点是，如果Broker没有可供消费的消息，将导致Consumer不断在循环中轮询，直到新消息到达。为了避免这点，Kafka有个参数可以让Consumer阻塞直到新消息到达。</p>
<p><a name="GUGhY"></a></p>
<h3 id="KafKa如何实现负载均衡和故障转移"><a href="#KafKa如何实现负载均衡和故障转移" class="headerlink" title="KafKa如何实现负载均衡和故障转移"></a>KafKa如何实现负载均衡和故障转移</h3><p>负载均衡是指让系统的负载根据一定的规则均衡地分配在所有参与工作的服务器上，从而最大限度保证系统整体运行效率与稳定性<br><strong>负载均衡</strong><br>Kakfa 的负载均衡就是每个 <strong>Broker</strong> 都有均等的机会为 Kafka 的客户端（生产者与消费者）提供服务，可以负载分散到所有集群中的机器上。Kafka 通过智能化的分区领导者选举来实现负载均衡，提供智能化的 Leader 选举算法，可在集群的所有机器上均匀分散各个Partition的Leader，从而整体上实现负载均衡。<br><strong>故障转移</strong><br>Kafka 的故障转移是通过使用<strong>会话机制</strong>实现的，每台 Kafka 服务器启动后会以会话的形式把自己注册到 Zookeeper 服务器上。一旦服务器运转出现问题，就会导致与Zookeeper 的会话不能维持从而超时断连，此时Kafka集群会选举出另一台服务器来完全替代这台服务器继续提供服务。</p>
<p><a name="coakq"></a></p>
<h3 id="KafKa中Zookeeoer的作用"><a href="#KafKa中Zookeeoer的作用" class="headerlink" title="KafKa中Zookeeoer的作用"></a>KafKa中Zookeeoer的作用</h3><p>Kafka 是一个使用 Zookeeper 构建的分布式系统。Kafka 的各 Broker 在启动时都要在Zookeeper上注册，由Zookeeper统一协调管理。如果任何节点失败，可通过Zookeeper从先前提交的偏移量中恢复，因为它会做周期性提交偏移量工作。同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也是Zookeeper在维护。</p>
<p><a name="QBIIn"></a></p>
<h2 id="asynq"><a href="#asynq" class="headerlink" title="asynq"></a>asynq</h2><p>Asynq 工作原理的高级概述：</p>
<ul>
<li>客户端将任务放入队列</li>
<li>服务器从队列中拉取任务并为每个任务启动一个工作协程</li>
<li>任务由多个worker同时处理</li>
</ul>
<p>任务队列用作跨多台机器分配工作的机制。一个系统可以由多个工作服务器和代理组成，使其具有高可用性和水平扩展特性。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710467440132-8e10534f-71c6-4c75-a50b-34df7612b407.png#averageHue=%23fdfcfb&clientId=ubd638408-3c9e-4&from=paste&height=510&id=zS4fB&originHeight=638&originWidth=921&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=105025&status=done&style=none&taskId=uf6916178-e7fc-47a7-b34d-a58514ab3d9&title=&width=736.8" alt="image.png"><br>特性：<br>Asynq有很多易用的特性，下面简单列举几个：</p>
<ul>
<li><strong>任务调度</strong></li>
<li><strong>保证任务至少执行一次</strong></li>
<li><strong>失败任务重试</strong></li>
<li><strong>自动恢复</strong></li>
<li><strong>优先级队列</strong></li>
<li><strong>使用唯一选项对任务进行重复数据删除</strong></li>
<li><strong>周期性任务</strong></li>
<li><strong>可视化的管理界面</strong></li>
<li><strong>支持Redis集群和哨兵模式</strong></li>
<li>与 Prometheus 集成以收集和可视化队列指标</li>
<li>用于检查和远程控制队列和任务的 Web UI</li>
<li>用于检查和远程控制队列和任务的 CLI</li>
</ul>
<p><a name="bWnwc"></a></p>
<h2 id="RocketMq"><a href="#RocketMq" class="headerlink" title="RocketMq"></a>RocketMq</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/558139014">https://zhuanlan.zhihu.com/p/558139014</a></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710898420656-30e62e17-b5f7-4e9b-b709-145978483c9c.png#averageHue=%23fbfcf8&clientId=u6ebe996a-f82a-4&from=paste&id=Gszlg&originHeight=432&originWidth=666&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=243850&status=done&style=none&taskId=ub0621e4c-55c9-4ecb-8b50-dbd85b02106&title=" alt="image.png"><br>架构图里面包含了四个主要部分：</p>
<ul>
<li>NameServer集群</li>
<li>Producer集群</li>
<li>Cosumer集群</li>
<li>Broker集群</li>
</ul>
<p><a name="oEmol"></a></p>
<h3 id="为什么使用NameServer而不是ZK"><a href="#为什么使用NameServer而不是ZK" class="headerlink" title="为什么使用NameServer而不是ZK"></a>为什么使用NameServer而不是ZK</h3><p>NameServer 是专为 RocketMQ 设计的轻量级名称服务，为 producer 和 consumer 提供路由信息。具有简单、可集群横吐扩展、无状态，节点之间互不通信等特点。而 RocketMQ 的架构设计决定了只需要一个轻量级的元数据服务器就足够了，只需要保持最终一致，而不需要 Zookeeper 这样的强一致性解决方案，不需要再依赖另一个中间件，从而减少整体维护成本。</p>
<p><a name="t2kQF"></a></p>
<h3 id="RocketMq如何防止消息丢失？"><a href="#RocketMq如何防止消息丢失？" class="headerlink" title="RocketMq如何防止消息丢失？"></a>RocketMq如何防止消息丢失？</h3><p>RocketMQ丢消息的场景</p>
<ul>
<li>生产者向RocketMQ发送消息时</li>
<li>RocketMQ主节点向从节点同步消息时</li>
<li>消费者向RocketMQ拉取消息消费时</li>
</ul>
<p><strong>1.生产者端使用事务消息机制防止消息丢失</strong></p>
<p><strong>2.RocketMQ端使用同步刷盘和Dledger主从架构防止消息丢失</strong></p>
<p><strong>3.消费者端使用同步消费机制</strong></p>
<ul>
<li>消费者从 broker 拉取消息，然后执行相应的业务逻辑。一旦执行成功，将会返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态给 Broker。</li>
<li>如果 Broker 未收到消费确认响应或收到其他状态，消费者下次还会再次拉取到该条消息，进行重试。</li>
</ul>
<p><a name="FEq3v"></a></p>
<h3 id="RocketMq如何保证消息有序？"><a href="#RocketMq如何保证消息有序？" class="headerlink" title="RocketMq如何保证消息有序？"></a>RocketMq如何保证消息有序？</h3><ul>
<li>全局有序：整个MQ系统的所有消息严格按照队列先入先出顺序进行消费</li>
<li>局部有序：只保证一部分关键消息的消费顺序</li>
</ul>
<ol>
<li>对于局部有序，只需要将有序的一组消息都存入同一个MessageQueue里，这样MessageQueue的FIFO设计就可以保证这一组消息的有序。即可以在发送者发送消息时指定一个MessageSelector对象，让这个对象来决定消息发入哪一MessageQueue，这样就可以保证一组有序的消息能够发到同一个MessageQueue里。</li>
<li>消费端是使用MessageListenerOrderly则已经默认实现了顺序消费，如果是使用了MessageListenerConcurrently则只需把线程池改成单线程模式。</li>
</ol>
<p><a name="ztIpl"></a></p>
<h3 id="RocketMq如何实现延迟消息"><a href="#RocketMq如何实现延迟消息" class="headerlink" title="RocketMq如何实现延迟消息"></a>RocketMq如何实现延迟消息</h3><p>临时存储+定时任务。<br>Broker收到延时消息了，会先发送到主题（SCHEDULE_TOPIC_XXXX）的相应时间段的Message Queue中，然后通过一个定时任务轮询这些队列，到期后，把消息投递到目标Topic的队列中，然后消费者就可以正常消费这些消息。</p>
<p><a name="yHJKW"></a></p>
<h3 id="消费消息是push还是pull"><a href="#消费消息是push还是pull" class="headerlink" title="消费消息是push还是pull"></a>消费消息是push还是pull</h3><p>RocketMQ没有真正意义的push，都是pull，虽然有push类，但实际底层实现采用的是长轮询机制，即拉取方式。</p>
<p><a name="PBBG3"></a></p>
<h3 id="RocketMq如何对消息去重"><a href="#RocketMq如何对消息去重" class="headerlink" title="RocketMq如何对消息去重"></a>RocketMq如何对消息去重</h3><p>只要通过网络交换数据，就无法避免因为网络不可靠而造成的消息重复这个问题。比如说RocketMq中，当consumer消费完消息后，因为网络问题未及时发送ack到broker,broker就不会删掉当前已经消费过的消息，那么，该消息将会被重复投递给消费者去消费。<br>虽然 RocketMq 保证了同一个消费组只能消费一次，但会被不同的消费组重复消费，因此这种重复消费的情况不可避免。<br>RocketMq本身并不保证消息不重复，这样肯定会因为每次的判断，导致性能打折扣，所以它将去重操作直接放在了消费端：</p>
<ul>
<li>消费端处理消息的业务逻辑保持幂等性。那么不管来多少条重复消息，可以实现处理的结果都一样</li>
<li>还可以建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费</li>
</ul>
<p>rocketmq有几种模式<br><a target="_blank" rel="noopener" href="https://juejin.cn/post/6997217228743507981">https://juejin.cn/post/6997217228743507981</a></p>
<ol>
<li>simple模式</li>
<li>work模式（轮询分发，公平分发）</li>
<li>publish&#x2F;subscribe模式（发布订阅模式）</li>
<li>Routing路由模式</li>
<li>Topic主题模式</li>
<li>RPC模式</li>
</ol>
<p><a name="z7DZL"></a></p>
<h1 id="常见限流算法"><a href="#常见限流算法" class="headerlink" title="常见限流算法"></a>常见限流算法</h1><p>那么我们先来看什么是限流？<br>通过对并发访问&#x2F;请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理，避免瞬间流量过大冲垮系统，应用场景一般在秒杀，抢购，爬虫等使用非常广泛。</p>
<p>那为什么我们需要限流呢，流量不应该越大越好吗？<br>因为，</p>
<ul>
<li><strong>后台服务能力的局限性，需要限流，否则服务会崩掉</strong></li>
<li><strong>可以根据测试性能去评估限流的设置，例如测试最大连接数，qps数量（每秒钟能处理的最大请求数）</strong></li>
<li><strong>防止爬虫、恶意攻击</strong></li>
</ul>
<p><a name="Sotin"></a></p>
<h2 id="固定窗口（窗口计数法）"><a href="#固定窗口（窗口计数法）" class="headerlink" title="固定窗口（窗口计数法）"></a>固定窗口（窗口计数法）</h2><p>最常用的是使用计数器来控制，<strong>设置固定的时间内，处理固定的请求数</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710155018631-61da48ca-9f4d-4982-91b8-9e13ce465196.png#averageHue=%23f9f4f4&clientId=u7be26187-811a-4&from=paste&height=606&id=UScEL&originHeight=606&originWidth=1067&originalType=binary&ratio=1&rotation=0&showTitle=false&size=249402&status=done&style=none&taskId=u851d48dc-a7fe-42f0-aad1-91f78a78c1d&title=&width=1067" alt="image.png"></p>
<p>上图所示，固定时间窗口来做限制，<strong>1 s内最多</strong>只能处理3<strong>个</strong>请求，红色请求则会被直接丢弃</p>
<ul>
<li>固定每1秒限制同时请求数为3</li>
<li>上述红色部分的请求会被扔掉，扔掉之后 整个服务负荷可能会降低</li>
<li>但是这个会丢掉请求，对于体验不好</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> limiter</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">   <span class="string">&quot;sync&quot;</span></span><br><span class="line">   <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// FixedWindowLimiter 固定窗口限流器</span></span><br><span class="line"><span class="keyword">type</span> FixedWindowLimiter <span class="keyword">struct</span> &#123;</span><br><span class="line">   limit    <span class="type">int</span>           <span class="comment">// 窗口请求上限</span></span><br><span class="line">   window   time.Duration <span class="comment">// 窗口时间大小</span></span><br><span class="line">   counter  <span class="type">int</span>           <span class="comment">// 计数器</span></span><br><span class="line">   lastTime time.Time     <span class="comment">// 上一次请求的时间</span></span><br><span class="line">   mutex    sync.Mutex    <span class="comment">// 避免并发问题</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewFixedWindowLimiter</span><span class="params">(limit <span class="type">int</span>, window time.Duration)</span></span> *FixedWindowLimiter &#123;</span><br><span class="line">   <span class="keyword">return</span> &amp;FixedWindowLimiter&#123;</span><br><span class="line">      limit:    limit,</span><br><span class="line">      window:   window,</span><br><span class="line">      lastTime: time.Now(),</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *FixedWindowLimiter)</span></span> TryAcquire() <span class="type">bool</span> &#123;</span><br><span class="line">   l.mutex.Lock()</span><br><span class="line">   <span class="keyword">defer</span> l.mutex.Unlock()</span><br><span class="line">   <span class="comment">// 获取当前时间</span></span><br><span class="line">   now := time.Now()</span><br><span class="line">   <span class="comment">// 如果当前窗口失效，计数器清0，开启新的窗口</span></span><br><span class="line">   <span class="keyword">if</span> now.Sub(l.lastTime) &gt; l.window &#123;</span><br><span class="line">      l.counter = <span class="number">0</span></span><br><span class="line">      l.lastTime = now</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 若到达窗口请求上限，请求失败</span></span><br><span class="line">   <span class="keyword">if</span> l.counter &gt;= l.limit &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 若没到窗口请求上限，计数器+1，请求成功</span></span><br><span class="line">   l.counter++</span><br><span class="line">   <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该算法的问题：主要是会存在临界问题，如果流量都集中在两个窗口的交界处，那么突发流量会是设置上限的两倍，还是没有避免掉可能的瞬时流量的问题。</p>
<p><a name="Cfl0F"></a></p>
<h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><p>能够去平滑一下处理的任务数量。滑动窗口计数器是通过将窗口再细分，并且按照时间滑动，这种算法避免了固定窗口算法带来的<strong>双倍突发请求</strong>，但时间区间精度越高，算法所需的空间容量越大。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710155091848-0a64c325-8f90-4b53-8005-42909acd80a8.png#averageHue=%23faf8f8&clientId=u7be26187-811a-4&from=paste&height=704&id=cBrJJ&originHeight=704&originWidth=1165&originalType=binary&ratio=1&rotation=0&showTitle=false&size=284685&status=done&style=none&taskId=u46d0744a-4f85-4656-aa8a-f1f8b840e65&title=&width=1165" alt="image.png"></p>
<ul>
<li>将时间划分为多个区间</li>
<li>在每个区间内每有一次请求就讲计数器加1维持一个时间窗口，占据多个区间</li>
<li>每经过一个区间的时间，则抛弃最老的一个区间，并纳入最新的一个区间</li>
<li>若当前的窗口内区间的请求总数和超过了限制数量，<strong>则本窗口内的请求都被丢弃</strong></li>
</ul>
<p>该算法虽然解决了固定窗口的边界问题，但是还是存在限流不够平滑的问题。例如：限流是每秒100个，在第一毫秒发送了100个请求，达到限流，剩余窗口时间的请求都将会被拒绝，体验不好，那我们继续看下面的算法。<br><a name="H8Ot5"></a></p>
<h2 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h2><p>漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。</p>
<p>该算法的优势：</p>
<ol>
<li><strong>平滑流量。</strong>由于漏桶算法以固定的速率处理请求，可以有效地平滑和整形流量，避免流量的突发和波动（类似于消息队列的削峰填谷的作用）。<br><strong>2.防止过载。</strong>当流入的请求超过桶的容量时，可以直接丢弃请求，防止系统过载。该算法的缺点：</li>
<li>无法处理突发流量：由于漏桶的出口速度是固定的，无法处理突发流量。例如，即使在流量较小的时候，也无法以更快的速度处理请求。</li>
<li>可能会丢失数据：如果入口流量过大，超过了桶的容量，那么就需要丢弃部分请求。在一些不能接受丢失请求的场景中，这可能是一个问题。</li>
<li>不适合速率变化大的场景：如果速率变化大，或者需要动态调整速率，那么漏桶算法就无法满足需求。</li>
</ol>
<p><a name="nGZe2"></a></p>
<h2 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h2><p>令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。<br>令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。</p>
<p>算法原理：</p>
<ol>
<li>令牌桶算法可控制发送到网络上数据的数目，并允许突发数据的发送；</li>
<li>大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌：<br>1）、令牌桶中的每一个令牌都代表一个字节<br>2）、如果令牌桶中存在令牌，则允许发送流量<br>3）、如果令牌桶中不存在令牌，则不允许发送流量<br>4）、若令牌不被消耗，或被消耗速度小于产生速度，令牌就会不断地增多，直到把桶填满<br>5）、传送到令牌桶的数据包需要消耗令牌，不同大小的数据包，消耗的令牌数量不同</li>
</ol>
<p>令牌桶算法的优势：</p>
<ol>
<li><strong>可以处理突发流量</strong>：令牌桶算法可以处理突发流量。当桶满时，能够以最大速度处理请求。这对于需要处理突发流量的应用场景非常有用；<br><strong>2. 限制平均速率</strong>：在长期运行中，数据的传输率会被限制在预定义的平均速率（即生成令牌的速率）；<br><strong>3. 灵活性</strong>：与漏桶算法相比，令牌桶算法提供了更大的灵活性。例如，可以动态地调整生成令牌的速率；</li>
</ol>
<p><strong>该算法的缺点：</strong><br><strong>1. 导致过载的可能性</strong>：要控制令牌的产生速度，如果令牌产生的速度过快，可能会导致大量的突发流量，这可能会使网络或服务过载。<br><strong>2. 内存资源限制</strong>：令牌桶需要一定的存储空间来保存令牌，可能会导致内存资源的浪费。</p>
<p><strong>总结：计数器、漏桶、令牌桶算法限流有各自的特点及应用场景，不能单一维度地判断哪个算法最好。</strong><br>计数器算法实现简单，适用于对接口频次的限制，如防恶意刷帖限制等;<br>漏桶限流适用于处理流量突刺现象，因为只要桶为空就可以接受请求；<br>令牌桶限流适用于应对突发流量，也是目前互联网架构中最常用的一种限流方式，只要能取到令牌即可处理请求。</p>
<p><a name="yCrcx"></a></p>
<h1 id="go-zero相关的问题"><a href="#go-zero相关的问题" class="headerlink" title="go-zero相关的问题"></a>go-zero相关的问题</h1><ol>
<li><strong>grpc是什么？有哪些优点</strong></li>
</ol>
<p>gRPC是一种高性能、开源的远程过程调用（RPC）框架，它可以使不同平台和语言之间的服务相互通信。它的优点包括：高效性、跨平台、异步流处理、支持多种语言、安全、易于使用和开源。</p>
<ol start="2">
<li><strong>gPRC和REST的区别是什么？</strong></li>
</ol>
<p>REST是基于HTTP协议的一种风格，而gRPC是一个独立于协议的RPC框架。 REST基于资源的状态转移，使用标准的HTTP方法，而gRPC使用协议缓冲区（Protocol Buffers）进行序列化和反序列化。 gRPC支持异步流处理和双向流，而REST通常只支持请求&#x2F;响应模式。</p>
<ol start="3">
<li><strong>Protocol Buffers是什么，为什么它被用于gRPC中？</strong></li>
</ol>
<p>Protocol Buffers是一种语言中立、平台中立、可扩展的序列化格式，它可以用于数据交换和持久化。它被用于gRPC中，因为它可以实现高效的序列化和反序列化，从而提高了gRPC的性能和效率。**</p>
<ol start="4">
<li><strong>gPRC的流程是什么？</strong></li>
</ol>
<p>gRPC流程分为四个步骤：定义服务、生成源代码、实现服务、启动服务。首先，需要定义要实现的服务及其接口，使用Protocol Buffers编写接口定义文件。其次，使用编译器生成客户端和服务器端的源代码。然后，实现生成的接口。最后，启动服务器并将其部署在适当的位置。<br>**<strong>5. gRPC支持哪些类型的序列化？</strong><br>gRPC支持两种类型的序列化：二进制（使用Protocol Buffers）和JSON。其中，二进制序列化在效率和性能方面比JSON序列化更优秀。但是，JSON序列化在可读性方面更好，可以方便地进行调试和测试。</p>
<ol start="6">
<li><strong>go-zero是什么？它的主要功能是是什么？它与其他Go框架有什么不同？</strong></li>
</ol>
<p>Go-Zero 是一个基于 Go 语言的微服务开发框架。它旨在提供简单、高效和可靠的微服务开发解决方案。Go-Zero 主要功能包括 RPC、缓存、限流、熔断、监控等。相较于其他 Go 框架，如 Gin 或 Beego，Go-Zero 更加专注于微服务开发，并提供了更多的开箱即用的功能。</p>
<ol start="7">
<li><strong>如何使用go-zero实现异步任务？</strong></li>
</ol>
<p>go-zero中提供了go-queue包来实现异步任务。具体步骤如下：<br>1）创建一个Redis连接池。<br>2）通过queue.New(queueConfig, redisConfig)创建一个队列实例。<br>3）通过producer :&#x3D; queue.NewProducer()创建一个生产者实例。<br>4）通过consumer :&#x3D; queue.NewConsumer(queueConfig, redisConfig)创建一个消费者实例。<br>5）通过producer.Enqueue(job)将任务放入队列。<br>6）通过consumer.Consume(processor)处理队列中的任务。</p>
<ol start="8">
<li><strong>go-zero如何实现限流？</strong></li>
</ol>
<p>go-zero中提供了go-ratelimit包来实现限流。具体步骤如下：<br>1）通过rate.NewLimiter(rate.Every(time.Second), 100)创建一个限流器实例，限制每秒处理100个请求。<br>2）通过limiter.Allow()方法判断当前请求是否被允许，若被允许则处理请求，否则返回错误提示。</p>
<p><a name="ceHhy"></a></p>
<h2 id="DTM的TTC"><a href="#DTM的TTC" class="headerlink" title="DTM的TTC"></a>DTM的TTC</h2><p>2pc<br>3pc<br>TTC<br>try-confirm-cancle</p>
<p><a name="pmTuG"></a></p>
<h1 id="微服务面经"><a href="#微服务面经" class="headerlink" title="微服务面经"></a>微服务面经</h1><p><a name="ABaQB"></a></p>
<h2 id="RPC和HTTP"><a href="#RPC和HTTP" class="headerlink" title="RPC和HTTP"></a>RPC和HTTP</h2><p><a name="rhpd6"></a></p>
<h3 id="RPC原理"><a href="#RPC原理" class="headerlink" title="RPC原理"></a>RPC原理</h3><p>RPC服务基本架构包含了四个核心的组件，分别是Client,Server,Clent Stub以及Server Stub。<br>RPC 让远程调用就像本地调用一样，其调用过程可拆解为以下步骤。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1711160551085-db6a9fb6-f1e5-475f-abef-220d7a33fbf6.png#averageHue=%23f6f5f4&clientId=ub244fb08-c28c-4&from=paste&height=624&id=u7651fe06&originHeight=624&originWidth=1221&originalType=binary&ratio=1&rotation=0&showTitle=false&size=203201&status=done&style=none&taskId=ub9951bff-3ab9-44f0-9fd4-af0b90c57c1&title=&width=1221" alt="image.png"></p>
<p><a name="fGiqM"></a></p>
<h3 id="流行的RPC框架"><a href="#流行的RPC框架" class="headerlink" title="流行的RPC框架"></a>流行的RPC框架</h3><p>目前流行的RPC框架有很多，下面介绍常见的三种。</p>
<ol>
<li>gRPC：gRPC是Google公布的开源项目，基于HTTP2.0协议，并支持常见的众多编程语言。HTTP 2.0协议是基于二进制的HTTP协议的升级版本，gRPC底层使用了Netty框架。</li>
<li>Thrift：Thrift是Facebook的一个开源项目，主要是一个跨语言的服务开发框架。它有一个代码生成器来对它所定义的IDL文件自动生成服务代码框架。Thrift对于底层的RPC通讯都是透明的，用户只需要对其进行二次开发即可，省去了一系列重复的前置基础开发工作。</li>
<li>Dubbo：Dubbo是阿里集团开源的一个极为出名的RPC框架，在很多互联网公司和企业应用中广泛使用。协议和序列化框架都可以插拔是及其鲜明的特色。</li>
</ol>
<p><a name="zE5BB"></a></p>
<h1 id="面经分享"><a href="#面经分享" class="headerlink" title="面经分享"></a>面经分享</h1><p><a name="nRIu7"></a></p>
<h2 id="字节二面"><a href="#字节二面" class="headerlink" title="字节二面"></a>字节二面</h2><ol>
<li>10进制转62进制</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">to62RadixString</span><span class="params">(seq <span class="type">int64</span>)</span></span> <span class="type">string</span> &#123;</span><br><span class="line">	ch := []<span class="type">byte</span>&#123;<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;9&#x27;</span>,</span><br><span class="line">		<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;j&#x27;</span>,</span><br><span class="line">		<span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;p&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;t&#x27;</span>,</span><br><span class="line">		<span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>,</span><br><span class="line">		<span class="string">&#x27;E&#x27;</span>, <span class="string">&#x27;F&#x27;</span>, <span class="string">&#x27;G&#x27;</span>, <span class="string">&#x27;H&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;J&#x27;</span>, <span class="string">&#x27;K&#x27;</span>, <span class="string">&#x27;L&#x27;</span>, <span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">		<span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;Q&#x27;</span>, <span class="string">&#x27;R&#x27;</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;U&#x27;</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;W&#x27;</span>, <span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;Y&#x27;</span>, <span class="string">&#x27;Z&#x27;</span>&#125;</span><br><span class="line">	ans := <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		remainder := <span class="type">int</span>(seq % <span class="number">62</span>)</span><br><span class="line">		ans = <span class="built_in">append</span>(ans, ch[remainder])</span><br><span class="line">		seq /= <span class="number">62</span></span><br><span class="line">		<span class="keyword">if</span> seq == <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	sort.Slice(ans, <span class="function"><span class="keyword">func</span><span class="params">(i, j <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> i &gt; j</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> <span class="type">string</span>(ans)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="G4SuU"></a></p>
<h1 id="奇怪的问题"><a href="#奇怪的问题" class="headerlink" title="奇怪的问题"></a>奇怪的问题</h1><p><a name="nW2Hb"></a></p>
<h2 id="在程序中一般溢出的处理？数据怎么存储的？"><a href="#在程序中一般溢出的处理？数据怎么存储的？" class="headerlink" title="在程序中一般溢出的处理？数据怎么存储的？"></a>在程序中一般溢出的处理？数据怎么存储的？</h2><p>原码</p>
<p>补码</p>
<p>反码<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710897685088-ea34779b-9eba-40da-bde7-c4a60878ec3b.png#averageHue=%23faf8f7&clientId=u6ebe996a-f82a-4&from=paste&height=396&id=mnLM3&originHeight=495&originWidth=1226&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=50961&status=done&style=none&taskId=u7422bc64-23b2-4be1-a7ae-dae8d4356ac&title=&width=980.8" alt="image.png"></p>
<p><a name="HF608"></a></p>
<h1 id="系统设计类的问题？"><a href="#系统设计类的问题？" class="headerlink" title="系统设计类的问题？"></a>系统设计类的问题？</h1><p><a name="kofC4"></a></p>
<h2 id="系统设计答题思路："><a href="#系统设计答题思路：" class="headerlink" title="系统设计答题思路："></a><strong>系统设计答题思路：</strong></h2><p><strong>使用场景 和 限制条件？</strong></p>
<ul>
<li>这个系统是在什么地方使用的？比如<strong>短网址系统提供给站内各种服务生成短网址</strong></li>
<li><strong>限制条件</strong>：用户估计多少，至少要能支撑多少用户</li>
<li><strong>估算并发qps</strong>：峰值qps，平均qps</li>
</ul>
<p><strong>数据库存储 ？</strong></p>
<ul>
<li>按需设计数据库表，需要哪些字段，使用什么类型？数据增长规模</li>
<li>数据库选型：是否需要持久化？使用关系型还是 NoSQL？</li>
<li>如何优化？如何设计索引？是否可以使用缓存？</li>
</ul>
<p><strong>算法模块设计</strong></p>
<ul>
<li>算法解决问题的核心。程序 &#x3D; 算法 + 数据结构。 系统 &#x3D; 服务  + 存储</li>
<li>需要哪些接口，接口如何设计</li>
<li>使用什么算法或模型</li>
<li>不同实现方法之间的优劣势对比，如何取舍</li>
</ul>
<p>延伸考点</p>
<ul>
<li>如果回答不错，可能会问一些深入的问题（扩展、容错）</li>
<li>用户多了，qps高了如何处理？</li>
<li>数据存储多了不够存了如何处理？</li>
<li>故障如何处理？单点失败、多点失败、雪崩问题</li>
</ul>
<p><a name="F4iMQ"></a></p>
<h2 id="短链路系统"><a href="#短链路系统" class="headerlink" title="短链路系统"></a>短链路系统</h2><p>如何设计一个短网址服务(TinyURL)？<br><strong>使用场景？</strong><br>微博和Twitter都有140字数的限制，如果分享一个长网址，很容易就超出限制，发布出去。短网址服务可以把一个长网址变成短网址，方便在社交网络上传播。<br><strong>需求(Needs)</strong><br>很显然，要尽可能的<strong>短</strong>。长度设计为多少才合适呢？</p>
<p>微博的短网址服务用的是长度为7的字符串，这个字符串可以看做是62进制的数，那么最大能表示{62}^7&#x3D;352161<strong><strong>208627&#x3D;3521614606208个网址，远远大于45亿。所以</strong>长度为7就足够了<strong>。<br>一个64位整数如何转化为字符串呢？，假设我们只是用大小写字母加数字，那么可以看做是62进制数，log_{62} {(2^{64}-1)}&#x3D;10.7_l</strong>o<strong>g_62(264−1)&#x3D;10.7，即字符串最长11就足够了。<br>实际生产中，还可以再短一点，比如新浪微博采用的长度就是7，因为 62^7&#x3D;352161</strong></strong>208627&#x3D;3521614606208，这个量级远远超过互联网上的URL总数了，绝对够用了。<br>现代的web服务器（例如Apache, Nginx）大部分都区分URL里的大小写了，所以用大小写字母来区分不同的URL是没问题的。<br>因此，<strong>正确答案：长度不超过7的字符串，由大小写字母加数字共62个字母组成</strong></p>
<p><strong>一对一还是一对多映射？</strong><br>一个长网址，对应一个短网址，还是可以对应多个短网址？这也是个重大选择问题<br>一般而言，一个长网址，在不同的地点，不同的用户等情况下，生成的短网址应该不一样，这样，在后端数据库中，可以更好的进行数据分析。如果一个长网址与一个短网址一一对应，那么在数据库中，仅有一行数据，无法区分不同的来源，就无法做数据分析了。<br>以这个7位长度的短网址作为唯一ID，这个ID下可以挂各种信息，比如生成该网址的用户名，所在网站，HTTP头部的 User Agent等信息，收集了这些信息，才有可能在后面做大数据分析，挖掘数据的价值。短网址服务商的一大盈利来源就是这些数据。<br><strong>正确答案：一对多</strong></p>
<p><strong>如何计算网址？</strong><br>现在我们设定了短网址是一个长度为7的字符串，如何计算得到这个短网址呢？<br>**最容易想到的办法是哈希，先hash得到一个64位整数，将它转化为62进制整，截取低7位即可。但是哈希算有冲突，如何处理冲突呢，又是一个麻烦。这个方法只是转移了矛盾，没有解决矛盾，抛弃。 **<br><strong>正确答案：分布式ID生成器</strong></p>
<p><strong>如何存储？</strong><br>如果存储短网址和长网址的对应关系？以短网址为 primary key, 长网址为value, 可以用传统的关系数据库存起来，例如MySQL, PostgreSQL，也可以用任意一个分布式KV数据库，例如Redis, LevelDB。<br>如果你手痒想要手工设计这个存储，那就是另一个话题了，你需要完整地造一个KV存储引擎轮子。当前流行的KV存储引擎有LevelDB和RockDB，去读它们的源码吧</p>
<p><strong>301还是302重定向？</strong><br>这也是一个有意思的问题。这个问题主要是考察你对301和302的理解，以及浏览器缓存机制的理解。<br>301是永久重定向，302是临时重定向。短地址一经生成就不会变化，所以用301是符合http语义的。但是如果用了301， Google，百度等搜索引擎，搜索的时候会直接展示真实地址，那我们就<strong>无法统计到短地址被点击的次数了，也无法收集用户的Cookie, User Agent 等信息</strong>，这些信息可以用来做很多有意思的大数据分析，也是短网址服务商的主要盈利来源。<br>所以，<strong>正确答案是302重定向</strong>。</p>
<p><strong>预防攻击？</strong><br>如果一些别有用心的黑客，短时间内向TinyURL服务器发送大量的请求，会迅速耗光ID，怎么办呢？<br>首先，<strong>限制IP的单日请求总数，超过阈值则直接拒绝服务。</strong><br>光限制IP的请求数还不够，因为黑客一般手里有上百万台肉鸡的，IP地址大大的有，所以光限制IP作用不大。<br>可以用一台Redis作为缓存服务器，存储的不是 ID-&gt;长网址，而是 <strong>长网址-&gt;ID</strong>，仅存储一天以内的数据，用LRU机制进行淘汰。这样，如果黑客大量发同一个长网址过来，直接从缓存服务器里返回短网址即可，他就无法耗光我们的ID了。</p>
<p><a name="bkQjI"></a></p>
<h2 id="设计秒杀系统"><a href="#设计秒杀系统" class="headerlink" title="设计秒杀系统"></a>设计秒杀系统</h2><p><strong>参考链接:</strong> <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1863530">https://cloud.tencent.com/developer/article/1863530</a></p>
<ol>
<li>瞬间高并发</li>
<li>页面静态化</li>
<li>秒杀按钮</li>
<li>读多写少</li>
<li>缓存问题</li>
<li>库存问题</li>
<li>分布式锁</li>
<li>mq异步处理</li>
<li>如何限流</li>
</ol>
<p><a name="V0YdM"></a></p>
<h3 id="瞬间高并发："><a href="#瞬间高并发：" class="headerlink" title="瞬间高并发："></a><strong>瞬间高并发：</strong></h3><p>一般在秒杀时间点（比如：12点）前几分钟，用户并发量才真正突增，达到秒杀时间点时，并发量会达到顶峰。<br>像这种瞬时高并发的场景，传统的系统很难应对，我们需要设计一套全新的系统。可以从以下几个方面入手：</p>
<ol>
<li><strong>页面静态化</strong></li>
<li><strong>CDN加速</strong></li>
<li><strong>缓存</strong></li>
<li><strong>mq异步处理</strong></li>
<li><strong>限流</strong></li>
<li><strong>分布式锁</strong></li>
</ol>
<p><a name="LvrlS"></a></p>
<h3 id="页面静态化"><a href="#页面静态化" class="headerlink" title="页面静态化"></a><strong>页面静态化</strong></h3><p>活动页面是用户流量的第一入口，所以是并发量最大的地方。<br>如果这些流量都能直接访问服务端，恐怕服务端会因为承受不住这么大的压力，而直接挂掉。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710940463688-00036929-2b3a-46d1-918f-c4f494a4315e.jpeg#averageHue=%23f5f4f2&clientId=uf7da8455-ee45-4&from=paste&id=gJMfi&originHeight=354&originWidth=1070&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u7c3ab00a-6a42-4f3e-9273-2a972ff9a2f&title="><br>活动页面绝大多数内容是固定的，比如：<strong>商品名称</strong>、<strong>商品描述、图片</strong>等。为了减少不必要的服务端请求，通常情况下，会对活动页面做静态化处理。用户浏览商品等常规操作，并不会请求到服务端。只有到了秒杀时间点，并且用户主动点了秒杀按钮才允许访问服务端。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710940493979-e2f9506a-20c1-4ea2-adb4-f1341cfd1af8.jpeg#averageHue=%23f4f3f3&clientId=uf7da8455-ee45-4&from=paste&id=R83DI&originHeight=342&originWidth=1144&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uc7b2e87a-da3f-4bb5-bf21-3c799510e98&title="><br>这样能过滤大部分无效请求。<br>但只做页面静态化还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，地域相差很远，网速各不相同。<br>如何才能让用户最快访问到活动页面呢？<br>这就需要使用<strong>CDN</strong>，它的全称是<strong>Content Delivery Network</strong>，即<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cdn?from_column=20065&from=20065">内容分发网络</a>。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710940528055-be2415f3-e45d-49da-bc21-ebbdf2b5b40f.jpeg#averageHue=%23f6f6f5&clientId=uf7da8455-ee45-4&from=paste&id=DWwBv&originHeight=550&originWidth=1246&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u1cbb3879-aa97-48dc-97c1-e860b526501&title="><br>使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。</p>
<p><a name="sXyTU"></a></p>
<h3 id="秒杀按钮"><a href="#秒杀按钮" class="headerlink" title="秒杀按钮"></a><strong>秒杀按钮</strong></h3><p>大部分用户怕错过秒杀时间点，一般会提前进入活动页面。此时看到的秒杀按钮是置灰，不可点击的。只有到了秒杀时间点那一时刻，秒杀按钮才会自动点亮，变成可点击的。<br>但此时很多用户已经迫不及待了，通过不停刷新页面，争取在第一时间看到秒杀按钮的点亮。<br>从前面得知，该活动页面是静态的。那么我们在静态页面中如何控制秒杀按钮，只在秒杀时间点时才点亮呢？<br>没错，<strong>使用js文件控制。</strong><br>为了性能考虑，<strong>一般会将css、js和图片等静态资源文件提前缓存到CDN上</strong>，让用户能够就近访问秒杀页面。<br>看到这里，有些聪明的小伙伴，可能会问：CDN上的js文件是如何更新的？<br>秒杀开始之前，js标志为false，还有另外一个随机参数。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710940843481-7c4da998-c8f8-4865-b37c-7d1a53924a64.jpeg#averageHue=%23f5f4f3&clientId=uf7da8455-ee45-4&from=paste&id=U1NV0&originHeight=482&originWidth=1406&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uf641d095-7602-410f-9a80-8f92bea628b&title="><br><strong>当秒杀开始的时候系统会生成一个新的js文件，此时标志为true，并且随机参数生成一个新值，</strong>然后同步给CDN。由于有了这个随机参数，CDN不会缓存数据，每次都能从CDN中获取最新的js代码。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710940898606-e84c5e27-3d25-457a-876c-cd20bb472c43.jpeg#averageHue=%23ecdcc4&clientId=uf7da8455-ee45-4&from=paste&id=AeXu1&originHeight=470&originWidth=1376&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u6514619e-d21e-408a-bafb-e1d02aab06b&title="><br>此外，前端还可以加一个定时器，控制比如：10秒之内，只允许发起一次请求。如果用户点击了一次秒杀按钮，则在10秒之内置灰，不允许再次点击，等到过了时间限制，又允许重新点击该按钮。</p>
<p><a name="zJkzy"></a></p>
<h3 id="读多写少"><a href="#读多写少" class="headerlink" title="读多写少"></a><strong>读多写少</strong></h3><p>在秒杀的过程中，系统一般会先查一下库存是否足够，如果足够才允许下单，写<a target="_blank" rel="noopener" href="https://cloud.tencent.com/solution/database?from_column=20065&from=20065">数据库</a>。如果不够，则直接返回该商品已经抢完。<br>由于大量用户抢少量商品，只有极少部分用户能够抢成功，所以绝大部分用户在秒杀时，库存其实是不足的，系统会直接返回该商品已经抢完。<br>这是非常典型的：读多写少 的场景。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941023642-acba858c-3320-4e44-af3b-60dda744a7fe.jpeg#averageHue=%23faf9f7&clientId=uf7da8455-ee45-4&from=paste&id=Bkrft&originHeight=842&originWidth=586&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u8eb8a61a-c337-4c0d-8a7c-da784ef2105&title="><br>如果有数十万的请求过来，同时通过数据库查缓存是否足够，此时数据库可能会挂掉。因为数据库的连接资源非常有限，比如：mysql，无法同时支持这么多的连接。<br><strong>而应该改用缓存，比如：redis。</strong><br>即便用了redis，也需要部署多个节点。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941104239-e2a5bd1c-ead5-4806-8c92-aa30ef774ced.jpeg#averageHue=%23fcfcfb&clientId=uf7da8455-ee45-4&from=paste&id=I0i8H&originHeight=888&originWidth=772&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uabf0b91c-4f3e-4766-af96-de7f44cf389&title="></p>
<p><a name="OBEvj"></a></p>
<h3 id="缓存问题"><a href="#缓存问题" class="headerlink" title="缓存问题"></a><strong>缓存问题</strong></h3><p>通常情况下，我们需要在redis中保存商品信息，里面包含：商品id、商品名称、规格属性、库存等信息，同时数据库中也要有相关信息，毕竟缓存并不完全可靠。<br>用户在点击秒杀按钮，请求秒杀接口的过程中，需要传入的商品id参数，然后服务端需要校验该商品是否合法。<br>大致流程如下图所示：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941193272-b72bf548-eb55-4079-8108-1335514b2ccd.jpeg#averageHue=%23fbfafa&clientId=uf7da8455-ee45-4&from=paste&id=O7Hcq&originHeight=804&originWidth=1204&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uf000a7c1-a9ec-47e4-a3b8-2b403be5d25&title="><br>根据商品id，先从缓存中查询商品，如果商品存在，则参与秒杀。如果不存在，则需要从数据库中查询商品，如果存在，则将商品信息放入缓存，然后参与秒杀。如果商品不存在，则直接提示失败。<br>这个过程表面上看起来是OK的，但是如果深入分析一下会发现一些问题。</p>
<p><strong>5.1缓存击穿</strong><br>比如商品A第一次秒杀时，缓存中是没有数据的，但数据库中有。虽说上面有如果从数据库中查到数据，则放入缓存的逻辑。<br>然而，在高并发下，同一时刻会有大量的请求，都在秒杀同一件商品，这些请求同时去查缓存中没有数据，然后又同时访问数据库。结果悲剧了，数据库可能扛不住压力，直接挂掉。<br>如何解决这个问题呢？<br>这就需要加锁，最好使用分布式锁。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941437752-29bd44ed-806d-4935-b033-c0a7311ada19.jpeg#averageHue=%23fafaf9&clientId=uf7da8455-ee45-4&from=paste&id=aRTXa&originHeight=814&originWidth=1454&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u217054ca-14f2-4b55-a7ff-34d365ef252&title="><br>当然，针对这种情况，最好在项目启动之前，先把缓存进行预热。即事先把所有的商品，同步到缓存中，这样商品基本都能直接从缓存中获取到，就不会出现缓存击穿的问题了。<br>是不是上面加锁这一步可以不需要了？<br>表面上看起来，确实可以不需要。但如果缓存中设置的过期时间不对，缓存提前过期了，或者缓存被不小心删除了，如果不加速同样可能出现缓存击穿。<br>其实这里加锁，相当于买了一份保险。</p>
<p>5.<strong>2 缓存击穿</strong><br>如果有大量的请求传入的商品id，在缓存中和数据库中都不存在，这些请求不就每次都会穿透过缓存，而直接访问数据库了。<br>由于前面已经加了锁，所以即使这里的并发量很大，也不会导致数据库直接挂掉。<br>但很显然这些请求的处理性能并不好，有没有更好的解决方案？<br>这时可以想到布隆过滤器。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941566762-31e2e997-26c8-4d7f-834e-44cc67442fa4.jpeg#averageHue=%23fafaf9&clientId=uf7da8455-ee45-4&from=paste&id=ZJ6B6&originHeight=664&originWidth=616&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uc2f07908-1209-49a0-a198-8890c372956&title="><br>系统根据商品id，先从布隆过滤器中查询该id是否存在，如果存在则允许从缓存中查询数据，如果不存在，则直接返回失败。<br>虽说该方案可以解决缓存穿透问题，但是又会引出另外一个问题：布隆过滤器中的数据如何更缓存中的数据保持一致？<br>这就要求，如果缓存中数据有更新，则要及时同步到布隆过滤器中。如果数据同步失败了，还需要增加重试机制，而且跨数据源，能保证数据的实时一致性吗？<br>显然是不行的。<br><strong>所以布隆过滤器绝大部分使用在缓存数据更新很少的场景中。</strong><br><strong>如果缓存数据更新非常频繁，又该如何处理呢？</strong><br>这时，就需要把不存在的商品id也缓存起来。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941622641-4f7ba7b5-27ff-460e-8828-31b9ff0d6677.jpeg#averageHue=%23fbfaf9&clientId=uf7da8455-ee45-4&from=paste&id=aZz6X&originHeight=660&originWidth=624&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u811bb8be-698b-4a3d-a94f-50d891212d4&title="><br>下次，再有该商品id的请求过来，则也能从缓存中查到数据，只不过该数据比较特殊，表示商品不存在。需要特别注意的是，这种特殊缓存设置的超时时间应该尽量短一点。</p>
<p><a name="kyMXy"></a></p>
<h3 id="库存问题"><a href="#库存问题" class="headerlink" title="库存问题"></a><strong>库存问题</strong></h3><p>对于库存问题看似简单，实则里面还是有些东西。<br>真正的秒杀商品的场景，不是说扣完库存，就完事了，如果用户在一段时间内，还没完成支付，扣减的库存是要加回去的。<br>所以，在这里引出了一个预扣库存的概念，预扣库存的主要流程如下：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710941712315-d5c1471c-f100-4f7c-b173-9ee7b8a4de15.jpeg#averageHue=%23fbfaf9&clientId=uf7da8455-ee45-4&from=paste&id=Y1MXY&originHeight=786&originWidth=620&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u936c1aa8-2ece-4c1d-8fad-279e187aad6&title="><br>扣减库存中除了上面说到的预扣库存和回退库存之外，还需要特别注意的是库存不足和库存超卖问题。</p>
<p><strong>6.1 数据库扣减库存</strong><br>使用数据库扣减库存，是最简单的实现方案了，假设扣减库存的sql如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> product <span class="keyword">set</span> stock<span class="operator">=</span>stock<span class="number">-1</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">123</span>;</span><br></pre></td></tr></table></figure>

<p>这种写法对于扣减库存是没有问题的，但如何控制库存不足的情况下，不让用户操作呢？<br>这就需要在update之前，先查一下库存是否足够了。<br>只需将上面的sql稍微调整一下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> product <span class="keyword">set</span> stock<span class="operator">=</span>stock<span class="number">-1</span> <span class="keyword">where</span> id<span class="operator">=</span>product <span class="keyword">and</span> stock <span class="operator">&gt;</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>在sql最后加上：stock &gt; 0，就能保证不会出现超卖的情况。<br><strong>但需要频繁访问数据库，我们都知道数据库连接是非常昂贵的资源。</strong>在高并发的场景下，可能会造成系统雪崩。而且，容易出现多个请求，同时竞争行锁的情况，造成相互等待，从而出现死锁的问题。</p>
<p><strong>6.2redis扣减库存</strong><br>redis的incr方法是原子性的，可以用该方法扣减库存。<br>伪代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">exist</span> <span class="operator">=</span> redisClient.query(productId,userId);</span><br><span class="line"><span class="keyword">if</span>(exist) &#123;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="variable">stock</span> <span class="operator">=</span> redisClient.queryStock(productId);</span><br><span class="line"><span class="keyword">if</span>(stock &lt;=<span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">redisClient.incrby(productId, -<span class="number">1</span>);</span><br><span class="line">redisClient.add(productId,userId);</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>代码流程如下：</p>
<ol>
<li>先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。</li>
<li>查询库存，如果库存小于等于0，则直接返回0，表示库存不足。</li>
<li>如果库存充足，则扣减库存，然后将本次秒杀记录保存起来。然后返回1，表示成功。</li>
</ol>
<p>估计很多小伙伴，一开始都会按这样的思路写代码。但如果仔细想想会发现，这段代码有问题。<br>有什么问题呢？<br>如果在高并发下，有多个请求同时查询库存，当时都大于0。由于查询库存和更新库存非原则操作，则会出现库存为负数的情况，即库存超卖。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">exist</span> <span class="operator">=</span> redisClient.query(productId,userId);</span><br><span class="line"><span class="keyword">if</span>(exist) &#123;</span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(redisClient.incrby(productId, -<span class="number">1</span>)&lt;<span class="number">0</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">redisClient.add(productId,userId);</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>该代码主要流程如下：</p>
<ol>
<li>先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。</li>
<li>扣减库存，判断返回值是否小于0，如果小于0，则直接返回0，表示库存不足。</li>
<li>如果扣减库存后，返回值大于或等于0，则将本次秒杀记录保存起来。然后返回1，表示成功。</li>
</ol>
<p>该方案咋一看，好像没问题。<br>但如果在高并发场景中，有多个请求同时扣减库存，大多数请求的incrby操作之后，结果都会小于0。<br>虽说，库存出现负数，不会出现超卖的问题。但由于这里是预减库存，如果负数值负的太多的话，后面万一要回退库存时，就会导致库存不准。<br>那么，有没有更好的方案呢？</p>
<p><strong>6.3 基于lua脚本扣减库存</strong><br>我们都知道lua脚本，是能够保证原子性的，它跟redis一起配合使用，能够完美解决上面的问题。<br>lua脚本有段非常经典的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">StringBuilder</span> <span class="variable">lua</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">lua.append(<span class="string">&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 1) then&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;    local stock = tonumber(redis.call(&#x27;get&#x27;, KEYS[1]));&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;    if (stock == -1) then&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;        return 1;&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;    end;&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;    if (stock &gt; 0) then&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;        redis.call(&#x27;incrby&#x27;, KEYS[1], -1);&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;        return stock;&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;    end;&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;    return 0;&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;end;&quot;</span>);</span><br><span class="line">lua.append(<span class="string">&quot;return -1;&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>该代码的主要流程如下：</strong></p>
<ol>
<li>先判断商品id是否存在，如果不存在则直接返回。</li>
<li>获取该商品id的库存，判断库存如果是-1，则直接返回，表示不限制库存。</li>
<li>如果库存大于0，则扣减库存。</li>
<li>如果库存等于0，是直接返回，表示库存不足。</li>
</ol>
<p><a name="HSbLf"></a></p>
<h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a><strong>分布式锁</strong></h3><p>之前我提到过，在秒杀的时候，需要先从缓存中查商品是否存在，如果不存在，则会从数据库中查商品。如果数据库中，则将该商品放入缓存中，然后返回。如果数据库中没有，则直接返回失败。<br>大家试想一下，如果在高并发下，有大量的请求都去查一个缓存中不存在的商品，这些请求都会直接打到数据库。数据库由于承受不住压力，而直接挂掉。<br>那么如何解决这个问题呢？<br>这就需要用redis分布式锁了。<br><strong>可以采用的分布式锁</strong></p>
<ol>
<li>setnx</li>
<li>自旋锁</li>
<li>redisson</li>
<li>redlock</li>
</ol>
<p><a name="FTJoL"></a></p>
<h3 id="mq异步"><a href="#mq异步" class="headerlink" title="mq异步"></a><strong>mq异步</strong></h3><p>我们都知道在真实的秒杀场景中，有三个核心流程：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/png/32717568/1710943283661-603f20ca-f397-4a7c-9d32-4004c150ac5e.png#averageHue=%23f8f4f4&clientId=uf7da8455-ee45-4&from=paste&id=RNgWD&originHeight=156&originWidth=860&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u994e5369-19ae-4907-992f-1bfd2753282&title="><br>而这三个核心流程中，真正并发量大的是秒杀功能，下单和支付功能实际并发量很小。所以，我们在设计秒杀系统时，有必要把下单和支付功能从秒杀的主流程中拆分出来，特别是下单功能要做成mq异步处理的。而支付功能，比如支付宝支付，是业务场景本身保证的异步。<br>于是，秒杀后下单的流程变成如下：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710943316877-dd646c0f-aa35-4728-a044-c56c9189d727.jpeg#averageHue=%23e5e6e0&clientId=uf7da8455-ee45-4&from=paste&id=MyJQJ&originHeight=334&originWidth=746&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u7d94d905-9203-4c19-8f02-97bcfafe607&title="><br>如果使用mq，需要关注以下几个问题：</p>
<p><strong>8.1 消息丢失问题</strong><br>秒杀成功了，往mq发送下单消息的时候，有可能会失败。原因有很多，比如：网络问题、broker挂了、mq服务端磁盘问题等。这些情况，都可能会造成消息丢失。<br>那么，如何防止消息丢失呢？<br>答：加一张<strong>消息发送表。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710943357417-c51458d6-5fd6-4750-8bf5-1405766a3733.jpeg#averageHue=%23e7e3d8&clientId=uf7da8455-ee45-4&from=paste&id=okXZh&originHeight=470&originWidth=818&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ud8803efc-b527-4de7-a264-c45424b942b&title="><br>在生产者发送mq消息之前，先把该条消息写入消息发送表，初始状态是待处理，然后再发送mq消息。消费者消费消息时，处理完业务逻辑之后，再回调生产者的一个接口，修改消息状态为已处理。<br>如果生产者把消息写入消息发送表之后，再发送mq消息到mq服务端的过程中失败了，造成了消息丢失。<br>这时候，要如何处理呢？<br>答：使用job，<strong>增加重试机制。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710943413890-e6ca3240-81ac-4bc3-a492-e6fbda09bcb9.jpeg#averageHue=%23f9f8f6&clientId=uf7da8455-ee45-4&from=paste&id=QbXhv&originHeight=296&originWidth=934&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u7149402a-3aaa-4b5e-861c-5c803beff2b&title="><br>用job每隔一段时间去查询消息发送表中状态为待处理的数据，然后重新发送mq消息。</p>
<p><strong>8.2 重复消费问题</strong><br>本来消费者消费消息时，在ack应答的时候，如果网络超时，本身就可能会消费重复的消息。但由于消息发送者增加了重试机制，会导致消费者重复消息的概率增大。<br>那么，如何解决重复消息问题呢？<br>答：<strong>加一张消息处理表。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710943532083-9448e33c-2d8a-402b-93f0-bf8555472199.jpeg#averageHue=%23fbfafa&clientId=uf7da8455-ee45-4&from=paste&id=XQqVw&originHeight=704&originWidth=814&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uf1b1a101-6c35-49b8-9968-5a55c40508e&title="><br>消费者读到消息之后，先判断一下消息处理表，是否存在该消息，如果存在，表示是重复消费，则直接返回。如果不存在，则进行下单操作，接着将该消息写入消息处理表中，再返回。<br>有个比较关键的点是：<strong>下单和写消息处理表，要放在同一个事务中，保证原子操作。</strong></p>
<p><strong>8.3 垃圾消息问题</strong><br>这套方案表面上看起来没有问题，但如果出现了消息消费失败的情况。比如：由于某些原因，消息消费者下单一直失败，一直不能回调状态变更接口，这样job会不停的重试发消息。最后，会产生大量的垃圾消息。<br>那么，如何解决这个问题呢？<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710943693323-0fa70129-4ed8-446f-8473-13522bccb1eb.jpeg#averageHue=%23fbfbfa&clientId=uf7da8455-ee45-4&from=paste&id=ZBB2m&originHeight=514&originWidth=1400&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ub15ac58e-4212-4b59-9938-aec24eaeaae&title="><br>每次在job重试时，需要先判断一下消息发送表中该消息的发送次数是否达到最大限制，如果达到了，则直接返回。如果没有达到，则将次数加1，然后发送消息。<br>这样如果出现异常，只会产生少量的垃圾消息，不会影响到正常的业务。</p>
<p><strong>8.4 延迟消费问题</strong><br>通常情况下，如果用户秒杀成功了，下单之后，在15分钟之内还未完成支付的话，该订单会被自动取消，回退库存。<br>那么，在15分钟内未完成支付，订单被自动取消的功能，要如何实现呢？<br>我们首先想到的可能是job，因为它比较简单。<br>但job有个问题，需要每隔一段时间处理一次，实时性不太好。<br>还有更好的方案？<br>答：<strong>使用延迟队列。</strong><br><strong>我们都知道rocketmq，自带了延迟队列的功能。</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710943863081-6c4cfac2-8e5c-4067-9922-4acdbfc5cc4a.jpeg#averageHue=%23fbfafa&clientId=uf7da8455-ee45-4&from=paste&id=I2Wxd&originHeight=714&originWidth=1196&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ucc3e489d-e442-4cac-8439-074d0b6bc2d&title="><br>下单时消息生产者会先生成订单，<strong>此时状态为待支付</strong>，然后会向延迟队列中发一条消息。达到了延迟时间，消息消费者读取消息之后，会查询该订单的状态是否为待支付。如果是待支付状态，则会更新订单状态为取消状态。如果不是待支付状态，说明该订单已经支付过了，则直接返回。<br>还有个关键点，用户完成支付之后，会修改订单状态为已支付。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2024/jpeg/32717568/1710944031634-faed1338-0bb5-4023-b6b6-09fe710fd6f9.jpeg#averageHue=%23fbfbfb&clientId=uf7da8455-ee45-4&from=paste&id=R55vp&originHeight=546&originWidth=776&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u9aa9848d-36d6-4f06-85d0-fe896127ccf&title="><br><a name="Pp5lR"></a></p>
<h3 id="如何限流？"><a href="#如何限流？" class="headerlink" title="如何限流？"></a>如何限流？</h3><p><a name="Gs79r"></a></p>
<h2 id="Gee实现web框架"><a href="#Gee实现web框架" class="headerlink" title="Gee实现web框架"></a>Gee实现web框架</h2><p>动态路由实现：<br>前缀树：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> gee</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;strings&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> node <span class="keyword">struct</span> &#123;</span><br><span class="line">	pattern  <span class="type">string</span>  <span class="comment">// 待匹配路由，例如 /p/:lang</span></span><br><span class="line">	part     <span class="type">string</span>  <span class="comment">// 路由中的一部分，例如 :lang</span></span><br><span class="line">	children []*node <span class="comment">// 子节点，例如 [doc, tutorial, intro]</span></span><br><span class="line">	isWild   <span class="type">bool</span>    <span class="comment">// 是否精确匹配，part 含有 : 或 * 时为true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第一个匹配成功的节点，用于插入</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span></span> matchChild(part <span class="type">string</span>) *node &#123;</span><br><span class="line">	<span class="keyword">for</span> _, child := <span class="keyword">range</span> n.children &#123;</span><br><span class="line">		<span class="keyword">if</span> child.part == part || child.isWild &#123;</span><br><span class="line">			<span class="keyword">return</span> child</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 所有匹配成功的节点，用于查找</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span></span> matchChildren(part <span class="type">string</span>) []*node &#123;</span><br><span class="line">	nodes := <span class="built_in">make</span>([]*node, <span class="number">0</span>)</span><br><span class="line">	<span class="keyword">for</span> _, child := <span class="keyword">range</span> n.children &#123;</span><br><span class="line">		<span class="keyword">if</span> child.part == part || child.isWild &#123;</span><br><span class="line">			nodes = <span class="built_in">append</span>(nodes, child)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> nodes</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span></span> insert(pattern <span class="type">string</span>, parts []<span class="type">string</span>, height <span class="type">int</span>) &#123;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(parts) == height &#123;</span><br><span class="line">		n.pattern = pattern</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	part := parts[height]</span><br><span class="line">	child := n.matchChild(part)</span><br><span class="line">	<span class="keyword">if</span> child == <span class="literal">nil</span> &#123;</span><br><span class="line">		child = &amp;node&#123;part: part, isWild: part[<span class="number">0</span>] == <span class="string">&#x27;:&#x27;</span> || part[<span class="number">0</span>] == <span class="string">&#x27;*&#x27;</span>&#125;</span><br><span class="line">		n.children = <span class="built_in">append</span>(n.children, child)</span><br><span class="line">	&#125;</span><br><span class="line">	child.insert(pattern, parts, height+<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span></span> search(parts []<span class="type">string</span>, height <span class="type">int</span>) *node &#123;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(parts) == height || strings.HasPrefix(n.part, <span class="string">&quot;*&quot;</span>) &#123;</span><br><span class="line">		<span class="keyword">if</span> n.pattern == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> n</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	part := parts[height]</span><br><span class="line">	children := n.matchChildren(part)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _, child := <span class="keyword">range</span> children &#123;</span><br><span class="line">		result := child.search(parts, height+<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">if</span> result != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> result</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/header.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/header.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">菠萝</div><div class="post-copyright__author_desc">可可爱爱，没有脑袋</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/')">Golang面经</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Golang面经&amp;url=https://kiritoabc.github.io/2024/03/30/Go%E9%9D%A2%E8%AF%95/&amp;pic=https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=51754bf9-ed78-4d2b-fbe8-4e9699cf5ca3" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://Kiritoabc.github.io" target="_blank">菠萝萝のBLOG</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E9%9D%A2%E7%BB%8F/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>面经<span class="tagsPageCount">2</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=3ce8ed58-ae54-a4f2-9fe5-8fa6ead0edf5" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/29/%E5%8D%8E%E4%B8%BA%E4%B8%8A%E6%9C%BA%E8%80%83%E8%AF%95%E5%87%86%E5%A4%87/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover7.jpg?_r_=2415063d-3e17-ad22-02ab-672e54533241" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">华为上机考试</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/31/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-WBS/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover.jpg?_r_=00ec53fb-27e9-37e6-44a6-eb449f00602c" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">项目管理--WBS</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2024/03/28/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E7%BB%8F%E7%B3%BB%E5%88%9701/" title="华为面经系列01"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover5.jpg?_r_=0c46dd35-9b91-73c0-d100-78edf59684fa" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-03-28</div><div class="title">华为面经系列01</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/header.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__description">菠萝，博客</div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">菠萝</h1><div class="author-info__desc">可可爱爱，没有脑袋</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Kiritoabc" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/372204786" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87"><span class="toc-number">1.</span> <span class="toc-text">数组和切片</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E5%90%8C"><span class="toc-number">1.1.</span> <span class="toc-text">1.数组和切片有什么不同</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%88%87%E7%89%87%E7%9A%84%E5%AE%B9%E9%87%8F%E6%98%AF%E6%80%8E%E4%B9%88%E5%A2%9E%E9%95%BF%E7%9A%84"><span class="toc-number">1.2.</span> <span class="toc-text">2.切片的容量是怎么增长的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%88%87%E7%89%87%E4%BD%9C%E4%B8%BA%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0"><span class="toc-number">1.3.</span> <span class="toc-text">3.切片作为函数参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%8C%87%E9%92%88%E5%9C%A8go%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">4.指针在go中的作用？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B0%88%E8%B0%88go%E4%B8%AD%E6%AF%94%E8%BE%83%E7%9B%B8%E7%AD%89"><span class="toc-number">2.</span> <span class="toc-text">谈谈go中比较相等</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E8%A1%A8"><span class="toc-number">3.</span> <span class="toc-text">哈希表</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-map%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">1.map的实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-map%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text">1.1 map的内存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%88%9B%E5%BB%BAmap"><span class="toc-number">3.1.2.</span> <span class="toc-text">1.2 创建map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.3.</span> <span class="toc-text">1.3 哈希函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-key-%E5%AE%9A%E4%BD%8D%E8%BF%87%E7%A8%8B"><span class="toc-number">3.1.4.</span> <span class="toc-text">1.4 key 定位过程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%89%A9%E5%AE%B9%E8%BF%87%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">2.扩容过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-key%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%97%A0%E5%BA%8F%E7%9A%84"><span class="toc-number">3.3.</span> <span class="toc-text">3.key为什么是无序的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-float%E7%B1%BB%E5%9E%8B%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BAmap%E7%9A%84key%E5%90%97%EF%BC%9F"><span class="toc-number">3.4.</span> <span class="toc-text">4.float类型可以作为map的key吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-map%E6%98%AF%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%90%97%EF%BC%9F"><span class="toc-number">3.5.</span> <span class="toc-text">6.map是线程安全的吗？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%A5%E5%8F%A3"><span class="toc-number">4.</span> <span class="toc-text">接口</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%80%BC%E6%8E%A5%E6%94%B6%E8%80%85%E5%92%8C%E6%8C%87%E9%92%88%E6%8E%A5%E6%94%B6%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">4.1.</span> <span class="toc-text">1.值接收者和指针接收者的区别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E5%88%86%E5%88%AB%E5%9C%A8%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8"><span class="toc-number">4.1.1.</span> <span class="toc-text">两者分别在何时使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%AE%9E%E7%8E%B0-iface-%E5%92%8C-eface-%E4%BB%A5%E5%8F%8A-itab"><span class="toc-number">4.2.</span> <span class="toc-text">接口的实现 iface 和 eface 以及 itab</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B0%88%E4%B8%80%E8%B0%88GO-%E7%9A%84GPM%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.</span> <span class="toc-text">谈一谈GO 的GPM模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E5%8D%8F%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">5.0.1.</span> <span class="toc-text">聊一聊协程和线程的区别</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8"><span class="toc-number">6.</span> <span class="toc-text">垃圾回收器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E5%AF%B9go%E7%9A%84context%E7%9A%84%E7%90%86%E8%A7%A3"><span class="toc-number">7.</span> <span class="toc-text">聊一聊你对go的context的理解</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E5%8F%8D%E5%B0%84"><span class="toc-number">8.</span> <span class="toc-text">聊一聊反射</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8Ago%E4%B8%ADmake%E5%92%8Cnew"><span class="toc-number">9.</span> <span class="toc-text">聊一聊go中make和new</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8ATCMalloc"><span class="toc-number">10.</span> <span class="toc-text">聊一聊TCMalloc</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#go%E8%AF%AD%E8%A8%80%E9%87%8C%E9%9D%A2%E7%9A%84%E7%A9%BA%E7%BB%93%E6%9E%84%E4%BD%93%E7%94%A8%E6%9D%A5%E5%81%9A%E4%BB%80%E4%B9%88"><span class="toc-number">11.</span> <span class="toc-text">go语言里面的空结构体用来做什么</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis"><span class="toc-number">12.</span> <span class="toc-text">redis</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%A5%BD%E5%8F%8B%E5%8A%9F%E8%83%BD"><span class="toc-number">12.1.</span> <span class="toc-text">redis 如何实现好友功能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">12.2.</span> <span class="toc-text">redis的持久化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E7%BC%93%E5%AD%98"><span class="toc-number">12.3.</span> <span class="toc-text">redis 缓存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%EF%BC%8C%E5%87%BB%E7%A9%BF%EF%BC%8C%E7%A9%BF%E9%80%8F"><span class="toc-number">12.3.1.</span> <span class="toc-text">什么是缓存雪崩，击穿，穿透</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">12.3.2.</span> <span class="toc-text">数据库和缓存如何保证一致性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81-2%E4%B8%AA%E6%93%8D%E4%BD%9C%E9%83%BD%E8%83%BD%E6%89%A7%E8%A1%8C%E6%88%90%E5%8A%9F%EF%BC%9F"><span class="toc-number">12.3.2.1.</span> <span class="toc-text">如何保证 2个操作都能执行成功？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">12.4.</span> <span class="toc-text">redis的线程模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-%E9%87%87%E7%94%A8%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-number">12.5.</span> <span class="toc-text">Redis 采用单线程为什么还那么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-6-0%E4%B9%8B%E5%90%8E%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%95%E5%85%A5%E4%BA%86%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="toc-number">12.6.</span> <span class="toc-text">Redis 6.0之后为什么引入了多线程？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">12.7.</span> <span class="toc-text">redis的持久化是如何实现的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis%E7%9A%84%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E6%A8%A1%E5%BC%8F"><span class="toc-number">12.8.</span> <span class="toc-text">redis的集群模式模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%9A"><span class="toc-number">12.8.1.</span> <span class="toc-text">主从的实现：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F"><span class="toc-number">12.8.2.</span> <span class="toc-text">哨兵模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E7%89%87%E6%A8%A1%E5%BC%8F"><span class="toc-number">12.8.3.</span> <span class="toc-text">切片模式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E8%84%91%E8%A3%82%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">12.9.</span> <span class="toc-text">集群脑裂导致数据丢失怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0"><span class="toc-number">12.10.</span> <span class="toc-text">Redis过期删除与内存淘汰</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">12.11.</span> <span class="toc-text">Redis数据结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">12.12.</span> <span class="toc-text">五种常见的Redis数据库是怎么实现的？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-%E7%9A%84%E9%94%AE%E5%80%BC%E5%AF%B9%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84"><span class="toc-number">12.12.1.</span> <span class="toc-text">redis 的键值对数据库是怎么实现的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SDS-string%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">12.12.2.</span> <span class="toc-text">SDS  string的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%93%BE%E8%A1%A8"><span class="toc-number">12.12.3.</span> <span class="toc-text">链表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E9%93%BE%E8%A1%A8"><span class="toc-number">12.12.4.</span> <span class="toc-text">压缩链表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E8%A1%A8-1"><span class="toc-number">12.12.5.</span> <span class="toc-text">哈希表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis%E7%9A%84rehash"><span class="toc-number">12.12.6.</span> <span class="toc-text">redis的rehash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%B3%E8%A1%A8"><span class="toc-number">12.12.7.</span> <span class="toc-text">跳表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#quicklist"><span class="toc-number">12.12.8.</span> <span class="toc-text">quicklist</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#listpack"><span class="toc-number">12.12.9.</span> <span class="toc-text">listpack</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">12.13.</span> <span class="toc-text">Redis常见数据类型和应用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#String"><span class="toc-number">12.13.1.</span> <span class="toc-text">String</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#List"><span class="toc-number">12.13.2.</span> <span class="toc-text">List</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hash"><span class="toc-number">12.13.3.</span> <span class="toc-text">Hash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Set"><span class="toc-number">12.13.4.</span> <span class="toc-text">Set</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ZSet"><span class="toc-number">12.13.5.</span> <span class="toc-text">ZSet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BitMap"><span class="toc-number">12.13.6.</span> <span class="toc-text">BitMap</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HyperLogLog"><span class="toc-number">12.13.7.</span> <span class="toc-text">HyperLogLog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GEO"><span class="toc-number">12.13.8.</span> <span class="toc-text">GEO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stream"><span class="toc-number">12.13.9.</span> <span class="toc-text">Stream</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="toc-number">12.14.</span> <span class="toc-text">Redis的过期策略与内存淘汰策略有什么区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E7%9A%84%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5"><span class="toc-number">12.15.</span> <span class="toc-text">Redis的缓存策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E5%AE%9E%E6%88%98"><span class="toc-number">12.16.</span> <span class="toc-text">Redis实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97"><span class="toc-number">12.16.1.</span> <span class="toc-text">Redis如何实现延迟队列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E7%AE%A1%E9%81%93%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">12.16.2.</span> <span class="toc-text">Redis管道有什么作用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F"><span class="toc-number">12.16.3.</span> <span class="toc-text">如何使用Redis实现分布式锁？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">13.</span> <span class="toc-text">计算机网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%84%E5%B1%82%E5%8D%8F%E8%AE%AE%E5%8F%8A%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">13.1.</span> <span class="toc-text">计算机网络的各层协议及作用？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TCP%E5%92%8CUDP%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">13.2.</span> <span class="toc-text">TCP和UDP的区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E4%BA%8BSYN%E6%B4%AA%E6%B3%9B%E6%94%BB%E5%87%BB%EF%BC%9F%E5%A6%82%E4%BD%95%E9%98%B2%E8%8C%83%EF%BC%9F"><span class="toc-number">13.3.</span> <span class="toc-text">什么事SYN洪泛攻击？如何防范？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TCP%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%8F%AF%E9%9D%A0%E6%80%A7%EF%BC%9F"><span class="toc-number">13.4.</span> <span class="toc-text">TCP协议如何保证可靠性？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTTP%E5%B8%B8%E8%A7%81%E7%9A%84%E7%8A%B6%E6%80%81%E7%A0%81%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">13.5.</span> <span class="toc-text">HTTP常见的状态码有哪些？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8A%B6%E6%80%81%E7%A0%81301%E5%92%8C302%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">13.6.</span> <span class="toc-text">状态码301和302的区别是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GET%E8%AF%B7%E6%B1%82%E5%92%8CPOST%E8%AF%B7%E6%B1%82%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">13.7.</span> <span class="toc-text">GET请求和POST请求的区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8BHTTP%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8C%E7%9F%AD%E9%93%BE%E6%8E%A5%EF%BC%9F"><span class="toc-number">13.8.</span> <span class="toc-text">解释一下HTTP长连接和短链接？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTTP%E8%AF%B7%E6%B1%82%E6%8A%A5%E6%96%87%E5%92%8C%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87%E7%9A%84%E6%A0%BC%E5%BC%8F"><span class="toc-number">13.9.</span> <span class="toc-text">HTTP请求报文和响应报文的格式?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BHTTP%E7%BC%93%E5%AD%98"><span class="toc-number">13.10.</span> <span class="toc-text">介绍一下HTTP缓存</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTTP-1-1%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96"><span class="toc-number">13.11.</span> <span class="toc-text">HTTP&#x2F;1.1如何优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTTPS-RSA%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B%EF%BC%9F"><span class="toc-number">13.12.</span> <span class="toc-text">HTTPS RSA握手解析过程？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTTP-1-0-%EF%BC%8CHTTP-1-1-HTTP-2-HTTP-3"><span class="toc-number">13.13.</span> <span class="toc-text">HTTP&#x2F;1.0 ，HTTP&#x2F;1.1 HTTP&#x2F;2 HTTP&#x2F;3</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP-1-1"><span class="toc-number">13.13.1.</span> <span class="toc-text">HTTP&#x2F;1.1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP-2"><span class="toc-number">13.13.2.</span> <span class="toc-text">HTTP&#x2F;2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP-3"><span class="toc-number">13.13.3.</span> <span class="toc-text">HTTP&#x2F;3</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">13.14.</span> <span class="toc-text"></span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP%E5%92%8CHTTPS%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">13.14.1.</span> <span class="toc-text">HTTP和HTTPS的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP1-0%E5%92%8CHTTP1-1%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">13.14.2.</span> <span class="toc-text">HTTP1.0和HTTP1.1的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP1-1%E5%92%8CHTTP2-0%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">13.14.3.</span> <span class="toc-text">HTTP1.1和HTTP2.0的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTPS%E8%A7%A3%E5%86%B3%E4%BA%86HTTP%E7%9A%84%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">13.14.4.</span> <span class="toc-text">HTTPS解决了HTTP的哪些问题？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%88%E4%B8%80%E8%B0%88%E7%BD%91%E5%9D%80%E5%88%B0%E9%A1%B5%E9%9D%A2%E6%98%BE%E7%A4%BA%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">13.15.</span> <span class="toc-text">谈一谈网址到页面显示，期间发生了什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GET-%E4%B8%8E-POST-%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">13.16.</span> <span class="toc-text">GET 与 POST 的区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%88%E8%B0%88HTTP%E5%92%8CHTTPS%E6%9C%89%E5%8C%BA%E5%88%AB"><span class="toc-number">13.17.</span> <span class="toc-text">谈谈HTTP和HTTPS有区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFCookie%E5%92%8CSession%EF%BC%9F"><span class="toc-number">13.18.</span> <span class="toc-text">什么是Cookie和Session？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cookie%E5%92%8CSession%E6%98%AF%E4%BD%95%E5%A6%82%E9%85%8D%E5%90%88%E7%9A%84%E5%91%A2%EF%BC%9F"><span class="toc-number">13.19.</span> <span class="toc-text">Cookie和Session是何如配合的呢？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cookie%E5%92%8CSession%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">13.20.</span> <span class="toc-text">Cookie和Session的区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%80%83%E8%99%91%E5%90%A7%E5%88%86%E5%B8%83%E5%BC%8FSession%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">13.21.</span> <span class="toc-text">如何考虑吧分布式Session问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFDDos%E6%94%BB%E5%87%BB%EF%BC%9F"><span class="toc-number">13.22.</span> <span class="toc-text">什么是DDos攻击？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFXSS%E6%94%BB%E5%87%BB%EF%BC%9F"><span class="toc-number">13.23.</span> <span class="toc-text">什么是XSS攻击？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SQL%E6%B3%A8%E5%85%A5%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%EF%BC%9F"><span class="toc-number">13.24.</span> <span class="toc-text">SQL注入是什么？如何避免？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E4%BA%86HTTP%E5%8D%8F%E8%AE%AE%EF%BC%8C%E8%BF%98%E6%9C%89RPC%E5%8D%8F%E8%AE%AE"><span class="toc-number">13.25.</span> <span class="toc-text">为什么又了HTTP协议，还有RPC协议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFTCP%E5%92%8CTCP%E8%BF%9E%E6%8E%A5"><span class="toc-number">13.26.</span> <span class="toc-text">什么是TCP和TCP连接</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%EF%BC%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B"><span class="toc-number">13.27.</span> <span class="toc-text">为什么三次握手，四次挥手</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8ATCP%E7%9A%84%E9%87%8D%E4%BC%A0%E6%9C%BA%E5%88%B6"><span class="toc-number">13.28.</span> <span class="toc-text">聊一聊TCP的重传机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%A0%E7%9F%A5%E9%81%93%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%90%97%EF%BC%9F"><span class="toc-number">13.29.</span> <span class="toc-text">你知道滑动窗口吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TCP%E5%A6%82%E4%BD%95%E5%81%9A%E7%9A%84-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E5%92%8C%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%EF%BC%9F"><span class="toc-number">13.30.</span> <span class="toc-text">TCP如何做的 流量控制和拥塞控制？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#IP"><span class="toc-number">13.31.</span> <span class="toc-text">IP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#IP%E5%8D%8F%E8%AE%AE%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF"><span class="toc-number">13.31.1.</span> <span class="toc-text">IP协议相关技术</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#DNS-%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90"><span class="toc-number">13.31.1.1.</span> <span class="toc-text">DNS 域名解析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DHCP-%E5%8D%8F%E8%AE%AE"><span class="toc-number">13.31.1.2.</span> <span class="toc-text">DHCP 协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NAT-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2NAT"><span class="toc-number">13.31.1.3.</span> <span class="toc-text">NAT  网络地址转换NAT</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ICMP%E5%8D%8F%E8%AE%AE-%E4%BA%92%E8%81%94%E7%BD%91%E6%8E%A7%E5%88%B6%E6%8A%A5%E6%96%87%E5%8D%8F%E8%AE%AE"><span class="toc-number">13.31.1.4.</span> <span class="toc-text">ICMP协议 互联网控制报文协议</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E5%AF%B9%E8%B7%A8%E5%9F%9F%E7%9A%84%E7%9C%8B%E6%B3%95%E3%80%82CORS"><span class="toc-number">13.32.</span> <span class="toc-text">聊一聊你对跨域的看法。CORS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E8%AF%B7%E6%B1%82"><span class="toc-number">13.32.1.</span> <span class="toc-text">简单请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E7%AE%80%E5%8D%95%E8%AF%B7%E6%B1%82"><span class="toc-number">13.32.2.</span> <span class="toc-text">非简单请求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%A3%80%E8%AF%B7%E6%B1%82"><span class="toc-number">13.32.2.1.</span> <span class="toc-text">预检请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%A3%80%E8%AF%B7%E6%B1%82%E7%9A%84%E5%9B%9E%E5%BA%94"><span class="toc-number">13.32.2.2.</span> <span class="toc-text">预检请求的回应</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E6%AD%A3%E7%A1%AE%E8%AF%B7%E6%B1%82%E5%92%8C%E5%9B%9E%E5%BA%94"><span class="toc-number">13.32.2.3.</span> <span class="toc-text">浏览器的正确请求和回应</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MySQL"><span class="toc-number">14.</span> <span class="toc-text">MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C-select-%E8%AF%AD%E5%8F%A5%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88"><span class="toc-number">14.1.</span> <span class="toc-text">执行 select 语句发生了什么</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%99%A8"><span class="toc-number">14.1.1.</span> <span class="toc-text">第一步：连接器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98"><span class="toc-number">14.1.2.</span> <span class="toc-text">第二步：查询缓存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E8%A7%A3%E6%9E%90SQL%E2%80%93%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="toc-number">14.1.3.</span> <span class="toc-text">第三步：解析SQL–解析器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E6%89%A7%E8%A1%8CSQL%E8%AF%AD%E5%8F%A5"><span class="toc-number">14.1.4.</span> <span class="toc-text">第四步：执行SQL语句</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL%E7%9A%84%E4%B8%80%E8%A1%8C%E8%AE%B0%E5%BD%95%E6%97%B6%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E7%9A%84%EF%BC%9F"><span class="toc-number">14.2.</span> <span class="toc-text">MySQL的一行记录时如何存储的？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E5%9C%A8%E5%93%AA%E4%B8%AA%E6%96%87%E4%BB%B6%EF%BC%9F"><span class="toc-number">14.2.1.</span> <span class="toc-text">MySQL的数据存放在哪个文件？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#-1"><span class="toc-number">14.2.2.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A8%E7%A9%BA%E9%97%B4%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%93%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84%E5%91%A2%EF%BC%9F"><span class="toc-number">14.2.3.</span> <span class="toc-text">表空间文件的结构是怎么样的呢？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E8%A1%8C%EF%BC%88row%EF%BC%89"><span class="toc-number">14.2.3.1.</span> <span class="toc-text">1、行（row）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E9%A1%B5%EF%BC%88page%EF%BC%89"><span class="toc-number">14.2.3.2.</span> <span class="toc-text">2、页（page）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E3%80%81%E5%8C%BA%EF%BC%88extent%EF%BC%89"><span class="toc-number">14.2.3.3.</span> <span class="toc-text">3、区（extent）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E3%80%81%E6%AE%B5%EF%BC%88segment%EF%BC%89"><span class="toc-number">14.2.3.4.</span> <span class="toc-text">4、段（segment）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#InnoDB-%E8%A1%8C%E6%A0%BC%E5%BC%8F%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">14.2.4.</span> <span class="toc-text">InnoDB 行格式有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Compact%E8%A1%8C%E6%A0%BC%E5%BC%8F%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%91%A2%EF%BC%9F"><span class="toc-number">14.2.5.</span> <span class="toc-text">Compact行格式长什么样呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%8C%E6%BA%A2%E5%87%BA%E5%90%8E%EF%BC%8CMySQL%E6%98%AF%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%E7%9A%84%EF%BC%9F"><span class="toc-number">14.2.6.</span> <span class="toc-text">行溢出后，MySQL是怎么处理的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">14.2.7.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95"><span class="toc-number">14.3.</span> <span class="toc-text">索引</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">14.3.1.</span> <span class="toc-text">什么是索引？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">14.3.2.</span> <span class="toc-text">索引的分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#B-%E6%A0%91%EF%BC%9F"><span class="toc-number">14.4.</span> <span class="toc-text">B+树？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#InnoDB%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E7%9A%84%EF%BC%9F"><span class="toc-number">14.4.1.</span> <span class="toc-text">InnoDB是如何存储数据的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E6%A0%91%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%9F%A5%E8%AF%A2%E7%9A%84%E5%91%A2%EF%BC%9F"><span class="toc-number">14.4.2.</span> <span class="toc-text">B+树是如何进行查询的呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%87%E7%94%A8B-%E6%A0%91%E4%BD%9C%E4%B8%BA%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">14.4.3.</span> <span class="toc-text">MySQL为什么采用B+树作为索引？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1"><span class="toc-number">14.5.</span> <span class="toc-text">事务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">14.5.1.</span> <span class="toc-text">事务隔离级别是如何实现的？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7%E5%91%A2%EF%BC%9F"><span class="toc-number">14.5.1.1.</span> <span class="toc-text">事务有哪些特性呢？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">14.5.1.2.</span> <span class="toc-text">事务隔离级别有哪些？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-number">14.5.2.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%94%81"><span class="toc-number">14.6.</span> <span class="toc-text">锁</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E9%94%81"><span class="toc-number">14.6.1.</span> <span class="toc-text">全局锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A8%E7%BA%A7%E9%94%81"><span class="toc-number">14.6.2.</span> <span class="toc-text">表级锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%8C%E9%94%81"><span class="toc-number">14.6.3.</span> <span class="toc-text">行锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%B7%E9%94%81%E7%9A%84"><span class="toc-number">14.6.4.</span> <span class="toc-text">MySQL是如何枷锁的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E6%AD%BB%E9%94%81%E4%BA%86%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">14.6.5.</span> <span class="toc-text">MySQL死锁了该怎么办？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A5%E5%BF%97"><span class="toc-number">14.7.</span> <span class="toc-text">日志</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undo-log"><span class="toc-number">14.7.1.</span> <span class="toc-text">undo log</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redo-log"><span class="toc-number">14.7.2.</span> <span class="toc-text">redo log</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#binlog"><span class="toc-number">14.7.3.</span> <span class="toc-text">binlog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#buffer-pool"><span class="toc-number">14.7.4.</span> <span class="toc-text">buffer pool</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">14.7.5.</span> <span class="toc-text">主从复制的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Update%E8%BF%87%E7%A8%8B%E7%A7%8D%E4%B8%89%E4%B8%AA%E6%97%A5%E5%BF%97"><span class="toc-number">14.7.6.</span> <span class="toc-text">Update过程种三个日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E4%B8%A4%E6%AE%B5%E6%8F%90%E4%BA%A4%EF%BC%9F2PC"><span class="toc-number">14.7.7.</span> <span class="toc-text">为什么需要两段提交？2PC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">14.7.8.</span> <span class="toc-text">两段提交的过程是怎样的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E9%87%8D%E5%90%AF%E4%BC%9A%E5%87%BA%E7%8E%B0%E4%BB%80%E4%B9%88%E7%8E%B0%E8%B1%A1%EF%BC%9F-2%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="toc-number">14.7.9.</span> <span class="toc-text">异常重启会出现什么现象？ 2段提交</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E6%AE%B5%E6%8F%90%E4%BA%A4%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">14.7.10.</span> <span class="toc-text">两段提交有什么问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%8F%E5%B0%91%E7%A3%81%E7%9B%98IO%E6%AC%A1%E6%95%B0%E7%9A%84-%E7%BB%84%E6%8F%90%E4%BA%A4"><span class="toc-number">14.7.11.</span> <span class="toc-text">减少磁盘IO次数的 组提交</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E7%A3%81%E7%9B%98I-O-%E5%BE%88%E9%AB%98%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8C%96%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-number">14.7.12.</span> <span class="toc-text">MySQL磁盘I&#x2F;O 很高，有什么优化的方法？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E6%9D%A1Update%E8%AF%AD%E5%8F%A5%E6%B5%81%E7%A8%8B"><span class="toc-number">14.8.</span> <span class="toc-text">一条Update语句流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#explain%E5%90%84%E4%B8%AA%E5%AD%97%E6%AE%B5%E7%9A%84%E6%84%8F%E6%80%9D"><span class="toc-number">14.9.</span> <span class="toc-text">explain各个字段的意思</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84grpc"><span class="toc-number">15.</span> <span class="toc-text">聊一聊项目中用到的grpc</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F"><span class="toc-number">16.</span> <span class="toc-text">分布式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CAP%E7%90%86%E8%AE%BA"><span class="toc-number">16.1.</span> <span class="toc-text">CAP理论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">16.2.</span> <span class="toc-text">分布式锁的使用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%92%8C3%E7%AB%AF%E6%8F%90%E4%BA%A4%E4%BB%A5%E5%8F%8A-TTC"><span class="toc-number">16.3.</span> <span class="toc-text">2段提交和3端提交以及 TTC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Raft%E7%AE%97%E6%B3%95%E5%92%8CPaxos%E5%85%B1%E8%AF%86%E6%80%A7%E7%AE%97%E6%B3%95%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="toc-number">16.4.</span> <span class="toc-text">Raft算法和Paxos共识性算法的步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7Hash%E7%AE%97%E6%B3%95"><span class="toc-number">16.5.</span> <span class="toc-text">一致性Hash算法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="toc-number">17.</span> <span class="toc-text">操作系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">17.1.</span> <span class="toc-text">CPU缓存一致性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="toc-number">17.2.</span> <span class="toc-text">CPU如何选择线程？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%BD%AF%E4%B8%AD%E6%96%AD"><span class="toc-number">17.3.</span> <span class="toc-text">什么是软中断</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98"><span class="toc-number">17.4.</span> <span class="toc-text">聊一聊虚拟内存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%AE%9E%E6%A8%A1%E5%BC%8F"><span class="toc-number">17.4.1.</span> <span class="toc-text">操作系统的保护模式和实模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%EF%BC%8C%E5%AE%83%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E5%A4%A7%E6%A6%82%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90%E7%9A%84%EF%BC%9F"><span class="toc-number">17.4.2.</span> <span class="toc-text">虚拟内存，它的内存布局大概是什么样子的？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B"><span class="toc-number">17.5.</span> <span class="toc-text">聊一聊进程和线程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B4%E4%B8%80%E8%AF%B4%E5%B8%B8%E8%A7%81%E7%9A%84%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="toc-number">17.6.</span> <span class="toc-text">说一说常见的调度算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E5%BC%8F%E5%91%A2%EF%BC%9F"><span class="toc-number">17.7.</span> <span class="toc-text">进程间的通信有哪些方式呢？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81%EF%BC%9F"><span class="toc-number">17.8.</span> <span class="toc-text">怎么避免死锁？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F"><span class="toc-number">17.9.</span> <span class="toc-text">网络系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%90%8C%E6%AD%A5%EF%BC%8C%E5%BC%82%E6%AD%A5%EF%BC%8C%E9%98%BB%E5%A1%9E%EF%BC%8C%E9%9D%9E%E9%98%BB%E5%A1%9E"><span class="toc-number">17.9.1.</span> <span class="toc-text">什么是同步，异步，阻塞，非阻塞</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="toc-number">17.9.2.</span> <span class="toc-text">什么是零拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%EF%BC%9A-select-poll-epoll"><span class="toc-number">17.9.3.</span> <span class="toc-text">I&#x2F;O多路复用： select&#x2F;poll&#x2F;epoll</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reactor%E5%92%8CProactor"><span class="toc-number">17.10.</span> <span class="toc-text">Reactor和Proactor</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C"><span class="toc-number">17.11.</span> <span class="toc-text">什么是一致性哈希</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MQ%E7%B3%BB%E5%88%97"><span class="toc-number">18.</span> <span class="toc-text">MQ系列</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#KafKa"><span class="toc-number">18.1.</span> <span class="toc-text">KafKa</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E7%9A%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">18.1.1.</span> <span class="toc-text">KafKa的设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E6%80%A7%E8%83%BD%E9%AB%98%E5%8E%9F%E5%9B%A0"><span class="toc-number">18.1.2.</span> <span class="toc-text">KafKa性能高原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E6%96%87%E4%BB%B6%E9%AB%98%E6%95%88%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86"><span class="toc-number">18.1.3.</span> <span class="toc-text">KafKa文件高效存储设计原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">18.1.4.</span> <span class="toc-text">KafKa的优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">18.1.5.</span> <span class="toc-text">KafKa的应用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%8A%8A%E6%B6%88%E6%81%AF%E5%88%86%E5%8C%BA"><span class="toc-number">18.1.6.</span> <span class="toc-text">KafKa为什么要把消息分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E6%B6%88%E6%81%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F"><span class="toc-number">18.1.7.</span> <span class="toc-text">KafKa消息的消费模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-number">18.1.8.</span> <span class="toc-text">KafKa如何实现负载均衡和故障转移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafKa%E4%B8%ADZookeeoer%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">18.1.9.</span> <span class="toc-text">KafKa中Zookeeoer的作用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#asynq"><span class="toc-number">18.2.</span> <span class="toc-text">asynq</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RocketMq"><span class="toc-number">18.3.</span> <span class="toc-text">RocketMq</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8NameServer%E8%80%8C%E4%B8%8D%E6%98%AFZK"><span class="toc-number">18.3.1.</span> <span class="toc-text">为什么使用NameServer而不是ZK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RocketMq%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="toc-number">18.3.2.</span> <span class="toc-text">RocketMq如何防止消息丢失？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RocketMq%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F%EF%BC%9F"><span class="toc-number">18.3.3.</span> <span class="toc-text">RocketMq如何保证消息有序？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RocketMq%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF"><span class="toc-number">18.3.4.</span> <span class="toc-text">RocketMq如何实现延迟消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E6%98%AFpush%E8%BF%98%E6%98%AFpull"><span class="toc-number">18.3.5.</span> <span class="toc-text">消费消息是push还是pull</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RocketMq%E5%A6%82%E4%BD%95%E5%AF%B9%E6%B6%88%E6%81%AF%E5%8E%BB%E9%87%8D"><span class="toc-number">18.3.6.</span> <span class="toc-text">RocketMq如何对消息去重</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95"><span class="toc-number">19.</span> <span class="toc-text">常见限流算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BA%E5%AE%9A%E7%AA%97%E5%8F%A3%EF%BC%88%E7%AA%97%E5%8F%A3%E8%AE%A1%E6%95%B0%E6%B3%95%EF%BC%89"><span class="toc-number">19.1.</span> <span class="toc-text">固定窗口（窗口计数法）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="toc-number">19.2.</span> <span class="toc-text">滑动窗口</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95"><span class="toc-number">19.3.</span> <span class="toc-text">漏桶算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95"><span class="toc-number">19.4.</span> <span class="toc-text">令牌桶算法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#go-zero%E7%9B%B8%E5%85%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">20.</span> <span class="toc-text">go-zero相关的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#DTM%E7%9A%84TTC"><span class="toc-number">20.1.</span> <span class="toc-text">DTM的TTC</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E7%BB%8F"><span class="toc-number">21.</span> <span class="toc-text">微服务面经</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#RPC%E5%92%8CHTTP"><span class="toc-number">21.1.</span> <span class="toc-text">RPC和HTTP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RPC%E5%8E%9F%E7%90%86"><span class="toc-number">21.1.1.</span> <span class="toc-text">RPC原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E8%A1%8C%E7%9A%84RPC%E6%A1%86%E6%9E%B6"><span class="toc-number">21.1.2.</span> <span class="toc-text">流行的RPC框架</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9D%A2%E7%BB%8F%E5%88%86%E4%BA%AB"><span class="toc-number">22.</span> <span class="toc-text">面经分享</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%97%E8%8A%82%E4%BA%8C%E9%9D%A2"><span class="toc-number">22.1.</span> <span class="toc-text">字节二面</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A5%87%E6%80%AA%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">23.</span> <span class="toc-text">奇怪的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%B8%80%E8%88%AC%E6%BA%A2%E5%87%BA%E7%9A%84%E5%A4%84%E7%90%86%EF%BC%9F%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%E7%9A%84%EF%BC%9F"><span class="toc-number">23.1.</span> <span class="toc-text">在程序中一般溢出的处理？数据怎么存储的？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%B1%BB%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">24.</span> <span class="toc-text">系统设计类的问题？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AD%94%E9%A2%98%E6%80%9D%E8%B7%AF%EF%BC%9A"><span class="toc-number">24.1.</span> <span class="toc-text">系统设计答题思路：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%AD%E9%93%BE%E8%B7%AF%E7%B3%BB%E7%BB%9F"><span class="toc-number">24.2.</span> <span class="toc-text">短链路系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F"><span class="toc-number">24.3.</span> <span class="toc-text">设计秒杀系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9E%AC%E9%97%B4%E9%AB%98%E5%B9%B6%E5%8F%91%EF%BC%9A"><span class="toc-number">24.3.1.</span> <span class="toc-text">瞬间高并发：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B5%E9%9D%A2%E9%9D%99%E6%80%81%E5%8C%96"><span class="toc-number">24.3.2.</span> <span class="toc-text">页面静态化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A7%92%E6%9D%80%E6%8C%89%E9%92%AE"><span class="toc-number">24.3.3.</span> <span class="toc-text">秒杀按钮</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%A4%9A%E5%86%99%E5%B0%91"><span class="toc-number">24.3.4.</span> <span class="toc-text">读多写少</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98"><span class="toc-number">24.3.5.</span> <span class="toc-text">缓存问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%93%E5%AD%98%E9%97%AE%E9%A2%98"><span class="toc-number">24.3.6.</span> <span class="toc-text">库存问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">24.3.7.</span> <span class="toc-text">分布式锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mq%E5%BC%82%E6%AD%A5"><span class="toc-number">24.3.8.</span> <span class="toc-text">mq异步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%99%90%E6%B5%81%EF%BC%9F"><span class="toc-number">24.3.9.</span> <span class="toc-text">如何限流？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gee%E5%AE%9E%E7%8E%B0web%E6%A1%86%E6%9E%B6"><span class="toc-number">24.4.</span> <span class="toc-text">Gee实现web框架</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/03/Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%B3%BB%E5%88%970/" title="Redis源码阅读0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=3ce8ed58-ae54-a4f2-9fe5-8fa6ead0edf5" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis源码阅读0"/></a><div class="content"><a class="title" href="/2024/04/03/Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%B3%BB%E5%88%970/" title="Redis源码阅读0">Redis源码阅读0</a><time datetime="2024-04-03T11:28:35.403Z" title="发表于 2024-04-03 11:28:35">2024-04-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/01/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/" title="内网穿透"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover7.jpg?_r_=a026381a-bbf2-4738-be23-8ec53a89e5e8" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="内网穿透"/></a><div class="content"><a class="title" href="/2024/04/01/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/" title="内网穿透">内网穿透</a><time datetime="2024-04-01T10:48:41.000Z" title="发表于 2024-04-01 10:48:41">2024-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/31/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-WBS/" title="项目管理--WBS"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover.jpg?_r_=00ec53fb-27e9-37e6-44a6-eb449f00602c" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="项目管理--WBS"/></a><div class="content"><a class="title" href="/2024/03/31/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-WBS/" title="项目管理--WBS">项目管理--WBS</a><time datetime="2024-03-31T11:30:00.000Z" title="发表于 2024-03-31 11:30:00">2024-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/30/Go%E9%9D%A2%E8%AF%95/" title="Golang面经"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover6.jpg?_r_=51754bf9-ed78-4d2b-fbe8-4e9699cf5ca3" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Golang面经"/></a><div class="content"><a class="title" href="/2024/03/30/Go%E9%9D%A2%E8%AF%95/" title="Golang面经">Golang面经</a><time datetime="2024-03-30T13:49:49.000Z" title="发表于 2024-03-30 13:49:49">2024-03-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/29/%E5%8D%8E%E4%B8%BA%E4%B8%8A%E6%9C%BA%E8%80%83%E8%AF%95%E5%87%86%E5%A4%87/" title="华为上机考试"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Kiritoabc/my_cdn/img/cover7.jpg?_r_=2415063d-3e17-ad22-02ab-672e54533241" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="华为上机考试"/></a><div class="content"><a class="title" href="/2024/03/29/%E5%8D%8E%E4%B8%BA%E4%B8%8A%E6%9C%BA%E8%80%83%E8%AF%95%E5%87%86%E5%A4%87/" title="华为上机考试">华为上机考试</a><time datetime="2024-03-29T00:00:00.000Z" title="发表于 2024-03-29 00:00:00">2024-03-29</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="workboard"><div id="runtimeTextTip"></div></div></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2020 - 2024 By <a class="footer-bar-link" href="/" title="菠萝" target="_blank">菠萝</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">11</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://Kiritoabc.github.io" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/UML/" style="font-size: 0.88rem;">UML<sup>1</sup></a><a href="/tags/WBS/" style="font-size: 0.88rem;">WBS<sup>1</sup></a><a href="/tags/go/" style="font-size: 0.88rem;">go<sup>3</sup></a><a href="/tags/redis/" style="font-size: 0.88rem;">redis<sup>3</sup></a><a href="/tags/sql/" style="font-size: 0.88rem;">sql<sup>1</sup></a><a href="/tags/why-what-how/" style="font-size: 0.88rem;">why? what? how?<sup>1</sup></a><a href="/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" style="font-size: 0.88rem;">中间件<sup>2</sup></a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="font-size: 0.88rem;">云原生<sup>2</sup></a><a href="/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 0.88rem;">前端开发小技巧<sup>3</sup></a><a href="/tags/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/" style="font-size: 0.88rem;">前端知识<sup>1</sup></a><a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 0.88rem;">博客<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size: 0.88rem;">后端<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AFGo/" style="font-size: 0.88rem;">后端Go<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AFgo/" style="font-size: 0.88rem;">后端go<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 0.88rem;">后端开发小技巧<sup>5</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86/" style="font-size: 0.88rem;">后端开发知识<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/" style="font-size: 0.88rem;">后端知识<sup>4</sup></a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9F%A5%E8%AF%86/" style="font-size: 0.88rem;">大数据知识<sup>1</sup></a><a href="/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" style="font-size: 0.88rem;">学习记录<sup>1</sup></a><a href="/tags/%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/" style="font-size: 0.88rem;">安卓开发<sup>1</sup></a><a href="/tags/%E6%9C%BA%E8%80%83/" style="font-size: 0.88rem;">机考<sup>1</sup></a><a href="/tags/%E6%B5%8B%E8%AF%95/" style="font-size: 0.88rem;">测试<sup>2</sup></a><a href="/tags/%E6%B5%8B%E8%AF%95%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 0.88rem;">测试小技巧<sup>1</sup></a><a href="/tags/%E7%AE%80%E5%8E%86%E5%88%B6%E4%BD%9C/" style="font-size: 0.88rem;">简历制作<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 0.88rem;">计网<sup>1</sup></a><a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 0.88rem;">设计模式<sup>1</sup></a><a href="/tags/%E9%9D%A2%E7%BB%8F/" style="font-size: 0.88rem;">面经<sup>2</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 0.88rem;">面试<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("10/01/2023 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2020 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 菠萝 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("10/01/2023 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      if (img != null) {
        img.src = "";
        img.title = "";
        img.alt = "";
      }

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>