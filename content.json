{"meta":{"title":"牵风散步の雲","subtitle":"","description":"","author":"菠萝","url":"https://Kiritoabc.github.io","root":"/"},"pages":[{"title":"四大皆空","date":"2024-03-18T09:39:39.130Z","updated":"2024-03-18T09:39:39.130Z","comments":true,"path":"/404.html","permalink":"https://kiritoabc.github.io/404.html","excerpt":"","text":""},{"title":"about","date":"2023-10-12T19:08:00.000Z","updated":"2024-03-18T09:39:39.198Z","comments":false,"path":"about/index.html","permalink":"https://kiritoabc.github.io/about/index.html","excerpt":"我是谁？ 自我介绍环节 你不需要一开始很厉害，你需要开始才能很厉害！","text":"我是谁？ 自我介绍环节 你不需要一开始很厉害，你需要开始才能很厉害！ 是名大学生 loving life &amp; loving coding 在为找工作努力学习ing 主要技术栈：golang 邮箱:2493381254@qq.com 是一名旅行者哦(心海加公子双厨)"},{"title":"analytics","date":"2023-12-26T14:58:15.000Z","updated":"2024-03-18T09:39:39.198Z","comments":false,"path":"analytics/index.html","permalink":"https://kiritoabc.github.io/analytics/index.html","excerpt":"","text":""},{"title":"分类","date":"2023-10-12T19:07:48.000Z","updated":"2024-03-18T09:39:39.198Z","comments":true,"path":"categories/index.html","permalink":"https://kiritoabc.github.io/categories/index.html","excerpt":"","text":""},{"title":"可爱的女孩子","date":"2023-10-12T19:11:56.000Z","updated":"2024-03-18T09:39:39.198Z","comments":true,"path":"girls/index.html","permalink":"https://kiritoabc.github.io/girls/index.html","excerpt":"","text":""},{"title":"留言板","date":"2024-01-13T01:07:52.000Z","updated":"2024-03-18T09:39:39.198Z","comments":true,"path":"conmment/index.html","permalink":"https://kiritoabc.github.io/conmment/index.html","excerpt":"","text":"有什么想说的? 有什么想问的?"},{"title":"我的小伙伴们","date":"2023-10-12T19:09:50.000Z","updated":"2024-03-18T09:39:39.202Z","comments":true,"path":"links/index.html","permalink":"https://kiritoabc.github.io/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-12-26T14:58:15.000Z","updated":"2024-03-18T09:39:39.202Z","comments":false,"path":"tags/index.html","permalink":"https://kiritoabc.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"设计模式","slug":"设计模式","date":"2024-03-18T09:39:39.198Z","updated":"2024-03-18T09:39:39.198Z","comments":true,"path":"2024/03/18/设计模式/","permalink":"https://kiritoabc.github.io/2024/03/18/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 今日设计模式——责任链模式","text":"设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 今日设计模式——责任链模式 责任链模式 责任链模式是一种行为设计模式，允许你将请求沿着处理者链进行发送。收到请求后，每个处理者均可对请求进行处理，或将其传递给链上的下个处理者。 模型说明 Handler：声明了所有具体处理者的通用接口。该接口通常仅包含单个方法用于请求处理，但有时其还包含一个设置链上下个处理者的方法。 BaseHandler：是一个可选的类，你可以将所有处理者共用的样本代码放置在其中。 通常情况下，该类中定义了一个保存对于下个处理者引用的成员变量。客户端可通过将处理者传递给上个处理者的构造函数或设定方法来创建链。该类还可以实现默认的处理行为：确定下个处理者存在后再将请求传递给它。 ConcreteHandlers：包含处理请求的实际代码。每个处理者接收到请求后，都必须决定是否进行处理，以及是否沿着链传递请求。 处理者通常是独立且不可变的，需要通过构造函数一次性地获得所有必要的数据。 Client：可根据程序逻辑一次性或者动态地生成链。值得注意的是，请求可发送给脸上的任意一个处理者，而非必须是第一个处理者 优缺点优点 1、降低耦合度。它将请求的发送者和接收者解耦。 2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 4、增加新的请求处理类很方便。 缺点 1、不能保证请求一定被接收。 2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 3、可能不容易观察运行时的特征，有碍于除错。 使用场景 当程序需要使用不同方式处理不同种类请求， 而且请求类型和顺序预先未知时， 可以使用责任链模式。 当必须按顺序执行多个处理者时， 可以使用该模式。 如果所需处理者及其顺序必须在运行时进行改变， 可以使用责任链模式。 案例看一个医院应用的责任链模式例子：病人来访时， 他们首先都会去前台， 然后是看医生、 取药， 最后结账。 去前台 看医生 取药 结账 定义病人 patient.go package patient // patient.go 病人 type Patient struct { Name string RegistrationDone bool // 1.去前台 DoctorCheckUpDone bool // 2.看医生 MedicineDone bool // 3.取药 PaymentDone bool // 4.结账 } 定义department.go 处理者接口 package department import \"sj-learn/zrl/patient\" // department.go 处理者接口 医院部门 type Department interface { Execute(*patient.Patient) SetNext(Department) } reception.go 具体处理者 package reception import ( \"fmt\" \"sj-learn/zrl/department\" \"sj-learn/zrl/patient\" ) // reception.go 具体处理者 (前台接待patient) type Reception struct { next department.Department } func (r *Reception) Execute(p *patient.Patient) { if p.RegistrationDone { fmt.Println(\"Patient registration already done\") r.next.Execute(p) return } fmt.Println(\"Reception registering patient\") p.RegistrationDone = true r.next.Execute(p) } func (r *Reception) SetNext(next department.Department) { r.next = next } doctor.go 具体处理者 package doctor import ( \"fmt\" \"sj-learn/zrl/department\" \"sj-learn/zrl/patient\" ) type Doctor struct { next department.Department } func (d *Doctor) Execute(p *patient.Patient) { if p.DoctorCheckUpDone { fmt.Println(\"Doctor checkup already done\") d.next.Execute(p) return } fmt.Println(\"Doctor checking patient\") p.DoctorCheckUpDone = true d.next.Execute(p) } func (d *Doctor) SetNext(next department.Department) { d.next = next } medical.go 具体处理者 package medical import ( \"fmt\" \"sj-learn/zrl/department\" \"sj-learn/zrl/patient\" ) // medical.go 具体处理者 type Medical struct { next department.Department } func (m *Medical) Execute(p *patient.Patient) { if p.MedicineDone { fmt.Println(\"Medicine already given to patient\") m.next.Execute(p) return } fmt.Println(\"Medical giving medicine to patient\") p.MedicineDone = true m.next.Execute(p) } func (m *Medical) SetNext(next department.Department) { m.next = next } cashier.go 具体处理者 package cashier import ( \"fmt\" \"sj-learn/zrl/department\" \"sj-learn/zrl/patient\" ) type Cashier struct { next department.Department } func (c *Cashier) Execute(p *patient.Patient) { if p.PaymentDone { fmt.Println(\"Payment Done\") } fmt.Println(\"Cashier getting money from patient patient\") } func (c *Cashier) SetNext(next department.Department) { c.next = next } main.go package main import ( \"sj-learn/zrl/cashier\" \"sj-learn/zrl/doctor\" \"sj-learn/zrl/medical\" \"sj-learn/zrl/patient\" \"sj-learn/zrl/reception\" ) func main() { cashier := &amp;cashier.Cashier{} //Set next for medical department medical := &amp;medical.Medical{} medical.SetNext(cashier) //Set next for doctor department doctor := &amp;doctor.Doctor{} doctor.SetNext(medical) //Set next for reception department reception := &amp;reception.Reception{} reception.SetNext(doctor) patient := &amp;patient.Patient{Name: \"张三\"} //Patient visiting reception.Execute(patient) } 结果： Reception registering patient Doctor checking patient Medical giving medicine to patient Cashier getting money from patient patient","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kiritoabc.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://kiritoabc.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"菠萝"},{"title":"软件测试--测试用例设计方法","slug":"软件测试","date":"2024-03-18T09:39:39.198Z","updated":"2024-03-18T09:39:39.198Z","comments":true,"path":"2024/03/18/软件测试/","permalink":"https://kiritoabc.github.io/2024/03/18/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/","excerpt":"一 等价类划分定义：依据需求将输入划分成若干个等价类，从等价类中选定一个测试用例，如果该用例通过，则表明整个等价类通过。 适用范围：适用于有无限多种输入。 目的：使用较少的测试用例尽可能多的将功能覆盖。 有效等价类：有意义的输入构成的集合，对需求规格说明书来说是合法的。 无效等价类：不满足需求的输入。","text":"一 等价类划分定义：依据需求将输入划分成若干个等价类，从等价类中选定一个测试用例，如果该用例通过，则表明整个等价类通过。 适用范围：适用于有无限多种输入。 目的：使用较少的测试用例尽可能多的将功能覆盖。 有效等价类：有意义的输入构成的集合，对需求规格说明书来说是合法的。 无效等价类：不满足需求的输入。 例如：学生成绩录入系统，分数X为0到100的整数。 有效等价类：0≤X≤100（50） 无效等价类：X≤0（-5），X≥100（200） 如果没有整数要求，还要考虑小数，非数字（字母，汉字，特殊字符）和空值。 但只按照等价类划分还不够，还要考虑边界值。 二 边界值分析法边界值分析法是对等价类划分法的补充，一般从等价类的边界寻找错误。 边界值分析法的基本思路： 正好等于边界值，刚好小于边界值，刚好大于边界值作为测试数据。 特殊：0/空是特殊的值，在考虑边界值的时候也要考虑这个特殊值。 边界值思想的体现：网上购物，库存12。 数量=11：下单成功；数量=12：下单成功；数量=13：下单失败，并给出提示。 例如：学生成绩录入系统，分数X为0到100的整数。 上边界：99，100，101 下边界：-1，0，1 所以等价类+边界值的取值范围为：-5，-1，0，1，50，99，100，101，200 因此可分成两个用例：有效输入：0，1，50，99，100；无效输入：-5，-1，101，200。 再例如：微信红包，最小0.01，最大200。 等价类+边界值的取值范围：-100.00，0，0.01，0.02，50.00，199.99，200，200.01，300.00。","categories":[{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/tags/%E6%B5%8B%E8%AF%95/"}],"author":"菠萝"},{"title":"认证授权","slug":"认证授权","date":"2024-03-18T09:39:39.190Z","updated":"2024-03-18T09:39:39.190Z","comments":true,"path":"2024/03/18/认证授权/","permalink":"https://kiritoabc.github.io/2024/03/18/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/","excerpt":"认证授权基础概念详解 认证和授权的区别是什么？这是一个绝大多数人都会混淆的问题。首先先从读音上来认识这两个名词，很多人都会把它俩的读音搞混，所以我建议你先先去查一查这两个单词到底该怎么读，他们的具体含义是什么。 说简单点就是： 认证 (Authentication)： 你是谁。 授权 (Authorization)： 你有权限干什么。","text":"认证授权基础概念详解 认证和授权的区别是什么？这是一个绝大多数人都会混淆的问题。首先先从读音上来认识这两个名词，很多人都会把它俩的读音搞混，所以我建议你先先去查一查这两个单词到底该怎么读，他们的具体含义是什么。 说简单点就是： 认证 (Authentication)： 你是谁。 授权 (Authorization)： 你有权限干什么。 稍微正式点（啰嗦点）的说法就是： Authentication（认证） 是验证您的身份的凭据（例如用户名/用户 ID 和密码），通过这个凭据，系统得以知道你就是你，也就是说系统存在你这个用户。所以，Authentication 被称为身份/用户验证。 Authorization（授权） 发生在 Authentication（认证） 之后。授权嘛，光看意思大家应该就明白，它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如 admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。 认证: 授权: 这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。 RBAC 模型了解吗？系统权限控制最常采用的访问控制模型就是 RBAC 模型 。 什么是 RBAC 呢？ RBAC 即基于角色的权限访问控制（Role-Based Access Control）。这是一种通过角色关联权限，角色同时又关联用户的授权的方式。 简单地说：一个用户可以拥有若干角色，每一个角色又可以被分配若干权限，这样就构造成“用户-角色-权限” 的授权模型。在这种模型中，用户与角色、角色与权限之间构成了多对多的关系，如下图 在 RBAC 中，权限与角色相关联，用户通过成为适当角色的成员而得到这些角色的权限。这就极大地简化了权限的管理。 本系统的权限设计相关的表如下（一共 5 张表，2 张用户建立表之间的联系）： 通过这个权限模型，我们可以创建不同的角色并为不同的角色分配不同的权限范围（菜单）。 通常来说，如果系统对于权限控制要求比较严格的话，一般都会选择使用 RBAC 模型来做权限控制。 什么是Cookie？Cookie的作用是什么？ Cookie 和 Session 都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。 维基百科是这样定义 Cookie 的： Cookies 是某些网站为了辨别用户身份而储存在用户本地终端上的数据（通常经过加密）。 简单来说：Cookie 存放在客户端，一般用来保存用户信息。 下面是 Cookie 的一些应用案例： 我们在 Cookie 中保存已经登录过的用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了。除此之外，Cookie 还能保存用户首选项，主题和其他设置信息。 使用 Cookie 保存 SessionId 或者 Token ，向后端发送请求的时候带上 Cookie，这样后端就能取到 Session 或者 Token 了。这样就能记录用户当前的状态了，因为 HTTP 协议是无状态的。 Cookie 还可以用来记录和分析用户行为。举个简单的例子你在网上购物的时候，因为 HTTP 协议是没有状态的，如果服务器想要获取你在某个页面的停留状态或者看了哪些商品，一种常用的实现方式就是将这些信息存放在 Cookie …… 如何在项目中使用Cookie呢？我们以Gin的项目为例 package main import ( \"github.com/gin-gonic/gin\" \"net/http\" ) func main() { r := gin.Default() r.GET(\"/setCookie\", func(c *gin.Context) { // 设置cookie c.SetCookie(\"cookie_name\", \"cookie_value\", 3600, \"/\", \"localhost\", false, true) /* name cookie的名称 value cookie的值 maxAge int, 单位为秒 path cookie所在目录 domain string,域名 secure 是否智能通过https访问 httpOnly bool 是否允许通过js获取自己的cookie */ c.JSON(http.StatusOK, gin.H{ \"message\": \"set cookie success.\", }) }) r.GET(\"/getCookie\", func(c *gin.Context) { // 读取cookie,根据cookie名读取 cookie, err := c.Cookie(\"cookie_name\") if err != nil { // 直接返回cookie值 c.JSON(http.StatusOK, gin.H{\"message\": \"get cookie fail\"}) return } c.JSON(http.StatusOK, gin.H{\"cookie_name\": cookie}) }) r.GET(\"/delCookie\", func(c *gin.Context) { // 删除cookie, 设置cookie MaxAge设置为-1，表示删除cookie c.SetCookie(\"cookie_name\", \"cookie_value\", -1, \"/\", \"localhost\", false, true) c.JSON(http.StatusOK, gin.H{ \"message\": \"delete cookie success.\", }) }) r.Run(\":8080\") } Cookie 和 Session 有什么区别？Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。 Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。 那么，如何使用 Session 进行身份验证？ 很多时候我们都是通过 SessionID 来实现特定的用户，SessionID 一般会选择存放在 Redis 中。举个例子： 用户成功登陆系统，然后返回给客户端具有 SessionID 的 Cookie 。 当用户向后端发起请求的时候会把 SessionID 带上，这样后端就知道你的身份状态了。 关于这种认证方式更详细的过程如下： 用户向服务器发送用户名、密码、验证码用于登陆系统。 服务器验证通过后，服务器为用户创建一个 Session，并将 Session 信息存储起来。 服务器向用户返回一个 SessionID，写入用户的 Cookie。 当用户保持登录状态时，Cookie 将与每个后续请求一起被发送出去。 服务器可以将存储在 Cookie 上的 SessionID 与存储在内存中或者数据库中的 Session 信息进行比较，以验证用户的身份，返回给用户客户端响应信息的时候会附带用户当前的状态。 使用 Session 的时候需要注意下面几个点： 依赖 Session 的关键业务一定要确保客户端开启了 Cookie。 注意 Session 的过期时间。 多服务器节点下 Session-Cookie 方案如何做？Session-Cookie 方案在单体环境是一个非常好的身份认证方案。但是，当服务器水平拓展成多节点时，Session-Cookie 方案就要面临挑战了。 举个例子：假如我们部署了两份相同的服务 A，B，用户第一次登陆的时候 ，Nginx 通过负载均衡机制将用户请求转发到 A 服务器，此时用户的 Session 信息保存在 A 服务器。结果，用户第二次访问的时候 Nginx 将请求路由到 B 服务器，由于 B 服务器没有保存 用户的 Session 信息，导致用户需要重新进行登陆。 我们应该如何避免上面这种情况的出现呢？ 有几个方案可供大家参考：（1.通过hash算法 2.采用第三方存储如redis缓存） 某个用户的所有请求都通过特性的哈希策略分配给同一个服务器处理。这样的话，每个服务器都保存了一部分用户的 Session 信息。服务器宕机，其保存的所有 Session 信息就完全丢失了。 每一个服务器保存的 Session 信息都是互相同步的，也就是说每一个服务器都保存了全量的 Session 信息。每当一个服务器的 Session 信息发生变化，我们就将其同步到其他服务器。这种方案成本太大，并且，节点越多时，同步成本也越高。 单独使用一个所有服务器都能访问到的数据节点（比如缓存）来存放 Session 信息。为了保证高可用，数据节点尽量要避免是单点。 Spring Session 是一个用于在多个服务器之间管理会话的项目。它可以与多种后端存储（如 Redis、MongoDB 等）集成，从而实现分布式会话管理。通过 Spring Session，可以将会话数据存储在共享的外部存储中，以实现跨服务器的会话同步和共享。 如果没有 Cookie 的话 Session 还能用吗？这是一道经典的面试题！ 一般是通过 Cookie 来保存 SessionID ，假如你使用了 Cookie 保存 SessionID 的方案的话， 如果客户端禁用了 Cookie，那么 Session 就无法正常工作。 但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将 SessionID 放在请求的 url 里面https://javaguide.cn/?Session_id=xxx 。这种方案的话可行，但是安全性和用户体验感降低。当然，为了安全你也可以对 SessionID 进行一次加密之后再传入后端。 为什么 Cookie 无法防止 CSRF 攻击，而 Token 可以？CSRF(Cross Site Request Forgery) 一般被翻译为 跨站请求伪造 。那么什么是 跨站请求伪造 呢？说简单用你的身份去发送一些对你不友好的请求。举个简单的例子： 小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了 10000 元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。 &lt;a src=http://www.mybank.com/Transfer?bankId=11&amp;money=10000>科学理财，年盈利率过万&lt;/> 上面也提到过，进行 Session 认证的时候，我们一般使用 Cookie 来存储 SessionId,当我们登陆后后端生成一个 SessionId 放在 Cookie 中返回给客户端，服务端通过 Redis 或者其他存储工具记录保存着这个 SessionId，客户端登录以后每次请求都会带上这个 SessionId，服务端通过这个 SessionId 来标示你这个人。如果别人通过 Cookie 拿到了 SessionId 后就可以代替你的身份访问系统了。 Session 认证中 Cookie 中的 SessionId 是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。 但是，我们使用 Token 的话就不会存在这个问题，在我们登录成功获得 Token 之后，一般会选择存放在 localStorage （浏览器本地存储）中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 Token,这样就不会出现 CSRF 漏洞的问题。因为，即使有个你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 Token 的，所以这个请求将是非法的。 需要注意的是：不论是 Cookie 还是 Token 都无法避免 跨站脚本攻击（Cross Site Scripting）XSS 。 跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为 XSS。 XSS 中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如 Cookie 。 推荐阅读：如何防止 CSRF 攻击？—美团技术团队","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端知识","slug":"后端知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"有栈协程和无栈协程","slug":"有栈协程和无栈协程","date":"2024-03-18T09:39:39.182Z","updated":"2024-03-18T09:39:39.182Z","comments":true,"path":"2024/03/18/有栈协程和无栈协程/","permalink":"https://kiritoabc.github.io/2024/03/18/%E6%9C%89%E6%A0%88%E5%8D%8F%E7%A8%8B%E5%92%8C%E6%97%A0%E6%A0%88%E5%8D%8F%E7%A8%8B/","excerpt":"有栈协程与无栈协程 进程的本质就是 一个程序的执行实例。在进程模型中，进程拥有对内存、I/O 通道、I/O 设备和文件等资源的控制权。 线程则是为了解决进程的执行效率而提出的。对于多核 CPU，多线程进程可以充分利用多核的特性，成倍地提升执行效率。 在现代操作系统中，我们可以认为线程是进程的更小粒度的划分，即进程包含了一个或多个线程。下图所示为，分别是单线程的进程模型和多线程的进程模型。","text":"有栈协程与无栈协程 进程的本质就是 一个程序的执行实例。在进程模型中，进程拥有对内存、I/O 通道、I/O 设备和文件等资源的控制权。 线程则是为了解决进程的执行效率而提出的。对于多核 CPU，多线程进程可以充分利用多核的特性，成倍地提升执行效率。 在现代操作系统中，我们可以认为线程是进程的更小粒度的划分，即进程包含了一个或多个线程。下图所示为，分别是单线程的进程模型和多线程的进程模型。 用户态&amp;内核态线程用户态线程 在线程的概念提出时，操作系统并不支持线程，为了验证线程的可行性，研究人员就编写了一个线程的函数库，用函数库来实现线程。这个线程库包含了 创建线程、终止线程 等，开发者可以通过调用这些函数来实现所需的功能，如：pthread_create、pthread_exit、pthread_join、pthread_yeild。 此时，操作系统内核对这个库一无所知，从内核的角度开，它还是按照正常的方式进行管理，即 只能一次在一个 CPU 核上运行。事实上，这也是用户态线程的缺点，这些线程只能占用一个核，无法做到并行加速，而且由于用户态线程对操作系统透明，操作系统无法主动切换线程。对此，开发者需要为用户态线程定制调度算法。 内核态线程 现代操作系统都已经支持内核态线程了，为了实现线程，内核里就需要有用来记录系统中所有线程的线程表。当需要创建一个新的线程时，就需要进行一次 系统调用，然后由操作系统对线程表进行更新。 相比于用户态线程，由于操作系统知道内核态线程的存在，它就可以自由调度各个线程，从而充分利用多核，实现真正的并行。 不过，内核态线程也有缺点。每当操作系统进行线程调度时，就需要陷入内核态，而操作系统从 用户态到内核态 的切换是由开销的，所以说，内核态线程切换的代价要比用户态线程大，这些开销主要包括以下几个方面： 上下文切换：即寄存器切换 特权模式切换：即调度算法中的动态特权级 内核检查：内核代码对用户不信任，需要进行额外的检查 除此之外，线程表是存储在操作系统中固定的堆栈空间中，因此内核态线程的数量是有限的，扩展性比不上用户态线程。 对比 由于用户态线程和内核态线程的存在，我们也就能够理解教科书中所说的三种线程模型了，如下图所示： 协程 那么，协程到底是什么呢？事实上，协程就是 用户态线程。协程的调度完全由开发者进行控制，因此实现协程的关键也就是 实现一个用户态线程的调度器。由于协程是在用户态中实现调度，避免了内核态的上下文切换造成的性能损失，从而突破了线程在 IO 上的性能瓶颈。 在理解了用户态线程后，其实不难看出，一个线程多个协程的情况下，在内核看来只有一个线程在运行，这些协程事实上是在串行运行，只能使用一个 CPU 核。因此，想要高效利用 CPU，我们还是得使用线程。协程最大的优势在于 协程的切换比线程的切度更快。那么，什么场景下更适合使用协程呢？ 答案是：IO 密集型任务。IO 密集型任务的特点是 CPU 消耗少，其大部分时间都是在等待 IO 操作完成。对于这样的场景，一个线程足矣，因此适合采用协程。 挂起和恢复相比于函数，协程最大的特点就是支持 挂起/恢复。什么意思？我们来看下面这个场景就能明白。 上图中，控制流会在 foo() 和 bar() 之间进行切换。比如，在第 3 阶段时，控制流从 foo() 中再次转移到了 bar() 中，此时并不是简单的函数调用，而是从上一次离开 bar() 的位置 std::cout &lt;&lt; \"1\" 之后继续执行。 由此可见，协程与简单的函数调用之间的区别。实现协程的这种能力的关键，就是要实现 挂起/恢复 的能力。 协程分类现代编程语言中，有很多都支持协程，虽然它们在实现细节上差异较大，但是总体而言仍然有章可循。 按调用栈分类由于协程必须支持 挂起/恢复，因此对于挂起点的状态保存就显得极其关键。我们知道，线程在切换时，它的中断状态会保存在调用栈中。事实上，协程的中断状态也可以通过开辟相应的调用栈来保存。因此，按照是否开辟相应的调用栈，我们可以将协程分为两类： 有栈协程（Stackful Coroutine）：每个协程都有自己的调用栈，类似于线程的调用栈。 无栈协程（Stackless Coroutine）：协程没有自己的调用栈，挂起点的状态通过状态机或闭包等语法来实现。 类似微信的 libco、阿里的 cooobjc、Golang 中的 goroutine、Lua 中的协程都是有栈协程；类似 ES6、Dart 中的 await/async、Python 的 Generator、Kotlin 中的协程、C++20 中的 cooroutine 都是无栈协程。 有栈协程有栈协程的一般实现是：在内存中给每个协程开辟一个栈内存，当协程挂起时会将它的运行时上下文（即栈空间）从系统栈中保存至其所分配的栈内存中，当协程恢复时会将其运行时上下文从栈内存中恢复至系统栈中 上图所示为在协程 foo() 和 bar() 之间切换时，栈空间的变化。很显然，有栈协程会改变函数调用栈。由于有栈协程需要保存各个协程自己的运行时上下文，一般会通过堆来分类内存空间。如果内存分配过小，可能会产生栈溢出；如果内存分配过大，可能会产生内存浪费。因此，很多编程语言对此进行了各种优化。 另一方面，当协程恢复时，需要将运行时上下文从堆中拷贝至栈中，这里也存在一定的开销。 虽然，有栈协程有上述的缺点，但是它可以在 任意函数调用层级的位置进行挂起，并转移调度权。事实上，这也是有栈协程的重要特定之一。 无栈协程与有栈协程相反，无栈协程不会为各个协程开辟相应的调用栈。无栈协程通常是 基于状态机或闭包 来实现。 基于状态机的解决方案一般是通过状态机，记录上次协程挂起时的位置，并基于此决定协程恢复时开始执行的位置。这个状态必须存储在栈以外的地方，从而避免状态与栈一同销毁。 以 bar() 为例，可以通过类似如下的方式实现挂起和恢复。从这种实现方式的角度来看，协程与函数无异，只不过前者会记录上次终端的位置，从而可以实现恢复执行的能力。当然，在实际过程中，恢复后的执行流可能会用到中断前的状态，因此无栈协程会将保存完整的状态，这些状态会被存储到堆上。 void bar() { static int state = 0; switch (state) { case 0: goto LABEL0; case 1: goto LABEL1; case 2: goto LABEL2; } LABEL0: std::cout < \"1\"; LABEL1: std::count < \"2\"; LABEL2: std::count < \"3\"; }","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端知识","slug":"后端知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"简历制作工具推荐","slug":"简历制作","date":"2024-03-18T09:39:39.182Z","updated":"2024-03-18T09:39:39.182Z","comments":true,"path":"2024/03/18/简历制作/","permalink":"https://kiritoabc.github.io/2024/03/18/%E7%AE%80%E5%8E%86%E5%88%B6%E4%BD%9C/","excerpt":"","text":"免费的简历制作中心推荐： https://www.polebrief.com/edit","categories":[{"name":"生活","slug":"生活","permalink":"https://kiritoabc.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://kiritoabc.github.io/tags/%E7%94%9F%E6%B4%BB/"}],"author":"菠萝"},{"title":"记录一次性能测试","slug":"系统测试","date":"2024-03-18T09:39:39.182Z","updated":"2024-03-18T09:39:39.182Z","comments":true,"path":"2024/03/18/系统测试/","permalink":"https://kiritoabc.github.io/2024/03/18/%E7%B3%BB%E7%BB%9F%E6%B5%8B%E8%AF%95/","excerpt":"吞吐量：每秒钟系统能够处理的请求数、任务数。 响应时间：服务处理一个请求或一个任务的耗时。 错误率：一批请求中结果出错的请求所占比例。","text":"吞吐量：每秒钟系统能够处理的请求数、任务数。 响应时间：服务处理一个请求或一个任务的耗时。 错误率：一批请求中结果出错的请求所占比例。 性能需求分析项目业务： 注册，登录，视频上传，视频搜索 需要压测的业务： 核心，用户量，与外部接口对接 分析： 需要压测的业务 —–&gt; 登录，视频搜索，视频上传 性能指标： 非硬件： 50%line &lt; 1s 90%line &lt; 1 s,TPS, 事务成功率100%（响应时间几十毫秒到几百毫秒） 硬件： CPU 内存 &lt;= 70% 性能方案设计7大场景: 单业务基准测试、单业务压力测试，单业务负载测试|综合业务基准测试，综合业务压力测试，综合业务负载测试，综合业务稳定性测试 单业务： 登录 基准：30min 2w登录 经过分析： 性能场景： 1s启动所有线程，压测5min，观察性能指标 登录测试: 1s内启动，20个线程组，持续300s docker内存使用情况图形化docker run --volume=/:/rootfs:ro --volume=/var/run:/var/run:rw --volume=/sys:/sys:ro --volume=/var/lib/docker/:/var/lib/docker:ro --volume=/dev/disk/:/dev/disk:ro --publish=8080:8080 --detach=true --name=cadvisor --privileged --device=/dev/kmsg lagoudocker/cadvisor:v0.37.0 业务建模 脚本优化执行测试 手机性能数据结果分析 性能测试报告 APP: mysql 登录接口第一次测试： APP mysql 第二次测试 APP mysql","categories":[{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/tags/%E6%B5%8B%E8%AF%95/"}],"author":"菠萝"},{"title":"数据库分片","slug":"数据库分片","date":"2024-03-18T09:39:39.178Z","updated":"2024-03-18T09:39:39.178Z","comments":true,"path":"2024/03/18/数据库分片/","permalink":"https://kiritoabc.github.io/2024/03/18/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%89%87/","excerpt":"Introduction 任何看到显著增长的应用程序或网站，最终都需要进行扩展，以适应流量的增加。以确保数据安全性和完整性的方式进行扩展，对于数据驱动的应用程序和网站来说十分重要。人们可能很难预测某个网站或应用程序的流行程度，也很难预测这种流行程度会持续多久，这就是为什么有些机构选择“可动态扩展的”数据库架构的原因。 “可动态扩展的”数据库架构：分片数据库。近年来，分片（Sharding）一直受到很多关注，但许多人并没有清楚地了解它是什么，或者对数据库进行分片可能有意义的场景。我们将讨论分片是什么，它的一些主要优点和缺点，以及一些常见的分片方法。","text":"Introduction 任何看到显著增长的应用程序或网站，最终都需要进行扩展，以适应流量的增加。以确保数据安全性和完整性的方式进行扩展，对于数据驱动的应用程序和网站来说十分重要。人们可能很难预测某个网站或应用程序的流行程度，也很难预测这种流行程度会持续多久，这就是为什么有些机构选择“可动态扩展的”数据库架构的原因。 “可动态扩展的”数据库架构：分片数据库。近年来，分片（Sharding）一直受到很多关注，但许多人并没有清楚地了解它是什么，或者对数据库进行分片可能有意义的场景。我们将讨论分片是什么，它的一些主要优点和缺点，以及一些常见的分片方法。 What is Sharding? 什么是分片？分片（Sharding）是一种与水平切分（horizontal partitioning）相关的数据库架构模式——将一个表里面的行，分成多个不同的表的做法（称为分区）。每个区都具有相同的模式和列，但每个表有完全不同的行。同样，每个分区中保存的数据都是唯一的，并且与其他分区中保存的数据无关。 从水平切分（horizontal partitioning）与垂直切分（vertical partitioning）的关系，可能会有所帮助。在垂直切分表中，所有的列被分离出来，并放入新的不同的表中。每个垂直切分内的数据，独立于所有其他分区中的数据，并且每个分区都包含不同的行和列。下图说明了如何在水平和垂直方向上对表进行分区： 分片（Sharding）将一个数据分成两个或多个较小的块，称为逻辑分片（logical shards）。然后，逻辑分片（logical shards）分布在单独的数据库节点上，称为物理分片（physical shards）。物理分片（physical shards）可以容纳多个逻辑分片（logical shards）。尽管如此，所有分片中保存的数据，共同代表整个逻辑数据集。 数据库分片（Database shards）是无共享架构的一个例子。这意味着分片是自治的：分片间不共享任何相同的数据或服务器资源。但是在某些情况下，将某些表复制到每个分片中作为参考表是有意义的。例如，假设某个应用程序的数据库依赖于重量测量的固定转换率。通过将包含必要转换率数据的表复制到每个分片中，有助于确保查询所需的所有数据都保存在每个分片中。 通常，分片（Sharding）在应用程序级别进行实现。这意味着应用程序包含“要向哪个分片发送读和写”的代码。但是，某些数据库管理系统内置了分片功能，允许您直接在数据库级别实现分片。 以上是分片（Sharding）的概述，接下来让我们来看一下，这种数据库架构的优点和缺点。 Benefits of Sharding 分片的好处数据库分片的主要吸引力在于，它可以帮助促进水平扩展（horizontal scaling），也称为向外扩展（scaling out）。水平扩展是将更多的机器添加到现有堆栈中，以分散负载，允许更多的流量和更快的处理。这通常与垂直扩展（vertical scaling）形成对比，垂直扩展也称为向上扩展（scaling up），是指升级现有服务器的硬件，通常是添加更多内存或CPU。 让一个关系数据库在单个机器上运行，并按需升级其服务器资源进行向上扩展是相对简单的。但最终，任何非分布式数据库在存储和计算能力方面都会受到限制，因此可以自由地水平扩展数据库，会使您的架构更加灵活且适应性强。 选择分片数据库架构的另一个原因，是为了加速查询响应的时间。当您对尚未分片的数据库提交查询时，必须先搜索您查询的表中的每一行，然后才能找到您要查找的结果集。对于具有大型单片数据库的应用程序，查询可能变得极其缓慢。但是，通过将一个表分成多个，查询过程会遍历更少的行，并且返回结果集的速度要快得多。 分片还可以通过减少宕机（outage）的影响，使应用程序更稳定可靠。如果您的应用程序或网站依赖于未分片的数据库，则宕机可能会导致整个应用程序不可用。但是，对于分片数据库，宕机可能只会影响单个分片。即使这可能使某些用户无法使用应用程序或网站部分功能，但仍会低于整个数据库崩溃带来的影响。 Drawbacks of Sharding 分片的缺点虽然对数据库进行分片可以使扩展更容易并提高性能，但它也可能会带来某些限制。在这里，我们将讨论其中的一些限制，以及为什么这些限制会让我们避免对数据库全部分片。 正确实现分片数据库架构，是十分复杂的，所以这是分片遇到的第一个困难。如果操作不正确，则分片过程可能会导致数据丢失或表损坏，这是一个很大的风险。但是，即使正确地进行了分片，也可能对团队的工作流程产生重大影响。与从单个入口点访问和管理数据不同，用户必须跨多个分片位置管理数据，这可能会让某些团队存在工作混乱。 在对数据库进行分片后，用户有时会遇到的一个问题是分片最终会变得不平衡。举例来说，假设您有一个数据库，其中有两个单独的分片，一个用于姓氏以字母A到M开头的客户，另一个用于名字以字母N到Z开头的客户。但是，您的应用程序为姓氏以字母G开头的人提供了过多的服务。因此，A-M分片逐渐累积的数据比N-Z分片要多，这会导致应用程序速度变慢，并对很大一部分用户造成影响。A-M分片已成为所谓的数据热点。在这种情况下，数据库分片的任何好处都被慢速和崩溃抵消了。数据库可能需要修复和重新分片，才能实现更均匀的数据分布。 另一个主要缺点是，一旦对数据库进行了分片，就很难将其恢复到未分片的架构。分片前数据库的备份数据，都无法与分片后写入的数据合并。因此，重建原始的非分片架构，需要将新的分区数据与旧备份合并，或者将分区的数据库转换回单个数据库，这两种方法都是昂贵且耗时的。 要考虑的最后一个缺点是，并不是每个数据库引擎本身都支持分片。例如，尽管可以手动分片PostgreSQL数据库，但PostgreSQL本身并不包括自动分片功能。有许多Postgres分支包括自动分片功能，但这些分支通常落后于最新的PostgreSQL版本，并且缺乏某些其他的功能特性。一些专业的数据库技术——如MySQL Cluster或某些数据库即服务产品（如MongoDB Atlas）确实包含自动分片功能，但这些数据库管理系统的普通版本却并不包含。因此，分片通常需要“自己动手”的方法。这意味着通常很难找到有关分片或故障排除技巧的文档。 现在我们已经介绍了一些分片的缺点和好处，我们将讨论一些分片数据库的不同架构。 一旦你决定对数据库进行分片，接下来你需要弄清楚的是如何进行分片。在运行查询或将传入的数据分发到分片表或数据库时，关键是要将其分配到正确的分片。否则，它可能导致数据丢失或查询速度缓慢。在本节中，我们将介绍一些常见的分片架构，每个架构使用稍微不同的流程来跨分片分发数据。 Key Based Sharding 基于键的分片 为了确保数据记录以正确的方式被放置在正确的分片中，哈希函数中输入的值都应该来自同一列。此列称为分片键。简单来说，分片键与主键类似，因为它们都是列，用于为各个行建立唯一标识符。一般来说，分片键应该是静态的，这意味着它不应包含可能随时间变化的值。否则，它会增加更新操作的工作量，并可能降低性能。 虽然基于键的分片是一种相当常见的分片架构，但在尝试动态添加或删除数据库中的其他服务器时，它会使事情变得棘手。在添加服务器时，每个服务器都需要一个相应的哈希值，并且许多现有条目（如果不是全部）都需要重新映射到新的正确哈希值，然后迁移到相应的服务器。当您开始重新平衡数据时，新旧哈希函数都不会有效。因此，在迁移期间，您的服务器将无法编写任何新数据，您的应用程序可能会停机。 这种策略的主要吸引力在于，它可以用于均匀分布数据，从而防止热点。此外，由于它以算法方式分配数据，因此无需维护所有数据所在位置的映射，而其他策略（如范围或基于目录的分片）必须维护数据位置的映射。 Range Based Sharding 基于范围的分片基于范围的分片（Range based sharding），基于给定值的范围进行数据分片。为了说明，假设您有一个数据库，用于存储零售商目录中所有产品的信息。您可以创建一些不同的分片，并根据每个产品的价格范围分配每个产品的信息，如下所示： 基于范围的分片的主要好处是，它实现起来相对简单。每个分片都包含一组不同的数据，但它们都具有相同的模式，以及原始数据库。应用程序代码只读取数据所属的范围，并将其写入相应的分片。 另一方面，基于范围的分片并不能预防数据不均匀分布的现象，而有可能会出现前面提到的数据热点现象。查看示例图，即使每个分片拥有相同数量的数据，特定产品比其他产品获得更多关注的可能性也会很大。相应的，各个的分片将接收不成比例的读取操作。 Directory Based Sharding 基于目录的分片要实现基于目录的分片，必须创建并维护一个查找表，该查找表使用分片键来跟踪哪个分片包含哪些数据。简而言之，查找表是一个表，其中包含有关可以找到特定数据的静态信息集。下图显示了基于目录的分片的简单示例： 此处，Delivery Zone列被定义为分片键。将来自分片键的数据，连同每一行应该写入的分片写入查找表。这与基于范围的分片类似，但不是确定分片键的数据落入哪个范围，而是将每个键绑定到其自己的特定分片。如果分片键的基数很低，并且分片键存储键的范围没有意义，那么基于目录的分片比基于范围的分片要更好。请注意，它也不同于基于密钥的分片，因为它不通过散列函数处理分片键; 它只是根据查找表检查键值，以查看数据需要写入的位置。 基于目录的分片的主要吸引力在于其灵活性。基于范围的分片架构只能指定键值范围，而基于键的分片架构只能使用固定的哈希函数，如前所述，在以后更改该函数非常困难。另一方面，基于目录的分片允许您使用任何系统或算法将数据项分配给分片，使用这种方法动态添加分片也相对容易。 虽然基于目录的分片是这里讨论的最灵活的分片方法，但是在每次查询或写入之前连接到查找表，可能会对应用程序的性能产生不利影响。此外，查找表可能出现单点故障：如果查询表损坏或出现其他故障，它可能会影响数据库写入新数据或访问现有数据的能力。 Should I Shard? 我应该分片吗？是否应该实现分片数据库架构，几乎总是一个争论的问题。有些人认为分片对于达到一定规模的数据库来说，是不可避免的结果。而另一些人则认为这是一个令人头疼的问题，除非绝对必要，否则应该避免，因为分片增加了操作的复杂性。 由于这种增加的复杂性，通常仅在处理非常大量的数据时才执行分片。以下是一些常见方案，可能对数据库分片的操作有所帮助： · 应用程序数据量增长到超过单个数据库节点的存储容量。 · 对数据库的读写量，超过单个节点或其只读副本可以处理的量，从而导致响应时间增加或超时。 · 应用程序所需的网络带宽，超过单个数据库节点和任何只读副本可用的带宽，从而导致响应时间增加或超时。 在分片之前，您应该用尽所有其他选项来优化数据库。您可能需要考虑的一些优化包括： 设置远程数据库。如果您使用的是一个整体应用程序，其中所有组件都位于同一个服务器上，那么可以通过将数据库移到它自己的机器上来提高数据库的性能。由于数据库的表保持不变，因此这不会增加分片的复杂性。但是，它仍然允许您垂直伸缩数据库，使其与基础结构的其他部分分离。 实现缓存。如果您的应用程序的读取性能导致您遇到麻烦，那么缓存是一种可以帮助改进它的策略。缓存涉及临时存储已在内存中请求的数据，以便您以后更快地访问它。 创建一个或多个只读副本。另一种有助于提高读取性能的策略，包括将数据从一个数据库服务器（主服务器）复制到一个或多个从服务器。在此之后，每次新的写操作在复制到从服务器之前都要先到主服务器，而读操作只对从服务器进行。像这样分发读写可以防止任何一台机器承担过多的负载，从而有助于防止速度下降和崩溃。请注意，创建读副本需要更多的服务器资源，因此花费更多的钱，这对一些人来说可能是一个很大的限制。 升级到更大的服务器。在大多数情况下，将一个数据库服务器扩展到具有更多资源的计算机比分片需要更少的工作量。与创建只读副本一样，具有更多资源的服务器升级可能会花费更多的钱。因此，只有当它确实是您的最佳选择时，您才应该进行服务器扩容。 请记住，如果您的应用程序或网站增长超过某个点，这些策略本身都不足以提高性能。在这种情况下，分片可能确实是您的最佳选择。 Conclusion 结语对于那些希望横向扩展数据库的人来说，分片是一个很好的解决方案。但是，它还会增加很多复杂性，并为您的应用程序创建更多潜在的故障点。分片对于某些人来说可能是必要的，但是创建和维护分片架构所需的时间和资源可能会超过对其他人的好处。 通过阅读这篇概念性文章，您应该更清楚地了解分片的优缺点。接下来，您可以使用这些见解来对分片数据库架构是否适合您，做出更明智的决定。 转载:数据库分片（Database Sharding)详解 - 知乎 (zhihu.com)","categories":[{"name":"sql","slug":"sql","permalink":"https://kiritoabc.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"https://kiritoabc.github.io/tags/sql/"}],"author":"菠萝"},{"title":"学习记录","slug":"学习记录","date":"2024-03-18T09:39:39.170Z","updated":"2024-03-18T09:39:39.170Z","comments":true,"path":"2024/03/18/学习记录/","permalink":"https://kiritoabc.github.io/2024/03/18/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"3月学习记录2024-3-7今日打卡 leetcode练习 64. 最小路径和 62. 不同路径 5. 最长回文子串 70. 爬楼梯 118. 杨辉三角 198. 打家劫舍 279. 完全平方数 322. 零钱兑换 背面试题 Redis相关 Redis的集群模式：主从，哨兵，cluster三种。 Redis使用惰性删除+定期删除策略配合使用来对过期的key进行删除 Redis的持久化：aof日志（以追加的方式写入，主要记录的是操作），rdb（对所有键值对的记录），混合模式（aof和rdb两种模式的混合使用） 缓存雪崩： 大量数据同时过期 均匀设计过期时间 互斥锁 双key策略 后台更新缓存，定时更新，消息队列通知更新。 Redis故障宕机 服务熔断 请求限流 构建Redis高可用集群。 缓存击穿： 频繁访问的热点数据过期： 互斥锁 不给热点数据设置过期时间，由后台定期更新缓存 缓存穿透： 访问的数据既不再缓存也不在数据库 非法请求的限制。 缓存空值或默认值。 使用布隆过滤器快速判断数据是否存在。 Redis的数据结构 Redis提供了常见的5种数据结构 字符串（string），哈希（hash），列表（list），集合（Set），有序集合（ZSet） ● String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。● List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。● Hash 类型：缓存对象、购物车等。● Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。● Zset 类型：排序场景，比如排行榜、电话和姓名排序等。● BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；● HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；● GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；● Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据 学习Redis如何实现延迟队列. 采用zset来实现 Kafka面试题 Kafka的设计： kafka是将消息以 topic 为单位归纳，发布消息的程序成为 Producer ，消费者的程序称为 Consumer Kafka是以集群的方式运行的，可以由一个或多个服务组成，每个服务叫做 Broker， Producer通过网络将消息发送到 KafKa集群，集群向消费者提供消息，broker在中间起到一个代理保存消息的中间站。 2024-3-8今日打卡 面试题 Redis Redis实现分布式锁： 1.使用set nx 命令，（解锁过程借助LUA脚本，解锁设计2部分，一部分是判断是否是自己的锁，另一部分就是删除锁操作，因为有2个操作，要保证一致性，所以采用LUA脚本来实现）； 2.RedLock（满足：一半以上结点响应，且响应时间小于设置的操作时间）。 敲代码： 完成12306模拟项目，用户模块部分接口的测试。 查看了基于asynq的定时任务模块，发现，好像火车时间没有改，所以查不出数据，哈哈哈哈。等后面写完了，再更新一下数据看看。 做题： 222. 完全二叉树的节点个数 110. 平衡二叉树 404. 左叶子之和 257. 二叉树的所有路径 513. 找树左下角的值 112. 路径总和 113. 路径总和 II 797. 所有可能的路径 学习图相关 dfs和bfs，了解升读优先搜索和广度优先搜索。 dfs是可一个方向去搜，不到黄河不回头，直到遇到绝境了，搜不下去了，再换方向（换方向的过程就涉及到了回溯）。 bfs是先把本节点所连接的所有节点遍历一遍，走到下一个节点的时候，再把连接节点的所有节点遍历一遍，搜索方向更像是广度，四面八方的搜索过程。 2024-3-9刷题： 200. 岛屿数量 98. 验证二叉搜索树 1971. 寻找图中是否存在路径 684. 冗余连接 685. 冗余连接 II 算法学习： 学习了DFS和BFS 学习并查集算法 面试题： Redis 五种常见的Redis集合的实现 计网学习： HTTPS，HTTP的握手过程 准备重新搭建自己的博客。 2024-3-10参加了leetcode第 388 场周赛 A了2道题跑路，呜呜呜 刷题leetcode hot 100 124. 二叉树中的最大路径和 108. 将有序数组转换为二叉搜索树 230. 二叉搜索树中第K小的元素 199. 二叉树的右视图 114. 二叉树展开为链表 面试题： HTTP的RSA握手过程 了解了一下HTTP/1.1,HTTP/2,HTTP/3 HTTP/3 的传输层采用的是UDP，通过QUIC协议 实现了 类似 TCP的可靠性传输 了解IP协议相关技术：DNS,NAT,DHCP，ICMP 呜呜呜，继续修改我的破博客.菜弄到 Twikoo 的评论部分，呜呜呜。 2024-3-11为面试做准备，背面试： 了解了一些限流算法： 固定窗口算法：设置固定时间内，处理请求的定值 滑动窗口算法：滑动窗口计数器是通过窗口再细分，并且按照时间滑动。避免了双倍请求突发 漏桶算法： 令牌桶算法： 了解了一些常见的负载均很该算法： 轮询 加权轮询 随机 最少连接 源IP哈希 响应时间 加权响应时间 一致性哈希 动态调整权重 Redis 的缓存 如何避免缓存雪崩？缓存击穿？缓存穿透？ 缓存雪崩： 1.把key的过期时间设置均匀； 2.不设置过期时间，我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题。 缓存击穿： 如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。 互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间； 缓存穿透： 非法请求的限制 设置空值或默认值 使用布隆过滤器 看了会MYSQL面试题 2024-3-12今天电脑屏幕坏了，拿去修，没有什么记录。 大概就看了一下面试题 了解了Redis里面DB结构 dict RedisObj 原来Redis里面的Rehash() 也是采用渐进式的，我之前就看到go里面的hash扩容是渐进式的。 了解了各种数据类型的实现 string list hash set zset bitmap hyperloglog（这个没看明白） geo stream SDS，链表，压缩链表，哈希表，整数集合，跳表，quicklist，listpack 别说，我觉得跳表的设计还蛮厉害的， 2024-3-13准备字节一面中，下午4点准备一面。加油。 学习打卡： 指针在go中的作用：1，引用传递；2.动态内存分配；3.修改函数外部变量；4.数据结构底层操作；5.低级内存操作；6接口实现 做题： 都是回溯算法。dfs的求解过程。 78. 子集 90. 子集 II 2024-3-14准备面试题： 看了同步/异步，阻塞/非阻塞。(同步，异步其实是接收方返回消息的方式)（阻塞，非阻塞看的是发送方等待的时候的状态） 刷题: 236. 二叉树的最近公共祖先 39. 组合总和 22. 括号生成 200. 岛屿数量 20. 有效的括号 35. 搜索插入位置 136. 只出现一次的数字 169. 多数元素 75. 颜色分类 31. 下一个排列 287. 寻找重复数(想不到 2024-3-15起床学习啦！！！ 刷题： 104. 二叉树的最大深度 （写了一下不采用递归的方式，感觉其实还行，就是使用queue模拟一下就好了） 455. 分发饼干 55. 跳跃游戏 45. 跳跃游戏 II 105. 从前序与中序遍历序列构造二叉树 437. 路径总和 III 215. 数组中的第K个最大元素 79. 单词搜索 51. N 皇后 leetcode终于300题了。 看面试题 2024-3-16刷题: 54. 螺旋矩阵 48. 旋转图像 240. 搜索二维矩阵 II 74. 搜索二维矩阵 2024-3-17看面试题： 负载均衡算法 刷题： 1005. K 次取反后最大化的数组和 134. 加油站 135. 分发糖果 860. 柠檬水找零 100. 相同的树 103. 二叉树的锯齿形层序遍历 算法图的遍历 广度优先 深度优先 2024-3-18刷题： 107. 二叉树的层序遍历 II 116. 填充每个节点的下一个右侧节点指针 117. 填充每个节点的下一个右侧节点指针 II LeetCode 热题100 复习 CS自学指南学习打卡编程入门MIT-Missing-Semester第一节：Course overview + the shell https://missing.csail.mit.edu/2020/course-shell/ 第二节：Shell Tools and Scripting https://missing.csail.mit.edu/2020/shell-tools/","categories":[{"name":"学习","slug":"学习","permalink":"https://kiritoabc.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"学习记录","slug":"学习记录","permalink":"https://kiritoabc.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"}],"author":"菠萝"},{"title":"接口测试","slug":"接口测试","date":"2024-03-18T09:39:39.170Z","updated":"2024-03-18T09:39:39.170Z","comments":true,"path":"2024/03/18/接口测试/","permalink":"https://kiritoabc.github.io/2024/03/18/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/","excerpt":"接口性能测试与调优相关一直是属于无经验状态。思考提升自己的能力，是否要学会压力测试？","text":"接口性能测试与调优相关一直是属于无经验状态。思考提升自己的能力，是否要学会压力测试？ JMeter Apache JMeter 是一种Java框架，用于各种负载测试，性能测试和功能测试。 注意：测试容易受到网络抖动的干扰，服务器硬件配置环境影响；因此压力测试一般情况下，都应该在内网进行，不在外网去测试； 官网：https://jmeter.apache.org/教程：Apache JMeter - User’s Manual 镜像下载地址：Apache JMeter - Apache JMeter™ windows可以使用图形化界面进行测试，linux建议使用命令模式进行测试。但是为了测试的便捷性，我们使用jmeter的图形化界面进行压力测试。 下载完成后可以尝试给JMeter配置一下环境变量 运行:点击 jmeter.bat 即可 打开后： 配置中文 使用JMeter对成程序接口进行测试首先如下程序，我们会进行一秒种的睡眠 package main import ( \"github.com/gin-gonic/gin\" \"net/http\" \"time\" ) func HelloHandler(c *gin.Context) { // 睡一秒 time.Sleep(time.Second) c.JSON(http.StatusOK, gin.H{\"message\": \"Hello, World!\"}) } func main() { r := gin.Default() r.GET(\"/hello\", HelloHandler) _ = r.Run(\":8080\") } 测试： 1）新建压力测试 2）配置线程组 线程数： 5000 ， 线程数量 ramp-up：表示在指定时间之内把这些线程全部启动起来。 这里表示 5s以内把 5000 个线程全部启动起来。 循环次数：20 ,表示把 5000 thread /5s 循环 20 次 3）配置HTTP接口 选择Java，选择keepalive方式，使用长连接的方式，防止频繁的建立连接，关闭连接消耗性能，这样我们的压测的性能消耗就会有部分消耗在建立，关闭连接的网络消耗上，这样会导致我们的压测数据不准确 4）配置结果监听： 配置监听器：监听压测结果【聚合报告和汇总结果很类似，看一个就行】 聚合报告：查询结果信息聚合汇总，例如样本、平均值、通吐量、最大值、最小值… 图像结果：分析了所有请求的平均值、终止、偏离值和通吐量之间的关系。 汇总结果：汇总压测结果 汇总图：将压测结果以图像形式展示 察看结果树：记录每一次压测请求 启动后保存报告，查看gin程序 查看报告1）聚合报告： 样本（sample）: 发送请求的总样本数量 响应时间【单位ms】： 平均值（average）：平均的响应时间 中位数（median）: 中位数的响应时间，50%请求的响应时间 90%百分位（90% Line）: 90%的请求的响应时间，意思就是说90%的请求是&lt;=1149ms返回，另外10%的请求是大于等于1149ms返回的。 95%百分位（95% Line）: 95%的请求的响应时间，95%的请求都落在1463ms之内返回的 99%百分位（99% Line）: 99%的请求的响应时间 最小值(min)：请求返回的最小时间，其中一个用时最少的请求 最大值(max)：请求返回的最大时间，其中一个用时最大的请求 异常（error）: 出现错误的百分比，错误率=错误的请求的数量/请求的总数 吞吐量TPS（throughout）: 吞吐能力，这个才是我们需要的并发数!!! Received KB/sec—-每秒从服务器端接收到的数据量 Sent KB/sec—-每秒从客户端发送的请求的数量 2）汇总报告 样本（sample）: 发送请求的总样本数量 响应时间【单位ms】： 平均值（average）：平均的响应时间 最小值(min)：请求返回的最小时间，其中一个用时最少的请求 最大值(max)：请求返回的最大时间，其中一个用时最大的请求 标准偏差：度量响应时间分布的分散程度的标准，衡量响应时间值偏离平均响应时间的程度。标准偏差越小，偏离越少，反之亦然。 异常（error）: 出现错误的百分比，错误率=错误的请求的数量/请求的总数 吞吐量TPS（throughout）: 吞吐能力，这个才是我们需要的并发数 每秒接收 KB/sec—-每秒从服务器端接收到的数据量 每秒发送KB/sec—-每秒从客户端发送的请求的数量 平均字节数 3）查看结果树 记录了样本的每一次请求 4）图形结果 分析了所有请求的平均值、终止、偏离值和通吐量之间的关系 横坐标：为请求数量，单位个数 纵坐标：响应时间，单位ms 线程属性参数原理 线程属性参数原理结论： 线程数设置：根据项目并发需求确定 Ramp-Up Period设置：不宜过小也不宜设置过大，经验的做法是设置ramp-up period等于总线程数 循环次数：决定测试执行时间 参数基本概念线程数： 线程组常用来模拟并发用户访问，每个线程均独立运行测试计划。 循环次数：循环执行多少次操作 循环次数表示了循环执行多少次操作！循环次数直接决定整个测试单个线程的执行时间，和整体测试执行时间。 单线程执行时间 = 单请求平均响应时间 * 循环次数 整个测试耗时 = 单线程执行时间 + (Ramp-Up - Ramp-Up / 线程数) Ramp-Up：建立全部线程耗时 Ramp-Up Period(in-seconds)代表隔多长时间执行， 0 代表同时并发 用于告知JMeter 要在多长时间内建立全部的线程，默认值是 0 。 为什么需要有Ramp-Up Period，立刻创建出来所有的线程不是更好？ 目的是为了模拟大部分网站的真实用户并发场景 对于绝大多数的网址或应用，更真实的情况是并发用户逐渐递增，而不是从一开始便立即有大量并发的用户，“ramp-up period”概念的引入可以覆盖测试这个场景；","categories":[{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"测试小技巧","slug":"测试小技巧","permalink":"https://kiritoabc.github.io/tags/%E6%B5%8B%E8%AF%95%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"sqlc和sqlx的使用","slug":"sqlx和sqlc","date":"2024-03-18T09:39:39.166Z","updated":"2024-03-18T09:39:39.166Z","comments":true,"path":"2024/03/18/sqlx和sqlc/","permalink":"https://kiritoabc.github.io/2024/03/18/sqlx%E5%92%8Csqlc/","excerpt":"什么是sqlc和sqlx? github上有解释，可以自行查找 https://github.com/sqlc-dev/sqlc https://github.com/jmoiron/sqlx","text":"什么是sqlc和sqlx? github上有解释，可以自行查找 https://github.com/sqlc-dev/sqlc https://github.com/jmoiron/sqlx sqlx的使用sqlx连接数据库–Connect 连接mysql数据库 import ( \"fmt\" _ \"github.com/go-sql-driver/mysql\" \"github.com/jmoiron/sqlx\" ) var DB *sqlx.DB func initMysql() (err error) { dsn := \"root:123456@tcp(127.0.0.1:3306)/demo\" DB, err = sqlx.Connect(\"mysql\", dsn) if err != nil { _ = fmt.Sprintf(\"database connect error: %v\\n\", err) return err } DB.SetMaxOpenConns(200) DB.SetMaxIdleConns(20) return } sqlx查询数据–Get,Select 查询单行记录可以使用 type User struct { Id int64 `db:\"id\"` Age int64 `db:\"age\"` FirstName string `db:\"firstName\"` LastName string `db:\"lastName\"` } func QueryRowById(id int64) (user User, err error) { err = DB.Get(&amp;user, \"select * from user where id = ?\", id) if err != nil { return } return } 查询多行记录 func SelectMData() ([]*User, error) { var list []*User err := DB.Select(&amp;list, \"select * from user order by id desc\") if err != nil { return list, err } return list, err } sqlx的Exec执行sql Exec and MustExec get a connection from the connection pool and executes the provided query on the server. For drivers that do not support ad-hoc query execution, a prepared statement may be created behind the scenes to be executed. The connection is returned to the pool before the result is returned. func ExecSQL() { schema := `CREATE TABLE place ( country text, city text NULL, telcode integer);` result, err := DB.Exec(schema) if err != nil { return } fmt.Println(result) // or, you can use MustExec, which panics on error cityState := `INSERT INTO place (country, telcode) VALUES (?, ?)` countryCity := `INSERT INTO place (country, city, telcode) VALUES (?, ?, ?)` DB.MustExec(cityState, \"Hong Kong\", 852) DB.MustExec(cityState, \"Singapore\", 65) DB.MustExec(countryCity, \"South Africa\", \"Johannesburg\", 27) } sqlx绑定数据 MySQL uses the ? variant shown above PostgreSQL uses an enumerated $1, $2, etc bindvar syntax SQLite accepts both ? and $1 syntax Oracle uses a :name syntax sqlx查询–Query Query is the primary way to run queries with database/sql that return row results. Query returns an sql.Rows object and an error: Query的使用 func QueryDemo() { // 查询数据库 rows, err := DB.Query(\"select * from user\") if err != nil { return } // 迭代器取数据 for rows.Next() { var id int64 var firstNam string var lastname string var age int64 rows.Scan(&amp;id, &amp;firstNam, &amp;lastname, &amp;age) fmt.Printf(\"id:%d, firstname:%s, lastname:%s, age:%d\\n\", id, firstNam, lastname, age) } } Queryx使用 The sqlx extension Queryx behaves exactly as Query does, but returns an sqlx.Rows, which has extended scanning behaviors: func QueryxDemo() { rows, err := DB.Queryx(\"select * from user\") if err != nil { return } for rows.Next() { var u User err := rows.StructScan(&amp;u) if err != nil { return } fmt.Printf(\"id:%d, firstname:%s, lastname:%s, age:%d\\n\", u.Id, u.FirstName, u.LastName, u.Age) } } sqlx的Transactions To use transactions, you must create a transaction handle with DB.Begin(). Code like this will not work: // this will not work if connection pool > 1 db.MustExec(\"BEGIN;\") db.MustExec(...) db.MustExec(\"COMMIT;\") 请记住，Exec和所有其他查询谓词都会向DB请求连接，然后每次将其返回到池中。不能保证您将接收到执行BEGIN语句的相同连接。因此，要使用事务，必须使用DB.Begin() tx, err := db.Begin() err = tx.Exec(...) err = tx.Commit() // 或者 tx := db.MustBegin() tx.MustExec(...) err = tx.Commit() sqlx的Prepared Statementsstmt, err := db.Prepare(`SELECT * FROM place WHERE telcode=?`) row = stmt.QueryRow(65) tx, err := db.Begin() txStmt, err := tx.Prepare(`SELECT * FROM place WHERE telcode=?`) row = txStmt.QueryRow(852) // Preparex stmt, err := db.Preparex(`SELECT * FROM place WHERE telcode=?`) var p Place err = stmt.Get(&amp;p, 852) sqlx–Query HelpersIn Queries SELECT * FROM users WHERE level IN (?); var levels = []int{4, 6, 7} rows, err := db.Query(\"SELECT * FROM users WHERE level IN (?);\", levels) var levels = []int{4, 6, 7} query, args, err := sqlx.In(\"SELECT * FROM users WHERE level IN (?);\", levels) // sqlx.In returns queries with the `?` bindvar, we can rebind it for our backend query = db.Rebind(query) rows, err := db.Query(query, args...) Named Queries // named query with a struct p := Place{Country: \"South Africa\"} rows, err := db.NamedQuery(`SELECT * FROM place WHERE country=:country`, p) // named query with a map m := map[string]interface{}{\"city\": \"Johannesburg\"} result, err := db.NamedExec(`SELECT * FROM place WHERE city=:city`, m) p := Place{TelephoneCode: 50} pp := []Place{} // select all telcodes > 50 nstmt, err := db.PrepareNamed(`SELECT * FROM place WHERE telcode > :telcode`) err = nstmt.Select(&amp;pp, p) arg := map[string]interface{}{ \"published\": true, \"authors\": []{8, 19, 32, 44}, } query, args, err := sqlx.Named(\"SELECT * FROM articles WHERE published=:published AND author_id IN (:authors)\", arg) query, args, err := sqlx.In(query, args...) query = db.Rebind(query) db.Query(query, args...) sqlx–Controlling Name Mapping用作StructScans目标的结构字段必须大写，以便sqlx可以访问。因此，sqlx使用NameMapper来应用字符串。降低字段名称以将它们映射到行结果中的列。这并不总是理想的，这取决于您的模式，因此sqlx允许以多种方式定制映射。 其中最简单的方法是使用sqlx.DB为数据库句柄设置它。MapperFunc，它接收一个func(string) string类型的参数。如果你的库需要一个特定的映射器，并且你不想毒害你收到的sqlx.DB，你可以创建一个副本在库中使用，以确保一个特定的默认映射: // if our db schema uses ALLCAPS columns, we can use normal fields db.MapperFunc(strings.ToUpper) // suppose a library uses lowercase columns, we can create a copy copy := sqlx.NewDb(db.DB, db.DriverName()) copy.MapperFunc(strings.ToLower) 每个sqlx. db使用sqlx/reflectx包的映射器来实现底层映射，并将活动映射器公开为sqlx. db .Mapper。您可以通过直接设置来进一步定制DB上的映射: import \"github.com/jmoiron/sqlx/reflectx\" // Create a new mapper which will use the struct field tag \"json\" instead of \"db\" db.Mapper = reflectx.NewMapperFunc(\"json\", strings.ToLower) sqlx– Connection Pool Statement preparation and query execution require a connection, and the DB object will manage a pool of them so that it can be safely used for concurrent querying. There are two ways to control the size of the connection pool as of Go 1.2: DB.SetMaxIdleConns(n int) DB.SetMaxOpenConns(n int) 默认情况下，池无限制地增长，只要池中没有可用的空闲连接，就会创建连接。您可以使用DB。SetMaxOpenConns设置池的最大大小。未使用的连接被标记为空闲，如果不需要则关闭。为了避免建立和关闭大量连接，请使用DB设置最大空闲大小。SetMaxIdleConns设置为适合您的查询负载的大小。 一不小心抓住关系不放很容易惹上麻烦。为了防止这种情况: 确保Scan()每个Row对象 确保使用Close()或通过Next()对每个Rows对象进行完全迭代 确保每个事务通过Commit()或Rollback()返回其连接 如果您忽略了这些事情中的一件，它们使用的连接可能会被保留到垃圾收集，并且您的数据库最终将立即创建更多的连接以补偿它使用的连接。注意，Rows.Close()可以安全地调用多次，所以不要害怕在不必要的地方调用它。 sqlx + SquirrelSquirrel Squirrel is not an ORM. For an application of Squirrel, check out structable, a table-struct mapper package main import ( \"fmt\" _ \"github.com/go-sql-driver/mysql\" \"github.com/jmoiron/sqlx\" ) import sq \"github.com/Masterminds/squirrel\" var DB *sqlx.DB func initMysql() (err error) { dsn := \"root:123456@tcp(127.0.0.1:3306)/demo\" DB, err = sqlx.Connect(\"mysql\", dsn) if err != nil { _ = fmt.Sprintf(\"database connect error: %v\\n\", err) return err } DB.SetMaxOpenConns(200) DB.SetMaxIdleConns(20) return } func main() { fmt.Println(\"hello squirrel\") _ = initMysql() sql, args, err := sq.Select(\"*\"). From(\"user\"). Where(sq.Eq{\"id\": 2}).ToSql() fmt.Printf(\"sql: %s, args: %v, err: %v\\n\", sql, args[0], err) // select * from user where id = 2 var id int64 var firstNam string var lastname string var age int64 err = DB.QueryRow(sql, args...). Scan(&amp;id, &amp;age, &amp;firstNam, &amp;lastname) if err != nil { fmt.Println(err) return } fmt.Printf(\"id:%d, firstname:%s, lastname:%s, age:%d\\n\", id, firstNam, lastname, age) }","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端开发小技巧","slug":"后端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"","slug":"博客搭建","date":"2024-03-18T09:39:39.166Z","updated":"2024-03-18T09:39:39.166Z","comments":true,"path":"2024/03/18/博客搭建/","permalink":"https://kiritoabc.github.io/2024/03/18/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","excerpt":"","text":"abbrlink: ‘0’ 重构博客1.Hexo的安装 注意：默认你安装了node，git，并且你有一个自己的Github账号呀。没有的话自行搜索安装一下。 更多详情可以参考官网Hexo 安装hexo的脚手架hexo-cli npm install hexo-cli -g 创建一个hexo博客 hexo init # 安装一下git提交插件 npm install hexo-deployer-git --save 此时你可以本地启动查看一下 hexo generate hexo server 默认的效果如下 2.选取主题anzhiyu可以参官方的教程 https://github.com/anzhiyu-c/hexo-theme-anzhiyu 安装butterfly主题 在刚才的目录安装主题： git clone -b main https://github.com/anzhiyu-c/hexo-theme-anzhiyu.git themes/anzhiyu 应用主题 在Hexo的更目录下_config.yml，把主题修改一下butterfly theme: anzhiyu 安装插件 npm install hexo-renderer-pug hexo-renderer-stylus --save 官方建议 在 hexo 的根目錄創建一個文件 _config.butterfly.yml，並把主題目錄的 _config.yml 內容複製到 _config.butterfly.yml 去。( 注意: 複製的是主題的 _config.yml ，而不是 hexo 的 _config.yml) 注意： 不要把主題目錄的 _config.yml 刪掉 注意： 以後只需要在 _config.butterfly.yml 進行配置就行。如果使用了 _config.butterfly.yml， 配置主題的 _config.yml 將不會有效果。 Hexo會自動合併主題中的 _config.yml 和 _config.anzhiyu.yml 裏的配置，如果存在同名配置，會使用 _config.anzhiyu.yml 的配置，其優先度較高。 完成以上操作再次启动 hexo clean hexo g hexo s 3.hexo SEO优化依赖安装 配置文章连接跳转数字或字幕: https://github.com/rozbo/hexo-abbrlink npm install hexo-abbrlink --save 修改配置文件 _config.yml permalink: posts/:abbrlink.html # abbrlink config abbrlink: alg: crc32 #support crc16(default) and crc32 rep: hex #support dec(default) and hex 本地搜索依赖： https://github.com/wzpan/hexo-generator-search npm install hexo-generator-search --save 添加配置 _config.yml search: path: search.xml field: all content: true 修改 _config.butterfly.yml,将local_search 修改成true # Local search local_search: enable: true live2d: https://github.com/EYHN/hexo-helper-live2d # 安装live2d npm install --save hexo-helper-live2d # 安装模型 npm install --save live2d-widget-model-koharu 4.部署到Github pages.yml name: Pages on: push: branches: - master # default branch jobs: pages: runs-on: ubuntu-latest permissions: contents: write steps: - uses: actions/checkout@v2 - name: Use Node.js 16.x uses: actions/setup-node@v2 with: node-version: \"16\" - name: Cache NPM dependencies uses: actions/cache@v2 with: path: node_modules key: ${{ runner.OS }}-npm-cache restore-keys: | ${{ runner.OS }}-npm-cache - name: Install Dependencies run: npm install - name: Build run: npm run build - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public dependabot.yml version: 2 updates: - package-ecosystem: npm directory: \"/\" schedule: interval: daily open-pull-requests-limit: 20 这样子就可以通过idea上传到github上去了，注意创建的仓库名字要与你的github名字一样(name.github.io)，例如： zhangsan.zhangsan.githun.io 5.美化博客https://Kiritoabc.github.io","categories":[],"tags":[]},{"title":"前端文件上传","slug":"前端文件上传","date":"2024-03-18T09:39:39.166Z","updated":"2024-03-18T09:39:39.166Z","comments":true,"path":"2024/03/18/前端文件上传/","permalink":"https://kiritoabc.github.io/2024/03/18/%E5%89%8D%E7%AB%AF%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/","excerpt":"用于记录我开发过程中碰到的文件上传方式","text":"用于记录我开发过程中碰到的文件上传方式 material ui的文件上传如果您正在使用 Material UI 并想要实现图片上传功能，可以使用 Material UI 的 Input 组件和 IconButton 组件，以及 HTML 的 input 标签和 label 标签来实现。 首先，您需要在 React 组件中创建一个 state 来存储上传的图片，例如： const [selectedFile, setSelectedFile] = useState(null); 然后，在 render 函数中，您可以创建一个包含 Input 组件和 IconButton 组件的 label 标签，如下所示： &lt;label htmlFor=\"upload-photo\"> &lt;Input style={{ display: 'none' }} id=\"upload-photo\" type=\"file\" onChange={handleFileInputChange} /> &lt;IconButton color=\"primary\" component=\"span\"> &lt;PhotoCamera /> &lt;/IconButton> &lt;/label> 在这里，Input 组件是隐藏的，而 IconButton 组件则显示为相机图标。当用户点击相机图标时，将触发与 Input 组件相关联的文件选择对话框。选择文件后，会调用 handleFileInputChange 函数来更新 selectedFile 状态。此外，htmlFor 属性将 label 组件与 Input 组件相关联，这样当用户点击相机图标时，也会触发文件选择对话框。 最后，您可以使用 selectedFile 状态来将上传的文件显示在您的组件中。 完整的代码示例如下： import React, { useState } from 'react'; import { Input, IconButton } from '@material-ui/core'; import { PhotoCamera } from '@material-ui/icons'; function ImageUpload() { const [selectedFile, setSelectedFile] = useState(null); const handleFileInputChange = (event) => { setSelectedFile(event.target.files[0]); }; return ( &lt;div> &lt;label htmlFor=\"upload-photo\"> &lt;Input style={{ display: 'none' }} id=\"upload-photo\" type=\"file\" onChange={handleFileInputChange} /> &lt;IconButton color=\"primary\" component=\"span\"> &lt;PhotoCamera /> &lt;/IconButton> &lt;/label> {selectedFile &amp;&amp; ( &lt;img src={URL.createObjectURL(selectedFile)} alt=\"uploaded\" /> )} &lt;/div> ); } export default ImageUpload; 如果要使用axios上传的话，可以用axios二次封装的发送请求，如: 封装好的请求: export function uploadTeachingVideo(data){ return request.post(\"/teachingVideo/upload\",data) } 在页面使用: // 创建FormData对象来上传文件 let formData = new FormData(); formData.append(\"video\",video) formData.append('videoIcon', videoIcon); // 添加上传的视频文件 formData.append('videoName', videoName); // 添加视频名称 formData.append('group', group); // 添加视频分组 formData.append('videoType', videoType); // 添加视频类型 uploadTeachingVideo( formData) // 上传到服务器，替换为你的上传端点 .then(response => { console.log(response); // 处理成功的响应，你可能需要在这里添加逻辑来处理上传成功的情况，例如重定向到另一个页面或显示消息给用户 }) .catch(error => { console.error(error); // 处理错误响应，你可能需要在这里添加逻辑来处理上传失败的情况，例如显示错误消息给用户 }); // 清除上传的视频和图标，以便用户可以上传另一个视频 setVideoIcon(null); setVideo(null);","categories":[{"name":"前端","slug":"前端","permalink":"https://kiritoabc.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端开发小技巧","slug":"前端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"prometheus","slug":"prometheus","date":"2024-03-18T09:39:39.162Z","updated":"2024-03-18T09:39:39.162Z","comments":true,"path":"2024/03/18/prometheus/","permalink":"https://kiritoabc.github.io/2024/03/18/prometheus/","excerpt":"Prometheus 是云原生计算基金会的一个项目，是一个系统和服务监控系统。它收集指标 从给定时间间隔的配置目标中，评估规则表达式， 显示结果，并可在观察到指定条件时触发警报。 Prometheus 与其他指标和监控系统的区别在于： 多维数据模型（由指标名称和键/值维度集定义的时间序列） PromQL，一种强大而灵活的查询语言，用于利用此维度 不依赖分布式存储;单服务器节点是自治的 用于时序集合的 HTTP 拉取模型 支持通过中间网关推送批处理作业的时序 通过服务发现或静态配置****发现目标 支持多种绘图和仪表板模式 支持分层和水平联合","text":"Prometheus 是云原生计算基金会的一个项目，是一个系统和服务监控系统。它收集指标 从给定时间间隔的配置目标中，评估规则表达式， 显示结果，并可在观察到指定条件时触发警报。 Prometheus 与其他指标和监控系统的区别在于： 多维数据模型（由指标名称和键/值维度集定义的时间序列） PromQL，一种强大而灵活的查询语言，用于利用此维度 不依赖分布式存储;单服务器节点是自治的 用于时序集合的 HTTP 拉取模型 支持通过中间网关推送批处理作业的时序 通过服务发现或静态配置****发现目标 支持多种绘图和仪表板模式 支持分层和水平联合 prometheus简单的使用 快速使用尝试首先保存如下配置prometheus.yml文件 global: scrape_interval: 15s # 默认情况下，每 15s 采集一次目标数据 # 与外部系统(如 federation, remote storage, Alertmanager)通信时，可以将这些标签应用到到和时间序列或告警上 external_labels: monitor: 'codelab-monitor' # 仅包含一个采集端点的采集配置：这里是 Prometheus 本身 scrape_configs: # 作业名称作为标签 `job=&lt;job_name>` 添加到从此配置中采集的时间序列上 - job_name: 'prometheus' # 覆盖全局默认的参数，并将采样时间间隔设置为 5s scrape_interval: 5s static_configs: - targets: ['localhost:9090'] docker启动 docker run --name prometheus -d -p 9090:9090 -v D:\\docker\\data\\prometheus\\prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus 使用表达式浏览器我们来尝试查看 Prometheus 采集的有关自身的一些数据。要使用 Prometheus 的内置表达式浏览器，请导航至 http://localhost:9090/graph 并在 “Graph” 页面选择 “Console” 视图。 在 localhost:9090/metrics 的数据采集中，Prometheus 导出了一个称为prometheus_target_interval_length_seconds(目标数据收集的实际时间)的数据指标。将其输入表达式控制台并点击 “Execute”： prometheus_target_interval_length_seconds 这将会返回很多种不通的时间序列(及时间序列记录的最新值)，所有的时间序列的名称均为prometheus_target_interval_length_seconds，但是带有不同的标签。这些标签指定了不同的延迟百分比和和目标组间隔。 如果我们仅仅对第 99 个百分位的延迟感兴趣，则我们可以使用下面的语句来查询该信息： prometheus_target_interval_length_seconds{quantile=\"0.99\"} 想要统计返回时间序列的个数，您可以执行： count(prometheus_target_interval_length_seconds) 有关表达式语言的更多信息，请见表达式语言文档 使用图形化接口请导航至 http://localhost:9090/graph 并使用 “Graph” 视图来使用图形表达式。 例如，输入以下表达式来绘制自身采集中Prometheus 每秒创建块的速率： rate(prometheus_tsdb_head_chunks_created_total[1m]) 在 graph 页面使用其它参数和设置进行实验。 PromQL Prometheus UI是Prometheus内置的一个可视化管理界面，通过Prometheus UI用户能够轻松的了解Prometheus当前的配置，监控任务运行状态等。 通过Graph面板，用户还能直接使用PromQL实时查询监控数据： 监控数据的可视化 Prometheus UI提供了快速验证PromQL以及临时可视化支持的能力，而在大多数场景下引入监控系统通常还需要构建可以长期使用的监控数据可视化面板（Dashboard）。这时用户可以考虑使用第三方的可视化工具如Grafana，Grafana是一个开源的可视化平台，并且提供了对Prometheus的完整支持。 docker run -d -p 3000:3000 grafana/grafana 访问http://localhost:3000就可以进入到Grafana的界面中，默认情况下使用账户admin/admin进行登录。在Grafana首页中显示默认的使用向导，包括：安装、添加数据源、创建Dashboard、邀请成员、以及安装应用和插件等主要流程: 添加数据源 2.选择Prometheus 填写prometheus的基本信息 在完成数据源的添加之后就可以在Grafana中创建我们可视化Dashboard了。Grafana提供了对PromQL的完整支持，如下所示，通过Grafana添加Dashboard并且为该Dashboard添加一个类型为“Graph”的面板。 并在该面板的“Metrics”选项下通过PromQL查询需要可视化的数据： 点击界面中的保存选项，就创建了我们的第一个可视化Dashboard了。 当然作为开源软件，Grafana社区鼓励用户分享Dashboard通过https://grafana.com/dashboards网站，可以找到大量可直接使用的Dashboard： 更多学习内容可以学习：https://yunlzheng.gitbook.io/prometheus-book/","categories":[{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/tags/go/"}],"author":"菠萝"},{"title":"kafka的基本使用","slug":"kafka","date":"2024-03-18T09:39:39.158Z","updated":"2024-03-18T09:39:39.158Z","comments":true,"path":"2024/03/18/kafka/","permalink":"https://kiritoabc.github.io/2024/03/18/kafka/","excerpt":"Kafka 结合了三个关键功能，因此您可以使用 一个经过实战检验的解决方案来实现端到端事件流的 用例： 发布（写入）和订阅（读取）事件流，包括从其他系统持续导入/导出数据。 根据需要持久可靠地存储事件 流。 在事件发生时或回顾性地 处理 事件流。","text":"Kafka 结合了三个关键功能，因此您可以使用 一个经过实战检验的解决方案来实现端到端事件流的 用例： 发布（写入）和订阅（读取）事件流，包括从其他系统持续导入/导出数据。 根据需要持久可靠地存储事件 流。 在事件发生时或回顾性地 处理 事件流。 Kafka启动拉取镜像 docker pull bitnami/kafka 启动kafka 参考：https://hub.docker.com/r/bitnami/kafka 第一步：创建网络 docker network create kafka-learn --driver bridge 第二步：启动 kafka 服务器实例(windows powershell)注意此处是使用kraft模式 集群的部署 docker-compose up -d version: \"3\" services: kafka1: image: docker.io/bitnami/kafka:latest container_name: kafka1 restart: always ports: - 19092:9092 - 19093:9093 volumes: - D:\\docker\\data\\kafka\\kafka1\\data:/bitnami/data privileged: true environment: #是否使用KRaft模式 KAFKA_ENABLE_KRAFT: yes KAFKA_CFG_PROCESS_ROLES: broker,controller KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093 KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT KAFKA_KRAFT_CLUSTER_ID: VaW86rUCTMmoxIcDiER_lA KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093 ALLOW_PLAINTEXT_LISTENER: yes KAFKA_HEAP_OPTS: -Xmx512M -Xms256M KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true #broker单独配置 KAFKA_CFG_NODE_ID: 1 KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:19092 kafka2: image: docker.io/bitnami/kafka:latest container_name: kafka2 restart: always ports: - 29092:9092 - 29093:9093 volumes: - D:\\docker\\data\\kafka\\kafka2\\data:/bitnami/data privileged: true environment: KAFKA_ENABLE_KRAFT: yes KAFKA_CFG_PROCESS_ROLES: broker,controller KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093 KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT KAFKA_KRAFT_CLUSTER_ID: VaW86rUCTMmoxIcDiER_lA KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093 ALLOW_PLAINTEXT_LISTENER: yes KAFKA_HEAP_OPTS: -Xmx512M -Xms256M KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true #broker单独配置 KAFKA_CFG_NODE_ID: 2 KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:29092 kafka3: image: docker.io/bitnami/kafka:latest container_name: kafka3 restart: always ports: - 39092:9092 - 39093:9093 volumes: - D:\\docker\\data\\kafka\\kafka3\\data:/bitnami/data privileged: true environment: KAFKA_ENABLE_KRAFT: yes KAFKA_CFG_PROCESS_ROLES: broker,controller KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093 KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT KAFKA_KRAFT_CLUSTER_ID: VaW86rUCTMmoxIcDiER_lA KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093 ALLOW_PLAINTEXT_LISTENER: yes KAFKA_HEAP_OPTS: -Xmx512M -Xms256M KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true #broker单独配置 KAFKA_CFG_NODE_ID: 3 KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:39092 kafka-ui: image: provectuslabs/kafka-ui:latest network_mode: kafka-learn container_name: kafka-ui restart: always ports: - 19091:8080 volumes: - D:\\docker\\data\\kafka-ui:/etc/localtime environment: # 集群名称 - KAFKA_CLUSTERS_0_NAME=local # 集群地址 - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9092,kafka3:9092 networks: default: external: true name: kafka-learn 单机的部署 version: '3' services: kafka-server: image: bitnami/kafka:latest container_name: kafka-server hostname: kafka-server networks: - kafka-learn ports: - \"9092:9092\" - \"9093:9093\" environment: - KAFKA_CFG_NODE_ID=0 - KAFKA_CFG_PROCESS_ROLES=controller,broker - KAFKA_CFG_LISTENERS=PLAINTEXT://localhost:9092,CONTROLLER://localhost:9093 - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-server:9093 - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER networks: default: external: true name: kafka-learn docker run启动 docker run -d --name kafka-server --hostname kafka-server --network kafka-learn ` -p 9092:9092 ` -p 9093:9093 ` -e KAFKA_CFG_NODE_ID=0 ` -e KAFKA_CFG_PROCESS_ROLES=controller,broker ` -e KAFKA_CFG_LISTENERS=PLAINTEXT://localhost:9092,CONTROLLER://localhost:9093 ` -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT ` -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-server:9093 ` -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER ` bitnami/kafka:latest kafka-ui docker-compose.yaml文件集群模式 version: \"3\" services: kafka-ui: image: provectuslabs/kafka-ui:latest network_mode: kafka-learn container_name: kafka-ui restart: always ports: - 19091:8080 volumes: - D:\\docker\\data\\kafka-ui:/etc/localtime environment: # 集群名称 - KAFKA_CLUSTERS_0_NAME=local # 集群地址 - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9092,kafka3:9092 单kafka模式 version: '3' services: kafka-single-broker: image: confluentinc/cp-kafka:latest # 确保使用的镜像版本支持KRaft模式 container_name: kafka-single-broker hostname: kafka ports: - \"9092:9092\" - \"9093:9093\" # Kafka内部使用的控制器监听端口 environment: KAFKA_BROKER_ID: 1 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 KAFKA_DELETE_TOPIC_ENABLE: \"true\" KAFKA_INTER_BROKER_PROTOCOL_VERSION: \"2.8\" # 根据你的Kafka版本选择合适的协议版本 KAFKA_AUTO_LEADER_REBALANCE_ENABLE: \"false\" KAFKA_DEFAULT_REPLICATION_FACTOR: 1 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093 KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_BOOTSTRAP_SERVERS: kafka:9092 KAFKA_KRAFT_CLUSTER_ID: my-cluster-id # 设置唯一的Kafka Raft集群ID KAFKA_NUM_PARTITIONS: 1 kafka-ui: image: provectuslabs/kafka-ui container_name: kafka-ui restart: always ports: - \"8080:8080\" environment: KAFKA_CLUSTERS_0_NAME: Local Kafka Cluster KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-single-broker:9092 # 如果需要安全认证，请在此处添加相关配置 networks: default: name: kafka-net 创建网络 docker network create app-tier --driver bridge 启动服务 docker run -d --name kafka-server --hostname kafka-server ` --network app-tier ` -e KAFKA_CFG_NODE_ID=0 ` -e KAFKA_CFG_PROCESS_ROLES=controller,broker ` -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 ` -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT ` -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-server:9093 ` -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER ` bitnami/kafka:latest kafka客户端 docker run -it --rm ` --network app-tier ` bitnami/kafka:latest kafka-topics.sh --list --bootstrap-server kafka-server:9092 概述 Apache Kafka 是一款开源分布式流处理平台。可以用来发布和订阅数据以及对数据进行实时或者离线处理。 特点 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作； 扩展性强：支持分布式集群部署，且kafka集群支持热扩展； 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失； 容错性强：允许集群中节点失败。（最多允许n-1个节点失败）； 高并发：支持多个客户端同时读写； 支持实时在线处理和离线处理：可以使用storm实时流处理系统对消息进行实时处理，同时还支持hadoop这种批处理系统进行离线处理； 多客户端支持：比如java、golang等； 主要应用场景 消息系统：常规的消息队列中间件，实现异步解耦、削峰等功能 日志收集：Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如Hadoop、Hbase、Solr等； 数据监控：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告； 流式处理：比如spark streaming和storm； Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到Hadoop、数据仓库中做离线分析和挖掘； 基本概念Broker每个Broker即一个kafka服务实例，多个broker构成一个kafka集群。生产者发布的消息保存在broker中，消费者从broker获取消息进行消费。 在集群中，根据每个kafka实例担任的角色可分为leader(controller)和broker。 Topickafka中将消息分类，每一类消息称为一个Topic，生产者通过指定Topic将消息发送到broker中，消费者通过指定Topic可以针对不同的Topic采取不同的消费逻辑。Topic有点类似于数据库的表。 Partition一个Topic可以分为多个Partition，每个Partition是一个有序队列，在Partition中每条消息都存在一个有序的偏移量offset代表这条消息在paitition中的位置。在一个Topic的多个partition中，分为leader和follower，只有leader进行读写操作，follower仅进行复制，客户端无法感知。 在一个集群中，同一个topic的不同partition可分布在不同的broker中，以保证数据安全可用。 Replica为了保证数据安全，partition有多个副本，至少会有一个leader副本和多个follower副本。leader负责处理客户端的读写请求，follower副本只复制leader副本的数据。当leader宕机时，follower会自动接替leader副本的工作，从而保证数据的可用性。 Producer生产者，负责生产消息，并发送到broker。 Consumer消费者，负责消费broker中topic消息，每个consumer归属于一个consumer group。 ​ 各组件关系 Kafka版本变更（重点） 在kafka版本2.8以前，kafka集群通过zookeeper进行集群管理，从2.8.0版本开始，kafka提供了另一种管理模式：KRaft。 KRaft模式KRaft 是 “Kafka” 和 “Raft” 的组合词，其中 Raft 是一个用于管理复制日志的分布式一致性算法。在 KRaft 模式中，Kafka 使用 Raft 协议来实现集群的元数据管理，包括主题配置、分区副本分配、访问控制列表等。 在 KRaft 模式下，Kafka 集群中的一个或多个 broker 将被指定为 controller，它们负责管理集群的元数据。当一个 controller 出现故障时，其他的 broker 可以通过 Raft 协议的领导者选举机制来选举出一个新的 controller。 它使得 Kafka 能够在没有 Apache ZooKeeper 的情况下运行。KRaft 模式的主要目标是简化 Kafka 的架构，提高其性能和稳定性。 两种模式对比架构复杂性及性能zookeeper模式：部署kafka集群时，必然要部署对应的zookeeper集群，既增加了系统的复杂性，同时也需要对zookeeper进行维护。kafka的性能不仅受到本身资源的限制，也受到zookeeper本身的限制以及kafka与zookeeper通信之间的限制。 KRaft模式：KRaft模式消除了kafka集群对zookeeper的依赖，降低了kafka部署及维护的难度；同时也消除了因zookeeper本身限制、通信方面的瓶颈以及由于引入zookeeper带来的系统风险，提高了kafka集群的性能和稳定性。 leader选举在 Kafka 集群中，Controller 是一个非常重要的角色。Kafka 集群会选举出一个 Broker 作为 Controller，这个 Controller 主要负责管理和协调整个 Kafka 集群中的分区和副本。 分区 Leader 的选举：当某个分区的 Leader 副本发生故障时，Controller 负责从该分区的 Follower 副本中选举出一个新的 Leader。 副本状态的管理：Controller 负责跟踪所有副本的状态，并在副本状态发生变化时进行相应的处理。例如，当一个新的副本加入到集群时，Controller 会将其状态设置为 “ReplicaOnline”。 Topic 和分区的管理：当创建或删除 Topic 时，Controller 负责在各个 Broker 上创建或删除相应的分区。 Broker 状态的监控：Controller 会持续监控集群中所有 Broker 的状态。当某个 Broker 发生故障时，Controller 会将其上的所有 Leader 分区迁移到其他健康的 Broker 上。 集群元数据的维护：Controller 负责维护 Kafka 集群的元数据，包括 Topic 配置、分区副本分配、访问控制列表等。 zookeeper模式：在zookeeper模式中，kafka的leader由zookeeper自行选举，用户无法指定。 KRaft模式： 在KRaft模式中，可以通过配置文件直接指定broker节点的角色（controller、broker），也可以由集群自己完成。 gin中接入kafka 在 Gin 框架中接入 Kafka 主要涉及两个部分：编写生产者（Producer）用于向 Kafka 发送消息，以及编写消费者（Consumer）用于从 Kafka 接收消息。以下是一个简单的示例流程： 参考库: confluentinc/confluent-kafka-go: Confluent’s Apache Kafka Golang client (github.com) 参考库: IBM/sarama: Sarama is a Go library for Apache Kafka. (github.com) 定义消费者 consumer.go package consumer import ( \"github.com/IBM/sarama\" \"log\" ) type KafKaConsumer struct { consumer sarama.Consumer topics []string } func NewKafkaConsumer(brokers []string, topics []string) (*KafKaConsumer, error) { config := sarama.NewConfig() config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin config.Consumer.Offsets.Initial = sarama.OffsetOldest config.Version = sarama.V3_6_0_0 consumer, err := sarama.NewConsumer(brokers, config) if err != nil { return nil, err } return &amp;KafKaConsumer{consumer: consumer, topics: topics}, nil } func (kc *KafKaConsumer) ConsumeMessages(handler func(message *sarama.ConsumerMessage) error) error { for _, topic := range kc.topics { partitionList, err := kc.consumer.Partitions(topic) if err != nil { return err } for _, partition := range partitionList { pc, err := kc.consumer.ConsumePartition(topic, partition, sarama.OffsetNewest) if err != nil { return err } go func(pc sarama.PartitionConsumer) { defer pc.Close() for msg := range pc.Messages() { if err := handler(msg); err != nil { log.Println(\"Error handling message:\", err) } } }(pc) } } return nil } 定义producer producer.go package producer import ( \"fmt\" \"github.com/IBM/sarama\" ) type KafkaProducer struct { producer sarama.SyncProducer } func NewKafkaProducer(brokers []string) (*KafkaProducer, error) { config := sarama.NewConfig() config.Producer.Return.Successes = true config.Version = sarama.V3_6_0_0 // 设置 Kafka 版本兼容性 p, err := sarama.NewSyncProducer(brokers, config) if err != nil { return nil, err } return &amp;KafkaProducer{producer: p}, nil } // 发送消息到 Kafka func (kp *KafkaProducer) SendMessage(topic string, message string) error { msg := &amp;sarama.ProducerMessage{ Topic: topic, Value: sarama.StringEncoder(message), } partition, offset, err := kp.producer.SendMessage(msg) if err != nil { return err } fmt.Printf(\"Message was produced to topic %s partition %d at offset %d\\n\", topic, partition, offset) return nil } main.go package main import ( \"fmt\" \"github.com/IBM/sarama\" \"github.com/gin-gonic/gin\" \"kafka-learn/consumer\" \"kafka-learn/producer\" \"log\" \"net/http\" ) func main() { router := gin.Default() kafkaProducer, err := producer.NewKafkaProducer([]string{\"localhost:19092\", \"localhost:29092\", \"localhost:39092\"}) if err != nil { panic(err) } // producer router.POST(\"/send-to-kafka\", func(c *gin.Context) { message := c.PostForm(\"message\") topic := \"my-topic\" if err := kafkaProducer.SendMessage(topic, message); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) return } c.JSON(http.StatusOK, gin.H{\"message\": \"Message sent to Kafka\"}) }) kafkaConsumer, err := consumer.NewKafkaConsumer([]string{\"localhost:19092\", \"localhost:29092\", \"localhost:39092\"}, []string{\"my-topic\"}) if err != nil { panic(err) } // consumer handler := func(msg *sarama.ConsumerMessage) error { fmt.Printf(\"Received message from topic %s partition %d offset %d: %s\\n\", msg.Topic, msg.Partition, msg.Offset, string(msg.Value)) // 在这里处理消息逻辑... return nil } go func() { if err := kafkaConsumer.ConsumeMessages(handler); err != nil { log.Fatal(\"Error consuming messages:\", err) } }() router.GET(\"/hello\", func(c *gin.Context) { c.JSON(200, gin.H{\"message\": \"Hello, World!\"}) }) router.Run(\":8080\") }","categories":[{"name":"中间件","slug":"中间件","permalink":"https://kiritoabc.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://kiritoabc.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"author":"菠萝"},{"title":"为什么学GO？GO是什么？怎么学GO？","slug":"WWH-01","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/WWH-01/","permalink":"https://kiritoabc.github.io/2024/03/18/WWH-01/","excerpt":"","text":"我为什么学GO 首先申明，我是一名大三的学生！以下学习GO的观点属于个人观点，只提供参考。 第一次听说go的契机 契机：就是由于听到同学在学，然后当时了解到的Docker的容器化技术是Go语言编写的，于是开始对于Go有了一些兴趣。 隔壁的哥哥推荐 推荐：由于在大二寒假的时候，对于技术的热爱(当时可能就只是想学更多东西吧)，询问了他如何学习，他和我分享了许多如何提升自己，还有一些基础知识十分重要和设计模式的重要性。并且他还推荐我学习Go语言。 网络上的说法（当然网络上众说风云） 学习GO语言主要是因为它在安全领域的应用，它是区块链最主流的编程语言，同时也是当前最具发展潜力的语言。它支持数据处理和大并发处理能力，能有效解决我的很多问题。Go语言是Google公司创造的语言，也是Google主推的语言。国外如Google、AWS、Cloudflare、CoreOS等，国内如七牛、阿里、小米、京东等都已经开始大规模使用Golang开发其云计算相关产品。 以下是一些参考 https://bbs.huaweicloud.com/blogs/279117 为什么要学go语言，golang的优势有哪些？ - 知乎 (zhihu.com) Go是什么？ Go is a new language. Although it borrows ideas from existing languages, it has unusual properties that make effective Go programs different in character from programs written in its relatives. A straightforward translation of a C++ or Java program into Go is unlikely to produce a satisfactory result—Java programs are written in Java, not Go. On the other hand, thinking about the problem from a Go perspective could produce a successful but quite different program. In other words, to write Go well, it’s important to understand its properties and idioms. It’s also important to know the established conventions for programming in Go, such as naming, formatting, program construction, and so on, so that programs you write will be easy for other Go programmers to understand. Go 是一门新语言。尽管它借鉴了现有语言的思想，但它具有不寻常的特性，这使得有效的 Go 程序在性质上与用其亲戚编写的程序不同。将 C++ 或 Java 程序直接翻译成 Go 不太可能产生令人满意的结果——Java 程序是用 Java 编写的，而不是用 Go 编写的。另一方面，从 Go 的角度思考问题可能会产生一个成功但完全不同的程序。换句话说，要写好 Go，了解它的属性和习语很重要。了解 Go 编程的既定约定也很重要，例如命名、格式、程序构造等，以便您编写的程序易于其他 Go 程序员理解。","categories":[{"name":"why? what? how?","slug":"why-what-how","permalink":"https://kiritoabc.github.io/categories/why-what-how/"}],"tags":[{"name":"1","slug":"1","permalink":"https://kiritoabc.github.io/tags/1/"}],"author":"菠萝"},{"title":"canal","slug":"canal","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/canal/","permalink":"https://kiritoabc.github.io/2024/03/18/canal/","excerpt":"","text":"canal简介 **canal [kə’næl]**，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费 早期阿里巴巴因为杭州和美国双机房部署，存在跨机房同步的业务需求，实现方式主要是基于业务 trigger 获取增量变更。从 2010 年开始，业务逐步尝试数据库日志解析获取增量变更进行同步，由此衍生出了大量的数据库增量订阅和消费业务。 基于日志增量订阅和消费的业务包括 数据库镜像 数据库实时备份 索引构建和实时维护(拆分异构索引、倒排索引等) 业务 cache 刷新 带业务逻辑的增量数据处理 工作原理MySQL主备复制原理 MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看) MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log) MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据 canal工作原理 canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议 MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal ) canal 解析 binary log 对象(原始为 byte 流) 使用这里我们使用docker启动 首先创建网络 docker network create canal-test 启动mysql docker run -d --name mysql-server ` -p 3306:3306 ` -v /D/docker/go-zero-12306/mysql/conf:/etc/mysql/conf.d ` -e MYSQL_ROOT_PASSWORD=123456 ` --network=canal-test ` mysql:8 启动canal docker run -d --name canal-instance ` --network=canal-test ` -e CANAL_INSTANCE_MASTER_ADDRESS=mysql-server ` -e CANAL_INSTANCE_DBUSERNAME=root ` -e CANAL_INSTANCE_DBPASSWORD=123456 ` -e CANAL_INSTANCE_CONNECTIONCHARSET=UTF-8 ` -e CANAL_INSTANCE_TSDB_ENABLE=true ` -e CANAL_INSTANCE_GTIDON=false ` -e CANAL_INSTANCE_FILTER_REGEX=\".*\\\\\\\\..*\" ` canal/canal-server:v1.1.1 cp容器中canal的配置文件 docker cp canal-instance:/home/canal/conf/instance.properties D:\\docker\\go-zero-12306\\canal\\","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://kiritoabc.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"author":"菠萝"},{"title":"Cron","slug":"cron","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/cron/","permalink":"https://kiritoabc.github.io/2024/03/18/cron/","excerpt":"​ 在使用定时调度任务的时候，我们最常用的，就是cron表达式了。通过cron表达式来指定任务在某个时间点或者周期性的执行。cron表达式配置起来简洁方便，无论是Spring的@Scheduled还是用Quartz框架，都支持cron表达式。但是理解cron表达式，还是需要花上几分钟的时间来学习的。 本次主要实在asynq的定时任务中又重新看到了，所以想把他掌握了，不再是去网上查查查。","text":"​ 在使用定时调度任务的时候，我们最常用的，就是cron表达式了。通过cron表达式来指定任务在某个时间点或者周期性的执行。cron表达式配置起来简洁方便，无论是Spring的@Scheduled还是用Quartz框架，都支持cron表达式。但是理解cron表达式，还是需要花上几分钟的时间来学习的。 本次主要实在asynq的定时任务中又重新看到了，所以想把他掌握了，不再是去网上查查查。 cron 表达式的组成​ cron表达式是一个字符串，由6到7个字段组成，用空格分隔。其中前6个字段是必须的，最后一个是可选的。每个字段的含义如图所示： 从左到右，依次对每个字段指定相应的值，就可以确定一个任务的执行时间点和周期了。 值可以由数字配合字符来组合。 99%的情况下会用到的字符在大部分使用cron的场景下， - * / ? 这几个常用字符就可以满足我们的需求了。 【*】：每的意思。在不同的字段上，就代表每秒，每分，每小时等。 【-】：指定值的范围。比如[1-10]，在秒字段里就是每分钟的第1到10秒，在分就是每小时的第1到10分钟，以此类推。 【,】：指定某几个值。比如[2,4,5]，在秒字段里就是每分钟的第2，第4，第5秒，以此类推。 【/】：指定值的起始和增加幅度。比如[3/5]，在秒字段就是每分钟的第3秒开始，每隔5秒生效一次，也就是第3秒、8秒、13秒，以此类推。 【?】：仅用于【日】和【周】字段。因为在指定某日和周几的时候，这两个值实际上是冲突的，所以需要用【?】标识不生效的字段。比如【0 1 * * * ?】就代表每年每月每日每小时的1分0秒触发任务。这里的周就没有效果了。","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端开发小技巧","slug":"后端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"flutter Android 打包","slug":"flutter打包程序","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/flutter打包程序/","permalink":"https://kiritoabc.github.io/2024/03/18/flutter%E6%89%93%E5%8C%85%E7%A8%8B%E5%BA%8F/","excerpt":"构建和发布为 Android 应用 呜呜呜，好麻烦啊，不想写。","text":"构建和发布为 Android 应用 呜呜呜，好麻烦啊，不想写。 呜呜呜","categories":[{"name":"前端","slug":"前端","permalink":"https://kiritoabc.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端开发小技巧","slug":"前端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"go时间处理","slug":"go时间处理","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/go时间处理/","permalink":"https://kiritoabc.github.io/2024/03/18/go%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/","excerpt":"由于在项目中对于时间的处理总是能看到不同的处理方式，Java中和go中都有不同的处理方式。每个人对于时间的处理方式也尽相同，主要记录go中对于时间的处理方式。 go在web项目中的时间处理","text":"由于在项目中对于时间的处理总是能看到不同的处理方式，Java中和go中都有不同的处理方式。每个人对于时间的处理方式也尽相同，主要记录go中对于时间的处理方式。 go在web项目中的时间处理 关于我在项目中看到的对于时间的表示在gin项目中使用gorm的时候 gorm中主要使用time.Time来表示时间和计算 在go-zero-looklook中 使用 int64–&gt;转换成time.Time go中时间处理常用方法时间的表示 Go 语言中时间的表示方式是通过 time.Time 结构体来表示的。time.Time 类型代表了一个时刻，它包含了年月日时分秒和纳秒等信息。 我们可以使用 time.Now() 函数获取当前时间，或者使用 time.Date() 函数创建一个指定的时间。 package main import ( \"fmt\" \"time\" ) func main() { fmt.Println(\"hello world\") // 获取当前时间 t1 := time.Now() fmt.Println(\"当前时间:\", t1) // 创建指定时间 t2 := time.Date(2023, 12, 26, 14, 0, 0, 0, time.Local) fmt.Println(\"指定时间:\", t2) } hello world 当前时间: 2023-12-26 13:53:31.5605696 +0800 CST m=+0.003511101 指定时间: 2023-12-26 14:00:00 +0800 CST 我们可以看到，当前时间和指定时间的格式都是 年-月-日 时:分:秒.纳秒 时区 的形式。 在Go语言中，还提供了一些常用的时间常量，如 time.RFC3339 和 time.RFC822 等。这些常量可以用于解析或格式化时间字符串，如下所示： package main import ( \"fmt\" \"time\" ) func main() { t1, err := time.Parse(time.RFC3339, \"2023-12-26T14:00:00+08:00\") if err != nil { return } fmt.Println(\"解析字符串:\", t1) // 格式化时间 fmt.Println(\"格式化时间:\", time.Now().Format(time.RFC3339)) } 解析字符串: 2023-12-26 14:00:00 +0800 CST 格式化时间: 2023-12-26T13:59:22+08:00 注意事项： time.Time 类型是一个值类型，不能使用指针来传递或比较。 Go 语言中的时间默认使用的是 UTC 时间，如果需要使用本地时间，可以使用 time.Local 来指定时区。 时间的计算在 Go 语言中，时间的计算是通过 time.Duration 类型来表示的。time.Duration 类型代表了一段时间，可以表示一段时间的长度，例如 5 分钟、10 小时等。 time.Duration 类型可以使用 time.ParseDuration() 函数从字符串中解析出来，也可以使用 time.Duration 类型的常量来表示，例如 5 * time.Minute 表示 5 分钟。 package main import \"time\" import \"fmt\" func main() { now := time.Now() time.Sleep(5 * time.Second) now2 := time.Now() d := now2.Sub(now) fmt.Println(d) t3 := time.Now().Add(10 * time.Minute) fmt.Println(\"Add 10 minutes:\", t3) } 5.0008615s Add 10 minutes: 2023-12-26 14:16:41.1629327 +0800 CST m=+605.003923301 注意事项： time.Duration 类型的值可以是正数、负数或零，可以进行加减运算。 time.Time 类型的 Add() 方法可以用于时间的加法运算，可以接收一个 time.Duration 类型的参数，也可以使用负数表示时间的减法运算。 时间的比较在 Go 语言中，可以使用 time.Before()、time.After() 和 time.Equal() 等方法来比较两个时间的先后顺序以及是否相等。 package main import ( &amp;nbsp; &amp;nbsp;\"fmt\" &amp;nbsp; &amp;nbsp;\"time\" ) func main() { // 时间比较 t1 := time.Date(2022, 9, 1, 10, 0, 0, 0, time.Local) t2 := time.Date(2023, 4, 28, 16, 12, 34, 567890123, time.Local) if t1.Before(t2) { fmt.Println(\"t1 在 t2 之前\") } if t1.After(t2) { fmt.Println(\"t1 在 t2 之后\") } if t1.Equal(t2) { fmt.Println(\"t1 和 t2 相等\") } else { fmt.Println(\"t1 和 t2 不相等\") } } 注意事项： time.Time 类型可以直接使用 &lt;、&gt; 和 == 等操作符进行比较，也可以使用 Before()、After() 和 Equal() 等方法来比较。 在比较两个时间是否相等时，尽量使用 Equal() 方法，而不是直接使用 == 操作符，因为 time.Time 类型是一个结构体类型，使用 == 操作符比较的是结构体的内存地址，而不是结构体的内容。 时区和时间的格式化 在 Go 语言中，可以使用 time.LoadLocation() 函数来加载时区信息，以便将本地时间转换为指定时区的时间。同时，还可以使用 time.Parse() 函数来将字符串解析成时间对象，并使用 time.Format() 函数将时间对象格式化成指定格式的字符串。 package main import \"time\" import \"fmt\" func main() { // 获取时区 location, err := time.LoadLocation(\"Asia/Shanghai\") if err != nil { return } // 将本地时间转换成指定时区 t := time.Now().In(location) fmt.Println(\"当前时间（相对于上海）:\", t) // 解析字符串为时间对象 layout := \"2006-01-02 15:04:05\" str := \"2023-12-26 14:00:00\" parse, err := time.Parse(layout, str) if err != nil { return } fmt.Println(\"解析字符串:\", parse) // 将时间对象解析为字符串 layout2 := \"2006年01月02日 15时04分05秒\" str2 := parse.Format(layout2) fmt.Println(\"格式化时间:\", str2) } 当前时间（相对于上海）: 2023-12-26 17:29:01.6119526 +0800 CST 解析字符串: 2023-12-26 14:00:00 +0000 UTC 格式化时间: 2023年12月26日 14时00分00秒 在上面的示例代码中，我们加载了纽约时区的信息，并将当前时间转换为纽约时区的时间。接着，我们使用 time.Parse() 函数将一个时间字符串解析成时间对象，再使用 time.Format() 函数将时间对象格式化成指定格式的字符串。 需要注意的是，时间格式字符串中的格式化符号必须是固定的，不能随意指定。常用的格式化符号如下：","categories":[{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/categories/go/"}],"tags":[{"name":"后端开发小技巧","slug":"后端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"Go系统监控","slug":"go系统监控","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/go系统监控/","permalink":"https://kiritoabc.github.io/2024/03/18/go%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/","excerpt":"系统监控 很多系统中都有守护进程，它们能够在后台监控系统的运行状态，在出现意外情况时及时响应。系统监控是 Go 语言运行时的重要组成部分，它会每隔一段时间检查 Go 语言运行时，确保程序没有进入异常状态。本节会介绍 Go 语言系统监控的设计与实现原理，包括它的启动、执行过程以及主要职责。","text":"系统监控 很多系统中都有守护进程，它们能够在后台监控系统的运行状态，在出现意外情况时及时响应。系统监控是 Go 语言运行时的重要组成部分，它会每隔一段时间检查 Go 语言运行时，确保程序没有进入异常状态。本节会介绍 Go 语言系统监控的设计与实现原理，包括它的启动、执行过程以及主要职责。 设计原理 在支持多任务的操作系统中，守护进程是在后台运行的计算机程序，它不会由用户直接操作，它一般会在操作系统启动时自动运行。Kubernetes 的 DaemonSet 和 Go 语言的系统监控都使用类似设计提供一些通用的功能： 守护进程是很有效的设计，它在整个系统的生命周期中都会存在，会随着系统的启动而启动，系统的结束而结束。在操作系统和 Kubernetes 中，我们经常会将数据库服务、日志服务以及监控服务等进程作为守护进程运行。 Go 语言的系统监控也起到了很重要的作用，它在内部启动了一个不会中止的循环，在循环的内部会轮询网络、抢占长期运行或者处于系统调用的 Goroutine 以及触发垃圾回收，通过这些行为，它能够让系统的运行状态变得更健康。 监控循环当 Go 语言程序启动时，运行时会在第一个 Goroutine 中调用 runtime.main 启动主程序，该函数会在系统栈中创建新的线程： func main() { ... if GOARCH != \"wasm\" { systemstack(func() { newm(sysmon, nil) }) } ... } runtime.newm 会创建一个存储待执行函数和处理器的新结构体 runtime.m。运行时执行系统监控不需要处理器，系统监控的 Goroutine 会直接在创建的线程上运行： func newm(fn func(), _p_ *p) { mp := allocm(_p_, fn) mp.nextp.set(_p_) mp.sigmask = initSigmask ... newm1(mp) } runtime.newm1 会调用特定平台的 runtime.newosproc 通过系统调用 clone 创建一个新的线程并在新的线程中执行 runtime.mstart： func newosproc(mp *m) { stk := unsafe.Pointer(mp.g0.stack.hi) var oset sigset sigprocmask(_SIG_SETMASK, &amp;sigset_all, &amp;oset) ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart))) sigprocmask(_SIG_SETMASK, &amp;oset, nil) ... } 在新创建的线程中，我们会执行存储在 runtime.m 中的 runtime.sysmon 启动系统监控： func sysmon() { sched.nmsys++ checkdead() lasttrace := int64(0) idle := 0 delay := uint32(0) for { if idle == 0 { delay = 20 } else if idle > 50 { delay *= 2 } if delay > 10*1000 { delay = 10 * 1000 } usleep(delay) ... } } 当运行时刚刚调用上述函数时，会先通过 runtime.checkdead 检查是否存在死锁，然后进入核心的监控循环；系统监控在每次循环开始时都会通过 usleep 挂起当前线程，该函数的参数是微秒，运行时会遵循以下的规则决定休眠时间： 初始的休眠时间是 20μs； 最长的休眠时间是 10ms； 当系统监控在 50 个循环中都没有唤醒 Goroutine 时，休眠时间在每个循环都会倍增； 当程序趋于稳定之后，系统监控的触发时间就会稳定在 10ms。它除了会检查死锁之外，还会在循环中完成以下的工作： 运行计时器 — 获取下一个需要被触发的计时器； 轮询网络 — 获取需要处理的到期文件描述符； 抢占处理器 — 抢占运行时间较长的或者处于系统调用的 Goroutine； 垃圾回收 — 在满足条件时触发垃圾收集回收内存； 我们在这一节中会依次介绍系统监控是如何完成上述几种不同工作的。 检查死锁系统监控通过 runtime.checkdead 检查运行时是否发生了死锁，我们可以将检查死锁的过程分成以下三个步骤： 检查是否存在正在运行的线程； 检查是否存在正在运行的 Goroutine； 检查处理器上是否存在计时器； 该函数首先会检查 Go 语言运行时中正在运行的线程数量，我们通过调度器中的多个字段计算该值的结果： func checkdead() { var run0 int32 run := mcount() - sched.nmidle - sched.nmidlelocked - sched.nmsys if run > run0 { return } if run &lt; 0 { print(\"runtime: checkdead: nmidle=\", sched.nmidle, \" nmidlelocked=\", sched.nmidlelocked, \" mcount=\", mcount(), \" nmsys=\", sched.nmsys, \"\\n\") throw(\"checkdead: inconsistent counts\") } ... } runtime.mcount 根据下一个待创建的线程 id 和释放的线程数得到系统中存在的线程数； nmidle 是处于空闲状态的线程数量； nmidlelocked 是处于锁定状态的线程数量； nmsys 是处于系统调用的线程数量； 利用上述几个线程相关数据，我们可以得到正在运行的线程数，如果线程数量大于 0，说明当前程序不存在死锁；如果线程数小于 0，说明当前程序的状态不一致；如果线程数等于 0，我们需要进一步检查程序的运行状态： func checkdead() { ... grunning := 0 for i := 0; i &lt; len(allgs); i++ { gp := allgs[i] if isSystemGoroutine(gp, false) { continue } s := readgstatus(gp) switch s &amp;^ _Gscan { case _Gwaiting, _Gpreempted: grunning++ case _Grunnable, _Grunning, _Gsyscall: print(\"runtime: checkdead: find g \", gp.goid, \" in status \", s, \"\\n\") throw(\"checkdead: runnable g\") } } unlock(&amp;allglock) if grunning == 0 { throw(\"no goroutines (main called runtime.Goexit) - deadlock!\") } ... } 当存在 Goroutine 处于 _Grunnable、_Grunning 和 _Gsyscall 状态时，意味着程序发生了死锁； 当所有的 Goroutine 都处于 _Gidle、_Gdead 和 _Gcopystack 状态时，意味着主程序调用了 runtime.goexit； 当运行时存在等待的 Goroutine 并且不存在正在运行的 Goroutine 时，我们会检查处理器中存在的计时器1： func checkdead() { ... for _, _p_ := range allp { if len(_p_.timers) > 0 { return } } throw(\"all goroutines are asleep - deadlock!\") } 如果处理器中存在等待的计时器，那么所有的 Goroutine 陷入休眠状态是合理的，不过如果不存在等待的计时器，运行时会直接报错并退出程序。 垃圾回收在最后，系统监控还会决定是否需要触发强制垃圾回收，runtime.sysmon 会构建 runtime.gcTrigger 并调用 runtime.gcTrigger.test 方法判断是否需要触发垃圾回收： func sysmon() { ... for { ... if t := (gcTrigger{kind: gcTriggerTime, now: now}); t.test() &amp;&amp; atomic.Load(&amp;forcegc.idle) != 0 { lock(&amp;forcegc.lock) forcegc.idle = 0 var list gList list.push(forcegc.g) injectglist(&amp;list) unlock(&amp;forcegc.lock) } ... } } 如果需要触发垃圾回收，我们会将用于垃圾回收的 Goroutine 加入全局队列，让调度器选择合适的处理器去执行。 总结 运行时通过系统监控来触发线程的抢占、网络的轮询和垃圾回收，保证 Go 语言运行时的可用性。系统监控能够很好地解决尾延迟的问题，减少调度器调度 Goroutine 的饥饿问题并保证计时器在尽可能准确的时间触发。","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端go","slug":"后端go","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AFgo/"}],"author":"菠萝"},{"title":"Go泛型","slug":"go语言泛型","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/go语言泛型/","permalink":"https://kiritoabc.github.io/2024/03/18/go%E8%AF%AD%E8%A8%80%E6%B3%9B%E5%9E%8B/","excerpt":"Go 1.18 泛型 2022年3月15日，争议非常大但同时也备受期待的泛型终于伴随着Go1.18发布了。 参考文档: Go 编程语言规范 - Go 编程语言","text":"Go 1.18 泛型 2022年3月15日，争议非常大但同时也备受期待的泛型终于伴随着Go1.18发布了。 参考文档: Go 编程语言规范 - Go 编程语言 Go还引入了非常多全新的概念： 类型形参 (Type parameter) 类型实参(Type argument) 类型形参列表( Type parameter list) 类型约束(Type constraint) 实例化(Instantiations) 泛型类型(Generic type) 泛型接收器(Generic receiver) 泛型函数(Generic function) 类型形参，类型实参，类型约束，泛型类型type IntSlice []int var a IntSlice = []int{1, 2, 3} // 正确 var b IntSlice = []float32{1.0, 2.0, 3.0} // ✗ 错误，因为IntSlice的底层类型是[]int，浮点类型的切片无法赋值 这里定义了一个新的类型 IntSlice ，它的底层类型是 []int ，理所当然只有int类型的切片能赋值给 IntSlice 类型的变量。 接下来如果我们想要定义一个可以容纳 float32 或 string 等其他类型的切片的话该怎么办？ type StringSlice []string type Float32Slie []float32 type Float64Slice []float64 但是这样做的问题显而易见，它们结构都是一样的只是成员类型不同就需要重新定义这么多新类型。那么有没有一个办法能只定义一个类型就能代表上面这所有的类型呢？ type Slice[T int|float32|float64 ] []T 泛型函数func Add(a int, b int) int { return a + b } func Add[T int | float32 | float64](a T, b T) T { return a + b }","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端Go","slug":"后端Go","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AFGo/"}],"author":"菠萝"},{"title":"Hello-World","slug":"hello-world","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/hello-world/","permalink":"https://kiritoabc.github.io/2024/03/18/hello-world/","excerpt":"这里是摘要 自我介绍环节 你不需要一开始很厉害，你需要开始才能很厉害！","text":"这里是摘要 自我介绍环节 你不需要一开始很厉害，你需要开始才能很厉害！ 一名懒惰的死宅 是名大学生 loving life &amp; loving coding 在为找工作努力学习ing 主要技术栈： golang react vue java 邮箱:2493381254@qq.com","categories":[],"tags":[],"author":"菠萝"},{"title":"Go语言调用外部程序","slug":"go调用外部程序","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/go调用外部程序/","permalink":"https://kiritoabc.github.io/2024/03/18/go%E8%B0%83%E7%94%A8%E5%A4%96%E9%83%A8%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"由于最近开发碰到了需要调用外部软件程序的任务，对此有一定的兴趣，所以本人翻阅互联网，寻找如何操作，得此文章。 Go语言调用外部程序os/exec包中的exec.Commad() package main import ( \"fmt\" \"os/exec\" \"runtime\" \"syscall\" ) const path = \"D:\\\\tools\\\\wangyiyun\\\\CloudMusic\\\\cloudmusic.exe\" func main() { // 注意一第一个参数，其实就是你要运行的 .exe程序 cmd := exec.Command(path) if runtime.GOOS == \"windows\" { cmd.SysProcAttr = &amp;syscall.SysProcAttr{HideWindow: true} } err := cmd.Run() fmt.Println(err.Error()) } syscall包下的CreateProcess()创建子进程来运行 package main import ( \"fmt\" \"syscall\" ) const path = \"D:\\\\tools\\\\wangyiyun\\\\CloudMusic\\\\cloudmusic.exe\" func main() { //cmd := exec.Command(path) //if runtime.GOOS == \"windows\" { // cmd.SysProcAttr = &amp;syscall.SysProcAttr{HideWindow: true} //} //err := cmd.Run() //fmt.Println(err.Error()) var sI syscall.StartupInfo var pI syscall.ProcessInformation argv, err2 := syscall.UTF16PtrFromString(path) if err2 != nil { return } err := syscall.CreateProcess( nil, argv, nil, nil, true, 0, nil, nil, &amp;sI, &amp;pI) fmt.Printf(\"Return: %d\\n\", err) } 这是一个使用Go语言编写的Windows系统调用函数，用于创建一个新的进程。以下是代码的详细解释： func CreateProcess(appName *uint16, commandLine *uint16, procSecurity *SecurityAttributes, threadSecurity *SecurityAttributes, inheritHandles bool, creationFlags uint32, env *uint16, currentDir *uint16, startupInfo *StartupInfo, outProcInfo *ProcessInformation) (err error)：定义了一个名为CreateProcess的函数，该函数接受10个参数，返回一个错误值（err）。这些参数的含义如下： appName *uint16：指向应用程序名称的字符串指针。 commandLine *uint16：指向命令行参数的字符串指针。 procSecurity *SecurityAttributes：指向进程安全属性的指针。 threadSecurity *SecurityAttributes：指向线程安全属性的指针。 inheritHandles bool：一个布尔值，表示是否继承句柄。 creationFlags uint32：表示创建进程的标志。 env *uint16：指向环境变量的指针。 currentDir *uint16：指向当前目录的字符串指针。 startupInfo *StartupInfo：指向启动信息的指针。 outProcInfo *ProcessInformation：指向进程信息的指针。 var _p0 uint32：定义了一个名为_p0的变量，其类型为uint32。这个变量用于存储inheritHandles变量的值，如果inheritHandles为true，则将其设置为1，否则设置为0。 if inheritHandles {：如果inheritHandles为true，执行以下操作： _p0 = 1：将_p0设置为1。 r1, _, e1 := Syscall12(procCreateProcessW.Addr(), 10, uintptr(unsafe.Pointer(appName)), uintptr(unsafe.Pointer(commandLine)), uintptr(unsafe.Pointer(procSecurity)), uintptr(unsafe.Pointer(threadSecurity)), uintptr(_p0), uintptr(creationFlags), uintptr(unsafe.Pointer(env)), uintptr(unsafe.Pointer(currentDir)), uintptr(unsafe.Pointer(startupInfo)), uintptr(unsafe.Pointer(outProcInfo)), 0, 0)：使用Syscall12函数调用Windows系统调用的地址（procCreateProcessW.Addr()），传递10个参数。这些参数的含义如下： procCreateProcessW.Addr()：表示CreateProcess系统调用的地址。 10：表示参数的数量。 uintptr(unsafe.Pointer(appName))：表示appName参数的地址。 uintptr(unsafe.Pointer(commandLine))：表示commandLine参数的地址。 uintptr(unsafe.Pointer(procSecurity))：表示procSecurity参数的地址。 uintptr(unsafe.Pointer(threadSecurity))：表示threadSecurity参数的地址。 uintptr(_p0)：表示_p0参数的地址。 uintptr(creationFlags)：表示creationFlags参数的地址。 uintptr(unsafe.Pointer(env))：表示env参数的地址。 uintptr(unsafe.Pointer(currentDir))：表示currentDir参数的地址。 uintptr(unsafe.Pointer(startupInfo))：表示startupInfo参数的地址。 uintptr(unsafe.Pointer(outProcInfo))：表示outProcInfo参数的地址。 0：表示_p0参数的长度。 0：表示_p0参数的字节顺序。 if r1 == 0 {：如果Syscall12函数返回的第一个返回值为`0 func CreateProcess(appName *uint16, commandLine *uint16, procSecurity *SecurityAttributes, threadSecurity *SecurityAttributes, inheritHandles bool, creationFlags uint32, env *uint16, currentDir *uint16, startupInfo *StartupInfo, outProcInfo *ProcessInformation) (err error) { var _p0 uint32 if inheritHandles { _p0 = 1 } r1, _, e1 := Syscall12(procCreateProcessW.Addr(), 10, uintptr(unsafe.Pointer(appName)), uintptr(unsafe.Pointer(commandLine)), uintptr(unsafe.Pointer(procSecurity)), uintptr(unsafe.Pointer(threadSecurity)), uintptr(_p0), uintptr(creationFlags), uintptr(unsafe.Pointer(env)), uintptr(unsafe.Pointer(currentDir)), uintptr(unsafe.Pointer(startupInfo)), uintptr(unsafe.Pointer(outProcInfo)), 0, 0) if r1 == 0 { err = errnoErr(e1) } return }","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF/"}],"author":"菠萝"},{"title":"Kubernetes","slug":"k8s","date":"2024-03-18T09:39:39.154Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/03/18/k8s/","permalink":"https://kiritoabc.github.io/2024/03/18/k8s/","excerpt":"Kubernetes, also known as K8s, is an open source system for managing containerized applications across multiple hosts. It provides basic mechanisms for the deployment, maintenance, and scaling of applications.","text":"Kubernetes, also known as K8s, is an open source system for managing containerized applications across multiple hosts. It provides basic mechanisms for the deployment, maintenance, and scaling of applications. KubernetesKubernets基础Kubernetes 协调一个高可用计算机集群，每个计算机作为独立单元互相连接工作。 Kubernetes 中的抽象允许你将容器化的应用部署到集群，而无需将它们绑定到某个特定的独立计算机。 为了使用这种新的部署模型，应用需要以将应用与单个主机分离的方式打包：它们需要被容器化。 与过去的那种应用直接以包的方式深度与主机集成的部署模型相比，容器化应用更灵活、更可用。 Kubernetes 以更高效的方式跨集群自动分发和调度应用容器。 Kubernetes 是一个开源平台，并且可应用于生产环境。 一个 Kubernetes 集群包含两种类型的资源： 控制面调度整个集群 节点负责运行应用 集群图 控制面负责管理整个集群。 控制面协调集群中的所有活动，例如调度应用、维护应用的所需状态、应用扩容以及推出新的更新。 节点是一个虚拟机或者物理机，它在 Kubernetes 集群中充当工作机器的角色。 每个节点都有 Kubelet，它管理节点而且是节点与控制面通信的代理。 节点还应该具有用于处理容器操作的工具，例如 Docker 或 rkt。 处理生产级流量的 Kubernetes 集群至少应具有三个节点，因为如果一个节点出现故障其对应的 etcd 成员和控制面实例都会丢失， 并且冗余会受到影响。你可以通过添加更多控制面节点来降低这种风险。 在 Kubernetes 上部署应用时，你告诉控制面启动应用容器。 控制面就编排容器在集群的节点上运行。 节点使用控制面暴露的 Kubernetes API 与控制面通信。终端用户也可以使用 Kubernetes API 与集群交互。 使用minikube模拟https://kubernetes.io/zh-cn/docs/tutorials/hello-minikube/ kubectl的基本命令 说明： 有关 kubectl 命令的更多信息，请参阅 kubectl 概述。 1.使用 kubectl create 命令创建管理 Pod 的 Deployment。该 Pod 根据提供的 Docker 镜像运行容器。 # 运行包含 Web 服务器的测试容器镜像 kubectl create deployment hello-node --image=registry.k8s.io/e2e-test-images/agnhost:2.39 -- /agnhost netexec --http-port=8080 2.查看 Deployment： kubectl get deployment 3.查看pod kubectl get pods 4.查看集群事件： kubectl get events 5.查看 kubectl 配置： kubectl config view 6.查看 Pod 中容器的应用程序日志。 kubectl logs hello-node-5f76cf6ccf-br9b5 部署第一个应用在Kubernetes 采用国内源启动：","categories":[{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/tags/go/"}],"author":"菠萝"},{"title":"UML--类图","slug":"UML","date":"2024-03-18T09:39:39.150Z","updated":"2024-03-18T09:39:39.150Z","comments":true,"path":"2024/03/18/UML/","permalink":"https://kiritoabc.github.io/2024/03/18/UML/","excerpt":"​ 统一建模语言(Unified Modeling Language，UML)是一种为面向对象系统的产品进行说明、可视化和编制文档的一种标准语言，是非专利的第三代建模和规约语言。UML是面向对象设计的建模工具，独立于任何具体程序设计语言。 UML —&gt; 类图 (Class Diagram)","text":"​ 统一建模语言(Unified Modeling Language，UML)是一种为面向对象系统的产品进行说明、可视化和编制文档的一种标准语言，是非专利的第三代建模和规约语言。UML是面向对象设计的建模工具，独立于任何具体程序设计语言。 UML —&gt; 类图 (Class Diagram) ​ 类图是描述系统中的类，以及各个类之间的关系的静态视图。能够让开发人员在正确编写代码以前对系统有一个全面的认识。类图是一种模型类型，确切地说，是一种静态模型类型。类图表示类、接口和它们之间的协作关系。 类的表示法类图标由三个部分组成：第一个部分是类名，第二个部分是属性，第三个部分是操作。 类名在它的命名空间中唯一。类名以大写字母开头，省略多个单词之间的空格。 属性和操作在类的范围内必须无二义。属性和操作是以小写字母开头，后续单词的首字母大写，且同样省略空格。 抽象类和抽象操作用斜体表示。 属性规格说明格式： 可见性 属性名称：类型 [多重性] = 默认值 {特性字符串} 操作规格说明格式： 可见性 操作名称（参数名称：类型）：返回值 {特性字符串} 可见性 公有可见性（+）：对能看到这个类的任何元素都可见。 保护可见性（#）：对这个类及其子类的其他元素可见。 私有可见性（-）：对这个类的其他元素可见。 包可见性（~）：对同一个包中的其他元素可见。 类关系类的基本联系包括关联、泛化、聚合和组合。 关联关联用不带箭头的实线表示。 关联连接了两个类，体现了一种语义关系。 关联通常用名词词组来标注，如下图中的Analyzes，以说明关系的实质。 类可能与它自己有关联（称为自关联），如PlanAnalyst类的实例之间的协作。注意，这里同时使用了关联端名称和关联名称，目的是提供清晰性。 关联可以进一步通过多重性来修饰（没有也可以）。多重性的语法如下： 精确到1个。 数目不限（0个或多个）。 0..*：0个或多个。 1..*：1个多多个。 0..1：0个或1个。 3..7：指定范围（3~7个，包含3和7） 多重性应用于关联的目标端，说明源类的每个实例与目标类实例的连接个数。除非显式说明，否则关系的多重性就是未指定的。 高级概念：关联的方向性。在分析时，我们认为关联是分析类之间的双向逻辑连接。在设计时，我们将关注的焦点转到关联的导航性上。 从GrainCrop类到GrainYieldPredictor类的单向关联通常意味着GrainCrop类的某些方法在实现时使用了GrainYieldPredictor类的服务。注意，GrainCrop类和GrainYieldPredictor类之间的关联端名称的可见性，GrainCrop对GrainYieldPredictor类似私有的。 泛化泛化描述的“是一种”的关系。 泛化用带有封闭箭头的实线表示。箭头指向超类，关联的另一端是子类。 子类继承超类的结构和行为。根据这些规则，一个类可以有一个（单继承）或多个（多继承）超类，超类间的名字冲突也可以根据所选语言的规则来处理。 泛化关系不能有多重性指定。 聚合聚合表明一种整体-部分的层次结构。 聚合用带有一个空心菱形的实线表示。菱形所在的一端是聚合体（整体），另一端的类代表它的实例构成了聚合对象的部分。 自聚合和循环聚合关系是可能的。这种整体-部分的层次关系并不意味着物理上的包容：一个专业协会有一些成员，但不表示协会拥有它的成员。就如汽车和轮胎，当汽车销毁的时候，并不意味着轮胎也销毁了。即两个对象的生命周期是相互独立的。 聚合关系末端的*（0个或多个）多重性进一步突出了这不是物理包容关系。 组合组合则是关联更强的聚合。部分与整体共存亡，是物理包容。 组合用带有一个实心菱形的实线表示。菱形所在的一端是整体，另外一端是部分。 整体所在的一端的多重性是1，因为根据定义，部分在整体之外就没有任何意义，整体拥有部分，部分的生命周期与整体式一样的。","categories":[{"name":"UML","slug":"UML","permalink":"https://kiritoabc.github.io/categories/UML/"}],"tags":[{"name":"UML","slug":"UML","permalink":"https://kiritoabc.github.io/tags/UML/"}],"author":"菠萝"},{"title":"Jaeger","slug":"Jaeger","date":"2024-03-18T09:39:39.146Z","updated":"2024-03-18T09:39:39.146Z","comments":true,"path":"2024/03/18/Jaeger/","permalink":"https://kiritoabc.github.io/2024/03/18/Jaeger/","excerpt":"分布式追踪系统 Jaeger","text":"分布式追踪系统 Jaeger Jaeger 受到Dapper和OpenZipkin的启发，是由Uber Technologies创建 。 可用于监控基于微服务的分布式系统： 分布式上下文传播 分布式事务监控 根本原因分析 服务依赖分析 性能/延迟优化 入门使用采用dcoker启动 docker run --rm --name jaeger \\ -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.53 windows上启动时: docker run -d --name 12306-jaeger ` --network go-zero-12306 ` -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 ` -p 6831:6831/udp ` -p 6832:6832/udp ` -p 5778:5778 ` -p 16686:16686 ` -p 4317:4317 ` -p 4318:4318 ` -p 14250:14250 ` -p 14268:14268 ` -p 14269:14269 ` -p 9411:9411 ` jaegertracing/all-in-one:1.53 启动后访问http://localhost:16686，如下 在go-zero中，添加链路追踪即可 #链路追踪 Telemetry: Name: template-api Endpoint: http://127.0.0.1:14268/api/traces Sampler: 1.0 Batcher: jaeger 服务性能监控在 Jaeger UI 中作为“Monitor”选项卡出现，此功能的动机是帮助识别有趣的跟踪（例如高 QPS、缓慢或错误的请求），而无需预先知道服务或操作名称。 它本质上是通过聚合跨度数据以生成 RED（请求、错误、持续时间）指标来实现的。 潜在的用例包括： 对整个组织或请求链中已知的依赖服务进行部署后健全性检查。 在收到问题警报时进行监控并找出根本原因。 为 Jaeger UI 新用户提供更好的入门体验。 QPS、错误和延迟的长期趋势分析。 容量规划。","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端知识","slug":"后端知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"React","slug":"React","date":"2024-03-18T09:39:39.146Z","updated":"2024-03-18T09:39:39.146Z","comments":true,"path":"2024/03/18/React/","permalink":"https://kiritoabc.github.io/2024/03/18/React/","excerpt":"复习React的相关知识","text":"复习React的相关知识 快速入门1. 创建和嵌套组件React 应用程序是由 组件 组成的。一个组件是 UI（用户界面）的一部分，它拥有自己的逻辑和外观。组件可以小到一个按钮，也可以大到整个页面。 React 组件是返回标签的 JavaScript 函数： function MyButton(){ return ( &lt;button>I'm a button&lt;/button> ) } 至此，你已经声明了 MyButton，现在把它嵌套到另一个组件中： export default function MyApp() { return ( &lt;div> &lt;h1>Welcome to my app&lt;/h1> &lt;MyButton /> &lt;/div> ); } 2. 使用JSX编写标签上面所使用的标签语法被称为 JSX。它是可选的，但大多数 React 项目会使用 JSX，主要是它很方便。所有 我们推荐的本地开发工具 都开箱即用地支持 JSX。 JSX 比 HTML 更加严格。你必须闭合标签，如 &lt;br /&gt;。你的组件也不能返回多个 JSX 标签。你必须将它们包裹到一个共享的父级中，比如 &lt;div&gt;...&lt;/div&gt; 或使用空的 &lt;&gt;...&lt;/&gt; 包裹： function AboutPage() { return ( &lt;> &lt;h1>About&lt;/h1> &lt;p>Hello there.&lt;br />How do you do?&lt;/p> &lt;/> ); } 如果你有大量的 HTML 需要移植到 JSX 中，你可以使用 在线转换器。 3. 添加样式在 React 中，你可以使用 className 来指定一个 CSS 的 class。它与 HTML 的 class 属性的工作方式相同： &lt;img className=\"avatar\" /> 4. 显示数据JSX 会让你把标签放到 JavaScript 中。而大括号会让你 “回到” JavaScript 中，这样你就可以从你的代码中嵌入一些变量并展示给用户。例如，这将显示 user.name： return ( &lt;h1> {user.name} &lt;/h1> ); 你还可以将 JSX 属性 “转义到 JavaScript”，但你必须使用大括号 而非 引号。例如，className=\"avatar\" 是将 \"avatar\" 字符串传递给 className，作为 CSS 的 class。但 src={user.imageUrl} 会读取 JavaScript 的 user.imageUrl 变量，然后将该值作为 src 属性传递： return ( &lt;img className=\"avatar\" src={user.imageUrl} /> ); 你也可以把更为复杂的表达式放入 JSX 的大括号内，例如 字符串拼接： const user = { name: 'Hedy Lamarr', imageUrl: 'https://i.imgur.com/yXOvdOSs.jpg', imageSize: 90, }; export default function Profile() { return ( &lt;> &lt;h1>{user.name}&lt;/h1> &lt;img className=\"avatar\" src={user.imageUrl} alt={'Photo of ' + user.name} style={{ width: user.imageSize, height: user.imageSize }} /> &lt;/> ); } 在上面示例中，style={{}} 并不是一个特殊的语法，而是 style={ } JSX 大括号内的一个普通 {} 对象。当你的样式依赖于 JavaScript 变量时，你可以使用 style 属性。 5. 条件渲染React 没有特殊的语法来编写条件语句，因此你使用的就是普通的 JavaScript 代码。例如使用 if 语句根据条件引入 JSX： let content; if (isLoggedIn) { content = &lt;AdminPanel />; } else { content = &lt;LoginForm />; } return ( &lt;div> {content} &lt;/div> ); 如果你喜欢更为紧凑的代码，可以使用 条件 ? 运算符。与 if 不同的是，它工作于 JSX 内部： &lt;div> {isLoggedIn ? ( &lt;AdminPanel /> ) : ( &lt;LoginForm /> )} &lt;/div> 当你不需要 else 分支时，你还可以使用 逻辑 &amp;&amp; 语法： &lt;div> {isLoggedIn &amp;&amp; &lt;AdminPanel />} &lt;/div> 所有这些方法也适用于有条件地指定属性。如果你对 JavaScript 语法不熟悉，你可以从一直使用 if...else 开始。 const products = [ { title: 'Cabbage', id: 1 }, { title: 'Garlic', id: 2 }, { title: 'Apple', id: 3 }, ]; 在你的组件中，使用 map() 函数将这个数组转换为 &lt;li&gt; 标签构成的列表: const listItems = products.map(product => &lt;li key={product.id}> {product.title} &lt;/li> ); return ( &lt;ul>{listItems}&lt;/ul> ); 注意， &lt;li&gt; 有一个 key 属性。对于列表中的每一个元素，你都应该传递一个字符串或者数字给 key，用于在其兄弟节点中唯一标识该元素。通常 key 来自你的数据，比如数据库中的 ID。如果你在后续插入、删除或重新排序这些项目，React 将依靠你提供的 key 来思考发生了什么。 const products = [ { title: 'Cabbage', isFruit: false, id: 1 }, { title: 'Garlic', isFruit: false, id: 2 }, { title: 'Apple', isFruit: true, id: 3 }, ]; export default function ShoppingList() { const listItems = products.map(product => &lt;li key={product.id} style={{ color: product.isFruit ? 'magenta' : 'darkgreen' }} > {product.title} &lt;/li> ); return ( &lt;ul>{listItems}&lt;/ul> ); } 6. 响应事件可以通过在组件中声明 事件处理 函数来响应事件： function MyButton() { function handleClick() { alert('You clicked me!'); } return ( Click me ); } 注意，onClick={handleClick} 的结尾没有小括号！不要 调用 事件处理函数：你只需 把函数传递给事件 即可。当用户点击按钮时 React 会调用你传递的事件处理函数。 7. 更新界面通常你会希望你的组件 “记住” 一些信息并展示出来，比如一个按钮被点击的次数。要做到这一点，你需要在你的组件中添加 state。 首先，从 React 引入 useState： import { useState } from 'react'; 现在你可以在你的组件中声明一个 state 变量： function MyButton() { const [count, setCount] = useState(0); // ... 你将从 useState 中获得两样东西：当前的 state（count），以及用于更新它的函数（setCount）。你可以给它们起任何名字，但按照惯例会像 [something, setSomething] 这样为它们命名。 第一次显示按钮时，count 的值为 0，因为你把 0 传给了 useState()。当你想改变 state 时，调用 setCount() 并将新的值传递给它。点击该按钮计数器将递增： function MyButton() { const [count, setCount] = useState(0); function handleClick() { setCount(count + 1); } return ( &lt;button onClick={handleClick}> Clicked {count} times &lt;/button> ); } React 将再次调用你的组件函数。第一次 count 变成 1。接着点击会变成 2。继续点击会逐步递增。 如果你多次渲染同一个组件，每个组件都会拥有自己的 state。你可以尝试点击不同的按钮： import { useState } from 'react'; export default function MyApp() { return ( &lt;div> &lt;h1>Counters that update separately&lt;/h1> &lt;MyButton /> &lt;MyButton /> &lt;/div> ); } function MyButton() { const [count, setCount] = useState(0); function handleClick() { setCount(count + 1); } return ( &lt;button onClick={handleClick}> Clicked {count} times &lt;/button> ); } 8. 使用Hook以 use 开头的函数被称为 Hook。useState 是 React 提供的一个内置 Hook。你可以在 React API 参考 中找到其他内置的 Hook。你也可以通过组合现有的 Hook 来编写属于你自己的 Hook。 Hook 比普通函数更为严格。你只能在你的组件（或其他 Hook）的 顶层 调用 Hook。如果你想在一个条件或循环中使用 useState，请提取一个新的组件并在组件内部使用它。 9. 组件间共享数据在前面的示例中，每个 MyButton 都有自己独立的 count，当每个按钮被点击时，只有被点击按钮的 count 才会发生改变： 然而，你经常需要组件 共享数据并一起更新。 为了使得 MyButton 组件显示相同的 count 并一起更新，你需要将各个按钮的 state “向上” 移动到最接近包含所有按钮的组件之中。 在这个示例中，它是 MyApp： 此刻，当你点击任何一个按钮时，MyApp 中的 count 都将改变，同时会改变 MyButton 中的两个 count。具体代码如下： 首先，将 MyButton 的 state 上移到 MyApp 中： export default function MyApp() { const [count, setCount] = useState(0); function handleClick() { setCount(count + 1); } return ( &lt;div> &lt;h1>Counters that update separately&lt;/h1> &lt;MyButton /> &lt;MyButton /> &lt;/div> ); } function MyButton() { // ... we're moving code from here ... } 接着，将 MyApp 中的点击事件处理函数以及 state 一同向下传递到 每个 MyButton 中。你可以使用 JSX 的大括号向 MyButton 传递信息。就像之前向 &lt;img&gt; 等内置标签所做的那样: export default function MyApp() { const [count, setCount] = useState(0); function handleClick() { setCount(count + 1); } return ( &lt;div> &lt;h1>Counters that update together&lt;/h1> &lt;MyButton count={count} onClick={handleClick} /> &lt;MyButton count={count} onClick={handleClick} /> &lt;/div> ); } 使用这种方式传递的信息被称作 prop。此时 MyApp 组件包含了 count state 以及 handleClick 事件处理函数，并将它们作为 prop 传递给 了每个按钮。 最后，改变 MyButton 以 读取 从父组件传递来的 prop： function MyButton({ count, onClick }) { return ( &lt;button onClick={onClick}> Clicked {count} times &lt;/button> ); } 当你点击按钮时，onClick 处理程序会启动。每个按钮的 onClick prop 会被设置为 MyApp 内的 handleClick 函数，所以函数内的代码会被执行。该代码会调用 setCount(count + 1)，使得 state 变量 count 递增。新的 count 值会被作为 prop 传递给每个按钮，因此它们每次展示的都是最新的值。这被称为“状态提升”。通过向上移动 state，我们实现了在组件间共享它。 import { useState } from 'react'; export default function MyApp() { const [count, setCount] = useState(0); function handleClick() { setCount(count + 1); } return ( &lt;div> &lt;h1>Counters that update together&lt;/h1> &lt;MyButton count={count} onClick={handleClick} /> &lt;MyButton count={count} onClick={handleClick} /> &lt;/div> ); } function MyButton({ count, onClick }) { return ( &lt;button onClick={onClick}> Clicked {count} times &lt;/button> ); } 安装React启动一个新的React项目 你需要安装 Node.js 用于本地开发。你也可以选择在生产环境中使用 Node.js，但你不一定要这样。许多 React 框架支持导出 HTML/CSS/JS 等静态文件。 生产级的React框架1. Next.jsNext.js 是一个全栈式的 React 框架。它用途广泛，可以让你创建任意规模的 React 应用——可以是静态博客，也可以是复杂的动态应用。要创建一个新的 Next.js 项目，请在你的终端运行： npx create-next-app@latest 2. RemixRemix 是一个具有嵌套路由的全栈式 React 框架。它可以把你的应用分成嵌套部分，该嵌套部分可以并行加载数据并响应用户操作进行刷新。要创建一个新的 Remix 项目，请运行： npx create-remix 3. GatsbyGatsby 是一个快速的支持 CMS 的网站的 React 框架。其丰富的插件生态系统和 GraphQL 数据层简化了将内容、API 和服务整合到一个网站的过程。要创建一个新的 Gatsby 项目，请运行： npx create-gatsby 4. Expo(用于原生应用) Expo 是一个 React 框架，可以让你创建具有真正原生 UI 的应用，包括 Android、iOS，以及 Web 应用。它为 React Native 提供了 SDK，使原生部分更容易使用。要创建一个新的 Expo 项目，请运行： npx create-expo-app","categories":[{"name":"前端","slug":"前端","permalink":"https://kiritoabc.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端知识","slug":"前端知识","permalink":"https://kiritoabc.github.io/tags/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"Redis源码阅读0","slug":"Redis源码阅读系列0","date":"2024-03-18T09:39:39.146Z","updated":"2024-03-18T09:39:39.146Z","comments":true,"path":"2024/03/18/Redis源码阅读系列0/","permalink":"https://kiritoabc.github.io/2024/03/18/Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%B3%BB%E5%88%970/","excerpt":"主要记录我对于redis7.2.3源码的阅读 What is Redis? Redis is often referred to as a data structures server. What this means is that Redis provides access to mutable data structures via a set of commands, which are sent using a server-client model with TCP sockets and a simple protocol. So different processes can query and modify the same data structures in a shared way. Redis通常被称为数据结构服务器。这意味着Redis通过一组命令提供对可变数据结构的访问，这些命令使用带有TCP套接字和简单协议的服务器-客户端模型发送。因此，不同的进程可以以共享的方式查询和修改相同的数据结构。 阅读方法采用提出问题 –&gt; 再去探索的思路。 问题一：Redis解析执行命令行命令的流程？","text":"主要记录我对于redis7.2.3源码的阅读 What is Redis? Redis is often referred to as a data structures server. What this means is that Redis provides access to mutable data structures via a set of commands, which are sent using a server-client model with TCP sockets and a simple protocol. So different processes can query and modify the same data structures in a shared way. Redis通常被称为数据结构服务器。这意味着Redis通过一组命令提供对可变数据结构的访问，这些命令使用带有TCP套接字和简单协议的服务器-客户端模型发送。因此，不同的进程可以以共享的方式查询和修改相同的数据结构。 阅读方法采用提出问题 –&gt; 再去探索的思路。 问题一：Redis解析执行命令行命令的流程？ Redis server 和一个客户端建立连接后，会在事件驱动框架中注册可读事件——客户端的命令请求。命令处理对应 4 个阶段： 命令读取：对应 readQueryFromClient 函数 命令解析：对应 processInputBuffer 函数 命令执行：对应 processCommand 函数 结果返回：对应 addReply 函数 在redis源码的 server.c中定义了一些 dictType （位于dict.h） 我的理解是，定义一个所有的命令公共的dictType结构体。 typedef struct dictType { uint64_t (*hashFunction)(const void *key); void *(*keyDup)(dict *d, const void *key); void *(*valDup)(dict *d, const void *obj); int (*keyCompare)(dict *d, const void *key1, const void *key2); void (*keyDestructor)(dict *d, void *key); void (*valDestructor)(dict *d, void *obj); int (*expandAllowed)(size_t moreMem, double usedRatio); /* Invoked at the start of dict initialization/rehashing (old and new ht are already created) */ void (*rehashingStarted)(dict *d); /* Invoked at the end of dict initialization/rehashing of all the entries from old to new ht. Both ht still exists * and are cleaned up after this callback. */ void (*rehashingCompleted)(dict *d); /* Flags */ /* The 'no_value' flag, if set, indicates that values are not used, i.e. the * dict is a set. When this flag is set, it's not possible to access the * value of a dictEntry and it's also impossible to use dictSetKey(). Entry * metadata can also not be used. */ unsigned int no_value:1; /* If no_value = 1 and all keys are odd (LSB=1), setting keys_are_odd = 1 * enables one more optimization: to store a key without an allocated * dictEntry. */ unsigned int keys_are_odd:1; /* TODO: Add a 'keys_are_even' flag and use a similar optimization if that * flag is set. */ } dictType; dictType是Redis中的一个结构体类型，用于定义字典（dict）的哈希表实现。它包含了一些回调函数指针，这些函数在字典初始化、重新哈希等操作时被调用。以下是各个字段的作用： hashFunction：哈希函数，用于计算键的哈希值。 keyDup：键复制函数，用于复制字典中的键。 valDup：值复制函数，用于复制字典中的值。 keyCompare：键比较函数，用于比较两个键是否相等。 keyDestructor：键析构函数，用于释放键所占用的内存。 valDestructor：值析构函数，用于释放值所占用的内存。 expandAllowed：扩展允许函数，用于判断是否可以扩展字典的大小。 rehashingStarted：重新哈希开始函数，在字典初始化或重新哈希开始时调用。 rehashingCompleted：重新哈希完成函数，在字典初始化或重新哈希完成后调用。 no_value：无值标志，如果设置为1，表示字典的值不使用，即字典是一个集合。当此标志为1时，无法访问字典条目的值，也无法使用dictSetKey()函数。条目元数据也不能使用。 keys_are_odd：键奇偶标志，如果设置为1且所有键都是奇数（最低有效位为1），则启用一个优化：在存储没有分配的字典条目时存储键。 在serve.c中运用dictType定义了一些基础命令格式如下： /* Set dictionary type. Keys are SDS strings, values are not used. */ dictType setDictType = { dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ dictSdsDestructor, /* key destructor */ .no_value = 1, /* no values in this dict */ .keys_are_odd = 1 /* an SDS string is always an odd pointer */ }; 在networking.c中有createClient 这里给conn设置了ReadHandler connSetReadHandler(conn, readQueryFromClient); client *createClient(connection *conn) { client *c = zmalloc(sizeof(client)); /* passing NULL as conn it is possible to create a non connected client. * This is useful since all the commands needs to be executed * in the context of a client. When commands are executed in other * contexts (for instance a Lua script) we need a non connected client. */ if (conn) { connEnableTcpNoDelay(conn); if (server.tcpkeepalive) connKeepAlive(conn,server.tcpkeepalive); connSetReadHandler(conn, readQueryFromClient); connSetPrivateData(conn, c); } ... } 那么我们知道了我们的读取命令的Handler在创建client的时候设置的，接下来我们来看看readQueryFormClient的实现 命令的读取 void readQueryFromClient(connection *conn) { client *c = connGetPrivateData(conn); int nread, big_arg = 0; size_t qblen, readlen; /* Check if we want to read from the client later when exiting from * the event loop. This is the case if threaded I/O is enabled. */ if (postponeClientRead(c)) return; /* Update total number of reads on server */ atomicIncr(server.stat_total_reads_processed, 1); readlen = PROTO_IOBUF_LEN; /* If this is a multi bulk request, and we are processing a bulk reply * that is large enough, try to maximize the probability that the query * buffer contains exactly the SDS string representing the object, even * at the risk of requiring more read(2) calls. This way the function * processMultiBulkBuffer() can avoid copying buffers to create the * Redis Object representing the argument. */ if (c->reqtype == PROTO_REQ_MULTIBULK && c->multibulklen && c->bulklen != -1 && c->bulklen >= PROTO_MBULK_BIG_ARG) { ssize_t remaining = (size_t)(c->bulklen+2)-(sdslen(c->querybuf)-c->qb_pos); big_arg = 1; /* Note that the 'remaining' variable may be zero in some edge case, * for example once we resume a blocked client after CLIENT PAUSE. */ if (remaining > 0) readlen = remaining; /* Master client needs expand the readlen when meet BIG_ARG(see #9100), * but doesn't need align to the next arg, we can read more data. */ if (c->flags & CLIENT_MASTER && readlen < PROTO_IOBUF_LEN) readlen = PROTO_IOBUF_LEN; } qblen = sdslen(c->querybuf); if (!(c->flags & CLIENT_MASTER) && // master client's querybuf can grow greedy. (big_arg || sdsalloc(c->querybuf) < PROTO_IOBUF_LEN)) { /* When reading a BIG_ARG we won't be reading more than that one arg * into the query buffer, so we don't need to pre-allocate more than we * need, so using the non-greedy growing. For an initial allocation of * the query buffer, we also don't wanna use the greedy growth, in order * to avoid collision with the RESIZE_THRESHOLD mechanism. */ c->querybuf = sdsMakeRoomForNonGreedy(c->querybuf, readlen); /* We later set the peak to the used portion of the buffer, but here we over * allocated because we know what we need, make sure it'll not be shrunk before used. */ if (c->querybuf_peak < qblen + readlen) c->querybuf_peak = qblen + readlen; } else { c->querybuf = sdsMakeRoomFor(c->querybuf, readlen); /* Read as much as possible from the socket to save read(2) system calls. */ readlen = sdsavail(c->querybuf); } nread = connRead(c->conn, c->querybuf+qblen, readlen); if (nread == -1) { if (connGetState(conn) == CONN_STATE_CONNECTED) { return; } else { serverLog(LL_VERBOSE, \"Reading from client: %s\",connGetLastError(c->conn)); freeClientAsync(c); goto done; } } else if (nread == 0) { if (server.verbosity querybuf,nread); qblen = sdslen(c->querybuf); if (c->querybuf_peak < qblen) c->querybuf_peak = qblen; c->lastinteraction = server.unixtime; if (c->flags & CLIENT_MASTER) { c->read_reploff += nread; atomicIncr(server.stat_net_repl_input_bytes, nread); } else { atomicIncr(server.stat_net_input_bytes, nread); } if (!(c->flags & CLIENT_MASTER) && sdslen(c->querybuf) > server.client_max_querybuf_len) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c->querybuf,64); serverLog(LL_WARNING,\"Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)\", ci, bytes); sdsfree(ci); sdsfree(bytes); freeClientAsync(c); atomicIncr(server.stat_client_qbuf_limit_disconnections, 1); goto done; } /* There is more data in the client input buffer, continue parsing it * and check if there is a full command to execute. */ if (processInputBuffer(c) == C_ERR) c = NULL; done: beforeNextClient(c); } 这段代码是Redis服务器的一部分，用于处理客户端的请求。它首先获取客户端连接的私有数据，然后根据客户端请求的类型和长度，确定是否需要读取更多的数据。如果需要，它会尝试从客户端读取更多的数据，并将其存储在查询缓冲区中。然后，它会检查客户端是否发送了完整的命令，如果是，则处理该命令。最后，它会更新服务器的统计信息，并在必要时关闭客户端连接。 获取数据：client *c = connGetPrivateData(conn); /* Get the associated private data pointer */ static inline void *connGetPrivateData(connection *conn) { return conn->private_data; } 命令解析processInputBuffer int processInputBuffer(client *c) { /* Keep processing while there is something in the input buffer */ while(c->qb_pos < sdslen(c->querybuf)) { /* Immediately abort if the client is in the middle of something. */ if (c->flags & CLIENT_BLOCKED) break; /* Don't process more buffers from clients that have already pending * commands to execute in c->argv. */ if (c->flags & CLIENT_PENDING_COMMAND) break; /* Don't process input from the master while there is a busy script * condition on the slave. We want just to accumulate the replication * stream (instead of replying -BUSY like we do with other clients) and * later resume the processing. */ if (isInsideYieldingLongCommand() && c->flags & CLIENT_MASTER) break; /* CLIENT_CLOSE_AFTER_REPLY closes the connection once the reply is * written to the client. Make sure to not let the reply grow after * this flag has been set (i.e. don't process more commands). * * The same applies for clients we want to terminate ASAP. */ if (c->flags & (CLIENT_CLOSE_AFTER_REPLY|CLIENT_CLOSE_ASAP)) break; /* Determine request type when unknown. */ if (!c->reqtype) { if (c->querybuf[c->qb_pos] == '*') { c->reqtype = PROTO_REQ_MULTIBULK; } else { c->reqtype = PROTO_REQ_INLINE; } } if (c->reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; } else if (c->reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; } else { serverPanic(\"Unknown request type\"); } /* Multibulk processing could see a argc == 0) { resetClient(c); } else { /* If we are in the context of an I/O thread, we can't really * execute the command here. All we can do is to flag the client * as one that needs to process the command. */ if (io_threads_op != IO_THREADS_OP_IDLE) { serverAssert(io_threads_op == IO_THREADS_OP_READ); c->flags |= CLIENT_PENDING_COMMAND; break; } /* We are finally ready to execute the command. */ if (processCommandAndResetClient(c) == C_ERR) { /* If the client is no longer valid, we avoid exiting this * loop and trimming the client buffer later. So we return * ASAP in that case. */ return C_ERR; } } } if (c->flags & CLIENT_MASTER) { /* If the client is a master, trim the querybuf to repl_applied, * since master client is very special, its querybuf not only * used to parse command, but also proxy to sub-replicas. * * Here are some scenarios we cannot trim to qb_pos: * 1. we don't receive complete command from master * 2. master client blocked cause of client pause * 3. io threads operate read, master client flagged with CLIENT_PENDING_COMMAND * * In these scenarios, qb_pos points to the part of the current command * or the beginning of next command, and the current command is not applied yet, * so the repl_applied is not equal to qb_pos. */ if (c->repl_applied) { sdsrange(c->querybuf,c->repl_applied,-1); c->qb_pos -= c->repl_applied; c->repl_applied = 0; } } else if (c->qb_pos) { /* Trim to pos */ sdsrange(c->querybuf,c->qb_pos,-1); c->qb_pos = 0; } /* Update client memory usage after processing the query buffer, this is * important in case the query buffer is big and wasn't drained during * the above loop (because of partially sent big commands). */ if (io_threads_op == IO_THREADS_OP_IDLE) updateClientMemUsageAndBucket(c); return C_OK; } 这段代码是一个名为processInputBuffer的函数，它接收一个指向客户端结构体的指针c作为参数。这个函数的主要目的是处理客户端发送到服务器的命令缓冲区。 函数首先检查客户端是否处于阻塞状态、是否有待处理的命令或者是否在执行主服务器上的脚本。如果满足这些条件之一，函数将立即终止循环并返回。 接下来，函数根据客户端请求的类型（单行或多行）来处理输入缓冲区。如果请求类型未知，函数将尝试确定请求类型。然后，根据请求类型调用相应的处理函数（processInlineBuffer或processMultibulkBuffer）。 在处理完输入缓冲区后，函数会检查客户端是否需要执行命令。如果需要，它将调用processCommandAndResetClient函数来执行命令并重置客户端。如果客户端不再有效，函数将提前返回错误。 最后，函数会根据客户端类型更新查询缓冲区的大小。对于主服务器客户端，它会将查询缓冲区裁剪到已应用的位置；对于其他类型的客户端，它会将查询缓冲区裁剪到当前位置。 在整个过程中，函数还会更新客户端的内存使用情况，这在某些情况下是很重要的，例如当查询缓冲区很大且在上述循环中没有被完全消耗时。 总之，这个函数的作用是处理客户端发送到服务器的命令缓冲区，并根据请求类型执行相应的操作。 执行命令processCommand 在上述函数中我们回调用processCommandAndResetClient函数，在这里面掉用了执行命令 processCommandAndResetClient函数 int processCommandAndResetClient(client *c) { int deadclient = 0; client *old_client = server.current_client; server.current_client = c; if (processCommand(c) == C_OK) { commandProcessed(c); /* Update the client's memory to include output buffer growth following the * processed command. */ updateClientMemUsageAndBucket(c); } if (server.current_client == NULL) deadclient = 1; /* * Restore the old client, this is needed because when a script * times out, we will get into this code from processEventsWhileBlocked. * Which will cause to set the server.current_client. If not restored * we will return 1 to our caller which will falsely indicate the client * is dead and will stop reading from its buffer. */ server.current_client = old_client; /* performEvictions may flush slave output buffers. This may * result in a slave, that may be the active client, to be * freed. */ return deadclient ? C_ERR : C_OK; } 函数首先将当前服务器的客户端设置为传入的客户端c。然后调用processCommand(c)来处理命令，如果处理成功，则调用commandProcessed(c)来标记命令已处理。接下来，调用updateClientMemUsageAndBucket(c)来更新客户端的内存使用情况和存储桶。 在处理完命令后，函数检查当前服务器的客户端是否为空，如果为空，则将deadclient标志设置为1，表示客户端已死亡。 为了确保在脚本超时时能够正确恢复旧的客户端状态，函数将服务器的当前客户端还原为之前保存的旧客户端old_client。 最后，函数根据deadclient标志的值返回相应的结果。如果客户端已死亡，则返回C_ERR；否则返回C_OK。 重点来了，执行命令 processCommand int processCommand(client *c) { if (!scriptIsTimedout()) { /* Both EXEC and scripts call call() directly so there should be * no way in_exec or scriptIsRunning() is 1. * That is unless lua_timedout, in which case client may run * some commands. */ serverAssert(!server.in_exec); serverAssert(!scriptIsRunning()); } /* in case we are starting to ProcessCommand and we already have a command we assume * this is a reprocessing of this command, so we do not want to perform some of the actions again. */ int client_reprocessing_command = c->cmd ? 1 : 0; /* only run command filter if not reprocessing command */ if (!client_reprocessing_command) { moduleCallCommandFilters(c); reqresAppendRequest(c); } /* Handle possible security attacks. */ if (!strcasecmp(c->argv[0]->ptr,\"host:\") || !strcasecmp(c->argv[0]->ptr,\"post\")) { securityWarningCommand(c); return C_ERR; } /* If we're inside a module blocked context yielding that wants to avoid * processing clients, postpone the command. */ if (server.busy_module_yield_flags != BUSY_MODULE_YIELD_NONE && !(server.busy_module_yield_flags & BUSY_MODULE_YIELD_CLIENTS)) { blockPostponeClient(c); return C_OK; } /* Now lookup the command and check ASAP about trivial error conditions * such as wrong arity, bad command name and so forth. * In case we are reprocessing a command after it was blocked, * we do not have to repeat the same checks */ if (!client_reprocessing_command) { c->cmd = c->lastcmd = c->realcmd = lookupCommand(c->argv,c->argc); sds err; if (!commandCheckExistence(c, &err)) { rejectCommandSds(c, err); return C_OK; } if (!commandCheckArity(c, &err)) { rejectCommandSds(c, err); return C_OK; } /* Check if the command is marked as protected and the relevant configuration allows it */ if (c->cmd->flags & CMD_PROTECTED) { if ((c->cmd->proc == debugCommand && !allowProtectedAction(server.enable_debug_cmd, c)) || (c->cmd->proc == moduleCommand && !allowProtectedAction(server.enable_module_cmd, c))) { rejectCommandFormat(c,\"%s command not allowed. If the %s option is set to \\\"local\\\", \" \"you can run it from a local connection, otherwise you need to set this option \" \"in the configuration file, and then restart the server.\", c->cmd->proc == debugCommand ? \"DEBUG\" : \"MODULE\", c->cmd->proc == debugCommand ? \"enable-debug-command\" : \"enable-module-command\"); return C_OK; } } } uint64_t cmd_flags = getCommandFlags(c); int is_read_command = (cmd_flags & CMD_READONLY) || (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_READONLY)); int is_write_command = (cmd_flags & CMD_WRITE) || (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_WRITE)); int is_denyoom_command = (cmd_flags & CMD_DENYOOM) || (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_DENYOOM)); int is_denystale_command = !(cmd_flags & CMD_STALE) || (c->cmd->proc == execCommand && (c->mstate.cmd_inv_flags & CMD_STALE)); int is_denyloading_command = !(cmd_flags & CMD_LOADING) || (c->cmd->proc == execCommand && (c->mstate.cmd_inv_flags & CMD_LOADING)); int is_may_replicate_command = (cmd_flags & (CMD_WRITE | CMD_MAY_REPLICATE)) || (c->cmd->proc == execCommand && (c->mstate.cmd_flags & (CMD_WRITE | CMD_MAY_REPLICATE))); int is_deny_async_loading_command = (cmd_flags & CMD_NO_ASYNC_LOADING) || (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_NO_ASYNC_LOADING)); int obey_client = mustObeyClient(c); if (authRequired(c)) { /* AUTH and HELLO and no auth commands are valid even in * non-authenticated state. */ if (!(c->cmd->flags & CMD_NO_AUTH)) { rejectCommand(c,shared.noautherr); return C_OK; } } if (c->flags & CLIENT_MULTI && c->cmd->flags & CMD_NO_MULTI) { rejectCommandFormat(c,\"Command not allowed inside a transaction\"); return C_OK; } /* Check if the user can run this command according to the current * ACLs. */ int acl_errpos; int acl_retval = ACLCheckAllPerm(c,&acl_errpos); if (acl_retval != ACL_OK) { addACLLogEntry(c,acl_retval,(c->flags & CLIENT_MULTI) ? ACL_LOG_CTX_MULTI : ACL_LOG_CTX_TOPLEVEL,acl_errpos,NULL,NULL); sds msg = getAclErrorMessage(acl_retval, c->user, c->cmd, c->argv[acl_errpos]->ptr, 0); rejectCommandFormat(c, \"-NOPERM %s\", msg); sdsfree(msg); return C_OK; } /* If cluster is enabled perform the cluster redirection here. * However we don't perform the redirection if: * 1) The sender of this command is our master. * 2) The command has no key arguments. */ if (server.cluster_enabled && !mustObeyClient(c) && !(!(c->cmd->flags&CMD_MOVABLE_KEYS) && c->cmd->key_specs_num == 0 && c->cmd->proc != execCommand)) { int error_code; clusterNode *n = getNodeByQuery(c,c->cmd,c->argv,c->argc, &c->slot,&error_code); if (n == NULL || n != server.cluster->myself) { if (c->cmd->proc == execCommand) { discardTransaction(c); } else { flagTransaction(c); } clusterRedirectClient(c,n,c->slot,error_code); c->cmd->rejected_calls++; return C_OK; } } /* Disconnect some clients if total clients memory is too high. We do this * before key eviction, after the last command was executed and consumed * some client output buffer memory. */ evictClients(); if (server.current_client == NULL) { /* If we evicted ourself then abort processing the command */ return C_ERR; } /* Handle the maxmemory directive. * * Note that we do not want to reclaim memory if we are here re-entering * the event loop since there is a busy Lua script running in timeout * condition, to avoid mixing the propagation of scripts with the * propagation of DELs due to eviction. */ if (server.maxmemory && !isInsideYieldingLongCommand()) { int out_of_memory = (performEvictions() == EVICT_FAIL); /* performEvictions may evict keys, so we need flush pending tracking * invalidation keys. If we don't do this, we may get an invalidation * message after we perform operation on the key, where in fact this * message belongs to the old value of the key before it gets evicted.*/ trackingHandlePendingKeyInvalidations(); /* performEvictions may flush slave output buffers. This may result * in a slave, that may be the active client, to be freed. */ if (server.current_client == NULL) return C_ERR; int reject_cmd_on_oom = is_denyoom_command; /* If client is in MULTI/EXEC context, queuing may consume an unlimited * amount of memory, so we want to stop that. * However, we never want to reject DISCARD, or even EXEC (unless it * contains denied commands, in which case is_denyoom_command is already * set. */ if (c->flags & CLIENT_MULTI && c->cmd->proc != execCommand && c->cmd->proc != discardCommand && c->cmd->proc != quitCommand && c->cmd->proc != resetCommand) { reject_cmd_on_oom = 1; } if (out_of_memory && reject_cmd_on_oom) { rejectCommand(c, shared.oomerr); return C_OK; } /* Save out_of_memory result at command start, otherwise if we check OOM * in the first write within script, memory used by lua stack and * arguments might interfere. We need to save it for EXEC and module * calls too, since these can call EVAL, but avoid saving it during an * interrupted / yielding busy script / module. */ server.pre_command_oom_state = out_of_memory; } /* Make sure to use a reasonable amount of memory for client side * caching metadata. */ if (server.tracking_clients) trackingLimitUsedSlots(); /* Don't accept write commands if there are problems persisting on disk * unless coming from our master, in which case check the replica ignore * disk write error config to either log or crash. */ int deny_write_type = writeCommandsDeniedByDiskError(); if (deny_write_type != DISK_ERROR_TYPE_NONE && (is_write_command || c->cmd->proc == pingCommand)) { if (obey_client) { if (!server.repl_ignore_disk_write_error && c->cmd->proc != pingCommand) { serverPanic(\"Replica was unable to write command to disk.\"); } else { static mstime_t last_log_time_ms = 0; const mstime_t log_interval_ms = 10000; if (server.mstime > last_log_time_ms + log_interval_ms) { last_log_time_ms = server.mstime; serverLog(LL_WARNING, \"Replica is applying a command even though \" \"it is unable to write to disk.\"); } } } else { sds err = writeCommandsGetDiskErrorMessage(deny_write_type); /* remove the newline since rejectCommandSds adds it. */ sdssubstr(err, 0, sdslen(err)-2); rejectCommandSds(c, err); return C_OK; } } /* Don't accept write commands if there are not enough good slaves and * user configured the min-slaves-to-write option. */ if (is_write_command && !checkGoodReplicasStatus()) { rejectCommand(c, shared.noreplicaserr); return C_OK; } /* Don't accept write commands if this is a read only slave. But * accept write commands if this is our master. */ if (server.masterhost && server.repl_slave_ro && !obey_client && is_write_command) { rejectCommand(c, shared.roslaveerr); return C_OK; } /* Only allow a subset of commands in the context of Pub/Sub if the * connection is in RESP2 mode. With RESP3 there are no limits. */ if ((c->flags & CLIENT_PUBSUB && c->resp == 2) && c->cmd->proc != pingCommand && c->cmd->proc != subscribeCommand && c->cmd->proc != ssubscribeCommand && c->cmd->proc != unsubscribeCommand && c->cmd->proc != sunsubscribeCommand && c->cmd->proc != psubscribeCommand && c->cmd->proc != punsubscribeCommand && c->cmd->proc != quitCommand && c->cmd->proc != resetCommand) { rejectCommandFormat(c, \"Can't execute '%s': only (P|S)SUBSCRIBE / \" \"(P|S)UNSUBSCRIBE / PING / QUIT / RESET are allowed in this context\", c->cmd->fullname); return C_OK; } /* Only allow commands with flag \"t\", such as INFO, REPLICAOF and so on, * when replica-serve-stale-data is no and we are a replica with a broken * link with master. */ if (server.masterhost && server.repl_state != REPL_STATE_CONNECTED && server.repl_serve_stale_data == 0 && is_denystale_command) { rejectCommand(c, shared.masterdownerr); return C_OK; } /* Loading DB? Return an error if the command has not the * CMD_LOADING flag. */ if (server.loading && !server.async_loading && is_denyloading_command) { rejectCommand(c, shared.loadingerr); return C_OK; } /* During async-loading, block certain commands. */ if (server.async_loading && is_deny_async_loading_command) { rejectCommand(c,shared.loadingerr); return C_OK; } /* when a busy job is being done (script / module) * Only allow a limited number of commands. * Note that we need to allow the transactions commands, otherwise clients * sending a transaction with pipelining without error checking, may have * the MULTI plus a few initial commands refused, then the timeout * condition resolves, and the bottom-half of the transaction gets * executed, see Github PR #7022. */ if (isInsideYieldingLongCommand() && !(c->cmd->flags & CMD_ALLOW_BUSY)) { if (server.busy_module_yield_flags && server.busy_module_yield_reply) { rejectCommandFormat(c, \"-BUSY %s\", server.busy_module_yield_reply); } else if (server.busy_module_yield_flags) { rejectCommand(c, shared.slowmoduleerr); } else if (scriptIsEval()) { rejectCommand(c, shared.slowevalerr); } else { rejectCommand(c, shared.slowscripterr); } return C_OK; } /* Prevent a replica from sending commands that access the keyspace. * The main objective here is to prevent abuse of client pause check * from which replicas are exempt. */ if ((c->flags & CLIENT_SLAVE) && (is_may_replicate_command || is_write_command || is_read_command)) { rejectCommandFormat(c, \"Replica can't interact with the keyspace\"); return C_OK; } /* If the server is paused, block the client until * the pause has ended. Replicas are never paused. */ if (!(c->flags & CLIENT_SLAVE) && ((isPausedActions(PAUSE_ACTION_CLIENT_ALL)) || ((isPausedActions(PAUSE_ACTION_CLIENT_WRITE)) && is_may_replicate_command))) { blockPostponeClient(c); return C_OK; } /* Exec the command */ if (c->flags & CLIENT_MULTI && c->cmd->proc != execCommand && c->cmd->proc != discardCommand && c->cmd->proc != multiCommand && c->cmd->proc != watchCommand && c->cmd->proc != quitCommand && c->cmd->proc != resetCommand) { queueMultiCommand(c, cmd_flags); addReply(c,shared.queued); } else { int flags = CMD_CALL_FULL; if (client_reprocessing_command) flags |= CMD_CALL_REPROCESSING; call(c,flags); if (listLength(server.ready_keys) && !isInsideYieldingLongCommand()) handleClientsBlockedOnKeys(); } return C_OK; } 这段代码是一个名为processCommand的函数，它用于处理客户端发送的命令。函数首先检查命令是否超时，然后根据命令的类型和权限进行相应的处理。接下来，函数会检查命令是否具有可重入性、写权限、读权限等属性，并根据这些属性判断命令是否可以执行。最后，函数会根据命令的类型和执行结果进行相应的操作，如拒绝命令、执行命令等。 ​ 返回响应addReply(c,shared.queued); 在上满执行命令后，我们会返回结果 /* ----------------------------------------------------------------------------- * Higher level functions to queue data on the client output buffer. * The following functions are the ones that commands implementations will call. * -------------------------------------------------------------------------- */ /* Add the object 'obj' string representation to the client output buffer. */ void addReply(client *c, robj *obj) { if (prepareClientToWrite(c) != C_OK) return; if (sdsEncodedObject(obj)) { _addReplyToBufferOrList(c,obj->ptr,sdslen(obj->ptr)); } else if (obj->encoding == OBJ_ENCODING_INT) { /* For integer encoded strings we just convert it into a string * using our optimized function, and attach the resulting string * to the output buffer. */ char buf[32]; size_t len = ll2string(buf,sizeof(buf),(long)obj->ptr); _addReplyToBufferOrList(c,buf,len); } else { serverPanic(\"Wrong obj->encoding in addReply()\"); } } 这段代码是一个名为addReply的函数，它接受两个参数：一个client指针和一个robj指针。该函数的主要目的是将给定的对象添加到客户端的回复缓冲区或列表中。 首先，函数调用prepareClientToWrite(c)来准备客户端以进行写操作。如果返回值不是C_OK，则函数直接返回，不执行任何操作。 接下来，函数检查对象是否为编码过的对象（通过sdsEncodedObject(obj)）。如果是编码过的对象，则使用_addReplyToBufferOrList函数将其添加到客户端的回复缓冲区或列表中。这里使用了obj-&gt;ptr作为要添加的对象，并使用sdslen(obj-&gt;ptr)获取其长度。 如果对象不是编码过的对象，但对象的编码类型是整数编码（通过obj-&gt;encoding == OBJ_ENCODING_INT），则函数会将整数转换为字符串，并将其添加到客户端的回复缓冲区或列表中。这里使用了优化过的函数ll2string来完成转换，并将结果存储在字符数组buf中。然后，使用_addReplyToBufferOrList函数将转换后的字符串添加到客户端的回复缓冲区或列表中。 如果对象既不是编码过的对象，也不是整数编码的对象，则函数会触发服务器异常，提示”Wrong obj-&gt;encoding in addReply()”。","categories":[{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/tags/redis/"}],"author":"菠萝"},{"title":"Redis源码阅读1","slug":"Redis源码阅读系列1","date":"2024-03-18T09:39:39.146Z","updated":"2024-03-18T09:39:39.146Z","comments":true,"path":"2024/03/18/Redis源码阅读系列1/","permalink":"https://kiritoabc.github.io/2024/03/18/Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%B3%BB%E5%88%971/","excerpt":"这里我想了解Redis的一些基础的类型的具体实现，所有尝试阅读Redis的源码，从源码中学习这些类型的实现。 Strings JSON Lists Sets Hashes Sorted sets Streams Geospatial Bitmaps Bitfields Probabilistic Time series Redis is a data structure server. At its core, Redis provides a collection of native data types that help you solve a wide variety of problems, from caching to queuing to event processing. Below is a short description of each data type, with links to broader overviews and command references. Redis是一个数据结构服务器。Redis的核心是提供了一组本地数据类型，可以帮助你解决各种各样的问题，从缓存到队列再到事件处理。下面是每种数据类型的简短描述，并提供了更广泛概述和命令参考的链接。","text":"这里我想了解Redis的一些基础的类型的具体实现，所有尝试阅读Redis的源码，从源码中学习这些类型的实现。 Strings JSON Lists Sets Hashes Sorted sets Streams Geospatial Bitmaps Bitfields Probabilistic Time series Redis is a data structure server. At its core, Redis provides a collection of native data types that help you solve a wide variety of problems, from caching to queuing to event processing. Below is a short description of each data type, with links to broader overviews and command references. Redis是一个数据结构服务器。Redis的核心是提供了一组本地数据类型，可以帮助你解决各种各样的问题，从缓存到队列再到事件处理。下面是每种数据类型的简短描述，并提供了更广泛概述和命令参考的链接。 data typesRedis的type定义在server.h中如下 /* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The 'encoding' field of the object * is set to one of this fields for this object. */ #define OBJ_ENCODING_RAW 0 /* Raw representation */ #define OBJ_ENCODING_INT 1 /* Encoded as integer */ #define OBJ_ENCODING_HT 2 /* Encoded as hash table */ #define OBJ_ENCODING_ZIPMAP 3 /* No longer used: old hash encoding. */ #define OBJ_ENCODING_LINKEDLIST 4 /* No longer used: old list encoding. */ #define OBJ_ENCODING_ZIPLIST 5 /* No longer used: old list/hash/zset encoding. */ #define OBJ_ENCODING_INTSET 6 /* Encoded as intset */ #define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */ #define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */ #define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of listpacks */ #define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree of listpacks */ #define OBJ_ENCODING_LISTPACK 11 /* Encoded as a listpack */ Strings Redis的Strings类型，其实底层是由三种数据结构组成 1.int:整数且小于二十位整数以下的数字数据才会使用这个类型 2.embstr（embedded string，表示嵌入式的String):代表embstr格式的SDS（Simple Dynamic String 简单动态字符串），保存长度小于44字节的字符串。 3.raw:保存长度大于44的字符串 测试 这就是redis中，Strings类型没有直接复用C语言的字符串，而是新建了属于自己的结构————SDS（简单动态字符串）。在Redis数据库里，包含字符串的键值对都是由SDS实现的，Redis中所有的值对象包含的字符串对象底层也是由SDS实现！ sds.h 这段代码是C语言编写的，用于处理Redis的字符串数据结构SDS（Simple Dynamic String）。SDS是一种动态分配和释放内存的字符串数据结构，它提供了一种高效的方式来存储和操作字符串。 代码中定义了一些宏和类型，以及一些函数，用于操作SDS字符串。例如，hi_sdslen函数返回SDS字符串的长度，hi_sdssetlen函数设置SDS字符串的长度，hi_sdsnew函数创建一个新的SDS字符串，等等。 此外，代码还包含了一些辅助函数，如hi_sdscat、hi_sdsdup、hi_sdsfree等，用于对SDS字符串进行各种操作，如连接、复制、释放等。 最后，代码还包含了一些用于处理SDS字符串的函数，如hi_sdstrim、hi_sdsrange等，用于对SDS字符串进行修剪、范围查询等操作。 /* SDSLib 2.0 -- A C dynamic strings library * * Copyright (c) 2006-2015, Salvatore Sanfilippo &lt;antirez at gmail dot com> * Copyright (c) 2015, Oran Agra * Copyright (c) 2015, Redis Labs, Inc * All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions are met: * * * Redistributions of source code must retain the above copyright notice, * this list of conditions and the following disclaimer. * * Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * Neither the name of Redis nor the names of its contributors may be used * to endorse or promote products derived from this software without * specific prior written permission. * * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE * POSSIBILITY OF SUCH DAMAGE. */ #ifndef HIREDIS_SDS_H #define HIREDIS_SDS_H #define HI_SDS_MAX_PREALLOC (1024*1024) #ifdef _MSC_VER typedef long long ssize_t; #define SSIZE_MAX (LLONG_MAX >> 1) #ifndef __clang__ #define __attribute__(x) #endif #endif #include &lt;sys/types.h> #include &lt;stdarg.h> #include &lt;stdint.h> typedef char *hisds; /* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) hisdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) hisdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) hisdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) hisdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) hisdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; #define HI_SDS_TYPE_5 0 #define HI_SDS_TYPE_8 1 #define HI_SDS_TYPE_16 2 #define HI_SDS_TYPE_32 3 #define HI_SDS_TYPE_64 4 #define HI_SDS_TYPE_MASK 7 #define HI_SDS_TYPE_BITS 3 #define HI_SDS_HDR_VAR(T,s) struct hisdshdr##T *sh = (struct hisdshdr##T *)((s)-(sizeof(struct hisdshdr##T))); #define HI_SDS_HDR(T,s) ((struct hisdshdr##T *)((s)-(sizeof(struct hisdshdr##T)))) #define HI_SDS_TYPE_5_LEN(f) ((f)>>HI_SDS_TYPE_BITS) static inline size_t hi_sdslen(const hisds s) { unsigned char flags = s[-1]; switch(flags &amp; HI_SDS_TYPE_MASK) { case HI_SDS_TYPE_5: return HI_SDS_TYPE_5_LEN(flags); case HI_SDS_TYPE_8: return HI_SDS_HDR(8,s)->len; case HI_SDS_TYPE_16: return HI_SDS_HDR(16,s)->len; case HI_SDS_TYPE_32: return HI_SDS_HDR(32,s)->len; case HI_SDS_TYPE_64: return HI_SDS_HDR(64,s)->len; } return 0; } static inline size_t hi_sdsavail(const hisds s) { unsigned char flags = s[-1]; switch(flags&amp;HI_SDS_TYPE_MASK) { case HI_SDS_TYPE_5: { return 0; } case HI_SDS_TYPE_8: { HI_SDS_HDR_VAR(8,s); return sh->alloc - sh->len; } case HI_SDS_TYPE_16: { HI_SDS_HDR_VAR(16,s); return sh->alloc - sh->len; } case HI_SDS_TYPE_32: { HI_SDS_HDR_VAR(32,s); return sh->alloc - sh->len; } case HI_SDS_TYPE_64: { HI_SDS_HDR_VAR(64,s); return sh->alloc - sh->len; } } return 0; } static inline void hi_sdssetlen(hisds s, size_t newlen) { unsigned char flags = s[-1]; switch(flags&amp;HI_SDS_TYPE_MASK) { case HI_SDS_TYPE_5: { unsigned char *fp = ((unsigned char*)s)-1; *fp = (unsigned char)(HI_SDS_TYPE_5 | (newlen &lt;&lt; HI_SDS_TYPE_BITS)); } break; case HI_SDS_TYPE_8: HI_SDS_HDR(8,s)->len = (uint8_t)newlen; break; case HI_SDS_TYPE_16: HI_SDS_HDR(16,s)->len = (uint16_t)newlen; break; case HI_SDS_TYPE_32: HI_SDS_HDR(32,s)->len = (uint32_t)newlen; break; case HI_SDS_TYPE_64: HI_SDS_HDR(64,s)->len = (uint64_t)newlen; break; } } static inline void hi_sdsinclen(hisds s, size_t inc) { unsigned char flags = s[-1]; switch(flags&amp;HI_SDS_TYPE_MASK) { case HI_SDS_TYPE_5: { unsigned char *fp = ((unsigned char*)s)-1; unsigned char newlen = HI_SDS_TYPE_5_LEN(flags)+(unsigned char)inc; *fp = HI_SDS_TYPE_5 | (newlen &lt;&lt; HI_SDS_TYPE_BITS); } break; case HI_SDS_TYPE_8: HI_SDS_HDR(8,s)->len += (uint8_t)inc; break; case HI_SDS_TYPE_16: HI_SDS_HDR(16,s)->len += (uint16_t)inc; break; case HI_SDS_TYPE_32: HI_SDS_HDR(32,s)->len += (uint32_t)inc; break; case HI_SDS_TYPE_64: HI_SDS_HDR(64,s)->len += (uint64_t)inc; break; } } /* hi_sdsalloc() = hi_sdsavail() + hi_sdslen() */ static inline size_t hi_sdsalloc(const hisds s) { unsigned char flags = s[-1]; switch(flags &amp; HI_SDS_TYPE_MASK) { case HI_SDS_TYPE_5: return HI_SDS_TYPE_5_LEN(flags); case HI_SDS_TYPE_8: return HI_SDS_HDR(8,s)->alloc; case HI_SDS_TYPE_16: return HI_SDS_HDR(16,s)->alloc; case HI_SDS_TYPE_32: return HI_SDS_HDR(32,s)->alloc; case HI_SDS_TYPE_64: return HI_SDS_HDR(64,s)->alloc; } return 0; } static inline void hi_sdssetalloc(hisds s, size_t newlen) { unsigned char flags = s[-1]; switch(flags&amp;HI_SDS_TYPE_MASK) { case HI_SDS_TYPE_5: /* Nothing to do, this type has no total allocation info. */ break; case HI_SDS_TYPE_8: HI_SDS_HDR(8,s)->alloc = (uint8_t)newlen; break; case HI_SDS_TYPE_16: HI_SDS_HDR(16,s)->alloc = (uint16_t)newlen; break; case HI_SDS_TYPE_32: HI_SDS_HDR(32,s)->alloc = (uint32_t)newlen; break; case HI_SDS_TYPE_64: HI_SDS_HDR(64,s)->alloc = (uint64_t)newlen; break; } } hisds hi_sdsnewlen(const void *init, size_t initlen); hisds hi_sdsnew(const char *init); hisds hi_sdsempty(void); hisds hi_sdsdup(const hisds s); void hi_sdsfree(hisds s); hisds hi_sdsgrowzero(hisds s, size_t len); hisds hi_sdscatlen(hisds s, const void *t, size_t len); hisds hi_sdscat(hisds s, const char *t); hisds hi_sdscatsds(hisds s, const hisds t); hisds hi_sdscpylen(hisds s, const char *t, size_t len); hisds hi_sdscpy(hisds s, const char *t); hisds hi_sdscatvprintf(hisds s, const char *fmt, va_list ap); #ifdef __GNUC__ hisds hi_sdscatprintf(hisds s, const char *fmt, ...) __attribute__((format(printf, 2, 3))); #else hisds hi_sdscatprintf(hisds s, const char *fmt, ...); #endif hisds hi_sdscatfmt(hisds s, char const *fmt, ...); hisds hi_sdstrim(hisds s, const char *cset); int hi_sdsrange(hisds s, ssize_t start, ssize_t end); void hi_sdsupdatelen(hisds s); void hi_sdsclear(hisds s); int hi_sdscmp(const hisds s1, const hisds s2); hisds *hi_sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count); void hi_sdsfreesplitres(hisds *tokens, int count); void hi_sdstolower(hisds s); void hi_sdstoupper(hisds s); hisds hi_sdsfromlonglong(long long value); hisds hi_sdscatrepr(hisds s, const char *p, size_t len); hisds *hi_sdssplitargs(const char *line, int *argc); hisds hi_sdsmapchars(hisds s, const char *from, const char *to, size_t setlen); hisds hi_sdsjoin(char **argv, int argc, char *sep); hisds hi_sdsjoinsds(hisds *argv, int argc, const char *sep, size_t seplen); /* Low level functions exposed to the user API */ hisds hi_sdsMakeRoomFor(hisds s, size_t addlen); void hi_sdsIncrLen(hisds s, int incr); hisds hi_sdsRemoveFreeSpace(hisds s); size_t hi_sdsAllocSize(hisds s); void *hi_sdsAllocPtr(hisds s); /* Export the allocator used by SDS to the program using SDS. * Sometimes the program SDS is linked to, may use a different set of * allocators, but may want to allocate or free things that SDS will * respectively free or allocate. */ void *hi_sds_malloc(size_t size); void *hi_sds_realloc(void *ptr, size_t size); void hi_sds_free(void *ptr); #ifdef REDIS_TEST int hi_sdsTest(int argc, char *argv[]); #endif #endif /* HIREDIS_SDS_H */ 它用sdshdr5、(2^5=32byte)sdshdr8、(2 ^ 8=256byte)sdshdr16、(2 ^ 16=65536byte=64KB)sdshdr32、 (2 ^ 32byte=4GB)sdshdr64，2的64次方byte＝17179869184G 来存储不同长度的字符串，len表示长度，这样获取字符串长度就可以在O(1)的情况下，拿到字符串，而不是像C语言一样去遍历。alloc可以计算字符串未被分配的空间，有了这个值就可以引入预分配空间的算法了，而不用去考虑内存分配的问题。buf 表示字符串数组，真存数据的。 小结： 1.只有整数才会使用int，如果是浮点数，就是用字符串保存。 2.embstr 与 raw 类型底层的数据结构其实都是 SDS (简单动态字符串，Redis 内部定义 sdshdr5， sdshdr8等等)。存储使用的是 char[]的数组。 Hashes 从定义中可以看出#define OBJ_ENCODING_HT 2 /* Encoded as hash table */ 在Redis中hash被定义为 OBJ_ENCODING_HT，接下来让我们看看hash table在Redis中的具体实现 Hash数据类型也和String有相似之处，到达了一定的阈值之后就会对数据结构进行升级。 数据结构：1）hashtable 就是和java当中使用的hashtable一样，是一个数组+链表的结构。 2）ziplist 压缩链表 单节点的结构体定义： /* We use this function to receive information about a ziplist entry. * Note that this is not how the data is actually encoded, is just what we * get filled by a function in order to operate more easily. */ typedef struct zlentry { unsigned int prevrawlensize; //上一个节点的长度 unsigned int prevrawlen; //存储上一个链表节点长度所需要的的字节数 unsigned int lensize; //当前节点所需要的的字节数 unsigned int len; //当前节点占用的长度 unsigned int headersize; //当前节点的头大小 unsigned char encoding; //编码方式 unsigned char *p; //指向当前节点起始位置 } zlentry; 为什么有链表了，redis还要整出一个压缩链表？1）普通的双向链表会有两个前后指针，在存储数据很小的情况下，我们存储的实际数据大小可能还没有指针占用的内存大。而ziplist是一个特殊的双向链表，并没有维护前后指针这两个字段，而是存储上一个entry的长度和当前entry的长度，通过长度推算下一个元素在什么地方。牺牲读取的性能，获取高效的空间利用率，因为（简短KV键值对）存储指针比存储entry长度更费内存，这是典型的时间换空间。 2）链表是不连续的，遍历比较慢，而ziplist却可以解决这个问题，ziplist将一些必要的偏移量信息都记录在了每一个节点里，使之能跳到上一个节点或者尾节点节点。 3）头节点里有头结点同时还有一个参数len，和SDS类型类似，这就是用来记录链表长度的。因此获取链表长度时不再遍历整个链表，直接拿到len值就可以了，获取长度的时间复杂度是O（1）。 遍历过程：通过指向表尾节点的位置指针zltail,减去节点的previous_entry_length，得到前一个节点的起始地址的指针。如此循环，从表尾节点遍历到表头节点。 由于都是一些基本的数据结构，这里就不再探索了。感兴趣可以自行阅读Redis的源码去了解。","categories":[{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/tags/redis/"}],"author":"菠萝"},{"title":"Redis线程模型","slug":"Redis线程模型","date":"2024-03-18T09:39:39.146Z","updated":"2024-03-18T09:39:39.146Z","comments":true,"path":"2024/03/18/Redis线程模型/","permalink":"https://kiritoabc.github.io/2024/03/18/Redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"Redis线程模型 redis 内部使用文件事件处理器 file event handler，它是单线程的，所以redis才叫做单线程模型。它采用IO多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。 文件事件处理器的结构： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）","text":"Redis线程模型 redis 内部使用文件事件处理器 file event handler，它是单线程的，所以redis才叫做单线程模型。它采用IO多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。 文件事件处理器的结构： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 线程模型多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。 一次客户端与redis的完整通信过程深入学习redis 的线程模型一、redis 的线程模型# redis 内部使用文件事件处理器 file event handler，它是单线程的，所以redis才叫做单线程模型。它采用IO多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。 文件事件处理器的结构： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 线程模型多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。 二、一次客户端与redis的完整通信过程建立连接 首先，redis 服务端进程初始化的时候，会将 server socket 的 AE_READABLE 事件与连接应答处理器关联。 客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。 文件事件分派器从队列中获取 socket，交给连接应答处理器。 连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。 执行一个set请求 客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将 socket01 压入队列， 此时事件分派器从队列中获取到 socket01 产生的 AE_READABLE 事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联， 因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。 操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。 如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中， 事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。","categories":[{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/tags/redis/"}],"author":"菠萝"},{"title":"Docker基础","slug":"Docker","date":"2024-03-18T09:39:39.142Z","updated":"2024-03-18T09:39:39.142Z","comments":true,"path":"2024/03/18/Docker/","permalink":"https://kiritoabc.github.io/2024/03/18/Docker/","excerpt":"记录Docker的一些应用 如何编写Dockerfile文件部署go项目 对于项目而言，我们要将所有项目编排在容器中，一般容器与容器之间的交互可以通过ip，但是比较麻烦，所以，这里推荐使用docker的network，将所有容器都存放在一个网络中，这样子容器之间的通信就相对比较容易。","text":"记录Docker的一些应用 如何编写Dockerfile文件部署go项目 对于项目而言，我们要将所有项目编排在容器中，一般容器与容器之间的交互可以通过ip，但是比较麻烦，所以，这里推荐使用docker的network，将所有容器都存放在一个网络中，这样子容器之间的通信就相对比较容易。 如何创建网络，使用命令 docker network create networkName 使用docker network connect连接到创建的网络 docker network connect networkName dockerName 我们可以通过以下命令查看该网络下的连接 docker network inspect networkName 通过网络就可以使用容器命进行通信了 已经将我们要的容器添加至同一network中后，就可以开始编写我们的dockerfile了。 Dockerfile操作指令如下 指令 含义 FROM 镜像 指定新镜像所基于的镜像，第一条指令必须为FROM指令,每创建一个镜像就需要一条FROM指令 MAINTAINER 名字 说明新镜像的维护人信息 RUN命令 在所基于的镜像上执行命令，并提交到新的镜像中 CMD [”要运行的程序”，”参数1,\"参数2 \"] 指令启动容器时要运行的命令或者脚本，Dockerfile只能有一条CMD命令， 如果指定多条则只能最后一条被执行 EXPOSE 端口号 指定新镜像加载到Docker时要开启的端口 ENV 环境变量 变量值 设置一个环境变量的值，会被后面的RUN使用 ADD 源文件/目录目标文件/目录 将源文件复制到目标文件，源文件要与Dockerfile位于相同目录中，或者是一个URL COPY 源文件/目录目标文件/目录 将本地主机上的文件/目录复制到目标地点，源文件/目录要与Dockerfile在相同的目录中 VOLUME [“目录\"] 在容器中创建一个挂载点 USER 用户名/UID 指定运行容器时的用户 WORKDIR 路径（类似cd） 为后续的RUN、CMD、ENTRYPOINT指定工作自录 ONBUILD 命令 指定所生成的镜像作为一个基础镜像时所要运行的命令 HEALTHCHECK 健康检查 dockerfilke文件如下 FROM golang:1.21 as builder WORKDIR /App COPY . . RUN go env -w GO111MODULE=on \\ && go env -w GOPROXY=https://goproxy.cn,direct \\ && go env -w CGO_ENABLED=0 \\ && go env \\ && go mod tidy \\ && go build -o server . FROM alpine:latest LABEL MAINTAINER=\"2493381254@qq.com\" WORKDIR /App COPY --from=0 /App ./ COPY --from=0 /App/config.docker.yaml ./ EXPOSE 8888 ENTRYPOINT ./server -c config.docker.yaml 使用dockerfile文件构建我们的镜像 命令： docker build -t qpp-demo -f ./Dockerfile ./ -t 指定镜像的名称，如果要指定版本，采用 image:tag 的写法。 -f 指定Dockerfile文件，默认当前文件夹下的Dockerfile。 启动镜像 docker run -d --net=app-demo-net -p 8888:8888 --name my-app-docker app-demo donfig.docker.yaml配置文件如下 # zap logger 的配置 zap: level: info format: console prefix: \"[Chinese_Learning_App]\" director: log show-line: true encode-level: LowercaseColorLevelEncoder stacktrace-key: stacktrace log-in-console: true # redis configuration #redis: # db: 0 # addr: 127.0.0.1:6379 # password: \"\" # system configuration system: env: public # Change to \"develop\" to skip authentication for development mode addr: 8888 db-type: mysql oss-type: local # 控制oss选择走本地还是 七牛等其他仓 自行增加其他oss仓可以在 server/utils/upload/upload.go 中 NewOss函数配置 use-redis: false # 使用redis use-multipoint: false # IP限制次数 一个小时15000次 iplimit-count: 15000 # IP限制一个小时 iplimit-time: 3600 # 路由全局前缀 router-prefix: \"\" # mysql connect configuration # 未初始化之前请勿手动修改数据库信息！！！如果一定要手动初始化请看（https://gin-vue-admin.com/docs/first_master） mysql: path: docker_mysql port: \"3306\" config: \"charset=utf8mb4&parseTime=True&loc=Local\" db-name: \"Chinese_Learning_DB\" username: \"root\" password: \"123456\" max-idle-conns: 10 max-open-conns: 100 log-mode: \"\" log-zap: false # MinIo的配置 minio: endpoint: my_minio:9001 # minio 的url accessKey: minio # userName secretKey: minio@123456 # password bucketName: \"test\" region: us-east-1 useSSL: false docker compose的使用","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端开发知识","slug":"后端开发知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"flutter","slug":"Flutter","date":"2024-03-18T09:39:39.142Z","updated":"2024-03-18T09:39:39.142Z","comments":true,"path":"2024/03/18/Flutter/","permalink":"https://kiritoabc.github.io/2024/03/18/Flutter/","excerpt":"flutter网络框架dio v5.3.3 dio 是一个强大的 HTTP 网络请求库，支持全局配置、Restful API、FormData、拦截器、 请求取消、Cookie 管理、文件上传/下载、超时、自定义适配器、转换器等。","text":"flutter网络框架dio v5.3.3 dio 是一个强大的 HTTP 网络请求库，支持全局配置、Restful API、FormData、拦截器、 请求取消、Cookie 管理、文件上传/下载、超时、自定义适配器、转换器等。 入门使用添加依赖 flutter pub add dio 使用 import 'package:dio/dio.dart'; final dio = Dio(); void getHttp() async { final response = await dio.get('https://dart.dev'); print(response); } GET请求 import 'package:dio/dio.dart'; final dio = Dio(); void request() async { Response response; response = await dio.get('/test?id=12&amp;name=dio'); print(response.data.toString()); // The below request is the same as above. response = await dio.get( '/test', queryParameters: {'id': 12, 'name': 'dio'}, ); print(response.data.toString()); } POST请求 response = await dio.post('/test', data: {'id': 12, 'name': 'dio'}); 发起多个并发的请求 response = await Future.wait([dio.post('/info'), dio.get('/token')]); 下载文件 response = await dio.download( 'https://www.google.com/', '${(await getTemporaryDirectory()).path}google.html', ); 以流的方式接收响应数据： final rs = await dio.get( url, options: Options(responseType: ResponseType.stream), // 设置接收类型为 `stream` ); print(rs.data.stream); // 响应流 以二进制数组的方式接收响应数据： final rs = await dio.get( url, options: Options(responseType: ResponseType.bytes), // 设置接收类型为 `bytes` ); print(rs.data); // 类型: List&lt;int> 发送 FormData: final formData = FormData.fromMap({ 'name': 'dio', 'date': DateTime.now().toIso8601String(), }); final response = await dio.post('/info', data: formData); 通过 FormData 上传多个文件: final formData = FormData.fromMap({ 'name': 'dio', 'date': DateTime.now().toIso8601String(), 'file': await MultipartFile.fromFile('./text.txt', filename: 'upload.txt'), 'files': [ await MultipartFile.fromFile('./text1.txt', filename: 'text1.txt'), await MultipartFile.fromFile('./text2.txt', filename: 'text2.txt'), ] }); final response = await dio.post('/info', data: formData); 监听发送（上传）数据进度: final response = await dio.post( 'https://www.dtworkroom.com/doris/1/2.0.0/test', data: {'aa': 'bb' * 22}, onSendProgress: (int sent, int total) { print('$sent $total'); }, ); 以流的形式提交二进制数据： // Binary data final postData = &lt;int>[0, 1, 2]; await dio.post( url, data: Stream.fromIterable(postData.map((e) => [e])), // 构建 Stream&lt;List&lt;int>> options: Options( headers: { Headers.contentLengthHeader: postData.length, // 设置 content-length. }, ), ); Dio APIs创建一个Dio实例并配置它 建议在项目中使用Dio单例，这样便可对同一个dio实例发起的所有请求进行一些统一的配置， 比如设置公共header、请求基地址、超时时间等。 这里有一个在Flutter工程中使用Dio单例 （定义为top level变量）的示例供开发者参考。 你可以使用默认配置或传递一个可选 BaseOptions参数来创建一个Dio实例 : final dio = Dio(); // With default `Options`. void configureDio() { // Update default configs. dio.options.baseUrl = 'https://api.pub.dev'; dio.options.connectTimeout = Duration(seconds: 5); dio.options.receiveTimeout = Duration(seconds: 3); // Or create `Dio` with a `BaseOptions` instance. final options = BaseOptions( baseUrl: 'https://api.pub.dev', connectTimeout: Duration(seconds: 5), receiveTimeout: Duration(seconds: 3), ); final anotherDio = Dio(options); } Dio 的核心 API 是： Future&lt;Response&lt;T>> request&lt;T>( String path, { Object? data, Map&lt;String, dynamic>? queryParameters, CancelToken? cancelToken, Options? options, ProgressCallback? onSendProgress, ProgressCallback? onReceiveProgress, }); final response = await dio.request( '/test', data: {'id': 12, 'name': 'dio'}, options: Options(method: 'GET'), ); 请求配置BaseOptions 描述的是 Dio 实例发起网络请求的的公共配置， 而 Options 描述了每一个Http请求的配置信息，每一次请求都可以单独配置， 单次请求的 Options 中的配置信息可以覆盖 BaseOptions 中的配置。 下面是 Options 的配置项： /// 请求方式。 String method; /// 请求基本地址，可以包含路径例如 https://dart.dev/api/。 String? baseUrl; /// HTTP 请求头。 Map&lt;String, dynamic>? headers; /// 连接服务器超时时间. Duration? connectTimeout; /// 两次数据流数据接收的最长间隔时间，注意不是请求的最长接收时间。 Duration? receiveTimeout; /// 请求内容体，可以是任意类型。 dynamic data; /// 请求路径，如果以 http(s)开始, 则 [baseURL] 会被忽略， /// 否则将会和 [baseUrl] 拼接出完整的地址。 String path = ''; /// 请求的 Content-Type。 /// /// 默认值会由 [ImplyContentTypeInterceptor] 根据请求载荷类型进行推导。 /// 可以调用 [Interceptors.removeImplyContentTypeInterceptor] 进行移除。 /// /// 如果你想以 `application/x-www-form-urlencoded` 格式编码请求数据, /// 可以设置此选项为 `Headers.formUrlEncodedContentType`, /// [Dio] 会自动编码请求体。 String? contentType; /// 期望以哪种格式（方式）接受响应数据，包括 `json`、`stream` 和 `plain`。 /// /// 默认值是 `json`, 当响应头中 content-type 为 `application/json` 时， /// dio 会自动将响应内容转化为 json 对象。 /// 如果想以二进制方式接受响应数据，如下载一个二进制文件，那么可以使用 `stream`。 /// /// 如果想以文本（字符串）格式接收响应数据，请使用 `plain`。 ResponseType? responseType; /// `validateStatus` 决定 HTTP 响应状态码是否被视为请求成功， /// 返回 `true` 请求结果就会按成功处理，否则会按失败处理. ValidateStatus? validateStatus; /// 用户自定义字段，可以在 [Interceptor]、[Transformer] 和 [Response] 中依次传递。 Map&lt;String, dynamic>? extra; /// 请求地址的参数。 Map&lt;String, dynamic /*String|Iterable&lt;String>*/ >? queryParameters; /// 请求数据中数组的编码的方式，默认值为 `multiCompatible`。 ListFormat? listFormat; 响应数据当请求成功时会返回一个Response对象，它包含如下字段： /// 响应数据。可能已经被转换了类型, 详情请参考 [ResponseType]。 T? data; /// 响应对应的请求配置。 RequestOptions requestOptions; /// 响应的 HTTP 状态码。 int? statusCode; /// 响应对应状态码的详情信息。 String? statusMessage; /// 响应是否被重定向 bool isRedirect; /// 请求连接经过的重定向列表。如果请求未经过重定向，则列表为空。 List&lt;RedirectRecord> redirects; /// 在 [RequestOptions] 中构造的自定义字段。 Map&lt;String, dynamic> extra; /// 响应对应的头数据。 Headers headers; 请求成功后，你可以访问到下列字段： final response = await dio.get('https://pub.dev'); print(response.data); print(response.headers); print(response.requestOptions); print(response.statusCode); 注意，Response.extra 与 RequestOptions.extra 是不同的实例，互相之间无关。 拦截器每个 Dio 实例都可以添加任意多个拦截器，他们会组成一个队列，拦截器队列的执行顺序是先进先出。 通过使用拦截器，你可以在请求之前、响应之后和发生异常时（未被 then 或 catchError 处理） 做一些统一的预处理操作。 dio.interceptors.add( InterceptorsWrapper( onRequest: (RequestOptions options, RequestInterceptorHandler handler) { // 如果你想完成请求并返回一些自定义数据，你可以使用 `handler.resolve(response)`。 // 如果你想终止请求并触发一个错误，你可以使用 `handler.reject(error)`。 return handler.next(options); }, onResponse: (Response response, ResponseInterceptorHandler handler) { // 如果你想终止请求并触发一个错误，你可以使用 `handler.reject(error)`。 return handler.next(response); }, onError: (DioException e, ErrorInterceptorHandler handler) { // 如果你想完成请求并返回一些自定义数据，你可以使用 `handler.resolve(response)`。 return handler.next(e); }, ), ); 一个简单的自定义拦截器示例: import 'package:dio/dio.dart'; class CustomInterceptors extends Interceptor { @override void onRequest(RequestOptions options, RequestInterceptorHandler handler) { print('REQUEST[${options.method}] => PATH: ${options.path}'); super.onRequest(options, handler); } @override void onResponse(Response response, ResponseInterceptorHandler handler) { print('RESPONSE[${response.statusCode}] => PATH: ${response.requestOptions.path}'); super.onResponse(response, handler); } @override Future onError(DioException err, ErrorInterceptorHandler handler) async { print('ERROR[${err.response?.statusCode}] => PATH: ${err.requestOptions.path}'); super.onError(err, handler); } } 完成和终止请求/响应在所有拦截器中，你都可以改变请求执行流， 如果你想完成请求/响应并返回自定义数据，你可以 resolve 一个 Response 对象 或返回 handler.resolve(data) 的结果。 如果你想终止（触发一个错误，上层 catchError 会被调用）一个请求/响应， 那么可以 reject 一个DioException 对象或返回 handler.reject(errMsg) 的结果。 dio.interceptors.add( InterceptorsWrapper( onRequest: (options, handler) { return handler.resolve( Response(requestOptions: options, data: 'fake data'), ); }, ), ); final response = await dio.get('/test'); print(response.data); // 'fake data' 如果同时发起多个网络请求，则它们是可以同时进入Interceptor 的（并行的）， 而 QueuedInterceptor 提供了一种串行机制： 它可以保证请求进入拦截器时是串行的（前面的执行完后后面的才会进入拦截器）。 假设这么一个场景：出于安全原因，我们需要给所有的请求头中添加一个 csrfToken， 如果 csrfToken 不存在，我们先去请求 csrfToken，获取到 csrfToken 后再重试。 假设刚开始的时候 csrfToken 为 null，如果允许请求并发，则这些并发请求并行进入拦截器时 csrfToken 都为 null，所以它们都需要去请求 csrfToken，这会导致 csrfToken 被请求多次。 为了避免不必要的重复请求，可以使用 QueuedInterceptor， 这样只需要第一个请求处理一次即可。 完整的示例代码请点击 这里. 日志拦截器我们可以添加 LogInterceptor 拦截器来自动打印请求和响应等日志： 注意： LogInterceptor 应该保持最后一个被添加到拦截器中， 否则在它之后进行处理的拦截器修改的内容将无法体现。 Dartdio.interceptors.add(LogInterceptor(responseBody: false)); // 不输出响应内容体 注意： 默认的 logPrint 只会在 DEBUG 模式（启用了断言） 的情况下输出日志。 你也可以使用 dart:developer 中的 log 来输出日志（在 Flutter 中也可以使用）。 Flutter在 Flutter 中你应该使用 debugPrint 来打印日志。 这样也会让调试日志能够通过 flutter logs 获取到。 注意： debugPrint 的意义 不是只在 DEBUG 模式下打印， 而是对输出内容进行节流，从而保证输出完整。 请不要在生产模式使用，除非你有意输出相关日志。 dio.interceptors.add( LogInterceptor( logPrint: (o) => debugPrint(o.toString()), ), ); 自定义拦截器开发者可以通过继承 Interceptor/QueuedInterceptor 类来实现自定义拦截器。 这是一个简单的 缓存拦截器。 错误处理当请求过程中发生错误时, Dio 会将 Error/Exception 包装成一个 DioException: try { // 404 await dio.get('https://api.pub.dev/not-exist'); } on DioException catch (e) { // The request was made and the server responded with a status code // that falls out of the range of 2xx and is also not 304. if (e.response != null) { print(e.response.data) print(e.response.headers) print(e.response.requestOptions) } else { // Something happened in setting up or sending the request that triggered an Error print(e.requestOptions) print(e.message) } } DioException/// 错误的请求对应的配置。 RequestOptions requestOptions; /// 错误的请求对应的响应内容。如果请求未完成，响应内容可能为空。 Response? response; /// 错误的类型。 DioExceptionType type; /// 实际错误的内容。 Object? error; /// 实际错误的堆栈。 StackTrace? stackTrace; /// 错误信息。 String? message; 使用 application/x-www-form-urlencoded 编码默认情况下, Dio 会将请求数据（除了 String 类型）序列化为 JSON。 如果想要以 application/x-www-form-urlencoded 格式编码, 你可以设置 contentType : // Instance level dio.options.contentType = Headers.formUrlEncodedContentType; // or only works once dio.post( '/info', data: {'id': 5}, options: Options(contentType: Headers.formUrlEncodedContentType), ); 发送 FormDataDio 支持发送 FormData, 请求数据将会以 multipart/form-data 方式编码, FormData 中可以包含一个或多个文件。 final formData = FormData.fromMap({ 'name': 'dio', 'date': DateTime.now().toIso8601String(), 'file': await MultipartFile.fromFile('./text.txt',filename: 'upload.txt') }); final response = await dio.post('/info', data: formData); 通常情况下只有 POST 方法支持发送 FormData。 这里有一个完整的 示例。 多文件上传多文件上传时，通过给 key 加中括号 [] 方式作为文件数组的标记，大多数后台也会通过 key[] 来读取多个文件。 然而 RFC 标准中并没有规定多文件上传必须要使用 []，关键在于后台与客户端之间保持一致。 final formData = FormData.fromMap({ 'files': [ MultipartFile.fromFileSync('path/to/upload1.txt', filename: 'upload1.txt'), MultipartFile.fromFileSync('path/to/upload2.txt', filename: 'upload2.txt'), ], }); 最终编码时会 key 会为 files[]， **如果不想添加 []**，可以通过 Formdata 的 files 来构建： final formData = FormData(); formData.files.addAll([ MapEntry( 'files', MultipartFile.fromFileSync('./example/upload.txt',filename: 'upload.txt'), ), MapEntry( 'files', MultipartFile.fromFileSync('./example/upload.txt',filename: 'upload.txt'), ), ]); 复用 FormData 和 MultipartFile如果你在重复调用的请求中使用 FormData 或者 MultipartFile，确保你每次使用的都是新实例。 常见的错误做法是将 FormData 赋值给一个共享变量，在每次请求中都使用这个变量。 这样的操作会加大 无法序列化 的错误出现的可能性。 你可以像以下的代码一样编写你的请求以避免出现这样的错误： Future&lt;void&gt; _repeatedlyRequest() async { Future&lt;FormData&gt; createFormData() async { return FormData.fromMap({ 'name': 'dio', 'date': DateTime.now().toIso8601String(), 'file': await MultipartFile.fromFile('./text.txt',filename: 'upload.txt'), }); } await dio.post('some-url', data: await createFormData()); } 转换器转换器 Transformer 用于对请求数据和响应数据进行编解码处理。 Dio 实现了一个默认转换器 DefaultTransformer。 如果你想对请求和响应数据进行自定义编解码处理，可以提供自定义转换器并通过 dio.transformer 设置。 Transformer.transformRequest 只在 PUT/POST/PATCH 方法中生效， 只有这些方法可以使用请求内容体 (request body)。 但是 Transformer.transformResponse 可以用于所有请求方法的返回数据。 在 Flutter 中进行设置如果你在开发 Flutter 应用，强烈建议通过 compute 在单独的 isolate 中进行 JSON 解码， 从而避免在解析复杂 JSON 时导致的 UI 卡顿。 /// Map&lt;String, dynamic&gt; _parseAndDecode(String response) { return jsonDecode(response) as Map&lt;String, dynamic&gt;; } Future&lt;Map&lt;String, dynamic&gt;&gt; parseJson(String text) { return compute(_parseAndDecode, text); } void main() { // 自定义 `jsonDecodeCallback` dio.transformer = DefaultTransformer()..jsonDecodeCallback = parseJson; runApp(MyApp()); } 其它示例这里有一个 自定义 Transformer 的示例。 HttpClientAdapterHttpClientAdapter 是 Dio 和 HttpClient 之间的桥梁。 Dio 实现了一套标准且强大的 API，而 HttpClient 则是真正发起 HTTP 请求的对象。 我们通过 HttpClientAdapter 将 Dio 和 HttpClient 解耦， 这样一来便可以自由定制 HTTP 请求的底层实现。 Dio 使用 IOHttpClientAdapter 作为原生平台默认的桥梁， BrowserClientAdapter 作为 Web 平台的桥梁。 你可以通过 HttpClientAdapter() 来根据平台创建它们。 dio.httpClientAdapter = HttpClientAdapter(); 如果你需要单独使用对应平台的适配器： 对于 Web 平台 import 'package:dio/browser.dart'; // ... dio.httpClientAdapter = BrowserClientAdapter(); 对于原生平台： import 'package:dio/io.dart'; // ... dio.httpClientAdapter = IOClientAdapter(); 示例 中包含了一个简单的自定义桥接。 设置代理IOHttpClientAdapter 提供了一个 createHttpClient 回调来设置底层 HttpClient 的代理： import 'package:dio/io.dart'; void initAdapter() { dio.httpClientAdapter = IOHttpClientAdapter( createHttpClient: () { final client = HttpClient(); client.findProxy = (uri) { // 将请求代理至 localhost:8888。 // 请注意，代理会在你正在运行应用的设备上生效，而不是在宿主平台生效。 return 'PROXY localhost:8888'; }; return client; }, ); } 完整的示例请查看 这里。 Web 平台不支持设置代理。 HTTPS 证书校验HTTPS 证书验证（或公钥固定）是指确保端侧与服务器的 TLS 连接的证书是期望的证书，从而减少中间人攻击的机会。 OWASP 中解释了该理论。 服务器响应证书 与其他方法不同，此方法使用服务器本身的证书。 void initAdapter() { const String fingerprint = 'ee5ce1dfa7a53657c545c62b65802e4272878dabd65c0aadcf85783ebb0b4d5c'; dio.httpClientAdapter = IOHttpClientAdapter( createHttpClient: () { // Don't trust any certificate just because their root cert is trusted. final HttpClient client = HttpClient(context: SecurityContext(withTrustedRoots: false)); // You can test the intermediate / root cert here. We just ignore it. client.badCertificateCallback = (cert, host, port) =&gt; true; return client; }, validateCertificate: (cert, host, port) { // Check that the cert fingerprint matches the one we expect. // We definitely require _some_ certificate. if (cert == null) { return false; } // Validate it any way you want. Here we only check that // the fingerprint matches the OpenSSL SHA256. return fingerprint == sha256.convert(cert.der).toString(); }, ); } 你可以使用 OpenSSL 读取密钥的 SHA-256： openssl s_client -servername pinning-test.badssl.com -connect pinning-test.badssl.com:443 &lt; /dev/null 2&gt;/dev/null \\ | openssl x509 -noout -fingerprint -sha256 #### SHA256 Fingerprint=EE:5C:E1:DF:A7:A5:36:57:C5:45:C6:2B:65:80:2E:42:72:87:8D:AB:D6:5C:0A:AD:CF:85:78:3E:BB:0B:4D:5C # (remove the formatting, keep only lower case hex characters to match the `sha256` above) 证书颁发机构验证 当您的服务器具有自签名证书时，可以用下面的方法，但它们不适用于 AWS 或 Let’s Encrypt 等第三方颁发的证书。 有两种方法可以校验证书，假设我们的后台服务使用的是自签名证书，证书格式是 PEM 格式，我们将证书的内容保存在本地字符串中， 那么我们的校验逻辑如下： void initAdapter() { String PEM = 'XXXXX'; // root certificate content dio.httpClientAdapter = IOHttpClientAdapter( createHttpClient: () { final client = HttpClient(); client.badCertificateCallback = (X509Certificate cert, String host, int port) { return cert.pem == PEM; // Verify the certificate. }; return client; }, ); } 对于自签名的证书，我们也可以将其添加到本地证书信任链中， 这样证书验证时就会自动通过，而不会再走到 badCertificateCallback 回调中： void initAdapter() { String PEM = 'XXXXX'; // root certificate content dio.httpClientAdapter = IOHttpClientAdapter( onHttpClientCreate: (_) { final SecurityContext sc = SecurityContext(); sc.setTrustedCertificates(File(pathToTheCertificate)); final HttpClient client = HttpClient(context: sc); return client; }, ); } 注意，通过 setTrustedCertificates() 设置的证书格式必须为 PEM 或 PKCS12， 如果证书格式为 PKCS12，则需将证书密码传入， 这样则会在代码中暴露证书密码，所以客户端证书校验不建议使用 PKCS12 格式的证书。 HTTP/2 支持dio_http2_adapter 提供了一个支持 HTTP/2 的桥接 。 请求取消你可以通过 CancelToken 来取消发起的请求。 一个 CancelToken 可以给多个请求共用， 在共用时调用 cancel() 会取消对应的所有请求： final cancelToken = CancelToken(); dio.get(url, cancelToken: cancelToken).catchError((DioException err) { if (CancelToken.isCancel(err)) { print('Request canceled: ${err.message}'); } else { // handle error. } }); // Cancel the requests with \"cancelled\" message. token.cancel('cancelled'); 完整的示例请参考 取消示例. 继承 Dio classDio 是一个拥有工厂构造函数的接口类，因此不能直接继承 Dio， 但是可以继承 DioForNative 或 DioForBrowser： import 'package:dio/dio.dart'; import 'package:dio/io.dart'; // 在浏览器中，导入 'package:dio/browser.dart'。 class Http extends DioForNative { Http([BaseOptions options]) : super(options) { // 构造函数执行 } } 我们也可以直接实现 Dio 接口类 : class MyDio with DioMixin implements Dio { // ... } Web 平台跨域资源共享 (CORS)在 Web 平台上发送网络请求时，如果请求不是一个 简单请求， 浏览器会自动向服务器发送 CORS 预检 (Pre-flight requests)， 用于检查服务器是否支持跨域资源共享。 你可以参考简单请求的定义修改你的请求，或者为你的服务加上 CORS 中间件进行跨域处理。","categories":[{"name":"安卓开发","slug":"安卓开发","permalink":"https://kiritoabc.github.io/categories/%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"安卓开发","slug":"安卓开发","permalink":"https://kiritoabc.github.io/tags/%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/"}],"author":"菠萝"},{"title":"记录我的面试经历","slug":"Go面试题","date":"2024-03-18T09:39:39.142Z","updated":"2024-03-18T09:39:39.142Z","comments":true,"path":"2024/03/18/Go面试题/","permalink":"https://kiritoabc.github.io/2024/03/18/Go%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"记录自己的面试过程！！！","text":"记录自己的面试过程！！！ 3月6号，腾讯一面（寄）1.使用过分布式锁吗？怎么实现的？goredisson redis的set nx 2.分布式锁的使用场景对共享资源的保护。 3.介绍一下子redis集群主从，哨兵，切片集群 4.redis集群的模式 主从 哨兵 切片 5.说一下缓存雪崩缓存雪崩的话，有几种情况： 缓存的key在同一时间同时失效 Redis宕机 6.缓存击穿和缓存穿透有什么区别缓存击穿一般是针对于热点key问题，是指，热点key过期的时候，会有大量的并发请求，一瞬间打到MySQL服务器，导致MySQL宕机 缓存击穿是指，某些非法数据，不存在于数据库中，频繁的访问，不经过缓存，直接打到数据库，且数据库也没有数据，无法被缓存。 7.说一下go语言中的Contextcontext就是上下文的意思。主要记录当前goroutine的上下文，一般用于goroutine之间传递信息，类似于map的key，value存储。 emptyCtx todoCtx valueCtx cancleCtx 8.问了一下项目。项目背景。项目难点。你是怎么做的。具体过程。9.三个题目 第一题就是简单的考察二叉树 // 1. 输入某二叉树的前序遍历和中序遍历的结果，请重建该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。 //例如，给出 //mid->left->right //前序遍历 preorder = [3,9,20,15,7] //left->mid->right //中序遍历 inorder = [9,3,15,20,7] //返回如下的二叉树： // 3 // / \\ // 9 20 // / \\ // 15 7 考察了二叉树的性质 // 2. 对于一棵满二叉排序树深度为K，节点数为 2^K - 1 ；节点值为 1至 (2^K-1)。 // 给出K和任意三个节点的值，输出包含该三个节点的最小子树的根节点值 // 样例输入：4 10 15 13 // 样例输出：12 // 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 常见的面试题 // 3. 最长回文子串： // 给你一个字符串s，找到 s 中最长的回文子串。 // 示例：输入：s = \"babad\" 输出：\"bab\" 解释：\"aba\" 同样是符合题意的答案。 // 输入：s = \"cbbd\" 输出：\"bb\" 字节面试题在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤？ 对浏览器的URL进行解析 通过DNS查询服务，找到URL的IP地址（具体查询过程…） 通过TCP三次握手简历连接 通过网卡发送 ==&gt; HTTP请求 在网络传输中，通过交换机和路由器，将请求发送到服务器 服务器响应请求，返回数据 浏览器进行渲染 如何排查一条慢SQL？可以从哪些方面入手？回答： 项目中 可以采用日志分析这个接口的运行时间 sql语句 采用explain指定去查这个sql的执行计划 数据库终端 开启mysql的慢日志查询，设置好时间阈值，进行捕获 在企业内部对于慢查SQL的优化主要经历以下的几个步骤： 在慢SQL的优化过程中，可以从以下五个角度去思考优化： SQL优化：SQL语句优化方式主要是通过选择合适的索引，优化查询语句，避免全表扫描等提高查询效率，减少慢SQL的出现 资源占用： 业务改造 数据减少 源头替换 资源占用 锁资源等待：在读写很热的表上，通常会发生锁资源争夺，从而导致慢查询情况。 谨慎使用 for update； 增删改尽量使用到索引； 降低并发，避免对同一条数据进行反复修改。 网络波动：往客户端发送数据时发生网络波动导致的慢查询 硬件配置：CPU利用率高，磁盘IO经常慢载，导致慢查询 业务改造 是不是真的需要全部查出来，还是取其中的top N就能够满足需求了 查询条件过多的情况下，能否前端页面提示限制过多的查询条件的使用 针对实时导出的数据，涉及到实时查DB导出大量数据时，限制导出数据量 or 走T+1的离线导出是不是也是可以的 现在业务上需要做数据搜索，使用了 LIKE “%关键词%” 做全模糊查询，从而导致了慢SQL。是不是可以让业务方妥协下，最右模糊匹配，这样就可以利用上索引了 3.13 字节日常实习一面1. 上来问了项目，为什么做这些项目？项目难点？你如何解决的？2. 两道算法题。 求平方根 子集合问题 3.Goroutine，GMP模型，还有go的内存分配，谈谈你的看法。4.计算机网络，三次握手，四次挥手，四次挥手的客户端最后处于什么状态？什么是MSL？5. 数据库的索引说一下。6.最左匹配原则，给了一些例子，问什么时候失效，结合B+树的结构说一下7.异步，同步，阻塞，非阻塞说一下你的理解。","categories":[{"name":"日常","slug":"日常","permalink":"https://kiritoabc.github.io/categories/%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"日常","slug":"日常","permalink":"https://kiritoabc.github.io/tags/%E6%97%A5%E5%B8%B8/"}],"author":"菠萝"},{"title":"Hadoop分布式文件系统---HDFS","slug":"Hadoop-分布式文件系统HDFS","date":"2024-03-18T09:39:39.142Z","updated":"2024-03-18T09:39:39.142Z","comments":true,"path":"2024/03/18/Hadoop-分布式文件系统HDFS/","permalink":"https://kiritoabc.github.io/2024/03/18/Hadoop-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS/","excerpt":"一、介绍HDFS （Hadoop Distributed File System）是 Hadoop 下的分布式文件系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。","text":"一、介绍HDFS （Hadoop Distributed File System）是 Hadoop 下的分布式文件系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。 二、HDFS设计原理 2.1 HDFS架构HDFS 遵循主/从架构，由单个 NameNode(NN) 和多个 DataNode(DN) 组成： NameNode : 负责执行有关 文件系统命名空间 的操作，例如打开，关闭、重命名文件和目录等。它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。 DataNode：负责提供来自文件系统客户端的读写请求，执行块的创建，删除等操作。 2.2 文件系统命名空间HDFS 的 文件系统命名空间 的层次结构与大多数文件系统类似 (如 Linux)， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。NameNode 负责维护文件系统名称空间，记录对名称空间或其属性的任何更改。 2.3 数据复制由于 Hadoop 被设计运行在廉价的机器上，这意味着硬件是不可靠的，为了保证容错性，HDFS 提供了数据复制机制。HDFS 将每一个文件存储为一系列块，每个块由多个副本来保证容错，块的大小和复制因子可以自行配置（默认情况下，块大小是 128M，默认复制因子是 3）。 2.4 数据复制的实现原理大型的 HDFS 实例在通常分布在多个机架的多台服务器上，不同机架上的两台服务器之间通过交换机进行通讯。在大多数情况下，同一机架中的服务器间的网络带宽大于不同机架中的服务器之间的带宽。因此 HDFS 采用机架感知副本放置策略，对于常见情况，当复制因子为 3 时，HDFS 的放置策略是： 在写入程序位于 datanode 上时，就优先将写入文件的一个副本放置在该 datanode 上，否则放在随机 datanode 上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。 如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上限，上限值通常为 （复制系数 - 1）/机架数量 + 2，需要注意的是不允许同一个 dataNode 上具有同一个块的多个副本。 2.5 副本的选择为了最大限度地减少带宽消耗和读取延迟，HDFS 在执行读取请求时，优先读取距离读取器最近的副本。如果在与读取器节点相同的机架上存在副本，则优先选择该副本。如果 HDFS 群集跨越多个数据中心，则优先选择本地数据中心上的副本。 2.6 架构的稳定性1. 心跳机制和重新复制每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值，NameNode 会跟踪这些块，并在必要的时候进行重新复制。 2. 数据的完整性由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下： 当客户端创建 HDFS 文件时，它会计算文件的每个块的 校验和，并将 校验和 存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的 校验和 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。 3.元数据的磁盘故障FsImage 和 EditLog 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可用。为了避免这个问题，可以配置 NameNode 使其支持 FsImage 和 EditLog 多副本同步，这样 FsImage 或 EditLog 的任何改变都会引起每个副本 FsImage 和 EditLog 的同步更新。 4.支持快照快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。 三、HDFS的特点3.1 高容错由于 HDFS 采用数据的多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。 3.2 高吞吐量HDFS 设计的重点是支持高吞吐量的数据访问，而不是低延迟的数据访问。 3.3 大文件支持HDFS 适合于大文件的存储，文档的大小应该是是 GB 到 TB 级别的。 3.3 简单一致性模型HDFS 更适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾，但不支持数据的随机访问，不能从文件任意位置新增数据。 3.4 跨平台移植性HDFS 具有良好的跨平台移植性，这使得其他大数据计算框架都将其作为数据持久化存储的首选方案。","categories":[{"name":"大数据","slug":"大数据","permalink":"https://kiritoabc.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据知识","slug":"大数据知识","permalink":"https://kiritoabc.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"JWT","slug":"JWT","date":"2024-03-18T09:39:39.142Z","updated":"2024-03-18T09:39:39.142Z","comments":true,"path":"2024/03/18/JWT/","permalink":"https://kiritoabc.github.io/2024/03/18/JWT/","excerpt":"了解什么是JWT JWT什么是JWT？JWT （JSON Web Token） 是目前最流行的跨域认证解决方案，是一种基于 Token 的认证授权机制。 从 JWT 的全称可以看出，JWT 本身也是 Token，一种规范化之后的 JSON 结构的 Token。 JWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息。这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。 可以看出，JWT 更符合设计 RESTful API 时的「Stateless（无状态）」原则 。 并且， 使用 JWT 认证可以有效避免 CSRF 攻击，因为 JWT 一般是存在在 localStorage 中，使用 JWT 进行身份验证的过程中是不会涉及到 Cookie 的。","text":"了解什么是JWT JWT什么是JWT？JWT （JSON Web Token） 是目前最流行的跨域认证解决方案，是一种基于 Token 的认证授权机制。 从 JWT 的全称可以看出，JWT 本身也是 Token，一种规范化之后的 JSON 结构的 Token。 JWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息。这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。 可以看出，JWT 更符合设计 RESTful API 时的「Stateless（无状态）」原则 。 并且， 使用 JWT 认证可以有效避免 CSRF 攻击，因为 JWT 一般是存在在 localStorage 中，使用 JWT 进行身份验证的过程中是不会涉及到 Cookie 的。 下面是 RFC 7519 对 JWT 做的较为正式的定义。 JSON Web Token (JWT) is a compact, URL-safe means of representing claims to be transferred between two parties. The claims in a JWT are encoded as a JSON object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or integrity protected with a Message Authentication Code (MAC) and/or encrypted. ——JSON Web Token (JWT) JWT由哪些部分组成 JWT 本质上就是一组字串，通过（.）切分成三个为 Base64 编码的部分： Header : 描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型。 Payload : 用来存放实际需要传递的数据 Signature（签名）：服务器通过 Payload、Header 和一个密钥(Secret)使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。 JWT 通常是这样的：xxxxx.yyyyy.zzzzz。 示例： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9. eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ. SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c 你可以在 jwt.io 这个网站上对其 JWT 进行解码，解码之后得到的就是 Header、Payload、Signature 这三部分。 Header 和 Payload 都是 JSON 格式的数据，Signature 由 Payload、Header 和 Secret(密钥)通过特定的计算公式和加密算法得到。 HeaderHeader 通常由两部分组成： typ（Type）：令牌类型，也就是 JWT。 alg（Algorithm）：签名算法，比如 HS256。 示例： { \"alg\": \"HS256\", \"typ\": \"JWT\" } JSON 形式的 Header 被转换成 Base64 编码，成为 JWT 的第一部分。 PayloadPayload 也是 JSON 格式数据，其中包含了 Claims(声明，包含 JWT 的相关信息)。 Claims 分为三种类型： Registered Claims（注册声明）：预定义的一些声明，建议使用，但不是强制性的。 Public Claims（公有声明）：JWT 签发方可以自定义的声明，但是为了避免冲突，应该在 IANA JSON Web Token Registry 中定义它们。 Private Claims（私有声明）：JWT 签发方因为项目需要而自定义的声明，更符合实际项目场景使用。 下面是一些常见的注册声明： iss（issuer）：JWT 签发方。 iat（issued at time）：JWT 签发时间。 sub（subject）：JWT 主题。 aud（audience）：JWT 接收方。 exp（expiration time）：JWT 的过期时间。 nbf（not before time）：JWT 生效时间，早于该定义的时间的 JWT 不能被接受处理。 jti（JWT ID）：JWT 唯一标识。 示例： { \"uid\": \"ff1212f5-d8d1-4496-bf41-d2dda73de19a\", \"sub\": \"1234567890\", \"name\": \"John Doe\", \"exp\": 15323232, \"iat\": 1516239022, \"scope\": [\"admin\", \"user\"] } Payload 部分默认是不加密的，一定不要将隐私信息存放在 Payload 当中！！！ JSON 形式的 Payload 被转换成 Base64 编码，成为 JWT 的第二部分。 SignatureSignature 部分是对前两部分的签名，作用是防止 JWT（主要是 payload） 被篡改。 这个签名的生成需要用到： Header + Payload。 存放在服务端的密钥(一定不要泄露出去)。 签名算法。 签名的计算公式如下： HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，这个字符串就是 JWT 。 如何基于JWT进行身份验证在基于 JWT 进行身份验证的的应用程序中，服务器通过 Payload、Header 和 Secret(密钥)创建 JWT 并将 JWT 发送给客户端。客户端接收到 JWT 之后，会将其保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。 简化后的步骤如下： 用户向服务器发送用户名、密码以及验证码用于登陆系统。 如果用户用户名、密码以及验证码校验正确的话，服务端会返回已经签名的 Token，也就是 JWT。 用户以后每次向后端发请求都在 Header 中带上这个 JWT 。 服务端检查 JWT 并从中获取用户相关信息。 两点建议： 建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。 请求服务端并携带 JWT 的常见做法是将其放在 HTTP Header 的 Authorization 字段中（Authorization: Bearer Token）。 如何防止JWT被篡改有了签名之后，即使 JWT 被泄露或者截获，黑客也没办法同时篡改 Signature、Header、Payload。 这是为什么呢？因为服务端拿到 JWT 之后，会解析出其中包含的 Header、Payload 以及 Signature 。服务端会根据 Header、Payload、密钥再次生成一个 Signature。拿新生成的 Signature 和 JWT 中的 Signature 作对比，如果一样就说明 Header 和 Payload 没有被修改。 不过，如果服务端的秘钥也被泄露的话，黑客就可以同时篡改 Signature、Header、Payload 了。黑客直接修改了 Header 和 Payload 之后，再重新生成一个 Signature 就可以了。 密钥一定保管好，一定不要泄露出去。JWT 安全的核心在于签名，签名安全的核心在密钥。 如何加强JWT的安全性 使用安全系数高的加密算法。 使用成熟的开源库，没必要造轮子。 JWT 存放在 localStorage 中而不是 Cookie 中，避免 CSRF 风险。 一定不要将隐私信息存放在 Payload 当中。 密钥一定保管好，一定不要泄露出去。JWT 安全的核心在于签名，签名安全的核心在密钥。 Payload 要加入 exp （JWT 的过期时间），永久有效的 JWT 不合理。并且，JWT 的过期时间不易过长。 ……","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端知识","slug":"后端知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/"}],"author":"菠萝"},{"title":"DDD","slug":"DDD","date":"2024-03-18T09:39:39.138Z","updated":"2024-03-18T09:39:39.138Z","comments":true,"path":"2024/03/18/DDD/","permalink":"https://kiritoabc.github.io/2024/03/18/DDD/","excerpt":"该思想源于2003年 Eric Evans编写的“Domain-Driven Design领域驱动设计”简称DDD，Evans DDD是一套综合软件系统分析和设计的面向对象建模方法。","text":"该思想源于2003年 Eric Evans编写的“Domain-Driven Design领域驱动设计”简称DDD，Evans DDD是一套综合软件系统分析和设计的面向对象建模方法。 服务器后端发展三个阶段 服务器后端发展三个阶段： 面向过程脚本：初始简单，业务复杂后，维护难度指数上升。–&gt;基本不为主流使用 面向数据库表：初始难度中，业务复杂后，维护难度延迟后再指数上升。—&gt;目前市面上主流 面向业务模型：DDD+SOA微服务的事件驱动的CQRS读写分离架构：应付复杂业务逻辑，以聚合模型替代数据表模型，以并发的事件驱动替代串联的消息驱动。真正实现以业务实体为核心的灵活拓展。初始难度高，业务复杂后，维护难度**线性上升(已很不错)**。 DDD的特点DDD革命性在于：领域模型准确反映了业务语言，而传统微服务数据对象除了简单setter/getter方法外，没有任何业务方法，即失血模型，那么DDD领域模型就是充血模型（业务方法定义在实体对象中）。 落地邻域模型设计以渠道中心（一个微服务）作为例子来做领域模型设计，核心就是设计2个图，一个是战略设计图（宏观） ，一个是战术设计图（细节）。 1.领域战略设计图战略设计图是从一个限界上下文的角度出发去分析业务场景。主要是宏观上的核心域、子域、实体关系图。demo如下图： 2.领域战术设计图战术设计图是从一个限界上下文的角度出发去分析业务场景。细化到核心业务字段、领域实体、值对象、领域服务、领域事件等等。基本上这个图画完，代码已经知道怎么写了。demo如下图： 技术实现整体项目框架分层图如下所示： 如上图，4层典型DDD分层结构， 1.展现层：controller层。无业务逻辑 2.应用服务层：此层可以包含查询逻辑，但核心业务逻辑必须下沉到领域层。 3.领域服务层：业务在这里组装。仓储（资源库）接口在此层定义。 4.基础设施层：仓储（资源库）实现层+PO持久化层。 注： 1.简单查询不涉及业务，是可以直接从应用层直接穿透到PO查询，不需要经过domain层。如下图所示，DDD本身是不限制非业务类操作跨层调用的。 2.DTO是不能存在于domain层的，DDD设计不认为DTO是业务对象，entity才是。或者传值简单数据类型也是可以的。 服务调用问题1.域内调用 领域内调用，随便调用，丝般顺滑。至于实现，可以由一个核心域的仓储实现层（第四层）去实现多个Repository接口。（比如这里A是核心域的实体名，B是支撑域、通用域等） 2.跨域调用 跨域分为 1.同上下文跨域：ACL层-&gt;Adapter适配器层→调用其它域的repository。—&gt;不得已才使用，不推荐使用。 推荐：1.使用领域事件 eventbus来做解耦 ​ 2.考虑是否有可能合并为一个领域. 2.跨上下文（肯定跨域）：ACL层-&gt;Adapter适配器层-&gt;feign调用 包结构包结构如下： 展开包结构如下： 展现层：Controller，仅做接口的入口定义和编排转发，不做任何的业务处理； 应用服务层：application，负责接口参数DTO的简单校验，以及DTO和实体值对象的数据转换，对于简单的业务，也可以在应用层加载实体直接执行实体行为方法； 领域层： 模型：根据领域模型分析领域内各实体、聚合、聚合根、值对象等，这些对象在*.domain.model定义，实体内的行为方法只负责维护实体自身的生命周期和状态； 行为：领域内各实体、聚合、聚合根等，会有相应的行为，在*.domain.model包下定义行为方法； 领域服务：领域提供的接口服务，需要定义在*.domain.service包下，业务相关的前置业务判断、多个实体或值对象的行为逻辑处理等，都在领域服务中实现，需要注意的是并不是每个实体都有一个对应的领域服务，但是依赖多个实体的行为方法，最好根据这个业务模块是建立一个领域服务； 仓储：领域服务或上层应用服务需要使用到的基础设施层，包括DB、Feign调用等，定义在*.domain.repository下，在*.infrastructure.repository下实现； 适配层：在acl包下的feign定义依赖外部的接口，并在acl的adapter包编写转换，由仓储层操作实体时调用； 持久层：与常用DAO定义一致，由仓储层操作实体时调用。 目前业内没有标杆，github开源地址：https://github.com/jovezhao/nest 。这个项目可以练手DDD。 http://192.168.0.116:9001/test/1112023-09-26 14-08-23.mkv 使用flutter写一个视频播放组件，要求有倍速，全屏，音量调节，暂停播放按钮 import 'package:flutter/material.dart'; import 'package:video_player/video_player.dart'; class VideoPlayerWidget extends StatefulWidget { final String videoUrl; VideoPlayerWidget({required this.videoUrl}); @override _VideoPlayerWidgetState createState() => _VideoPlayerWidgetState(); } class _VideoPlayerWidgetState extends State&lt;VideoPlayerWidget> { late VideoPlayerController _controller; @override void initState() { super.initState(); _controller = VideoPlayerController.network(videoUrl) ..initialize().then((_) { setState(() {}); }); } @override void dispose() { _controller.dispose(); super.dispose(); } @override Widget build(BuildContext context) { return AspectRatio( aspectRatio: _controller.value.aspectRatio, child: VideoPlayer(_controller), ); } } import 'package:flutter/material.dart'; import 'video_player_widget.dart'; void main() { runApp(MyApp()); } class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( home: Scaffold( appBar: AppBar(title: Text('Video Player')), body: Center(child: VideoPlayerWidget(videoUrl: 'https://example.com/video.mp4')), ), ); } } 使用flutter写一个要求有倍速，全屏，音量调节，暂停播放按钮的视频播放组件， import 'package:flutter/material.dart'; import 'package:video_player/video_player.dart'; class VideoPlayerWidget extends StatefulWidget { final String videoUrl; VideoPlayerWidget({required this.videoUrl}); @override _VideoPlayerWidgetState createState() => _VideoPlayerWidgetState(); } class _VideoPlayerWidgetState extends State&lt;VideoPlayerWidget> { late VideoPlayerController _controller; double _volume = 1.0; bool _isPlaying = false; @override void initState() { super.initState(); _controller = VideoPlayerController.network(widget.videoUrl); _controller.initialize().then((_) { setState(() {}); }); } @override void dispose() { _controller.dispose(); super.dispose(); } void _togglePlayPause() { if (_controller.value.isPlaying) { _controller.pause(); } else { _controller.play(); } setState(() { _isPlaying = !_isPlaying; }); } void _setVolume(double value) { _controller.setVolume(value); setState(() { _volume = value; }); } @override Widget build(BuildContext context) { return Stack( children: [ AspectRatio( aspectRatio: _controller.value.aspectRatio, child: VideoPlayer(_controller), ), Positioned.bottomRight( child: IconButton( icon: Icon(_isPlaying ? Icons.pause : Icons.play_arrow), onPressed: _togglePlayPause, ), ), Positioned.bottomLeft( child: Slider( min: 0, max: 1, value: _volume, onChanged: _setVolume, ), ), ], ); } } import 'dart:io'; import 'package:chewie/chewie.dart'; import 'package:chewie_example/app/theme.dart'; import 'package:flutter/material.dart'; // ignore: depend_on_referenced_packages import 'package:video_player/video_player.dart'; class ChewieDemo extends StatefulWidget { const ChewieDemo({ Key? key, this.title = 'Chewie Demo', }) : super(key: key); final String title; @override State&lt;StatefulWidget> createState() { return _ChewieDemoState(); } } class _ChewieDemoState extends State&lt;ChewieDemo> { TargetPlatform? _platform; late VideoPlayerController _videoPlayerController1; late VideoPlayerController _videoPlayerController2; ChewieController? _chewieController; int? bufferDelay; @override void initState() { super.initState(); initializePlayer(); } @override void dispose() { _videoPlayerController1.dispose(); _videoPlayerController2.dispose(); _chewieController?.dispose(); super.dispose(); } List&lt;String> srcs = [ \"https://assets.mixkit.co/videos/preview/mixkit-spinning-around-the-earth-29351-large.mp4\", \"https://assets.mixkit.co/videos/preview/mixkit-daytime-city-traffic-aerial-view-56-large.mp4\", \"https://assets.mixkit.co/videos/preview/mixkit-a-girl-blowing-a-bubble-gum-at-an-amusement-park-1226-large.mp4\" ]; Future&lt;void> initializePlayer() async { _videoPlayerController1 = VideoPlayerController.networkUrl(Uri.parse(srcs[currPlayIndex])); _videoPlayerController2 = VideoPlayerController.networkUrl(Uri.parse(srcs[currPlayIndex])); await Future.wait([ _videoPlayerController1.initialize(), _videoPlayerController2.initialize() ]); _createChewieController(); setState(() {}); } void _createChewieController() { // final subtitles = [ // Subtitle( // index: 0, // start: Duration.zero, // end: const Duration(seconds: 10), // text: 'Hello from subtitles', // ), // Subtitle( // index: 0, // start: const Duration(seconds: 10), // end: const Duration(seconds: 20), // text: 'Whats up? :)', // ), // ]; final subtitles = [ Subtitle( index: 0, start: Duration.zero, end: const Duration(seconds: 10), text: const TextSpan( children: [ TextSpan( text: 'Hello', style: TextStyle(color: Colors.red, fontSize: 22), ), TextSpan( text: ' from ', style: TextStyle(color: Colors.green, fontSize: 20), ), TextSpan( text: 'subtitles', style: TextStyle(color: Colors.blue, fontSize: 18), ) ], ), ), Subtitle( index: 0, start: const Duration(seconds: 10), end: const Duration(seconds: 20), text: 'Whats up? :)', // text: const TextSpan( // text: 'Whats up? :)', // style: TextStyle(color: Colors.amber, fontSize: 22, fontStyle: FontStyle.italic), // ), ), ]; _chewieController = ChewieController( videoPlayerController: _videoPlayerController1, autoPlay: true, looping: true, progressIndicatorDelay: bufferDelay != null ? Duration(milliseconds: bufferDelay!) : null, additionalOptions: (context) { return &lt;OptionItem>[ OptionItem( onTap: toggleVideo, iconData: Icons.live_tv_sharp, title: 'Toggle Video Src', ), ]; }, subtitle: Subtitles(subtitles), subtitleBuilder: (context, dynamic subtitle) => Container( padding: const EdgeInsets.all(10.0), child: subtitle is InlineSpan ? RichText( text: subtitle, ) : Text( subtitle.toString(), style: const TextStyle(color: Colors.black), ), ), hideControlsTimer: const Duration(seconds: 1), // Try playing around with some of these other options: // showControls: false, // materialProgressColors: ChewieProgressColors( // playedColor: Colors.red, // handleColor: Colors.blue, // backgroundColor: Colors.grey, // bufferedColor: Colors.lightGreen, // ), // placeholder: Container( // color: Colors.grey, // ), // autoInitialize: true, ); } int currPlayIndex = 0; Future&lt;void> toggleVideo() async { await _videoPlayerController1.pause(); currPlayIndex += 1; if (currPlayIndex >= srcs.length) { currPlayIndex = 0; } await initializePlayer(); } @override Widget build(BuildContext context) { return MaterialApp( title: widget.title, theme: AppTheme.light.copyWith( platform: _platform ?? Theme.of(context).platform, ), home: Scaffold( appBar: AppBar( title: Text(widget.title), ), body: Column( children: &lt;Widget>[ Expanded( child: Center( child: _chewieController != null &amp;&amp; _chewieController! .videoPlayerController.value.isInitialized ? Chewie( controller: _chewieController!, ) : const Column( mainAxisAlignment: MainAxisAlignment.center, children: [ CircularProgressIndicator(), SizedBox(height: 20), Text('Loading'), ], ), ), ), TextButton( onPressed: () { _chewieController?.enterFullScreen(); }, child: const Text('Fullscreen'), ), Row( children: &lt;Widget>[ Expanded( child: TextButton( onPressed: () { setState(() { _videoPlayerController1.pause(); _videoPlayerController1.seekTo(Duration.zero); _createChewieController(); }); }, child: const Padding( padding: EdgeInsets.symmetric(vertical: 16.0), child: Text(\"Landscape Video\"), ), ), ), Expanded( child: TextButton( onPressed: () { setState(() { _videoPlayerController2.pause(); _videoPlayerController2.seekTo(Duration.zero); _chewieController = _chewieController!.copyWith( videoPlayerController: _videoPlayerController2, autoPlay: true, looping: true, /* subtitle: Subtitles([ Subtitle( index: 0, start: Duration.zero, end: const Duration(seconds: 10), text: 'Hello from subtitles', ), Subtitle( index: 0, start: const Duration(seconds: 10), end: const Duration(seconds: 20), text: 'Whats up? :)', ), ]), subtitleBuilder: (context, subtitle) => Container( padding: const EdgeInsets.all(10.0), child: Text( subtitle, style: const TextStyle(color: Colors.white), ), ), */ ); }); }, child: const Padding( padding: EdgeInsets.symmetric(vertical: 16.0), child: Text(\"Portrait Video\"), ), ), ) ], ), Row( children: &lt;Widget>[ Expanded( child: TextButton( onPressed: () { setState(() { _platform = TargetPlatform.android; }); }, child: const Padding( padding: EdgeInsets.symmetric(vertical: 16.0), child: Text(\"Android controls\"), ), ), ), Expanded( child: TextButton( onPressed: () { setState(() { _platform = TargetPlatform.iOS; }); }, child: const Padding( padding: EdgeInsets.symmetric(vertical: 16.0), child: Text(\"iOS controls\"), ), ), ) ], ), Row( children: &lt;Widget>[ Expanded( child: TextButton( onPressed: () { setState(() { _platform = TargetPlatform.windows; }); }, child: const Padding( padding: EdgeInsets.symmetric(vertical: 16.0), child: Text(\"Desktop controls\"), ), ), ), ], ), if (Platform.isAndroid) ListTile( title: const Text(\"Delay\"), subtitle: DelaySlider( delay: _chewieController?.progressIndicatorDelay?.inMilliseconds, onSave: (delay) async { if (delay != null) { bufferDelay = delay == 0 ? null : delay; await initializePlayer(); } }, ), ) ], ), ), ); } } class DelaySlider extends StatefulWidget { const DelaySlider({Key? key, required this.delay, required this.onSave}) : super(key: key); final int? delay; final void Function(int?) onSave; @override State&lt;DelaySlider> createState() => _DelaySliderState(); } class _DelaySliderState extends State&lt;DelaySlider> { int? delay; bool saved = false; @override void initState() { super.initState(); delay = widget.delay; } @override Widget build(BuildContext context) { const int max = 1000; return ListTile( title: Text( \"Progress indicator delay ${delay != null ? \"${delay.toString()} MS\" : \"\"}\", ), subtitle: Slider( value: delay != null ? (delay! / max) : 0, onChanged: (value) async { delay = (value * max).toInt(); setState(() { saved = false; }); }, ), trailing: IconButton( icon: const Icon(Icons.save), onPressed: saved ? null : () { widget.onSave(delay); setState(() { saved = true; }); }, ), ); } }","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端开发小技巧","slug":"后端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"分布式必备理论基础CAP和BASE","slug":"CAP","date":"2024-03-18T09:39:39.130Z","updated":"2024-03-18T09:39:39.130Z","comments":true,"path":"2024/03/18/CAP/","permalink":"https://kiritoabc.github.io/2024/03/18/CAP/","excerpt":"在理论计算机科学中，CAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点：[1][2] 一致性（Consistency） （等同于所有节点访问同一份最新的数据副本） 可用性（Availability）（每次请求都能获取到非错的响应———但是不保证获取的数据为最新数据） 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[3]。） 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项[4]。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。","text":"在理论计算机科学中，CAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点：[1][2] 一致性（Consistency） （等同于所有节点访问同一份最新的数据副本） 可用性（Availability）（每次请求都能获取到非错的响应———但是不保证获取的数据为最新数据） 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[3]。） 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项[4]。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。 CAP理论理解 CAP 理论的 C!= 事务ACID特性中的C 我们可以把CAP理论中的C理解为副本一致性。即所有副本给出的结果都一致。 在没有网络分区和网络波动的情况下，我们无需为了P而舍弃C或A；而出现网络波动时，为了保证P,就要舍弃C和A中的一个。 辩证看待CAP理论 用CAP视角看目前成熟的分布式方案 CAP理论什么是CAPCAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。 一致性 ：数据在多个副本之间能够保持一致的特性。 可用性：系统提供的服务一直处于可用的状态，每次请求都能获得正确的响应。 分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 什么是分区在分布式系统中，不同的节点分布在不同的子网络中，由于一些特殊的原因，这些子节点之间出现了网络不通的状态，但他们的内部子网络是正常的。从而导致了整个系统的环境被切分成了若干个孤立的区域，这就是分区。 为什么三者不可兼容首先，我们得知道，分布式系统，是避免不了分区的，分区容错性是一定要满足的，我们看看在满足分区容错的基础上，能不能同时满足一致性和可用性？ 假如现在有两个分区N1和N2，N1和N2分别有不同的分区存储D1和D2，以及不同的服务S1和S2。 在满足一致性 的时候，N1和N2的数据要求值一样的，D1=D2。 在满足可用性的时候，无论访问N1还是N2，都能获取及时的响应。 好的，现在有这样的场景： 用户访问了N1，修改了D1的数据。 用户再次访问，请求落在了N2。此时D1和D2的数据不一致。 接下来： 保证一致性：此时D1和D2数据不一致，要保证一致性就不能返回不一致的数据，可用性无法保证。 保证可用性：立即响应，可用性得到了保证，但是此时响应的数据和D1不一致，一致性无法保证。 所以，可以看出，分区容错的前提下，一致性和可用性是矛盾的。 关于分布式一致性算法— Raft VS Paxos (待学习)Paxos算法 Paxos算法，该算法是通过将共识直接应用于构建分布式系统的状态机方法而获得的，这种方法应该是众所周知的，因为它可能是分布式系统理论中最常被引用的文章的主题 PAXOS 《分布式系列文章——Paxos算法原理与推导》 《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》 《【分布式】Zookeeper与Paxos》 ​ Paxos算法分为两个阶段。具体如下： 阶段一： (a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 (b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 阶段二： (a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对**[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定**。 (b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 通过选取主Proposer，就可以保证Paxos算法的活性。至此，我们得到一个既能保证安全性，又能保证活性的分布式一致性算法——Paxos算法。 Raft 虽然 Raft 的论文比 Paxos 简单版论文还容易读了，但论文依然发散的比较多，相对冗长。读完后掩卷沉思觉得还是整理一下才会更牢靠，变成真正属于自己的。这里我就借助前面黑白棋落子里第一种极简思维来描述和概念验证下 Raft 协议的工作方式。 Raft 为什么是更易理解的分布式一致性算法 - mindwind - 博客园 (cnblogs.com) 在一个由 Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人） 就像一个民主社会，领袖由民众投票选出。刚开始没有领袖，所有集群中的参与者都是群众，那么首先开启一轮大选，在大选期间所有群众都能参与竞选，这时所有群众的角色就变成了候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除领袖的候选人又变回群众角色服从领袖领导。这里提到一个概念「任期」，用术语 Term 表达。关于 Raft 协议的核心概念和术语就这么多而且和现实民主制度非常匹配，所以很容易理解。三类角色的变迁图如下，结合后面的选举过程来看很容易理解。","categories":[{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"后端开发小技巧","slug":"后端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"Axios","slug":"Axios","date":"2024-03-18T09:39:39.130Z","updated":"2024-03-18T09:39:39.130Z","comments":true,"path":"2024/03/18/Axios/","permalink":"https://kiritoabc.github.io/2024/03/18/Axios/","excerpt":"Axios学习 Axios项目中对于axios的简单二次封装","text":"Axios学习 Axios项目中对于axios的简单二次封装 使用yarn添加axios yarn add axios 封装,创建一个request.js文件 import axios from \"axios\"; const instance = axios.create({ baseURL: 'http://localhost:8080', timeout: 2000 }); // todo: 拦截器暂时不需要 /** * 基于axios 二次封装的get 请求 * @param url * @param params * @returns {Promise&lt;unknown>} */ const get = function (url, params) { return new Promise((resolve, reject) => { instance .get(url, params) .then(res => { resolve(res) }) .catch(err => { reject(err) }) }) }; /** * 基于axios 二次封装的 post 请求 * @param url * @param data * @returns {Promise&lt;unknown>} */ const post = function (url, data) { return new Promise((resolve, reject) => { instance .post(url, data) .then(res => { resolve(res) }) .catch(err => { reject(err) }) }) }; export default {get, post} 封装完成后可以在 api 文件夹下创建属于自己的 api 用于发送请求，便于管理。 例如 import request from '../../utils/request'; export function helloApi(){ return request.get(\"/hello\",{}) }","categories":[{"name":"前端","slug":"前端","permalink":"https://kiritoabc.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端开发小技巧","slug":"前端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"author":"菠萝"},{"title":"redsync","slug":"redsync","date":"2024-03-11T00:04:41.000Z","updated":"2024-03-18T09:39:39.166Z","comments":true,"path":"2024/03/11/redsync/","permalink":"https://kiritoabc.github.io/2024/03/11/redsync/","excerpt":"","text":"了解什么是redsync 分析参考：https://zhuanlan.zhihu.com/p/631362580 Github仓库：https://github.com/go-redsync/redsync","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/tags/go/"}]},{"title":"analytics","slug":"analytics","date":"2024-02-18T22:00:02.000Z","updated":"2024-03-18T09:39:39.154Z","comments":true,"path":"2024/02/18/analytics/","permalink":"https://kiritoabc.github.io/2024/02/18/analytics/","excerpt":"","text":"","categories":[],"tags":[]}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kiritoabc.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/categories/%E6%B5%8B%E8%AF%95/"},{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"生活","slug":"生活","permalink":"https://kiritoabc.github.io/categories/%E7%94%9F%E6%B4%BB/"},{"name":"sql","slug":"sql","permalink":"https://kiritoabc.github.io/categories/sql/"},{"name":"学习","slug":"学习","permalink":"https://kiritoabc.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"前端","slug":"前端","permalink":"https://kiritoabc.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/categories/go/"},{"name":"中间件","slug":"中间件","permalink":"https://kiritoabc.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"why? what? how?","slug":"why-what-how","permalink":"https://kiritoabc.github.io/categories/why-what-how/"},{"name":"UML","slug":"UML","permalink":"https://kiritoabc.github.io/categories/UML/"},{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/categories/redis/"},{"name":"安卓开发","slug":"安卓开发","permalink":"https://kiritoabc.github.io/categories/%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/"},{"name":"日常","slug":"日常","permalink":"https://kiritoabc.github.io/categories/%E6%97%A5%E5%B8%B8/"},{"name":"大数据","slug":"大数据","permalink":"https://kiritoabc.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"后端开发","slug":"后端开发","permalink":"https://kiritoabc.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://kiritoabc.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"测试","slug":"测试","permalink":"https://kiritoabc.github.io/tags/%E6%B5%8B%E8%AF%95/"},{"name":"后端知识","slug":"后端知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/"},{"name":"生活","slug":"生活","permalink":"https://kiritoabc.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"sql","slug":"sql","permalink":"https://kiritoabc.github.io/tags/sql/"},{"name":"学习记录","slug":"学习记录","permalink":"https://kiritoabc.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"name":"测试小技巧","slug":"测试小技巧","permalink":"https://kiritoabc.github.io/tags/%E6%B5%8B%E8%AF%95%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"后端开发小技巧","slug":"后端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"前端开发小技巧","slug":"前端开发小技巧","permalink":"https://kiritoabc.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"go","slug":"go","permalink":"https://kiritoabc.github.io/tags/go/"},{"name":"中间件","slug":"中间件","permalink":"https://kiritoabc.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"1","slug":"1","permalink":"https://kiritoabc.github.io/tags/1/"},{"name":"后端go","slug":"后端go","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AFgo/"},{"name":"后端Go","slug":"后端Go","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AFGo/"},{"name":"后端","slug":"后端","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"UML","slug":"UML","permalink":"https://kiritoabc.github.io/tags/UML/"},{"name":"前端知识","slug":"前端知识","permalink":"https://kiritoabc.github.io/tags/%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86/"},{"name":"redis","slug":"redis","permalink":"https://kiritoabc.github.io/tags/redis/"},{"name":"后端开发知识","slug":"后端开发知识","permalink":"https://kiritoabc.github.io/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86/"},{"name":"安卓开发","slug":"安卓开发","permalink":"https://kiritoabc.github.io/tags/%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/"},{"name":"日常","slug":"日常","permalink":"https://kiritoabc.github.io/tags/%E6%97%A5%E5%B8%B8/"},{"name":"大数据知识","slug":"大数据知识","permalink":"https://kiritoabc.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9F%A5%E8%AF%86/"}]}